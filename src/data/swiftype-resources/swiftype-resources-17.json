{
  "/docs/style-guide/quick-reference/tables": [
    {
      "sections": [
        "Bold or code, not italics"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-10-07T20:55:42Z",
      "updated_at": "2021-09-27T15:17:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.31116,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-10-08T04:44:25Z",
      "updated_at": "2021-09-14T14:45:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.80893,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-10-07T11:01:50Z",
      "updated_at": "2021-09-14T05:45:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.03024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " Markdown-<em>style</em> indented code formatting, as this can cause unexpected formatting problems. Highlight user input with &lt;var&gt; Use the &lt;var&gt; tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use &lt;var&gt; tags, see &lt; var&gt; formatting guidelines"
      },
      "id": "6042212b28ccbc7c9eeba772"
    }
  ],
  "/docs/style-guide/quick-reference/titles": [
    {
      "sections": [
        "Infrastructure agent overhead",
        "Linux single-task host",
        "Linux Docker host",
        "Windows host",
        "Linux ARM64 host",
        "Manage data"
      ],
      "title": "Infrastructure agent overhead",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Install the infrastructure agent",
        "Manage your agent"
      ],
      "external_id": "cd4b0d49bf6d11a12ff3a8357b223786b4c3f881",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/manage-your-agent/infrastructure-agent-performance-overhead/",
      "published_at": "2021-10-07T16:47:00Z",
      "updated_at": "2021-10-07T16:47:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The infrastructure agent is a lightweight piece of software, designed to minimize its impact on the performance of your hosts. However, the exact load varies depending on your host's workload, particularly on the number of processes running on the host. This is because the agent collects detailed data from each individual process. As a general guideline, New Relic has collected benchmarks for some common types of hosts: Linux single-task host The agent has very low performance overhead on a classic, single-task host. For example, a server running Apache, Unicorn, or a single Java application. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Operating system: CentOS 7 For this type of classic, single-task host, typical usage is: CPU: about 0.3% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or short-lived. Our benchmarks for this type of host are based on an Amazon EC2 t3.2xlarge: vCPUs: 8 vCPUs Memory: 32.0 GB Storage: 160.0 GB Number of containers: 25 containers, about 100 long-lived processes running in containers Operating system: CentOS 7 For this type of Docker host, typical usage is: CPU: about 0.8% Virtual memory: about 1 GB Resident memory: 25 to 35 MB Storage on disk: about 50 MB Windows host The agent has very low performance overhead on a typical Windows host serving web apps and running the Windows/IIS stack. Our benchmarks for this type of host are based on an Amazon EC2 t2.small: vCPUs: 1 Memory: 2.0 GB Storage: 30.0 GB Operating system: Windows Server 2012 R2 For this type of Windows host, typical usage is: CPU: 2 to 3% Resident Memory: 30 MB Storage on disk: about 50 MB Linux ARM64 host The agent has similar performance overhead on an ARM64 (Graviton 2) host on EC2 when compared with AMD64 machines. The benchmark is based on Amazon EC2 t3.2xlarge vs. t4g.2xlarge instances. Amazon Linux 2 EC2 instance with infrastructure agent default settings: CPU: about 0.1% on ARM vs 0.13% AMD Virtual memory: about 0.75GB ARM vs 1 GB AMD Resident memory: 20MB ARM vs 22 MB AMD We are always improving the performance of the infrastructure agent. If you see unusually high agent performance overhead, get support at support.newrelic.com. Manage data For how to adjust how much data our infrastructure monitoring ingests and reports, see Manage infrastructure data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.48654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " on disk: about 50 MB Linux Docker host The agent has very low performance overhead on a host running Docker, with exact usage depending on the number of Docker containers your machine hosts, and whether those processes are long- or <em>short</em>-lived. Our benchmarks for this type of host are based on an Amazon"
      },
      "id": "6043fa3464441f329a378f18"
    },
    {
      "sections": [
        "Rename or redirect a document",
        "Caution",
        "URL format",
        "Change titles",
        "Change anchor links",
        "Edit redirects"
      ],
      "title": "Rename or redirect a document",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "f117225cac5b0cf73daa56bd32807c4a58c4a31e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/rename-or-redirect-document/",
      "published_at": "2021-10-07T17:45:03Z",
      "updated_at": "2021-09-01T19:30:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document describes how to change the title of a document and how to create, edit, and delete redirects. Procedures are the same for both standard docs (\"basic pages\") and release notes. Caution Changing titles or updating redirects can create issues with finding content. If you need to change a title or a redirect, create a GitHub issue or, if you're a New Relic employee, contact the Docs hero via the #documentation Slack channel. URL format A document's URL is based solely on its filename and filepath in the GitHub repo. For more information, see Doc URL. Change titles To change a document title, change the title being used in the title field in the frontmatter at the top of the doc. If you want to update a title in the sidebar, change the title for that doc in the nav file. Change anchor links Wherever possible, do not change the [#anchor_ids] of an H2 or collapser. There is no way to redirect from a deleted anchor to its new value. Even if the anchor id is outdated, this does not affect the majority of users who pay no attention to URLs. Edit redirects If you change the URL of a doc, make sure you add the old URL to the redirects frontmatter section at the top of the doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 211.93811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rename or <em>redirect</em> a document",
        "sections": "Rename or <em>redirect</em> a document",
        "body": "This document describes how to change the title of a document and how to create, edit, and delete <em>redirects</em>. Procedures are the same for both standard docs (&quot;basic pages&quot;) and release notes. Caution Changing <em>titles</em> or updating <em>redirects</em> can create issues with finding content. If you need to change"
      },
      "id": "604220ec196a670d0ba83dd4"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/levels-headings/",
      "sections": [
        "Levels of headings",
        "Use parallel construction",
        "Keep it short, avoid -ing words",
        "Do not use h1 headings",
        "Use level two headings to identify chunks of information",
        "Important",
        "Avoid using level three headings"
      ],
      "published_at": "2021-10-07T02:06:32Z",
      "title": "Levels of headings",
      "updated_at": "2021-09-13T20:28:22Z",
      "type": "docs",
      "external_id": "981282f676b2697e24f69ad23bce7e3412bb1d22",
      "document_type": "page",
      "popularity": 1,
      "body": "Taking some time to consider your headings and document titles will be time well spent. Titles and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document titles, use sentence case. Use parallel construction Use parallel construction when naming headers. For example, use all nouns (\"Organization,\" \"Tone\"), all verbs (\"Create,\" \"Delete\"), etc. Keep it short, avoid -ing words For all headers, keep the title as short as possible. In particular, avoid headers that are more than a line long. As with all our writing, you should feel free to address the reader directly: Install the agent, for example, rather than Agent installation. You should also avoid -ing words, which add to character count without contributing clarity. Do not use h1 headings After you publish your doc, the docs site will automatically use what you added to the Title field as the doc's level one heading (h1). To ensure that your doc is properly indexed for search, do not manually create additional h1 headings. If your doc's title is long and you would like a shorter title to appear in the sidebar menu, create a GitHub issue and we'll help you with that change. Use level two headings to identify chunks of information Organize chunks of information into sections with level two headings (##). For example: ## Create a new user [#create-new-user] Copy Important If you don't specify an ID manually, the site will use your header text as that header's ID (also known as anchor link). Create a manual ID to preserve links to that header if you change the header text. If you have too many level sections, consider splitting the document into multiple pages. Avoid using level three headings Avoid using ### headings unless it makes sense for the content or if the content is lengthy. Collapsers, tables, and other structural elements are often a better choice. Be particularly careful about level three headings that make a level two section longer than a single screen height. Here are two examples of good scenarios for using level three headings: Example #1: Events-to-metrics API doc Example #2: Infrastructure integration doc",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 190.86986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Keep it <em>short</em>, avoid -ing words",
        "body": "Taking some time to consider your headings and document <em>titles</em> will be time well spent. <em>Titles</em> and headings are not only important for search results, but they can make your docs easier to skim. For all headings and document <em>titles</em>, use sentence case. Use parallel construction Use parallel"
      },
      "id": "604221d3196a677e3aa83db4"
    }
  ],
  "/docs/style-guide/quick-reference/ui-paths": [
    {
      "sections": [
        "Bold or code, not italics"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-10-07T20:55:42Z",
      "updated_at": "2021-09-27T15:17:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.3111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-10-08T04:44:25Z",
      "updated_at": "2021-09-14T14:45:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-10-07T11:01:50Z",
      "updated_at": "2021-09-14T05:45:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.0302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " Markdown-<em>style</em> indented code formatting, as this can cause unexpected formatting problems. Highlight user input with &lt;var&gt; Use the &lt;var&gt; tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use &lt;var&gt; tags, see &lt; var&gt; formatting guidelines"
      },
      "id": "6042212b28ccbc7c9eeba772"
    }
  ],
  "/docs/style-guide/quick-reference/usage-dictionary": [
    {
      "sections": [
        "Bold or code, not italics"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-10-07T20:55:42Z",
      "updated_at": "2021-09-27T15:17:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 332.3111,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        "Callouts",
        "Types of callouts",
        "Caution (callout-caution)",
        "Caution",
        "Important (callout-important)",
        "Important",
        "Tip (callout-tip)",
        "Tip",
        "User-related permissions",
        "Pricing (callout-pricing) Do not use.",
        "Custom callouts",
        "Beta feature",
        "Avoid callout fatigue",
        "Stacked callouts example"
      ],
      "title": "Callouts",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "4c8337fb61ea2576fe138fe4540929e67d501ce2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/callouts/",
      "published_at": "2021-10-08T04:44:25Z",
      "updated_at": "2021-09-14T14:45:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Callouts direct your attention to information of special importance or to information that doesn't fit smoothly into the main text. Consider your reader. If your doc has too many callouts, it might confuse your reader about what matters the most and distract them from what does. Use your callouts judiciously. Recommendation: Skim the complete doc. If there are too many callouts, decide which ones can be removed. Types of callouts Here's an example of the callout format: <Callout variant=\"tip\"> Your tip text goes here. It can have multiple paragraphs. </Callout> Copy On our docs site, we use these callout classes: Caution (callout-caution) Cautions scream at you that this could cause a crash or cost you data loss beyond the task at hand. Cautions use the callout-caution class. At a traffic light, a Caution would be red. Caution Avoid disabling auto-transaction naming, because metric grouping issues will likely occur. Instead, use API calls to name your transactions. Important (callout-important) Important notes urge awareness that this could impair the task at hand or cost you time if you ignore the text. Important notes use the callout-important class. At a traffic light, an Important note would be yellow. Important Custom events sent via the agent API are not compatible with high security mode. Tip (callout-tip) Tips whisper to you that this is nice to know, like a shortcut, best practice, or reminder, but is unnecessary to complete the task at hand. Tips use the callout-tip class. At a traffic light, a Tip would be a green light. Tip If you have integrated your New Relic account with a ticketing system such as Lighthouse, Pivotal Tracker, or Atlassian JIRA, you can use the note to file a ticket or story. User-related permissions For recommended wording, see User-related language and styles. Pricing (callout-pricing) Do not use. Pricing callouts let you know that you may need a specific subscription level in order to access the product or feature. Pricing callouts use the callout-pricing class. Typically, pricing callouts appear in the intro of a doc. See the example below for standard verbiage in the callout. With the new pricing model, these are rarely used. Tip Access to this feature depends on your subscription level. Custom callouts Custom callouts are available for special cases, such as beta docs. Here's what you can control with custom callouts: Title text: Change the callout label by inserting the title attribute like this: title=\"YOUR CUSTOM TITLE\". When you publish, this field is automatically converted to all capital letters. Color: The color is limited to the color of the variant you include, or if you don't include a variant, you get the default border color (blue-grey). Here is what the code looks like: <Callout variant=\"caution\" title=\"YOUR CUSTOM TITLE\"> Your callout message goes here! </Callout> Copy For beta docs, add a custom callout. Also, we recommend that you don't include a variant so you display the default color: Beta feature This feature is still in development, but we encourage you to try it out! Avoid callout fatigue Callout fatigue is what happens when there are too many callouts on a doc. A single callout is a great way to draw attention to important information, but the more callouts there are, the more likely it is that your reader won't read the callouts. Keep these things in mind when you're working with callouts: If you add a callout, remove a callout. Wherever possible, don't increase the number of callouts. Do not use stacked callouts. Stacked callouts are two or more callouts that follow directly one after another. Not only do not use these, but if you see this in a doc, take a few minutes to break these callouts up. Remove outdated callouts. As you're going through the docs site, if you see a callout that's outdated, for whatever reason, take a few minutes to delete it from the doc. Be stingy in your use of important and warning callouts. If we use important and warning callouts too often, they lose their effectiveness. Stacked callouts example Here's an example of the stacked callouts we'd love to avoid. Tip The more callouts there are, the more difficult it is to spot the information that's important. Important Not everything is important enough to put in a callout. Caution Think carefully before adding another callout on the page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.8089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>"
      },
      "id": "60421e82e7b9d23d022a07f2"
    },
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-10-07T11:01:50Z",
      "updated_at": "2021-09-14T05:45:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.0302,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Style</em> <em>guide</em> <em>quick</em> <em>reference</em>",
        "body": " Markdown-<em>style</em> indented code formatting, as this can cause unexpected formatting problems. Highlight user input with &lt;var&gt; Use the &lt;var&gt; tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use &lt;var&gt; tags, see &lt; var&gt; formatting guidelines"
      },
      "id": "6042212b28ccbc7c9eeba772"
    }
  ],
  "/docs/style-guide/writer-workflow/github-intro": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the GitHub web editor vs local build",
        "1. Set up your local environment",
        "2. Run the site locally",
        "Prerequisites",
        "Build the site",
        "3. Edit a doc",
        "4. Commit your changes",
        "5. Publish your commits",
        "6. Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging",
        "Writers only: Work on a branch, not a fork"
      ],
      "published_at": "2021-10-07T11:18:43Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-09-27T15:37:07Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the GitHub web editor vs local build Need to edit a doc? Use this table to decide where to work! Use the GitHub web editor for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. 1. Set up your local environment Running the site locally makes testing and previewing large changes much easier. Here's how to get setup: Install GitHub Desktop Sign in to GitHub Desktop. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Navigate to the Docs Site repository on GitHub.com. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. 2. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. For example: cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ 3. Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. 4. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] 5. Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. 6. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you're merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) To request a review from another Tech Writer: in GitHub open the PR, navigate to the Conversation section, and then select or type in a reviewer name in the Reviewer section. Add any relevant labels to your PR. If you do not add from_tw, the PR will not be automatically assigned to another writer for review. Once you're satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. At the bottom of the pull request page, you will see a Checks section. These checks ensure your PR doesn't break the build process of the site. Ensure all checks marked required pass before merging. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. If you don't add the from_tw label when you first create a PR, it will not automatically assign a reviewer. If you forget to add the label before opening the PR: Add the from_tw label. Turn the PR into a draft PR. Select the PR is ready for review button at the bottom of the page to reopen the PR. The PR should now have a reviewer. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Gatsby Cloud: Full preview of the live site with no overhead, and a very convenient way to share a preview of your draft with a SME. Gatsby Cloud will comment on your PR with a link to a preview version of the site once the build is ready. Building the site generally takes about 15 minutes, but can sometimes take longer if there are a lot of changes. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it. Writers only: Work on a branch, not a fork Some teams work on branches, some teams work on forks; the Docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.79913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Edit in the <em>GitHub</em> web editor vs local build",
        "body": " easier. Here&#x27;s how to <em>get</em> setup: Install <em>GitHub</em> Desktop Sign in to <em>GitHub</em> Desktop. On Macs, click on <em>GitHub</em> Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Navigate to the Docs Site repository"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "https://opensource.newrelic.com/static/New_Relic_One_Catalog_Project-cd2c8d0767ab48318831ff6d37ae2df6.png",
      "url": "https://opensource.newrelic.com/oss-category",
      "sections": [
        "Categories",
        "Community Project",
        "Requirements",
        "Community Plus",
        "New Relic One Catalog",
        "Example Code",
        "New Relic Experimental",
        "Archived"
      ],
      "published_at": "2021-10-10T01:41:03Z",
      "title": "New Relic Open Source Categories",
      "updated_at": "2021-09-30T01:38:55Z",
      "type": "opensource",
      "external_id": "b5abb19cb8d9e38477650d3d525a7e1b4083b945",
      "document_type": "page",
      "popularity": 1,
      "info": "",
      "body": "External Projects Highlighted Projects New Relic Projects Standards Menu External Projects Highlighted Projects New Relic Projects Standards Categories Community Project Community Plus New Relic One Catalog Example Code New Relic Experimental Archived For the code snippets that appear in the project's README file, see this documentation. Community Project This code is developed in the open with input from the community through issues and PRs. There is an active maintainer team within New Relic, troubleshooting support in the New Relic Explorers Hub, and the documentation is available in the project repository. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Has active maintainer / maintainers, including at least one Relic Troubleshooting support via the New Relic Explorers Hub Issues and PR’s managed in GitHub Documentation reviewed by the New Relic documentation team Linted code An automated release pipeline Community Plus This code is developed in the open with input from the community through issues and PRs. A New Relic engineering team serves as the maintainer. Troubleshooting support is available in the New Relic Explorers Hub, and documentation is available in the project repository and docs.newrelic.com. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Is maintained by a New Relic engineering team Troubleshooting support via the New Relic Explorers Hub Issues and PR’s managed in GitHub For additional details on support options, see the Open Source Support Policy Documentation reviewed by the New Relic documentation team Linted code An automated release pipeline New Relic One Catalog This code is a part of the New Relic One Catalog. It meets the criteria for a Community Project; but it also contains UI workflows for configuration. Most Catalog projects seek to maintain a public roadmap, often expressed in a GitHub Project board and Issues within the repository. Requirements All the requirements of a Community Project An empty state application workflow that guides users through the setup of configuration data that is stored in NerdStorage Architectural review (including UX) by New Relic (Optional) maintains a public roadmap (recommended via a GitHub project in the repo) Example Code This code demonstrates an aspect of building on the New Relic One platform. Find the complete description of its usage and other relevant docs in the README. There is no long-term maintainer for this code nor is support provided, but the author(s) may address future updates / needs as platform features change. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file (optional) Issues are available at the project author's discretion Documentation reviewed by the New Relic documentation team Linted code New Relic Experimental This code solves an interesting problem but does not yet have an active maintainer(s). The project is being developed in the open for the purpose of feedback on a new feature or function. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Typically hosted in the New Relic Experimental GitHub org (Optional) Issues at the project owner's discretion Archived This code is read-only. There is neither a maintainer team nor support. Requirements Complies with New Relic's legal requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Previous references to Support should be modified or removed from the README Project is read-only and available for cloning only",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 154.44563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " via the New Relic Explorers <em>Hub</em> Issues and PR’s managed in <em>GitHub</em> Documentation reviewed by the New Relic documentation team Linted code An automated release pipeline Community Plus This code is developed in the open with input from the community through issues and PRs. A New Relic engineering team"
      },
      "id": "5f31822228ccbc916988dff8"
    },
    {
      "sections": [
        "Kubernetes plugin for log forwarding",
        "Enable Kubernetes for log management",
        "View log data",
        "What's next?"
      ],
      "title": "Kubernetes plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "c55c6a084a1de057aac4f85ed3807c41317f63e1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/kubernetes-plugin-log-forwarding/",
      "published_at": "2021-10-08T04:16:21Z",
      "updated_at": "2021-10-08T04:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If your log data is already being monitored by Fluent Bit, you can use our Fluent Bit output plugin to forward and enrich your log data in New Relic.This plugin is also provided in a standalone Docker image that can be installed in a Kubernetes cluster in the form of a DaemonSet. We refer to this as our Kubernetes plugin. Forwarding your Kubernetes logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Enable Kubernetes for log management To forward your logs to New Relic with our Kubernetes plugin for Fluent Bit: Make sure you have: A New Relic license key Kubernetes cluster deployed Follow the procedures in GitHub to install the Kubernetes plugin. Optional: If you are installing the plugin as a Helm chart, you can set numerous configurations. However, we recommend the standard setup, as it is valid for most users. Generate some traffic and wait a few minutes, then check your account for data. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.13913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Make sure you have: A New Relic license key Kubernetes cluster deployed Follow the procedures in <em>GitHub</em> to install the Kubernetes plugin. Optional: If you are installing the plugin as a Helm chart, you can set numerous configurations. However, we recommend the standard setup, as it is valid for most"
      },
      "id": "603ec19128ccbcad24eba748"
    }
  ],
  "/docs/style-guide/writer-workflow/github-troubleshooting": [
    {
      "sections": [
        "Diagnostics CLI (nrdiag)",
        "Compatibility",
        "Get started"
      ],
      "title": "Diagnostics CLI (nrdiag)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Diagnostics CLI (nrdiag)"
      ],
      "external_id": "973501f4752e56caf3d68e37bf21b823d0e42078",
      "image": "",
      "url": "https://docs.newrelic.com/docs/using-new-relic/cross-product-functions/diagnostics-cli-nrdiag/diagnostics-cli-nrdiag/",
      "published_at": "2021-10-07T03:33:01Z",
      "updated_at": "2021-03-13T05:45:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Download latest version The Diagnostics CLI (nrdiag) is a utility that automatically detects common problems with New Relic products. If the Diagnostics CLI detects a problem, it suggests troubleshooting steps. The Diagnostics CLI can also automatically attach troubleshooting data to a New Relic Support ticket. The Diagnostics CLI is open source and is located in GitHub. For additional troubleshooting steps for your agent, check out Not seeing data. Here's an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates zipped troubleshooting logs that are ready to be attached to support tickets. Compatibility The Diagnostics CLI is available for Linux, macOS, and Windows. It can detect common configuration issues for: APM: Available for all APM agents except C SDK. For the Go agent, only basic connectivity checks are available. Browser monitoring: Browser agent detection Infrastructure monitoring: Linux and Windows agents Mobile agents: iOS and Android Synthetic monitoring: Containerized private minions (CPM) The Diagnostics CLI does not require superuser or admin permissions to run, although we recommend those permissions for some checks. It will return an error if it does not have permissions to read the files it scans. Get started To use the Diagnostics CLI: Run the Diagnostics CLI, including task suites and command line options as needed. Include an attachment key when you upload the results to your Support ticket. Optional: Validate your config file settings. Interpret the output. Like any other New Relic tool, the Diagnostics CLI service is designed to protect you and your customers' data privacy. For detailed information, see our Diagnostics CLI licensing and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 568.67883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Support ticket. The Diagnostics CLI is open source and is located in <em>GitHub</em>. For additional <em>troubleshooting</em> steps for your agent, check out Not seeing data. Here&#x27;s an example of the Diagnostics CLI running on Ubuntu Linux. The program checks your New Relic agent configurations for issues and generates"
      },
      "id": "604469f8e7b9d2abb65799f0"
    },
    {
      "image": "https://opensource.newrelic.com/static/New_Relic_One_Catalog_Project-cd2c8d0767ab48318831ff6d37ae2df6.png",
      "url": "https://opensource.newrelic.com/oss-category",
      "sections": [
        "Categories",
        "Community Project",
        "Requirements",
        "Community Plus",
        "New Relic One Catalog",
        "Example Code",
        "New Relic Experimental",
        "Archived"
      ],
      "published_at": "2021-10-10T01:41:03Z",
      "title": "New Relic Open Source Categories",
      "updated_at": "2021-09-30T01:38:55Z",
      "type": "opensource",
      "external_id": "b5abb19cb8d9e38477650d3d525a7e1b4083b945",
      "document_type": "page",
      "popularity": 1,
      "info": "",
      "body": "External Projects Highlighted Projects New Relic Projects Standards Menu External Projects Highlighted Projects New Relic Projects Standards Categories Community Project Community Plus New Relic One Catalog Example Code New Relic Experimental Archived For the code snippets that appear in the project's README file, see this documentation. Community Project This code is developed in the open with input from the community through issues and PRs. There is an active maintainer team within New Relic, troubleshooting support in the New Relic Explorers Hub, and the documentation is available in the project repository. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Has active maintainer / maintainers, including at least one Relic Troubleshooting support via the New Relic Explorers Hub Issues and PR’s managed in GitHub Documentation reviewed by the New Relic documentation team Linted code An automated release pipeline Community Plus This code is developed in the open with input from the community through issues and PRs. A New Relic engineering team serves as the maintainer. Troubleshooting support is available in the New Relic Explorers Hub, and documentation is available in the project repository and docs.newrelic.com. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Is maintained by a New Relic engineering team Troubleshooting support via the New Relic Explorers Hub Issues and PR’s managed in GitHub For additional details on support options, see the Open Source Support Policy Documentation reviewed by the New Relic documentation team Linted code An automated release pipeline New Relic One Catalog This code is a part of the New Relic One Catalog. It meets the criteria for a Community Project; but it also contains UI workflows for configuration. Most Catalog projects seek to maintain a public roadmap, often expressed in a GitHub Project board and Issues within the repository. Requirements All the requirements of a Community Project An empty state application workflow that guides users through the setup of configuration data that is stored in NerdStorage Architectural review (including UX) by New Relic (Optional) maintains a public roadmap (recommended via a GitHub project in the repo) Example Code This code demonstrates an aspect of building on the New Relic One platform. Find the complete description of its usage and other relevant docs in the README. There is no long-term maintainer for this code nor is support provided, but the author(s) may address future updates / needs as platform features change. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file (optional) Issues are available at the project author's discretion Documentation reviewed by the New Relic documentation team Linted code New Relic Experimental This code solves an interesting problem but does not yet have an active maintainer(s). The project is being developed in the open for the purpose of feedback on a new feature or function. Requirements Complies with New Relic's legal and security requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Typically hosted in the New Relic Experimental GitHub org (Optional) Issues at the project owner's discretion Archived This code is read-only. There is neither a maintainer team nor support. Requirements Complies with New Relic's legal requirements for open source software Contains the appropriate New Relic open source category header in the repository's README file Previous references to Support should be modified or removed from the README Project is read-only and available for cloning only",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.06146,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " Relic open source category header in the repository&#x27;s README file Is maintained by a New Relic engineering team <em>Troubleshooting</em> support via the New Relic Explorers <em>Hub</em> Issues and PR’s managed in <em>GitHub</em> For additional details on support options, see the Open Source Support Policy Documentation"
      },
      "id": "5f31822228ccbc916988dff8"
    },
    {
      "sections": [
        "Kubernetes plugin for log forwarding",
        "Enable Kubernetes for log management",
        "View log data",
        "What's next?"
      ],
      "title": "Kubernetes plugin for log forwarding",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "c55c6a084a1de057aac4f85ed3807c41317f63e1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/kubernetes-plugin-log-forwarding/",
      "published_at": "2021-10-08T04:16:21Z",
      "updated_at": "2021-10-08T04:16:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If your log data is already being monitored by Fluent Bit, you can use our Fluent Bit output plugin to forward and enrich your log data in New Relic.This plugin is also provided in a standalone Docker image that can be installed in a Kubernetes cluster in the form of a DaemonSet. We refer to this as our Kubernetes plugin. Forwarding your Kubernetes logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Enable Kubernetes for log management To forward your logs to New Relic with our Kubernetes plugin for Fluent Bit: Make sure you have: A New Relic license key Kubernetes cluster deployed Follow the procedures in GitHub to install the Kubernetes plugin. Optional: If you are installing the plugin as a Helm chart, you can set numerous configurations. However, we recommend the standard setup, as it is valid for most users. Generate some traffic and wait a few minutes, then check your account for data. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.03772,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ": Make sure you have: A New Relic license key Kubernetes cluster deployed Follow the procedures in <em>GitHub</em> to install the Kubernetes plugin. Optional: If you are installing the plugin as a Helm chart, you can set numerous configurations. However, we recommend the standard setup, as it is valid for most"
      },
      "id": "603ec19128ccbcad24eba748"
    }
  ],
  "/docs/style-guide/writer-workflow/peer-editor-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the GitHub web editor vs local build",
        "1. Set up your local environment",
        "2. Run the site locally",
        "Prerequisites",
        "Build the site",
        "3. Edit a doc",
        "4. Commit your changes",
        "5. Publish your commits",
        "6. Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging",
        "Writers only: Work on a branch, not a fork"
      ],
      "published_at": "2021-10-07T11:18:43Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-09-27T15:37:07Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the GitHub web editor vs local build Need to edit a doc? Use this table to decide where to work! Use the GitHub web editor for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. 1. Set up your local environment Running the site locally makes testing and previewing large changes much easier. Here's how to get setup: Install GitHub Desktop Sign in to GitHub Desktop. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Navigate to the Docs Site repository on GitHub.com. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. 2. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. For example: cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ 3. Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. 4. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] 5. Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. 6. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you're merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) To request a review from another Tech Writer: in GitHub open the PR, navigate to the Conversation section, and then select or type in a reviewer name in the Reviewer section. Add any relevant labels to your PR. If you do not add from_tw, the PR will not be automatically assigned to another writer for review. Once you're satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. At the bottom of the pull request page, you will see a Checks section. These checks ensure your PR doesn't break the build process of the site. Ensure all checks marked required pass before merging. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. If you don't add the from_tw label when you first create a PR, it will not automatically assign a reviewer. If you forget to add the label before opening the PR: Add the from_tw label. Turn the PR into a draft PR. Select the PR is ready for review button at the bottom of the page to reopen the PR. The PR should now have a reviewer. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Gatsby Cloud: Full preview of the live site with no overhead, and a very convenient way to share a preview of your draft with a SME. Gatsby Cloud will comment on your PR with a link to a preview version of the site once the build is ready. Building the site generally takes about 15 minutes, but can sometimes take longer if there are a lot of changes. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it. Writers only: Work on a branch, not a fork Some teams work on branches, some teams work on forks; the Docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 98.30965,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tech Writer <em>workflow</em>",
        "sections": "Tech Writer <em>workflow</em>",
        "body": "This document will guide you through the entire <em>workflow</em> for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text <em>editor</em>) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the GitHub web <em>editor</em> vs local build Need"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/create-edit-content/",
      "sections": [
        "Create and edit content",
        "Edit a doc",
        "Create new docs",
        "Clone (copy) an existing doc",
        "For bigger projects",
        "Delete pages",
        "Private edits",
        "Request a future publication date (for New Relic employees)"
      ],
      "published_at": "2021-10-07T11:06:44Z",
      "title": "Create and edit content",
      "updated_at": "2021-09-27T15:28:12Z",
      "type": "docs",
      "external_id": "96d8ee8adf5279fde74c26bf462be94d11dfa6fe",
      "document_type": "page",
      "popularity": 1,
      "body": "We welcome your contributions, whether you are a New Relic employee or a New Relic user! And we don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. That said, if you're curious about our style guidelines, you're welcome (but not obligated) to take a look. Edit a doc If you see a minor problem in our documentation that you want to quickly fix, you can use GitHub to edit the file and submit your pull request. A member of the Docs team will review your edit and publish your changes. We'll follow up with you if we have any questions. To edit existing content without building the site locally: On the docs site, navigate to the doc you'd like to edit. Click Edit page on the top corner of the right nav. A GitHub page will open with the source of the doc. Click the pencil icon in the top right. Make your edits (don't worry too much about formatting or grammar, we're happy to take care of that). At the bottom of the page, enter acommit message that describes your change, then click Commit changes. Follow the prompts to submit your pull request. A member of the Docs team will review your pull request and comment with any feedback. Once we've merged your pull request into the Develop branch, your changes will go live with our next deploy (usually within a few hours). Create new docs You can use article templates or clone an existing doc as a template. To create a new doc: Clone the repo on your computer. In /src/content/docs/, find a good location for your doc. Using your text editor, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer to handle when they review your pull request. Commit your changes and create a pull request. The Tech Docs team has two heroes watching for new pull requests. We'll help you get the content finalized and make sure that it's in the right place. Clone (copy) an existing doc Once you've cloned the docs-website repository, use your text editor to copy an existing doc. Rename and edit the copy and then save it as a new doc. Your cloned doc automatically inherits the original doc's frontmatter content. Make sure to change that, too. If you want your cloned doc to be translated, follow standard procedures to request translation. For bigger projects If you're making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go for it. If not, ask us by: File an issue in the docs-website repo, or contact the @hero in the #documentation channel if you're a New Relic employee. We'll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs hero in the #documentation Slack channel. Request a future publication date (for New Relic employees) If your draft needs to be released on a specific date or within a specific timeframe (for example, right before a release), contact the Tech Docs @hero in the #documentation Slack channel. If you're not a New Relic employee, please create a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.96147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". In &#x2F;src&#x2F;content&#x2F;docs&#x2F;, find a good location for your doc. Using your text <em>editor</em>, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer"
      },
      "id": "6042219c196a67b1ada83d81"
    },
    {
      "sections": [
        "Troubleshooting docs guide",
        "Problem",
        "Solution",
        "Cause",
        "Related info"
      ],
      "title": "Troubleshooting docs guide",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Article templates"
      ],
      "external_id": "ba7c99eb79d6fa7ad574db5768a742a4d2084a41",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/troubleshooting-docs-guide/",
      "published_at": "2021-10-07T16:13:52Z",
      "updated_at": "2021-05-10T03:34:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our troubleshooting docs have these main sections: problem, solution, and (optionally) cause. Otherwise, a troubleshooting doc uses the basic doc template Problem Generally, this is the who, what, when, and where of the troubleshooting doc. Provide a clear, concise description of the problem the user is trying to solve. Include steps for reproduction, symptoms, and other key points when applicable. Re-state the problem in different ways if needed, to ensure customers can find this doc via Google. If the problem text is very short, you can include the cause text here. Solution Generally, this is the how of the troubleshooting doc. Provide an ordered list of steps to guide users through the solution. If there are multiple causes and solutions, consider creating a standard, basic page doc rather than using the troubleshooting template. Consider the best approach to help the reader, and discuss your reasoning with your peer editor. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn't solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes the problem and cause. Do not include a solution. Also, include any statements promising that the issue will be fixed in a future release. Cause Generally, this is the why of the troubleshooting doc, and is optional. The Cause section is particularly useful when the product works in an unintuitive way. Provide background information or context that gives the user additional insight into the problem. If the problem and the cause text are both very short, you can include the cause in the Problem section. Related info In general, leave blank. The standard For more help footer block will appear automatically when published. If necessary, use this section to link to other, related docs if it does not make sense to refer to them within the context of other information in the troubleshooting doc itself.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 71.84371,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ", and discuss your reasoning with your <em>peer</em> <em>editor</em>. If the issue you are documenting is more of a known issue (FYI in nature), or if it doesn&#x27;t solve the issue: Incorporate the information into other relevant docs. Do not refer to it as a known issue. OR Create a troubleshooting doc that describes"
      },
      "id": "6043f591196a675446960f74"
    }
  ],
  "/docs/style-guide/writer-workflow/tech-writer-workflow": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/create-edit-content/",
      "sections": [
        "Create and edit content",
        "Edit a doc",
        "Create new docs",
        "Clone (copy) an existing doc",
        "For bigger projects",
        "Delete pages",
        "Private edits",
        "Request a future publication date (for New Relic employees)"
      ],
      "published_at": "2021-10-07T11:06:44Z",
      "title": "Create and edit content",
      "updated_at": "2021-09-27T15:28:12Z",
      "type": "docs",
      "external_id": "96d8ee8adf5279fde74c26bf462be94d11dfa6fe",
      "document_type": "page",
      "popularity": 1,
      "body": "We welcome your contributions, whether you are a New Relic employee or a New Relic user! And we don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. That said, if you're curious about our style guidelines, you're welcome (but not obligated) to take a look. Edit a doc If you see a minor problem in our documentation that you want to quickly fix, you can use GitHub to edit the file and submit your pull request. A member of the Docs team will review your edit and publish your changes. We'll follow up with you if we have any questions. To edit existing content without building the site locally: On the docs site, navigate to the doc you'd like to edit. Click Edit page on the top corner of the right nav. A GitHub page will open with the source of the doc. Click the pencil icon in the top right. Make your edits (don't worry too much about formatting or grammar, we're happy to take care of that). At the bottom of the page, enter acommit message that describes your change, then click Commit changes. Follow the prompts to submit your pull request. A member of the Docs team will review your pull request and comment with any feedback. Once we've merged your pull request into the Develop branch, your changes will go live with our next deploy (usually within a few hours). Create new docs You can use article templates or clone an existing doc as a template. To create a new doc: Clone the repo on your computer. In /src/content/docs/, find a good location for your doc. Using your text editor, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer to handle when they review your pull request. Commit your changes and create a pull request. The Tech Docs team has two heroes watching for new pull requests. We'll help you get the content finalized and make sure that it's in the right place. Clone (copy) an existing doc Once you've cloned the docs-website repository, use your text editor to copy an existing doc. Rename and edit the copy and then save it as a new doc. Your cloned doc automatically inherits the original doc's frontmatter content. Make sure to change that, too. If you want your cloned doc to be translated, follow standard procedures to request translation. For bigger projects If you're making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go for it. If not, ask us by: File an issue in the docs-website repo, or contact the @hero in the #documentation channel if you're a New Relic employee. We'll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs hero in the #documentation Slack channel. Request a future publication date (for New Relic employees) If your draft needs to be released on a specific date or within a specific timeframe (for example, right before a release), contact the Tech Docs @hero in the #documentation Slack channel. If you're not a New Relic employee, please create a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1138.9318,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " procedures to request translation. For bigger projects If you&#x27;re making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see <em>Tech</em> <em>writer</em> <em>workflow</em>. Delete pages If you are comfortable with deleting the page yourself, go"
      },
      "id": "6042219c196a67b1ada83d81"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/peer-editor-workflow/",
      "sections": [
        "Peer editor workflow",
        "Peer editing workflow in GitHub",
        "Developmental edit pass",
        "Copy edit workflow"
      ],
      "published_at": "2021-10-07T11:04:33Z",
      "title": "Peer editor workflow",
      "updated_at": "2021-06-14T00:56:46Z",
      "type": "docs",
      "external_id": "c5cade26eea3b846e8c6cc5f3b89552147d724be",
      "document_type": "page",
      "popularity": 1,
      "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the Tech Writer workflow doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing workflow in GitHub If you’re peer editing a doc or have been otherwise assigned to a PR as a reviewer, you have a few choices for how and where to do the work. The most streamlined and open-source approach is to do the edit using GitHub options, rather than copying the file to Google Docs and editing there. Developmental edit pass For cases where you have questions and suggestions rather than straight copy edits, follow these steps. Open the PR that you’re assigned to review. On the Files changed tab, you can either: Click Review changes and then select one of the following: Comment - use if you have a comment that doesn’t require follow up. Approve - use if you just want to approve the PR. You can request changes in the Leave a comment area, and select Approve if you want to let the writer make the edits and merge the file without a follow-up review from you. Request changes - use for times when you want to make sure the changes you request are included. You’ll be notified with any updates that the writer makes. OR, start making comments on lines or sections of the doc. To do this, click the add comment icon , and leave an edit or comment for that specific line in the page. With this option, you get the choice between adding a single comment or starting a review. If you’re going to make comments throughout a doc, choose Start a review so the comments will all be rolled into one commit. Click Finish your review to complete your review. This triggers a notification to the writer alerting them that you’ve made suggestions. Copy edit workflow If you have copy edits for a file rather than comments and suggestions, you can make the changes to the file in different ways. Here are two main options: Edit using the GitHub browser: On the Files changed tab, in the diff window click the editing button (three dots). When you finish your edits, add a comment at the bottom of the file and choose to either commit the changes directly, or create a branch and start a pull request. Choose to branch and start a pull request if you expect a writer to review the diff and accept or revise your edits. Edit locally: Check out the branch containing the file you want to edit. In GitHub Desktop, click the Current branch down arrow and select the branch. Then, make the edits on your local drive, save, and commit your changes to the branch. Note that this approach adds your edits to the open pull request. You can now see the changes you added to the file on the Files changed tab in the PR. These are just a few of many editing options. You’ll find your preferred way, just as with any other tool.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 825.27814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Peer editor <em>workflow</em>",
        "sections": "Peer editor <em>workflow</em>",
        "body": "Use this document to learn how to review and peer edit docs for you fellow writers in GitHub. Check the <em>Tech</em> <em>Writer</em> <em>workflow</em> doc for info on how to set up your local environment. To troubleshoot GitHub issues, see our guide. Peer editing <em>workflow</em> in GitHub If you’re peer editing a doc or have been"
      },
      "id": "60c6a94ee7b9d21cd1d6779f"
    },
    {
      "sections": [
        "Use content types and text formats",
        "Docs meta content (frontmatter)",
        "Document body",
        "Page templates"
      ],
      "title": "Use content types and text formats",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "22895e5a8b552b1cc2b278bf117f7269a539a61e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/use-content-types-text-formats/",
      "published_at": "2021-10-07T13:54:47Z",
      "updated_at": "2021-09-14T14:45:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our docs site is made up of different content types and templates. Most of the time, the default page content type and the basic template will have everything you'll need. Read on for more information about our page types. Docs meta content (frontmatter) Thr top of every doc begins with a set of metadata. Read on for more information about this metadata content: Meta content field Description Title Whenever possible, provide an action-oriented or task-oriented title; for example, \"AJAX page: Identify time-consuming calls.\" In general, use sentence case. Capitalize only the first word. Do not capitalize any other word in the title unless it's a proper noun, such as a specific product name, or it follows a colon (:). If you're looking for ideas on how to choose a title, browse the titles of similar docs. The title used in the sidebar (left navigation pane) is set in the nav file. type For the basicDoc template, use page or omit type. If omitted, the default type is page and the basicDoc template is used. template The template determines the basic layout and style of a page. Use basicDoc for more pages. tags Keywords related to your doc. Start each topic with a _* on a new line. A topic can include multiple words separated by spaces. japaneseVersion The URL to the Japanese language version of the doc. Leave this blank if there isn't a Japanese version. Document body The document body is where you edit the page content. Use the GitHub Markdown format when you write content. Page templates For most situations, use the basicDoc page template. Read on for information about our other page templates. Content type Description Basic page A standard HTML webpage without special fields. This content type is used for the majority of content on the site. API doc This format is for API reference documentation. For more information, see apiStyleGuidelines (for style guidelines) and Work with the API doc content type (for how to use and configure). Attribute definition This format is for defining attributes and event types. These definitions are shared with the UI via the data dictionary service. For more information, see Work with attribute definition content type. Landing pages This format is for a more user-friendly and readable landing page, which replaces the standard taxonomy list views. For more information, see Working with landing pages. Release notes This format includes specific fields for release notes. Users rely on release notes to keep up with smaller changes in the product, particularly for downloadble software like the agents. For more information, see Create release notes. What's New posts This format includes specific fields for product announcements. What's New posts are created by PMM for larger announcements. They're available in the docs site, but they're also visible in the New Relic One UI. For more information, see What's New style guidelines. Troubleshooting doc This format is for troubleshooting docs in a Problem-Solution-Cause format. For more information, see Troubleshooting docs guide.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.12825,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Tech</em> <em>writer</em> style guide"
      },
      "id": "6042220e64441f28b64e8843"
    }
  ],
  "/docs/style-guide/writing-guidelines/code-formatting-guidelines-var-mark": [
    {
      "sections": [
        "Code examples",
        "For inline code or data (<code>)",
        "For multi-line code blocks (<pre>)",
        "Highlight user input with <var>",
        "Highlight important sections with <mark>",
        "Add syntax highlighting",
        "Link to other docs"
      ],
      "title": "Code examples",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c8690ad4669d2a9b3eadad8a7bcbc1e05ff9093c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/code-examples/",
      "published_at": "2021-10-07T11:01:50Z",
      "updated_at": "2021-09-14T05:45:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We use a variety of formatting to highlight code or other technical language. You can use the <code>, <pre>, and <var> tags to indicate \"raw\" technical content such as excerpts from a config file, an API method name, or a file path. For inline code or data (<code>) To surround small blocks of code or data (single words or lines), mark as code: Source: Use <code> tags. Markdown: Surround the text with backtick ` characters. For multi-line code blocks (<pre>) To surround longer blocks of data that run multiple lines, mark as preformatted text: Source: Use <pre> tags. Markdown: Do not use Markdown-style indented code formatting, as this can cause unexpected formatting problems. Highlight user input with <var> Use the <var> tag to highlight areas of a code block where a user is expected to supply their own value. For more context on when to use <var> tags, see < var> formatting guidelines. Follow these guidelines when you use <var> tags: Address the reader directly Use all caps and underscores _ to separate words (also known as SCREAMING_SNAKE_CASE). Don't use other punctuation (such as wrapping the text in angle brackets). Exception: REST API examples use a ${VARNAME} syntax inspired by Bash conventions. Standard examples: echo \"license_key: YOUR_LICENSE_KEY\" | sudo tee -a /etc/newrelic-infra.yml Copy msiexec.exe /qn /i PATH\\TO\\newrelic-infra.msi Copy https://rpm.newrelic.com/accounts/ACCOUNT_ID/applications/APP_ID Copy REST API v2 example: curl -X GET \"https://api.newrelic.com/v2/applications/${APPID}/metrics/data.xml\" \\ -H \"X-Api-Key:${APIKEY}\" -i \\ -d 'names[]=HttpDispatcher&values[]=average_call_time&values[]=call_count&from=2014-03-01T20:59:00+00:00&to=2014-03-01T21:59:00+00:00&summarize=true' Copy Highlight important sections with <mark> Use the <mark> tag to highlight areas of a code block that are particularly important. Most commonly, <mark> is used to highlight New Relic API methods in sample code that contains a lot of \"other logic.\" When you use <mark>, you should usually follow the code block with a list of bullets that explain what each API call is doing and link to method syntax. For more context on when to use <mark> tags, see < mark> formatting guidelines. Examples: Example of using the <mark> tag private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal(DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()) ; // fire and forget DB_POOL.submit(() -> { segment.end() ; insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For method syntax, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. For method syntax, see the Javadoc. segment.end(): Stops timing this segment. For method syntax, see the Javadoc. Add syntax highlighting To add syntax highlighting to a code block, add class=\"highlight\" to the <pre> tag. The syntax highlighter tries to auto-detect the language. If it's not working as expected, ensure the language is supported and specify the language by adding the a lang-LANG-NAME class (for example: lang-html). View a full list of supported languages for syntax highlighting. Element colors and themes are fully customizable. Link to other docs You can add <a href> tags inside a <pre> blocks, just as you would any other content. However, make sure to use them judiciously since they can be easy to miss. A good example is the Infrastructure config file template, where each config element links to the relevant section of the main config doc.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.61649,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Code</em> examples",
        "sections": "<em>Code</em> examples",
        "body": " Markdown-style indented <em>code</em> <em>formatting</em>, as this can cause unexpected <em>formatting</em> problems. Highlight user input with &lt;<em>var</em>&gt; Use the &lt;<em>var</em>&gt; tag to highlight areas of a <em>code</em> block where a user is expected to supply their own value. For more context on when to use &lt;<em>var</em>&gt; tags, see &lt; <em>var</em>&gt; <em>formatting</em> <em>guidelines</em>"
      },
      "id": "6042212b28ccbc7c9eeba772"
    },
    {
      "sections": [
        "Bold or code, not italics"
      ],
      "title": "Bold or code, not italics",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "c4d55d70ca7e6d5a8359be160059ea2e1190cf27",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/bold-or-code-not-italics/",
      "published_at": "2021-10-07T20:55:42Z",
      "updated_at": "2021-09-27T15:17:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you'd like to emphasize text in our docs, please follow these simple guidelines: Use code for things the user is likely to copy and paste, like a file path or a command line example. Use bold for anything else you need to emphasize, like a UI name or to highlight an important word. We don't format text in our docs with italics. Here are more specific guidelines our team uses. For this... Bold Code Example Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config in the %ALLUSERSPROFILE%\\New Relic\\.NET Agent directory. Insights event names and attributes To analyze APM errors, use the TransactionError event. Method names To initialize the APM agent, use startAgent(). Non-clickable URLs In your web browser, navigate to the minion Overview page at http://MINION_IP_ADDRESS. The <var> formatting automatically applies color coding and italics in this situation. Pages, paths, fields, etc. in the user interface Go to one.newrelic.com > APM > (select an app) > Transactions. For more information, see UI paths.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.34253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Bold or <em>code</em>, not italics",
        "sections": "Bold or <em>code</em>, not italics",
        "body": " <em>format</em> text in our docs with italics. Here are more specific <em>guidelines</em> our team uses. For this... Bold <em>Code</em> Example Command line utility names To install the utility, use apt. Emphasis Stop IIS before running the installer. File paths and file names The agent looks for newrelic.config"
      },
      "id": "60421e1de7b9d2eadb2a0800"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/90e8518fffeb7d9cc28f58f29fe749a5/e5166/LogsInContext-Log4Net.jpg",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-07T16:30:11Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration](https://www.nuget.org/packages/Microsoft.Extensions.Configuration/) Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.41258,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing <em>formatting</em> and output of log files on a different thread. Don&#x27;t collect MDC or the MDLC data (default): The following <em>code</em> example enriches log"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/style-guide/writing-guidelines/create-edit-content": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-10-07T11:02:41Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 384.70932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> <em>and</em> <em>edit</em> categories",
        "body": " large groups of docs at once, please <em>create</em> an issue to request these types of changes and we&#x27;ll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see <em>Create</em> and <em>edit</em> <em>content</em>. To learn how to <em>create</em> and publish release notes, see <em>Create</em> release notes. To make it even easier to start a new doc, use templates."
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-07T01:22:54Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.84595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Create</em> new custom groups <em>and</em> roles",
        "tags": "Accounts <em>and</em> billing",
        "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups <em>Create</em> custom user groups Grant user groups access to specific roles and accounts Important"
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-10-07T00:36:23Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 82.710884,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Add custom <em>content</em> using the markdown <em>editor</em>",
        "tags": "Explore <em>and</em> query data",
        "body": ". <em>Create</em> new <em>content</em> by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/style-guide/writing-guidelines/docs-translation": [
    {
      "sections": [
        "Create smoother charts with sliding windows",
        "When to use sliding windows",
        "Valid NRQL syntax for SLIDE BY",
        "Translation from PromQL-style queries",
        "Use SLIDE BY with MAX and AUTO",
        "Tip"
      ],
      "title": "Create smoother charts with sliding windows",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "97fe07b51e5f2c6a2868c924d1c829d82fd8f585",
      "image": "https://docs.newrelic.com/static/9d882293c1b7b04e65b4bcf6f3ae4bbf/e5166/SlidingWindow2.jpg",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows/",
      "published_at": "2021-10-07T03:40:10Z",
      "updated_at": "2021-03-16T13:22:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Sliding windows are a technique for generating charts using the SLIDE BY clause in conjunction with the TIMESERIES clause. With sliding windows, data is gathered in time \"windows\" that overlap with each other. For example, in the image below, a query gathers data with 5 minute windows. The windows \"slide\" by 1 minute. Each window overlaps with the previous window by 4 minutes. 5-minute windows with 1-minute \"slide\" In contrast, with \"tumbling\" or \"cascading\" windows, the windows do not overlap. For example, in this TIMESERIES 3 minutes NRQL query, the windows are 3 minutes in length, with each beginning when the other ends. There is no overlap in the measurement interval. 3-minute windows with no overlap or \"slide\". When to use sliding windows Sliding windows are helpful when you need to smooth out \"spiky\" charts. One common use case is to use sliding windows to smooth line graphs that have a lot of variation over short periods of time in cases where the rolling aggregate (for example a rolling mean) is more important than aggregates from narrow windows of time. In the example below, data varies greatly from one minute to another, so the 1-minute tumbling window chart shows many high peaks and low valleys. TIMESERIES query without SLIDE BY clause However, in this example, 5-minute wide TIMESERIES windows are smoothed with the help of 1-minute SLIDE BY intervals. The query returns similar data but creates a much smoother chart. TIMESERIES query with SLIDE BY clause Valid NRQL syntax for SLIDE BY Valid NRQL syntax for the SLIDE BY clause will follow the format below. SELECT ... TIMESERIES integer1 units SLIDE BY integer2 units Copy integer1 specifies the sliding window width and integer2 specifies the SLIDE BY interval. units is a time unit, such as second, minute, hour, or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy Translation from PromQL-style queries When applicable, a PromQL-style query is translated into a NRQL sliding window query. For example, if your PromQL style query uses rate(request_count[5m]) for the past 60 minutes with a 1-minute window overlap, the NRQL translation would be the query below. SELECT rate(sum(request_count), 1 SECONDS) FROM Metric SINCE 3600 SECONDS AGO UNTIL NOW FACET dimensions() LIMIT 100 TIMESERIES 300000 SLIDE BY 60000 Copy In the translation output, the default unit of millisecond is used for TIMESERIES and SLIDE BY clauses. For TIMESERIES, 300000 ms is 300 seconds, or 5 minutes, specifying a window size of 5 minutes. For SLIDE BY, 60000 ms is 60 seconds, specifying a slide interval of 1 minute. Use SLIDE BY with MAX and AUTO You can combine SLIDE BY with MAX and AUTO arguments to further tailor query results, as shown in the examples below. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy Tip When paired with SLIDE BY, TIMESERIES does not support AUTO or MAX. The TIMESERIES value must be an integer time unit value. In other words, SLIDE BY AUTO or SLIDE BY MAX will work, but TIMESERIES AUTO or TIMESERIES MAX followed by SLIDE BY and MAX, AUTO, or a specific integer time unit is not supported. Tip The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which will show up as gaps and unexpected results. If you experience these issues with query results, consider checking for instances of SLIDE BY where the step interval exceeds the window size.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 55.701283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Translation</em> from PromQL-style queries",
        "body": ", or day. All standard NRQL time units are accepted. Here’s a real-life example. It shows 5-minute TIMESERIES windows with a 1-minute SLIDE BY interval. SELECT average(duration) from Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy <em>Translation</em> from PromQL-style queries When applicable"
      },
      "id": "603e8a2528ccbc56e5eba774"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writing-guidelines/create-edit-content/",
      "sections": [
        "Create and edit content",
        "Edit a doc",
        "Create new docs",
        "Clone (copy) an existing doc",
        "For bigger projects",
        "Delete pages",
        "Private edits",
        "Request a future publication date (for New Relic employees)"
      ],
      "published_at": "2021-10-07T11:06:44Z",
      "title": "Create and edit content",
      "updated_at": "2021-09-27T15:28:12Z",
      "type": "docs",
      "external_id": "96d8ee8adf5279fde74c26bf462be94d11dfa6fe",
      "document_type": "page",
      "popularity": 1,
      "body": "We welcome your contributions, whether you are a New Relic employee or a New Relic user! And we don't want you to worry about style. When you edit a file, tech writers on our team review it for style, grammar, and formatting. That said, if you're curious about our style guidelines, you're welcome (but not obligated) to take a look. Edit a doc If you see a minor problem in our documentation that you want to quickly fix, you can use GitHub to edit the file and submit your pull request. A member of the Docs team will review your edit and publish your changes. We'll follow up with you if we have any questions. To edit existing content without building the site locally: On the docs site, navigate to the doc you'd like to edit. Click Edit page on the top corner of the right nav. A GitHub page will open with the source of the doc. Click the pencil icon in the top right. Make your edits (don't worry too much about formatting or grammar, we're happy to take care of that). At the bottom of the page, enter acommit message that describes your change, then click Commit changes. Follow the prompts to submit your pull request. A member of the Docs team will review your pull request and comment with any feedback. Once we've merged your pull request into the Develop branch, your changes will go live with our next deploy (usually within a few hours). Create new docs You can use article templates or clone an existing doc as a template. To create a new doc: Clone the repo on your computer. In /src/content/docs/, find a good location for your doc. Using your text editor, create a new .mdx file or copy an existing doc. Write your content. Optional: Add your doc to the right nav .yml file. The navigation files can be a bit hard to work with, so feel free to leave this step for a Docs writer to handle when they review your pull request. Commit your changes and create a pull request. The Tech Docs team has two heroes watching for new pull requests. We'll help you get the content finalized and make sure that it's in the right place. Clone (copy) an existing doc Once you've cloned the docs-website repository, use your text editor to copy an existing doc. Rename and edit the copy and then save it as a new doc. Your cloned doc automatically inherits the original doc's frontmatter content. Make sure to change that, too. If you want your cloned doc to be translated, follow standard procedures to request translation. For bigger projects If you're making larger changes like adding a whole new doc or editing many existing docs, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go for it. If not, ask us by: File an issue in the docs-website repo, or contact the @hero in the #documentation channel if you're a New Relic employee. We'll take a look at your issue and help out. Private edits If you need to stage content for a private beta or limited release, contact the docs hero in the #documentation Slack channel. Request a future publication date (for New Relic employees) If your draft needs to be released on a specific date or within a specific timeframe (for example, right before a release), contact the Tech Docs @hero in the #documentation Slack channel. If you're not a New Relic employee, please create a GitHub issue.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 54.33339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Create new <em>docs</em>",
        "body": " procedures to request <em>translation</em>. For bigger projects If you&#x27;re making larger changes like adding a whole new <em>doc</em> or editing many existing <em>docs</em>, it can be helpful to run the site locally. For instructions, see Tech writer workflow. Delete pages If you are comfortable with deleting the page yourself, go"
      },
      "id": "6042219c196a67b1ada83d81"
    },
    {
      "sections": [
        "Update the home page",
        "Update a link's URL",
        "Add a new tile to the home page",
        "Add a new section to the home page"
      ],
      "title": "Update the home page",
      "type": "docs",
      "tags": [
        "home page",
        "landing pages"
      ],
      "external_id": "d637697a72493d8dbe0c9538e5b35f13f62d7474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/edit-homepage/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-04-11T08:27:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can't just hit the edit button docs.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It's rare that you'll need to make changes to this file. Most home page changes will be to add a new tile or section to the page, or update links. These types of changes are handled in two files: src/data/homepage.yml - contains home page section titles, section descriptions, and the URLs for tiles. src/i18n/translations/en/translation.json - contains tile info, including the title and short description of tiles. Update a link's URL Change or add new links using homepage.yml. In homepage.yml, search for the link you want to change. Edit the URL, save, commit, and PR the change. Add a new tile to the home page You'll make changes to both homepage.yml and translations.json On the translations.json doc, find the spot where you want to add the new tile (which section, and in what order you want it to appear), and add a new entry with this format: \"t#\": { \"title\": \"tile name\", \"description\": \"Short description.\" }, Copy Make sure you update the number on the tile. If you want to insert it in the middle of a group, update all the subsequent tile numbers as well. Save the file. Open homepage.yml, find the spot where the new tile will be, and add a new line with the relative link for the new tile. For example, - /docs/new-relic-one/use-new-relic-one/workloads/workloads-isolate-resolve-incidents-faster Save and check that your new tile builds properly on a local build. Commit, push, PR when you're ready. Add a new section to the home page On the translations.json page, add a new section modeled in the spot where you want the new section to appear. Include at least one title. For example, here's the TDP entry, with one tile: \"tdp\": { \"title\": \"Telemetry Data Platform\", \"description\": \"Ingest, visualize, and alert on all your telemetry data in one place.\", \"t1\": { \"title\": \"Introduction to Telemetry Data Platform\", \"description\": \"How to manage all your monitoring in one place.\" }, Copy When you're done creating the info, save the file. In the homepage.yml page, find the corresponding location for the new section, and add the short name you provided in the translation.json file, title, description, and tile URLs. For example, here's the corresponding TDP section on homepage.yml. tdp: title: Telemetry Data Platform description: Ingest, visualize, and alert on all your telemetry data in one place. tiles: - /docs/data-ingest-apis/get-data-new-relic/getting-started/get-started-telemetry-data-platform Copy Save, build locally, commit, PR.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 50.39491,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "You can&#x27;t just hit the edit button <em>docs</em>.newrelic.com to make edits to the home page. The page that opens is index.js, the file that manages the parts of the home page, but not the content. It&#x27;s rare that you&#x27;ll need to make changes to this file. Most home page changes will be to add a new tile"
      },
      "id": "6072b300e7b9d231b2a5c663"
    }
  ],
  "/docs/style-guide/writing-guidelines/five-questions-help-write-docs": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure-remote-write/prometheus-remote-write-integration/",
      "sections": [
        "Prometheus remote write integration",
        "Why it matters",
        "Compatibility",
        "Scale your data and get moving quickly",
        "What's next"
      ],
      "published_at": "2021-10-07T02:57:48Z",
      "title": "Prometheus remote write integration",
      "updated_at": "2021-09-07T23:51:26Z",
      "type": "docs",
      "external_id": "aaf44eb9ee0ffc4b6f751ca18c5dd5b34cd11649",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the Prometheus remote write integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about five minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which scrape data from Prometheus endpoints, the remote write integration allows you to forward telemetry data from your existing Prometheus servers to New Relic. You can leverage the full range of options for setup and management, from raw data to queries and dashboards and beyond. With the Prometheus remote write integration, you can: Store and visualize crucial metrics on a single platform Combine and group data across your entire software stack Get a fully connected view of the relationship between data about your software stack and the behaviors and outcomes you’re monitoring Connect your Grafana dashboards (optional) Compatibility New Relic supports the Prometheus remote write integration for Prometheus versions 2.15.0 or newer. Scale your data and get moving quickly Once logged in to New Relic, you can get data flowing with a few simple steps: Generate your remote_write URL. Add the new remote_write URL to the configuration file for your Prometheus server. Restart your Prometheus server. View your data. What's next Ready to get started? Read the setup documentation. Configure a Prometheus data source in Grafana. Set up the integration on New Relic US EU",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 78.49933,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Prometheus remote <em>write</em> integration",
        "sections": "Prometheus remote <em>write</em> integration",
        "body": "You can use the Prometheus remote <em>write</em> integration to get data flowing into New Relic. Once you integrate, your data will be visible in query-based dashboards (and other query results), often within about <em>five</em> minutes. Why it matters Unlike Kubernetes and Docker OpenMetrics integrations, which"
      },
      "id": "60ea272a196a670c6038adbf"
    },
    {
      "sections": [
        "Support resources for New Relic partners",
        "Tip",
        "New Relic Support",
        "Documentation",
        "Agent documentation",
        "Agent release notes",
        "Online Technical Community"
      ],
      "title": "Support resources for New Relic partners",
      "type": "docs",
      "tags": [
        "New Relic partnerships",
        "Partner integration guide",
        "Getting started"
      ],
      "external_id": "56246fb8462659d929766125f8afbbc429f42ee5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-partnerships/partner-integration-guide/getting-started/support-resources-new-relic-partners/",
      "published_at": "2021-10-08T01:02:23Z",
      "updated_at": "2021-09-08T00:27:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for New Relic partners. After you complete your partnership integration, you will be introduced to your technical contacts at New Relic. Use these channels for non-urgent escalations. Tip If you are not a New Relic partner, see New Relic's resources for finding help or filing a support ticket. New Relic Support To obtain support for partner accounts, create a ticket at support.newrelic.com. If you need to call New Relic directly, contact your Business Development representative. Documentation Documentation from New Relic's docs site is an important resource for your support group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self help and reduce your support efforts. Top level entry point for New Relic documentation: docs.newrelic.com. From here you can select information about New Relic products and features by category. Tip The docs site includes a Partnerships category with information for New Relic partners and some partnership customers. Here are the five most commonly consulted articles on the New Relic docs site. Providing easily found and direct links to these articles can provide many users with self-serve answers to their questions. Create your New Relic account Name your application Configure the agent Not seeing data Apdex: Measuring user satisfaction Agent documentation Here are links to New Relic documentation categories organized by APM agent languages: Go Java .NET Node.js PHP Python Ruby Agent release notes Here are links to New Relic release notes organized by agent languages: Go Java .NET Node.js PHP Python Ruby Online Technical Community The New Relic Explorers Hub brings together the expertise of New Relic employees, our Partners, and our community regarding all things New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.441654,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Documentation</em>",
        "body": " group when providing Level 1 support to your New Relic subscribers. Posting these links on your support pages is an effective way to encourage self <em>help</em> and reduce your support efforts. Top level entry point for New Relic documentation: <em>docs</em>.newrelic.com. From here you can select information about"
      },
      "id": "60450ecf28ccbc45632c6095"
    },
    {
      "sections": [
        "Infrastructure monitoring Hosts page",
        "System tab",
        "System tab functions",
        "APM and infrastructure data",
        "Important",
        "Network tab",
        "Network tab functions",
        "Processes tab",
        "Tip",
        "Processes tab functions",
        "Storage tab",
        "Storage tab functions",
        "Docker containers tab",
        "Docker containers tab functions"
      ],
      "title": "Infrastructure monitoring Hosts page",
      "type": "docs",
      "tags": [
        "Infrastructure",
        "Infrastructure monitoring UI",
        "Infrastructure UI"
      ],
      "external_id": "41d8a2ac3ecbbdee164fd0bec6ac94bb3e8def64",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/infrastructure-ui-pages/infrastructure-ui/infrastructure-hosts-page/",
      "published_at": "2021-10-07T06:58:15Z",
      "updated_at": "2021-08-27T07:06:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to help determine root causes. You can also set alert notifications to help prevent problems. To view your hosts information, go to one.newrelic.com > Infrastructure > Hosts, then click any of the following tabs: System: Overview of your hosts' performance Network: Bandwidth and error data about your network interfaces Processes: Data about CPU percentage, I/O bytes, and memory usage for individual or groups of processes Storage: Resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations Docker containers: CPU percentage, I/O bytes, and memory usage for individual or group of containers System tab Here are the default graphs shown on the Hosts page. For additional chart options, select the dropdown for any chart. CPU %: On the System tab, CPU Percent is a derived metric that is part of the SystemSample event. The CPU percentage is not collected by New Relic, but derived from several other metrics. Specifically, the cpuPercent attribute is an aggregation of cpuUserPercent, cpuSystemPercent, cpuIoWaitPercent and cpuStealPercent. Load average five minute: represents an average of the number of tasks waiting to do work on a system over the last 5 minutes. Memory free %: compares the amount of free memory bytes to the amount of used memory bytes. For explanations of different chart metrics, see Default infrastructure attributes and events. Functions for adjusting chart data include: Select different host groups: Use the host filter. Change time range: Use the time picker above the charts, or drag and select a time range on a chart. Change the number of elements on charts: use the Chart shows dropdown. Change data used to order hosts: Use the table below the charts to order the chart elements by different metrics; for example, from highest to lowest CPU user % to lowest, or from lowest to highest Disk free. System tab functions Here are some of the things you can do from the System tab: If you want to... Do this... Filter and group hosts Use filter sets to show only hosts matching certain criteria, or use group by to aggregate the results. Understand host health Use the Health column of the table. To see more details about specific violations, select the health status icons. Find root causes of issues Use the Events heatmap at the top of the page to compare performance to important events happening in your infrastructure. For more, see Events heatmap. Set an alert condition for a metric Mouse over a chart, select and then Create alert. View host's alert threshold violation If present, select the host's Critical icon or Warning icon. APM and infrastructure data If you have APM data associated with your infrastructure data, there are several ways to access your APM data on the Hosts page: Use the hosts filter to filter on hosts running specific applications. In the host list below the charts, select the Application column to filter on specific applications. From the chart selector dropdown beside a chart's name, select one of the application-related charts. Important APM charts in infrastructure monitoring do not have View query or Create alert options like the other infrastructure charts do. For more about using APM and infrastructure monitoring together, see APM data in infrastructure. Network tab The Network page provides real-time visibility into the health and performance of individual hosts, web servers, or other groups of resources across your network. Default charts show bandwidth metrics by packet, bandwidth by bytes, and errors per second. Details about individual interfaces can help you: Examine saturation levels across your network or for selected filter sets. Compare load balances between specific resources. Identify unexpected differences in capacity patterns between similar hosts. Evaluate the top five network errors that New Relic automatically presents for the selected time period. This real-time network data can then help you determine whether to resolve errors by reconfiguring your network, rebalancing the loads, or taking other preventative maintenance actions before needing to make a purchase decision. From the Network tab you can view bandwidth and error data about your network interfaces. The Network page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Network page chart, see NetworkSample attributes. Network tab functions Here are some of the things you can do from the Network tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings, including: Received Bytes Received Dropped Received Errors Received Packets Transmitted Bytes Transmitted Dropped Transmitted Errors Transmitted Packets Search and filter the list Type in the Search interfaces search bar to filter the list to only those items containing the text you've typed. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add items to chart The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item from a chart, select its name below the chart. Set an alert condition for a metric Mouse over a chart, select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Processes tab Important By default, the infrastructure agent doesn't send data about the operating system's processes unless you use guided install. To enable the sending of process data set enable_process_metrics to true. To fine-tune which processes you want to monitor, configure include_matching_metrics. Use the Processes tab to get information about processes running on your hosts, and to set alerts on process metrics. The Processes tab shows data such as CPU percentage, I/O bytes, and memory usage for individual processes or groupings of processes. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Pinpoint processes that are causing performance issues. Create alerts for conditions such as CPU percentage and memory usage. On the Processes page, CPU percent is scoped to individual processes, rather than hosts. Because of this, the CPU percent metric does not take into account the resources of the entire system. Instead, it shows how much of a single CPU core each process is taking. Example Here's an example of how to pinpoint an issue and set an alert: You notice on the Hosts page that a cluster has a CPU percentage much higher than normal. You go to the Processes page and filter down to that cluster's processes. You notice that several instances of the same process have excessive CPU percentage. After fixing the issue, you decide to create an alert condition that triggers when the CPU percentage for that process type exceeds a certain threshold. For a technical explanation of the attributes used to populate the Processes page chart, see ProcessSample attributes. Tip You cannot start, stop, or restart processes from the UI. Instead, follow standard procedures to start, stop, check, or restart the infrastructure agent manually. Processes tab functions Here are some of the things you can do from the Processes tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as hostID and entityName. If you are monitoring AWS EC2 instances, EC2-related attributes such as awsRegion will be available. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker metrics To view process usage by Docker containers, see Docker instrumentation. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: Memory: Resident or virtual size CPU percentage Disk I/O: Read or write Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Storage tab The Storage page allows you to monitor your resources' capacity and efficiency, including your devices' overall utilization, disk usage, or I/O operations. This can help you to: Examine unexpected patterns; for example, a cluster of mirrored machines that do not process I/O tasks uniformly. Monitor usage levels before disk space completely runs out. Set alert conditions to notify you about problems with one or more hosts; for example, long processing times for read or write operations, disk availability or utilization based on percentage or bytes, etc. Make informed decisions about where to redistribute hosts with higher or lower than normal processing requests. Use data to help plan for additions or changes to your infrastructure budget before an emergency arises. The Storage page includes an Events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. For a technical explanation of the attributes used to populate the Storage page chart, see StorageSample attributes. Storage tab functions Here are some of the things you can do from the Storage tab: If you want to... Do this... Filter and group Use filter sets to show only hosts matching certain criteria, or use Group by to aggregate the results. Select a time range Use the time picker on the upper right to change the range of time selected. You can also click and drag on the chart to select a custom time range. When you select a time range, it carries over when you go from one infrastructure page to another. Change metrics displayed in chart Use the sorting dropdown to switch what metric the chart is displaying for the chosen process groupings. Choices include: Total Utilization % Read Utilization % Write Utilization % Disk Used Bytes Disk Free Bytes I/O Read Operations I/O Write Operations Search and filter the list Type in the Search devices search bar to filter the list. You can also filter the list by simply selecting the list item or user name you want to filter for. The chosen filters are displayed beside the filter icon above the chart. Add/remove chart items The chart, by default, displays the top five results. Use the Chart shows dropdown to display more results. To remove an item, select its name below the chart. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. (Not available on APM charts.) View host's alert threshold violation Select the host's Critical icon or Warning icon. Docker containers tab Use the Docker containers tab to get information about the containers running on your hosts, and to set alerts on container metrics. The Docker containers tab shows data such as CPU percentage, I/O bytes, and memory usage for individual containers or groupings of containers. The page also includes an events heatmap, which provides a snapshot of the events occurring within the same time range as the displayed metrics. Use this information to: Identify containers that are experiencing performance issues. Create alerts for conditions such as CPU percentage and memory usage. Docker containers tab functions Here are some of the things you can do from the Docker containers tab: If you want to... Do this... Only show hosts matching certain criteria Use filter sets. Aggregate results or group by host attributes Use Group by to change how the processes are grouped in the chart and the list. The dropdown contains host-related attributes such as image and operatingSystem. Select a time range Use either of these options: Select any of the time picker options at the top of the page. Click and drag on the chart to select a custom time range. After you select a time range, it carries over from one infrastructure page to another. View Docker integration dashboard To open the Docker integration dashboard, click the Dashboard link above the data table. Change charts Select the dropdown beside the chart's name to switch what metric the chart displays. Choices include: CPU: Used cores, kernel percentage Memory: Size limit, cache bytes I/O: Write count per second, total bytes Network: Errors per second, packets Process: Process count, restart count Search and filter the list Use either of these options: Type in the Search processes search bar. Select the list item or user name you want to filter for. The selected filters appear beside the filter icon above the chart, where you can select and remove them as needed. Set an alert condition for a metric Mouse over a chart. Select and then Create alert. View host's alert threshold violation Select the host's Critical icon or Warning icon.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 59.224976,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Docker</em> containers tab",
        "body": "Use the Hosts page to better understand important performance metrics, like resource usage, network and processes performance, and data about your containers. You can filter your hosts by attributes and compare their performance with inventory change events to <em>help</em> determine root causes. You can"
      },
      "id": "60440a6d196a675f6c960f58"
    }
  ],
  "/docs/style-guide/writing-guidelines/formatting-terminal-commands": [
    {
      "image": "",
      "url": "https://developer.newrelic.com/contribute-to-quickstarts/build-a-quickstart/deploy-your-application/",
      "sections": [
        "Deploy your application",
        "Lab",
        "Prepare your environment",
        "Spin up demo services"
      ],
      "published_at": "2021-10-09T01:44:58Z",
      "title": "Deploy your application",
      "updated_at": "2021-09-30T18:19:07Z",
      "type": "developer",
      "external_id": "0681f5292e5caefff48c28a98bc079070450bdd2",
      "document_type": "page",
      "popularity": 1,
      "info": "Spin up your demo services to follow along the lab",
      "body": "Lab This procedure is a part of lab that teaches you how to build a quickstart. If you haven't already, check out the lab introduction. Before you build a quickstart, you need to spin up a docker container. The container consists of two important services: A python program that mimics the database and also provides functions for create, read, update, and delete (CRUD) operations. It also makes use of newrelic_telemetry_sdk to send telemetry data to New Relic. A simulator service that generates dummy database traffic so you don't have to manually perform CRUD operations To spin up these services, you first need to set NEW_RELIC_INSERT_KEY environment variable. Prepare your environment On your local machine, set your license key in an environment variable: bash Copy $ export NEW_RELIC_INSERT_KEY=<YOUR_LICENSE_KEY> Your mock database uses this key to write telemetry data to New Relic. You can find your New Relic license key in your account settings. Spin up demo services Clone the lab repository from GitHub: bash Copy $ git clone https://github.com/newrelic-experimental/build-a-quickstart-lab.git This repository contains the code for Flashdb as well as the simulator for dummy database traffic. Navigate to the demo directory and execute the following commands to build and run docker image: bash Copy $ docker build -t flashdb . $ docker run -e NEW_RELIC_INSERT_KEY=$NEW_RELIC_INSERT_KEY flashdb Here, you build and run docker image that generates mock database traffic. You will observe this data in New Relic. Once the docker image is up and running, you see the following output in your terminal: bash Copy $ docker build -t flashdb . $ docker run -e NEW_RELIC_INSERT_KEY=$NEW_RELIC_INSERT_KEY flashdb Writing... try_send Writing... try_send Reading... try_send Reading... try_send Sent metrics successfully! sending event... Event sent successfully! Writing... try_send Writing... try_send Reading... Next, you observe this data in New Relic using dashboard. Lab This procedure is a part of lab that teaches you how to build a quickstart. Continue on to next lesson: Create a dashboard.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.202515,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " database traffic. Navigate to the demo directory and execute the following <em>commands</em> to build and run docker image: bash Copy $ docker build -t flashdb . $ docker run -e NEW_RELIC_INSERT_KEY=$NEW_RELIC_INSERT_KEY flashdb Here, you build and run docker image that generates mock database traffic. You"
      },
      "id": "6155ff9be7b9d2a5a58de396"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/writer-workflow/tech-writer-workflow/",
      "sections": [
        "Tech Writer workflow",
        "Resources",
        "Edit in the GitHub web editor vs local build",
        "1. Set up your local environment",
        "2. Run the site locally",
        "Prerequisites",
        "Build the site",
        "3. Edit a doc",
        "4. Commit your changes",
        "5. Publish your commits",
        "6. Open your pull request",
        "Preview a doc",
        "Revise and publish a doc",
        "Revert merging",
        "Writers only: Work on a branch, not a fork"
      ],
      "published_at": "2021-10-07T11:18:43Z",
      "title": "Tech Writer workflow",
      "updated_at": "2021-09-27T15:37:07Z",
      "type": "docs",
      "external_id": "074905b02af0ab6eb53640c1c80e83296a8a0b02",
      "document_type": "page",
      "popularity": 1,
      "body": "This document will guide you through the entire workflow for editing the New Relic documentation site as a New Relic Tech Docs Writer. Resources VSCode (or another text editor) VSCode has great GitHub integrations GitHub account GitHub Desktop Edit in the GitHub web editor vs local build Need to edit a doc? Use this table to decide where to work! Use the GitHub web editor for: Use the local build for: Adding content to one doc: Rewriting sentences, or 1-2 lines Editing small amounts of content: updating URLs, deleting typos, etc. Brand new docs Rewrites of more than 1 or 2 lines Any updates to doc frontmatter Title changes Taxonomy changes Metadescription updates Redirects Updating images Editing multiple docs at once Continue reading for instructions on how to edit a doc locally. 1. Set up your local environment Running the site locally makes testing and previewing large changes much easier. Here's how to get setup: Install GitHub Desktop Sign in to GitHub Desktop. On Macs, click on GitHub Desktop in the top left corner of your screen and select Preferences. Select the blue Sign In button and follow the prompts in the browser window. Navigate to the Docs Site repository on GitHub.com. Click the green Code button and then select Open with GitHub Desktop. Choose the location where you want the repo, and this will clone the entire repository to your local machine at the designated path. You can ensure the repo was cloned by navigating to your local GitHub folder (the default is ~/Documents/github). Once you have cloned the repo, you don't need to clone it again in the future. 2. Run the site locally Build the site locally using the terminal to preview changes before opening a Pull Request. While it's highly recommended to build the site locally, this is technically an optional step. The site will automatically reflect any local changes once build. Node and Yarn are tools used to build the site on your local machine. Prerequisites Install Node Install Yarn npm install -g yarn Build the site In your terminal, go to your cloned repo, docs-website. For example: cd ~/Documents/github/docs-website Run yarn with the following commands: yarn && yarn start The site will take a few minutes to build. Make yourself some tea or coffee. Once it's built, you can access your preview site in your browser by navigating to http://localhost:8000/ 3. Edit a doc Once your local environment and branch are set up, you're ready to edit a doc. Check out the style guide for writing guidelines. First, ensure your Current Branch in GitHub Desktop is set to the correct branch, not Develop. Navigate to the doc you want to edit in Finder. If I wanted to edit a Python agent doc, I would navigate to: ~/Documents/github/docs-website/src/content/docs/agents/python-agent/hosting-services/python-agent-stackato.mdx Edit the doc in your text editor of choice. You should write docs in markdown language. Reference the style guide for help with formatting markdown Save the file with your edits, then follow the same process for any other docs you wish to edit. 4. Commit your changes Once your edits are done, you can commit them. This stages your changes, which you will later push upstream to Github. By pushing your changes, everyone will have access to your branch and commits. Navigate to GitHub Desktop. The left column should have a record of all the edits you have made to docs. In the bottom left corner, name your commit and add a good description of your edits. It should be descriptive enough to ensure that someone can understand all the changes made by simply scanning this description. Click Commit to [yourbranchname] 5. Publish your commits Once you have committed your changes, you're almost ready to open your Pull Request. First, you need to ensure your branch is pushed upstream. On GitHub desktop, click the blue Publish Branch button if available. If you don't see the Publish Branch, click the blue Push Origin button. This will push all your commits upstream and make them available to everyone else through the GitHub repository. 6. Open your pull request Now that your commits are available to everyone, you need to notify people that your changes are ready to be merged into the develop branch. To do this, you open a pull request: On GitHub Desktop, click the blue Create Pull Request button. This will open GitHub in your browser, and prompt you to fill in your pull request. Ensure you're merging from your branch into either the main or develop branch. If you scroll down, you can review all your commits to ensure they reflect all your changes. Just like your commit description, your pull request description should be detailed and give the full context of your changes. Feel free to add any additional context here (issue or Jira number, SMEs, etc.) To request a review from another Tech Writer: in GitHub open the PR, navigate to the Conversation section, and then select or type in a reviewer name in the Reviewer section. Add any relevant labels to your PR. If you do not add from_tw, the PR will not be automatically assigned to another writer for review. Once you're satisfied with your pull request, click the green Create pull request button. You can either publish the changes directly by approving the pull request yourself, or you can request for another Tech Writer to peer edit it. At the bottom of the pull request page, you will see a Checks section. These checks ensure your PR doesn't break the build process of the site. Ensure all checks marked required pass before merging. Once the pull request has passed the checks and it has been approved by another tech writer (or you are confident the changes are ready to be published), click the green Merge pull request button. This will merge your branch and commits into the repository and will begin the build process. If you don't add the from_tw label when you first create a PR, it will not automatically assign a reviewer. If you forget to add the label before opening the PR: Add the from_tw label. Turn the PR into a draft PR. Select the PR is ready for review button at the bottom of the page to reopen the PR. The PR should now have a reviewer. Preview a doc There are two main ways to preview branches you’ve already published and run commits on: Local: Quicker, but requires a semi-substantial amount of setup and familiarity with a terminal. Gatsby Cloud: Full preview of the live site with no overhead, and a very convenient way to share a preview of your draft with a SME. Gatsby Cloud will comment on your PR with a link to a preview version of the site once the build is ready. Building the site generally takes about 15 minutes, but can sometimes take longer if there are a lot of changes. Revise and publish a doc If you’re notified that a reviewer has submitted a review to your file, go to your PR and review the changes. You might see them in the diff view, if they’re part of a review with comments; otherwise, they might appear as copy edits in the file. Respond to any comments in the file. Either reply with follow up discussion, or click Resolve conversation. When you’ve resolved all the comments, and all of the automatic checks have passed, you can merge the pull request. Merging the pull request sets in motion the automated build process and your changes will be published shortly. Note: You will only be able to merge when the Merge pull request button is green. If it’s not green, review for any comments you missed, or other messages that indicate why GitHub is blocking you from merging. Revert merging Remember that you can almost always undo things. If you merge a PR, and then find that you shouldn’t have, you can unmerge with the Revert button. On the Pull requests tab in GitHub, click Closed on the tally bar to see all the issues and PRs that have alredy been merged. Locate the PR you merged, and locate the Revert button. Click Revert. That creates a new PR, which needs to be merged. If you want to reopen it, you need to follow the link back to the original PR and either revert that or reopen it. Writers only: Work on a branch, not a fork Some teams work on branches, some teams work on forks; the Docs team works in branches. As long as a branch has been pushed upstream, this allows us to work collaboratively and ensure that no work is ever lost when someone goes on vacation. To create a branch on the docs-website repo: Open GitHub Desktop Click on Current branch: xxx Click on New Branch You will be prompted to name your new branch. Descriptive names are best. It's a great way to quickly clue people in to what your work is all about. For example, if you are working on What’s New pages, you might name the branch Whats-new-updates. When you create a new branch, don't forget to add the Jira issue's key (DOC-1234) to the branch name and the PR title.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.011856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is ~&#x2F;Documents&#x2F;github). Once you have cloned the repo, you don&#x27;t need to clone it again in the future. 2. Run the site locally Build the site locally using the <em>terminal</em> to preview changes before opening a Pull Request. While it&#x27;s highly recommended to build the site locally, this is technically"
      },
      "id": "60c6a91764441f404d91f8c6"
    },
    {
      "sections": [
        "On-host integrations: Legacy configuration format",
        "Important",
        "Configuration file structure",
        "Definition file",
        "Definition file header",
        "Definition file commands",
        "Configuration file",
        "Tip",
        "Config file field definitions"
      ],
      "title": "On-host integrations: Legacy configuration format",
      "type": "docs",
      "tags": [
        "Create integrations",
        "Infrastructure Integrations SDK",
        "Specifications"
      ],
      "external_id": "8f1d23b9999a433e49ff5c2ea7d9d9db95eb57a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/create-integrations/infrastructure-integrations-sdk/specifications/host-integrations-legacy-configuration-format/",
      "published_at": "2021-10-07T13:05:35Z",
      "updated_at": "2021-09-26T11:14:27Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Infrastructure on-host integrations can use one of two types of configuration formats. This document explains the older, legacy configuration format. Important New Relic recommends using the new standard improved configuration format. To update your configuration file to this new format, check the update section For an introduction to configuration, see Config overview. Configuration file structure An on-host integration that uses the standard configuration format requires two configuration files: A definition file A configuration file Definition file The definition file has a naming format like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of commands it can execute, and arguments that it accepts. It lives in this directory: Linux: /var/db/newrelic-infra/newrelic-integrations Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\newrelic-integrations Copy Here's an example of an NGINX integration definition file with two command sections on a Linux system: name: com.myorg.nginx protocol_version: 2 description: Collect metric and configuration data from NGINX os: linux commands: metrics: command: - myorg-nginx - --metrics interval: 15 inventory: command: - myorg-nginx - --inventory interval: 120 prefix: integration/myorg-nginx Copy A definition file can be broken down into two parts: The header The commands section Definition file header Here are explanations of a definition file's header elements: Definition header field Description name Required. A unique name name to identify the integration for logging, internal metrics, etc. When the agent loads the config file, New Relic uses the name to look up the integration in the agent's registry. protocol_version Required. The version number of the protocol. New Relic uses this to ensure compatibility between the integration and the agent. If the agent does not recognize an integration's version, it will filter out that integration and create a log message. The current version of the JSON protocol is 2. For more on protocol changes, see SDK changes. description Optional. Human-friendly explanation of what the integration does. os Optional. The operating system where the integration runs. New Relic uses this to filter integrations that you intend to run only on specific operating systems. Default: Run the integration regardless of the os value. To restrict the integration to a specific operating system, use either of these options: linux windows Definition file commands After the header is a list of commands. The commands section defines: One or more independent operating modes for the executable The runtime data required for it to be executed The commands section is a YAML map of command definitions, where each key is the unique alias name of the command in the integration's config file that specifies the executable to run. Definition commands Description command Required. The actual command line to be executed as a YAML array of command parts. These are assembled to run the actual command. For simple commands, the array might be only a single element. Additional command rules include: command arguments: The command and any command line arguments that are shared for all instances of the integration configuration. command execution: The command will be executed in the same directory as the definition file. command path: Any commands available on the host's $PATH can be used. Executables located in the same directory as the definition file, or in a subdirectory of it, can be executed using a relative path. For example: Linux: To run an executable called myorg-nginx in the same directory as the definition file, you could use myorg-nginx or ./myorg-nginx. Linux systems will execute myorg-nginx as if the user used ./myorg-nginx. Windows: To run an executable called myorg-nginx.exe in the same directory as the definition file, you could use \\myorg-nginx.exe or .\\myorg-nginx.exe. Windows systems writing myorg-nginx.exe will be executed as if indicating the current path: .\\myorg-nginx.exe. To use a command installed inside a directory on the host's $PATH, simply use the command name. Example: python. To run any other executable which is neither on the host's $PATH nor within the integration's directory, use an absolute path to the executable. Example: /opt/jdk/bin/java. If the given executable name exists within the integration's directory but also exists elsewhere on the system $PATH, the version in the integration's directory takes precedence. interval Optional. The number of seconds between two consecutive executions of the command, in particular between the end of the previous execution and the start of the next execution. Default for metric polling: 30 seconds. Minimum (floor): 15 seconds. Alerts: For metrics being used for alerts, use an interval of 30 seconds or less. prefix Optional. The categorization of the inventory in the form of category/short_integration_name. Example: integration/myorg-nginx. The prefix is not a platform-specific path. The forward slash is the correct separator between the category and short_integration_name. The prefix can have a maximum of two levels. Otherwise inventory will not be reported. Default value if not set: integration/integration_name. Configuration file The configuration file has a naming format like INTEGRATION_NAME-config.yml. This file specifies which executables to run and the parameters required to run them. It lives in this directory: Linux: /etc/newrelic-infra/integrations.d/ Copy Windows: C:\\Program Files\\New Relic\\newrelic-infra\\integrations.d Copy Tip We recommend linting the YAML configuration files before using them to avoid formatting issues. Here's an example of a config file with one instance defined. Explanations of these fields are explained below the example. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://127.0.0.1/status labels: environment: production role: load_balancer Copy Another example of a config file with two instances defined. integration_name: com.myorg.nginx instances: - name: nginx1.myorg.com-metrics command: metrics arguments: status_url: http://one.url/status labels: environment: production role: load_balancer - name: nginx2.myorg.com-metrics command: metrics arguments: status_url: http://another.url/status labels: environment: production role: load_balancer Copy Config file field definitions Config file field Description integration_name Required. This is the header and is used to identify which executables to run. This name must exactly match the name specified in the integration's definition file. Recommendation: To ensure unique names, use reverse domain name notation. name Required. This is the name for the specific invocation (instance) of the integration. This is used to help identify any log messages generated by this integration and is also useful for troubleshooting. command Required. This is the command to be executed. This must exactly match one of the unique alias names specified in the integration's definition file. arguments Optional. A YAML object where: Keys: The argument name. Transformed to upper case when set as environment variable. Values: The argument values. Passed through as is. The arguments are made available to an integration as a set of environment variables. Arguments in the config file cannot be capitalised and should use underscores to separate words. labels Optional. A YAML object where: Keys: The label name. Values: The defined label value. integration_user Optional. String with the name the agent will use for executing the integration binary. Default: depends on the usermode. By default, integrations are executed with the same user that's running the integration agent, nri-agent for privileged and unprivileged mode and root user for root mode. When present, the Infrastructure agent will execute the integration binary as the specified user. For example, to run the integration binary as the root user when running the agent in a usermode different than root, just add integration_user: root to the configuration file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 87.85443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "On-host integrations: Legacy configuration <em>format</em>",
        "sections": "Definition file <em>commands</em>",
        "body": " a naming <em>format</em> like INTEGRATION_NAME-definition.yml. This file provides descriptive information about the integration, such as: the version of the JSON protocol it supports, a list of <em>commands</em> it can execute, and arguments that it accepts. It lives in this directory: Linux: &#x2F;var&#x2F;db&#x2F;newrelic-infra&#x2F;newrelic"
      },
      "id": "61505613196a676ce3b70d9a"
    }
  ],
  "/docs/style-guide/writing-guidelines/hyperlinks": [
    {
      "sections": [
        "Monitor services running on Kubernetes",
        "Get started",
        "What you need",
        "Enable monitoring of services",
        "Get the config YAML for the integration",
        "Example configuration",
        "Configuration options for each integration",
        "Monitor services in our Kubernetes integration installed with Helm",
        "Learn more",
        "Manually configure service monitoring",
        "How the service-specific YAML config works",
        "Add a service YAML to the Kubernetes integration config",
        "Add multiple services to the same config"
      ],
      "title": "Monitor services running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "4c67f6272bda36eda4ad7883e89697a203aa2153",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes/",
      "published_at": "2021-10-07T10:06:32Z",
      "updated_at": "2021-10-07T10:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's Kubernetes integration you can monitor both Kubernetes and the services running on it, such as Cassandra, Redis, MySQL, and other supported services. Get started Our Kubernetes integration comes bundled with some of our on-host integrations (like Cassandra, MySQL, and Apache). This lets you get data for those supported services by adding a section to the Kubernetes integration's configuration, which lives as a ConfigMap inside a manifest. What you need Enable this feature for a service Details about how configuration works For an example of how to monitor Redis running on a Kubernetes PHP Guestbook, see this tutorial. What you need To monitor services running on Kubernetes, you only need a Kubernetes cluster running the Kubernetes integration, version 1.16.0 or higher (install | check version | update). We support the following services running on Kubernetes: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP Enable monitoring of services To enable our Kubernetes integration to monitor one or more services: Expand this dropdown and get the YAML snippets for the service(s) you want to monitor: Get the config YAML for the integration For the services you want to monitor, follow the links to GitHub to get the YAML snippets you'll need for the next step: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Add the snippet to the Kubernetes integration's ConfigMap, after the data: section: Example configuration This example shows the YAML config for the Apache integration ( highlighted ) added to the Kubernetes integration's config. Respect the indentation levels. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: apache-config.yaml: | --- # Run auto discovery to find pods with label \"app=apache\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the optional arguments: # --namespaces: Comma separated namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: apache integrations: - name: nri-apache env: # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/server-status?auto METRICS: 1 Copy You can add snippets for multiple services to the same config file. See an example. Depending on your environment, you may need or want to set additional config options. Expand the dropdown below for links to configuration options. Configuration options for each integration Select a service to see available config options: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Verify monitoring is enabled: Go to one.newrelic.com > Infrastructure, select Third party services, and then select the service's dashboard. You should see data being reported. Additional notes about enabling services: Enabling multiple services may use more resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources section. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes integration installed with Helm If you installed our Kubernetes integration using Helm, to monitor services you need to update the existing installation with the new configuration, which contains the services to monitor: helm upgrade --reuse-values -f values.yaml [RELEASE] [CHART] Copy If you use nri-bundle charts, you need to update the children's chart values. Find some examples here. Learn more More resources for learning about configuration: Learn technical details about how configuration works. Learn how to configure monitoring of multiple services with the same config file. See a step-by-step tutorial showing how to monitor a Redis service on Kubernetes. Manually configure service monitoring The enable procedure should be all you need to get monitoring working, but if you run into problems, understanding some technical details about configuration can be helpful. This section goes into more detail about how configuration works. For each service you wish to monitor, you must add a configuration file for that integration to our Kubernetes integration's configuration. This document will cover these subjects: How the service-specific configuration YAML snippet works Adding the service-specific YAML in the Kubernetes integration's config file Adding multiple services to the Kubernetes integration's config file How the service-specific YAML config works Our Kubernetes integration's configuration follows the ConfigMap format. Using a ConfigMap allows us to decouple the configuration for the integrations from the Kubernetes image. The other benefit is that a ConfigMap can be updated automatically without reloading the running container. Because the infrastructure agent uses YAML to configure its associated integrations, ConfigMaps are a good choice for storing YAML. (For more information on config file format, see the Integration config file format.) The Kubernetes integration image comes with an auto-discovery feature that simplifies the configuration of multiple instances of services using a single configuration file. For example, if you have several NGINX instances running, creating an NGINX integration configuration file for every instance would be hard to implement and hard to update. With our auto-discovery option, you can discover and monitor all your NGINX instances with a single configuration file. Each integration has its own specific configuration YAML. Our NGINX integration default config file looks like this: nginx-config.yml: | --- discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --port: Port used to connect to the kubelet. Default is 10255 # --tls: Use secure (TLS) connection # Custom Example: # exec: /var/db/newrelic-infra/nri-discovery-kubernetes --namespaces namespace1,namespace2 --port 10250 --tls # Default exec: /var/db/newrelic-infra/nri-discovery-kubernetes match: label.app: nginx integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}/status STATUS_MODULE: discover METRICS: 1 Copy The above config enables the following: Runs nri-discovery-kubernetes to query the data for the node we are currently on. Parses the data that comes back and looks for any Kubernetes pod that has a Kubernetes container with an app= label with value nginx. For any matches, it attempts to run the NGINX integration. The status URL is built from: The pod's IP address The status page is pulled from the label on K8s pod called status_url This automatic discovery works the same as the container auto-discovery used by the infrastructure agent. For more advanced options, see Container auto-discovery. Add a service YAML to the Kubernetes integration config It's best practice to configure enabled integrations alongside the Kubernetes integration configuration. This is easier than maintaining configuration files for every single service/integration instance. Below is an example of a Kubernetes integration's ConfigMap. The highlighted section shows where an integration configuration YAML (in this case, NGINX) is placed. For more information on discovery:, see Container auto-discovery for on-host integrations. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 Copy This configuration map can then be referenced in the DaemonSet, the same as the one that was generated via the command line. Make sure the namespace used is the same one used by the Kubernetes integration manifest. If you haven't changed it in the downloaded manifest file, the value is default. Add multiple services to the same config You can monitor several services using the same Kubernetes integration config file. To do this, add another integration configuration YAML to the same Kubernetes integration config file. Below is the Kubernetes config created in the last section, with a new section for the Cassandra integration's config (highlighted). --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 cassandra-configuration.yml: | --- # Run auto discovery to find pods with label \"app=cassandra\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: cassandra integrations: - name: nri-cassandra env: # Use the discovered IP as the host address HOSTNAME: ${discovery.ip} PORT: 7199 USERNAME: cassandra PASSWORD: cassandra METRICS: 1/mark Copy The Kubernetes integration config is now set up to monitor these two services. Additionally, depending on your environment, there may be some additional service-specific configuration you must do. When you've completed configuration, our infrastructure agent looks for any pod with a label cassandra and runs the integration against it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 120.11674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Link</em> apps and services"
      },
      "id": "6044e50c196a676012960f35"
    },
    {
      "sections": [
        "API tutorial template",
        "Introduction (this heading will not be visible)",
        "Optional: Provide an overview for complex processes",
        "Provide a procedure to accomplish the task",
        "Tip",
        "Step 1. Do something...",
        "If needed: Step 2. Do something else...",
        "If needed: Step 3. Do something else...",
        "Last step. Verify that the task was completed...",
        "Optional: Do something else with the API",
        "Optional: Large example code block",
        "Code block example",
        "Optional: Troubleshooting"
      ],
      "title": "API tutorial template  ",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "a3fb036bc32f2dbc39c252acc9306e5ae0d5b7bb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/api-tutorial-template/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-09-14T09:16:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content link in the Page tools box. Delete all content up to Introduction (this heading won't be visible). For the doc title (the field at top of page): Doc should be named in a practical, use-case-focused way. Example: Add custom attributes to transactions Introduction (this heading will not be visible) Provide a brief explanation of what this document will teach customers, and why it is valuable for customers to know how to do that. Focus on the value the API provides to the customers and mention specific, common use cases. Any relevant notes about support/compatability should go here, too. Here's an example from the Java API asynchronous tutorial doc: New Relic for Java includes an API to instrument asynchronous activity. For supported frameworks, the Java agent usually instruments async work automatically. However, the async API can be useful for adding more detail to your data. This document provides examples of using tokens and segments to instrument your app. Optional: Provide an overview for complex processes This is an optional section for complicated tutorials that involve either using several methods in one procedure or that have different alternate steps you can take to achieve similar results. This section can link to lower-down sections to allow users to skip around as needed. For simple tutorials, this section isn't necessary. For an example, see this section of the Java async tutorial. Provide a procedure to accomplish the task Tell the user how to accomplish the task, and link to the methods necessary to accomplish that task. As much as possible, we're looking to describe tasks in \"procedures\" (procedure is tech writer jargon for a series of numbered steps). This may be tough to do for fairly open-ended/variable tasks, but it will usually be possible to chunk the content at a fairly high-level to make it into a procedure. Along the way, explain what the importance of the procedure step is, and how one might verify that the step was done correctly. For code samples, avoid using large chunks of code. Instead, use smaller pieces of code and give context for how they are being used. (If you think a large app code example would be helpful, place that later in the doc in the Example section.) Tip For an example of an open-ended task segmented into procedural chunks, see the Asynchronous doc section Connecting async threads. For another example, see this TomCat GAE Flex procedure. Base your procedure on the simple structure below. Tech writers will edit your content to match our style and formatting requirements: Step 1. Do something... Methods and example code to implement the first step. For each step, if applicable, indicate the significance of that step (why it's important) and how the user might verify that the step was done correctly (for example, something showing up in UI, or running a verification test of some sort). If needed: Step 2. Do something else... Methods and example code to implement step 2. If needed: Step 3. Do something else... Methods and example code to implement step 3. Last step. Verify that the task was completed... Explain how a user would know they'd completed the task correctly. In particular, how would the user find the new change or data in the New Relic UI. What NR products and pages would the change be noticed on? If new data shows up in Insights, what event types can it be found under? Optional: Do something else with the API Same as above. Make as many headings and separate procedures as needed. Optional: Large example code block If you think a large app code example would be useful, place here. Within any code block, explain all New Relic functions/methods, not just the main methods. Instead of in-line comments, consider using highlighted sections underneath the code block to give additional context. Here's an example: Code block example The following code example shows a segment starting in the storeItem method to measure how long the Lambda statement is waiting in the thread pool. To stop timing the segment, you must call either .end() or .ignore(). If you don't want to report the segment as part of its parent transaction, call .ignore(). Otherwise, to report the segment as part of its parent transaction, call .end(). private void storeItem(long id) { Segment segment = NewRelic.getAgent().getTransaction(). startSegment(\"storeItem\") ; segment. reportAsExternal (DatastoreParameters .product(\"H2\") .collection(null) .operation(\"insert\") .instance(\"localhost\", 8080) .databaseName(\"test\") .build()); // fire and forget DB_POOL.submit(() -> { segment.end(); insertData(id); }); } Copy The agent API calls in this sample are: startSegment(...): Begins the segment that will time the code. For more on this method, see the Javadoc. reportAsExternal(DatastoreParameters()): Associates the time with a datastore external call This will show up in APM with datastore data. For more information, see reportAsExternal API. segment.end(): Stops timing this segment. For more on this method, see the Javadoc. Optional: Troubleshooting Optional area for any common errors or troubleshooting tips.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.77366,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "API writing <em>guidelines</em>",
        "body": "This document is a template for an API tutorial document: Please skim the entire template first to understand the expected structure for this type of doc. Then, clone this doc using the Clone content <em>link</em> in the Page tools box. Delete all content up to Introduction (this heading won&#x27;t be visible"
      },
      "id": "60441b4a64441f7766378f09"
    },
    {
      "sections": [
        "apiStyleGuidelines (Example agent API)",
        "Syntax",
        "Requirements",
        "Description",
        "Tip",
        "Parameters",
        "Return values",
        "Examples",
        "URL guidelines",
        "Title guidelines",
        "Short title guidelines",
        "Syntax guidelines",
        "Important"
      ],
      "title": "apiStyleGuidelines (Example agent API)",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "API writing guidelines"
      ],
      "external_id": "41eee9dfacd933b49935d7bd4d32cb76476c29ed",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/article-templates/apistyleguidelines-example-agent-api/",
      "published_at": "2021-10-07T17:38:22Z",
      "updated_at": "2021-03-10T23:41:36Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the \"View all methods\" page. Requirements Agent version 1.2.3.4 or higher. Additional requirements on their own line (do not use bullets). Do not use any callouts. If there are no special requirements, write: Compatible with all agent versions. Description Describe the behavior of the call with as much detail as possible. Do not describe what individual parameters do except in broad strokes; details of parameters and call variants belong under the Parameters heading. Similarly, do not describe return values. When cross-referencing another API call, format its name with code blocks, and include parentheses () like this: anotherCoolMethod(). Tip You can include callouts, but use discretion. These pages are already visually busy. Parameters If there are no parameters, leave this section blank. If there is only one call variant, do not include a syntax block in this section. Parameter Description newrelic.apiStyleGuidelines(data type $parameter_name[, integer $optional_param]) Copy $parameter_name data type Required. Brief description of parameter. $optional_param integer Optional. Brief description of parameter. newrelic.apiStyleGuidelines(data type $parameter_name, array $different_param) Copy $parameter_name data type Required. Brief description of parameter. $different_param array Required. Brief description of parameter. $third_param string Required. Brief description of parameter. Return values What does this call return, and in what circumstances? Are there any things we expect customers to do with that return value? If the call does not return anything, leave this section blank. Examples This section documents rules for oddballs that aren't self-documenting. The rest of the examples are embedded within the page itself. In general, this page is intended for style reference. For examples of how to write good API method pages, check out our existing API docs, such as the PHP API. URL guidelines For the doc's URL: Manually edit the URL slug to remove the agent name. Where the API call does not already include separators (as in newrelic_awesome_call), separate the bits with hyphens -. For example: https://docs.newrelic.com/docs/new-relic-only/advanced-style-guide/writing-guidelines/api-style-guidelines Copy Title guidelines For the doc's title: Include the method name and the agent name in parentheses. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses () in the call itself. For example: apiStyleGuidelines (Example agent API) Copy Short title guidelines For the doc's short title: Include only the method name. Do not include newrelic. prefixes unless they are integral to the call name (as in the PHP agent). Do not include parentheses (). Adjust if necessary to fit on a single line in the category's sidebar. For example: apiStyleGuidelines Copy Syntax guidelines Important The Python and iOS agents use their own guidelines. For those guidelines, see the existing methods in those languages. Document each variant of a call on its own line. Do not use any formatting except italicizing the data type. Wrap optional parameters (including the comma separator) in square brackets []. Indicate the variable portion by prefacing it with a dollar sign $. If the call must be prefixed with newrelic. or similar, include that in the syntax. Optional: Include the return value, if that seems important for your particular agent. If you do, follow language conventions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 67.22411,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "URL <em>guidelines</em>",
        "tags": "API writing <em>guidelines</em>",
        "body": "Syntax newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name[, integer $optional_param]) newrelic.apiStyle<em>Guidelines</em>(data type $parameter_name, array $different_param, string $third_param) Copy Briefly describe the call. Ideally, one line or less on the &quot;View all methods&quot; page. Requirements Agent"
      },
      "id": "60441b8d28ccbc0ab22c60b3"
    }
  ],
  "/docs/style-guide/writing-guidelines/levels-headings": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/get-started/introduction-style-guide/",
      "sections": [
        "Introduction to the style guide",
        "Organize your doc to make it easier to read",
        "Use action-oriented titles",
        "Start the document with an introductory paragraph",
        "Keep documents short",
        "Use the New Relic voice",
        "Change doc titles and anchors",
        "Create and edit categories",
        "Start writing and editing docs"
      ],
      "published_at": "2021-10-07T11:02:41Z",
      "title": "Introduction to the style guide",
      "updated_at": "2021-04-12T11:26:22Z",
      "type": "docs",
      "external_id": "b0bfbe0b3791c4feb00fe86a41e49312cd9e82cd",
      "document_type": "page",
      "popularity": 1,
      "body": "We've written these guidelines to make it easier for you to contribute to our docs, as well as to give you some insight into how we think about good technical writing. We, the Tech Docs team, rely on your expertise to keep New Relic's documentation updated and useful. Thank you for your willingness to share your knowledge! Our style guide focuses on style and usage that's particular to our site. Our site follows American English conventions. For topics that aren't covered, please refer to the Microsoft Writing Style Guide (for guidelines on technical terminology) or the Chicago Manual of Style (for general writing and editing guidelines). Organize your doc to make it easier to read Consider these organization guidelines when thinking about the order of information in a doc. By following these guidelines, you'll make it easier for readers to skim and find what they need. How to organize information Comments Separate what and why from how. Define any necessary prerequisites, policies, or background information (the what and the why) before you step through the how (step-by-step procedures). Examples: Explain what the feature is and why it matters before telling readers how to use it. Describe any limitations with user permissions or subscription levels that would prevent them from using the feature. If the feature is available for any user or subscription level, don't bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting a procedure that they have everything they need. Front-load directions with context. Make sure readers know where they need to be, before telling them what to do. In general, use (select an app) to describe what users select from the product index. Examples: Go to one.newrelic.com > Explorer > (select an app or service). Select (account dropdown) > User preferences. On the command line, type gitk. Also, structure steps by front-loading context from the user's point of view. For example, instead of \"Go to x to do y,\" structure the step as \"To do y, go to x.\" Separate requirements from options. Example: Type the Email you use to sign in and to receive information from New Relic. Optional: Type additional user emails, separated by commas. Follow the \"five to nine\" guideline. Depending on the topic, organize the information so there is a maximum of five to nine chunks of information. For example, readers may start to get lost or overwhelmed after about five h2 sections or seven steps into a procedure. If you have more than nine h2 sections or steps, you might need to create an additional doc or procedure. Other organization tools to consider: Levels of headings Lists Collapsers Callouts Tables Code examples For more help section Use action-oriented titles Wherever possible, give your document or h2 heading a task- or action-oriented title. Focus on what users are trying to accomplish or the problem they're trying to solve. Use present-tense verbs, rather than \"-ing\" verbs. Quality Title example Bad The query history Okay View query history Good Query history: Create and edit NRQL queries Start the document with an introductory paragraph Unless the document is less than a single screen in length, begin with a brief paragraph that introduces the topic or summarizes the important points. Not sure where to start? Try writing all the content for your document first, and then add the introduction to the top to summarize your key points. Or use the introduction to expand on the text in your metaDescription in the metadata. Keep documents short The amount of content needed can help you decide whether you need one or more documents for the topic. If all of the document's contents apply directly to the title, then everything belongs in the same document. If several related sections could be logically split into individual documents, and the overall length of your document is more than about two screenfuls, split those sections into other documents. Be sure to include links to the related contents. If a large document needs to be broken into multiple smaller documents, consider whether they might be best grouped together in their own sub-category. Use the New Relic voice We strive for a voice that's approachable, expert, and visionary. Check out our voice guidelines for how to write content with these qualities. And keep in mind these essential writing tips that apply to any type of documentation. Guidelines Comments Be clear and direct. Remember to: Use present tense. Use active voice; avoid passive voice. Tell users what to do, not what they \"should\" do. If absolutely necessary, tell users what not to do in situations where unexpected results may occur. Whenever possible, provide an alternative suggestion when telling users what not to do. Example: Using active voice with an alternative suggestion for what not to do Do not use your config file to change this setting, because this could affect other processes. Instead, go to one.newrelic.com > APM > (select an app or service) > Settings > Application. Write to aid localization and translation. Do not use euphemisms, idioms, jargon, or slang. Use the same terms and wording consistently. If you need to include an abbreviation or acronym, spell it out the first time it appears in the document. Always take a moment to ask yourself whether people will really understand the terms you are using in the way you're using them. Change doc titles and anchors Because changes to doc titles, anchors, and redirects can break links to other docs, please create an issue to request these types of changes and we'll help you out with that. Create and edit categories Because changes to categories can affect large groups of docs at once, please create an issue to request these types of changes and we'll help you out with that. Start writing and editing docs You are ready to start writing and editing New Relic docs! To learn the steps for basic docs, see Create and edit content. To learn how to create and publish release notes, see Create release notes. To make it even easier to start a new doc, use templates.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 440.02875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " it. Describe any limitations with user permissions or subscription <em>levels</em> that would prevent them from using the feature. If the feature is available for any user or subscription <em>level</em>, don&#x27;t bother to say so. Provide a roadmap for what users will be able to accomplish, so they know before starting"
      },
      "id": "60415293e7b9d262f32a07d7"
    },
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-10-08T04:44:25Z",
      "updated_at": "2021-09-13T22:05:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.69057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Headings</em> (H2s)",
        "body": " that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they&#x27;ve found the right doc. It provides a short, readable overview of the doc&#x27;s contents. <em>Headings</em> (H2s) Check that: Heading names are concise, yet provide information that helps readers"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-10-07T02:07:33Z",
      "updated_at": "2021-09-14T05:24:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.2241,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Use sentence case in <em>headings</em>",
        "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document&#x27;s title, <em>headings</em>, products, features, and other elements"
      },
      "id": "60421e50196a67d785a83d97"
    }
  ],
  "/docs/style-guide/writing-guidelines/more-help-section": [
    {
      "sections": [
        "Okta SCIM/SSO application configuration",
        "Requirements",
        "Step 1. Create authentication domain and enable SCIM",
        "Step 2. Set up Okta's New Relic app",
        "Step 3. Configure provisioning",
        "Step 4. Assign users and groups",
        "Assignments tab",
        "Push groups tab",
        "Step 5. Manage user type",
        "Step 6. Assign access grants",
        "Step 7. Configure SAML SSO",
        "Additional considerations",
        "Moving users between groups"
      ],
      "title": "Okta SCIM/SSO application configuration",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "Automated user management"
      ],
      "external_id": "7a00399a6ce11aaa2cb52046f994a80f5986c0e4",
      "image": "https://docs.newrelic.com/static/3f3318e1dc8c9049231c207a7b4e5c54/c1b63/okta-add-user-type-to-profile.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts/automated-user-management/okta-scimsso-application-configuration/",
      "published_at": "2021-10-07T19:07:02Z",
      "updated_at": "2021-10-07T19:07:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our automated user management (AUM) allows allows you to import and configure your New Relic users from your identity provider via SCIM. This guide provides Okta specific details on how to configure the New Relic Okta SCIM/SSO application. Requirements Before using this guide, read our AUM requirements. Note that these instructions require going back and forth between your identity provider and New Relic. Step 1. Create authentication domain and enable SCIM To get to the New Relic authentication domain UI: From one.newrelic.com, click the account dropdown, click Organization and access, and then click Authentication domains. If you don't already have one, create a new authentication domain for your SCIM-provisioned users by clicking + Add new. For that authentication domain, under Source of users, select SCIM. Copy and save the API token for later use. Note that this will be shown only once. Step 2. Set up Okta's New Relic app Next, set up Okta's New Relic SCIM/SSO application: Go to okta.com/ and sign in with an account that has administrator permissions. From the Okta home page, click on Admin. From the Okta admin Dashboard, choose the Applications page. Click Browse app catalog and search for \"New Relic by organization\" (not \"New Relic by account\") and choose that from the results. From the New Relic by Organization page, click on Add. From the Add New Relic by organization page, check the two Application visibility \"Do not display...\" checkboxes and click on Done. We will make the application visible later after configuration is complete and provisioning has begun. Step 3. Configure provisioning Configure Okta's New Relic SCIM/SSO application to automatically provision your users to New Relic: From the app, click on the Provisioning tab. From the Integration form, click on Configure API integration. Check the Enable API integration checkbox. Take the API token you saved in Step 1 and input it in the Okta New Relic app's API token field. Optional: click on Test API credentials to verify a SCIM connection can be established to New Relic. If a connection can be established, a success message is displayed. If a connection was not established, re-enter the API Token and try the test again. Click Save. Note that the save process does a test of the API credentials. If a connection is not established to New Relic, the save will fail. On the newly displayed To App form, click on Edit. Check the Enable checkbox in the Create users, Update user attributes, and Deactivate users sections. Click Save. Step 4. Assign users and groups Next, you'll assign users in Okta's New Relic application. Assigning users is done using two different tabs in the app. We recommend having your New Relic users selected on the Assignments tab and their associated groups selected on the Push groups tab. Assignments tab In the app, click on the Assignments tab. From the Assignments form, click on Assign. From the pop up menu, click on Assign to groups. From the Assign ... to groups form, click on Assign for the group you wish to assign to the application. Highly recommended: Set your users' time zones in Okta. The time zone affects how date/times for that user are shown in New Relic. Users without a time zone configured will be shown in UTC time in New Relic. Time zone is specified in IANA Time Zone database format, also known as the \"Olson\" time zone database format (e.g., \"America/Los_Angeles\"). There are several ways in Okta to assign users' time zone, so consult the Okta docs for more information if needed. Here is one way to do this in the Assignments tab: In the Time zone field, enter the default time zone for members of the group. Click on Save and go back. Repeat the steps to add a group until all desired groups have been assigned to the application. Click Done. Push groups tab In the app, click on the Push groups tab. From the Push groups form, click on Push groups. From the pop up menu, click on Find groups by name. From the Push groups to... form, in the search field enter the first few characters of the name of the group you want to send to New Relic. Leave the Push group memberships immediately checkbox checked. Click on your group in the pop up search results list. In the Match result & push action section, No match found should be displayed, meaning that the group does not yet exist at New Relic. Leave the selector set to Create group and leave the default name for the group. The intent here is to have a group of the same name created at New Relic. If this is the last group you wish to send to New Relic, click on Save. Otherwise, if you have more groups to configure, click on Save & add another and repeat the steps to add a group. When you've added one or more groups, you should be able to see the users you've added by going to the User management UI page. Step 5. Manage user type If your organization is on New Relic One pricing, the count of your full users is a billing factor. To change some of your users to free basic users, you have two choices: Manage user type from New Relic using the User management UI, OR Manage user type from Okta (described below). To manage your users' user type from Okta: Go to the New Relic authentication domain UI and click Enable Manage user type with SCIM. Note that when this is enabled, you can’t manage user type from the New Relic UI and can only manage it from Okta. Go into your Okta instance. The rest of these instructions are done from Okta. Next, you'll configure Okta to be able to send a new attribute nrUserType. Steps: Go to the Profile editor. In the Attributes section, click Add attribute. Set your settings to match the screenshot below (except for the variable name, which is created automatically). The only two fields that must match exactly are External name and External namespace. The value for External namespace must be urn:ietf:params:scim:schemas:extension:newrelic:2.0:User Next, you'll configure your Okta user profile to have this field. Steps: In the Profile editor, go to Users and click the User (default) profile. Add a new New Relic user type attribute to that profile (see Okta user profile instructions). How you set this will depend on your own setup and preferences for defining user type. Note that the expected values for user type are Basic user and Full user. Below is an example with information filled in. In the People section, define the user type for your users. How you do this will depend on your setup and preferences. For example, you may choose to set this manually by setting each user’s user type, or you may use Okta to manage these in bulk. Next, you’ll set up mapping for that attribute. Steps: In the app's Provisioning section, click Unmapped attributes. Go into edit mode for the unmapped New Relic user type attribute. Configure it based on how you want to set the user type. To learn about why you'd set them as basic users or full users, see User type. Learn more about Okta attribute mappings. Step 6. Assign access grants Once these steps are completed, you're able to see your users in New Relic by going to the User management UI. Now that your users are present in New Relic, you must grant them access to specific roles on specific accounts. If this is not done, your users don't yet have access to New Relic. To learn how to do this, see: How access grants work The user management tutorial Step 7. Configure SAML SSO To enable SAML SSO, see the SAML instructions. Additional considerations In this section we discuss other important things to know when using the New Relic SCIM/SSO application. This section includes tips to work around potential issues that could cause undesired results when integrating between Okta and New Relic. Moving users between groups When moving a user between groups, you must manually synchronize the old group's membership with New Relic. This is because Okta does not send a SCIM request to remove a user from a group. So, the admin needs to push the old group's membership to New Relic manually to inform New Relic that the user is no longer a member of the old group. Here are the steps to manually synchronize a group's membership: From the New Relic SCIM/SSO application page, click on the Push groups tab. From the Push groups form, open the pick list on the desired group's button under the Push Status column. From the displayed pick list on the button, click Push now. This causes an immediate synchronization of the group's membership with New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 69.014694,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " is specified in IANA Time Zone database format, also known as the &quot;Olson&quot; time zone database format (e.g., &quot;America&#x2F;Los_Angeles&quot;). There are several ways in Okta to assign users&#x27; time zone, so consult the Okta docs for <em>more</em> information if needed. Here is one way to do this in the Assignments tab"
      },
      "id": "6043f5cae7b9d2758b579a0c"
    },
    {
      "sections": [
        "Monitor services running on Kubernetes",
        "Get started",
        "What you need",
        "Enable monitoring of services",
        "Get the config YAML for the integration",
        "Example configuration",
        "Configuration options for each integration",
        "Monitor services in our Kubernetes integration installed with Helm",
        "Learn more",
        "Manually configure service monitoring",
        "How the service-specific YAML config works",
        "Add a service YAML to the Kubernetes integration config",
        "Add multiple services to the same config"
      ],
      "title": "Monitor services running on Kubernetes",
      "type": "docs",
      "tags": [
        "Integrations",
        "Kubernetes integration",
        "Link apps and services"
      ],
      "external_id": "4c67f6272bda36eda4ad7883e89697a203aa2153",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/kubernetes-integration/link-apps-services/monitor-services-running-kubernetes/",
      "published_at": "2021-10-07T10:06:32Z",
      "updated_at": "2021-10-07T10:06:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With New Relic's Kubernetes integration you can monitor both Kubernetes and the services running on it, such as Cassandra, Redis, MySQL, and other supported services. Get started Our Kubernetes integration comes bundled with some of our on-host integrations (like Cassandra, MySQL, and Apache). This lets you get data for those supported services by adding a section to the Kubernetes integration's configuration, which lives as a ConfigMap inside a manifest. What you need Enable this feature for a service Details about how configuration works For an example of how to monitor Redis running on a Kubernetes PHP Guestbook, see this tutorial. What you need To monitor services running on Kubernetes, you only need a Kubernetes cluster running the Kubernetes integration, version 1.16.0 or higher (install | check version | update). We support the following services running on Kubernetes: Apache (does not report inventory data) Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ (does not report inventory data) Redis SNMP Enable monitoring of services To enable our Kubernetes integration to monitor one or more services: Expand this dropdown and get the YAML snippets for the service(s) you want to monitor: Get the config YAML for the integration For the services you want to monitor, follow the links to GitHub to get the YAML snippets you'll need for the next step: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Add the snippet to the Kubernetes integration's ConfigMap, after the data: section: Example configuration This example shows the YAML config for the Apache integration ( highlighted ) added to the Kubernetes integration's config. Respect the indentation levels. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: apache-config.yaml: | --- # Run auto discovery to find pods with label \"app=apache\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the optional arguments: # --namespaces: Comma separated namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: apache integrations: - name: nri-apache env: # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/server-status?auto METRICS: 1 Copy You can add snippets for multiple services to the same config file. See an example. Depending on your environment, you may need or want to set additional config options. Expand the dropdown below for links to configuration options. Configuration options for each integration Select a service to see available config options: Apache Cassandra Couchbase Elasticsearch HAProxy HashiCorp Consul JMX Kafka Memcached MongoDB MySQL NGINX PostgreSQL RabbitMQ Redis SNMP Verify monitoring is enabled: Go to one.newrelic.com > Infrastructure, select Third party services, and then select the service's dashboard. You should see data being reported. Additional notes about enabling services: Enabling multiple services may use more resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources section. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes integration installed with Helm If you installed our Kubernetes integration using Helm, to monitor services you need to update the existing installation with the new configuration, which contains the services to monitor: helm upgrade --reuse-values -f values.yaml [RELEASE] [CHART] Copy If you use nri-bundle charts, you need to update the children's chart values. Find some examples here. Learn more More resources for learning about configuration: Learn technical details about how configuration works. Learn how to configure monitoring of multiple services with the same config file. See a step-by-step tutorial showing how to monitor a Redis service on Kubernetes. Manually configure service monitoring The enable procedure should be all you need to get monitoring working, but if you run into problems, understanding some technical details about configuration can be helpful. This section goes into more detail about how configuration works. For each service you wish to monitor, you must add a configuration file for that integration to our Kubernetes integration's configuration. This document will cover these subjects: How the service-specific configuration YAML snippet works Adding the service-specific YAML in the Kubernetes integration's config file Adding multiple services to the Kubernetes integration's config file How the service-specific YAML config works Our Kubernetes integration's configuration follows the ConfigMap format. Using a ConfigMap allows us to decouple the configuration for the integrations from the Kubernetes image. The other benefit is that a ConfigMap can be updated automatically without reloading the running container. Because the infrastructure agent uses YAML to configure its associated integrations, ConfigMaps are a good choice for storing YAML. (For more information on config file format, see the Integration config file format.) The Kubernetes integration image comes with an auto-discovery feature that simplifies the configuration of multiple instances of services using a single configuration file. For example, if you have several NGINX instances running, creating an NGINX integration configuration file for every instance would be hard to implement and hard to update. With our auto-discovery option, you can discover and monitor all your NGINX instances with a single configuration file. Each integration has its own specific configuration YAML. Our NGINX integration default config file looks like this: nginx-config.yml: | --- discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --port: Port used to connect to the kubelet. Default is 10255 # --tls: Use secure (TLS) connection # Custom Example: # exec: /var/db/newrelic-infra/nri-discovery-kubernetes --namespaces namespace1,namespace2 --port 10250 --tls # Default exec: /var/db/newrelic-infra/nri-discovery-kubernetes match: label.app: nginx integrations: - name: nri-nginx env: STATUS_URL: http://${discovery.ip}/status STATUS_MODULE: discover METRICS: 1 Copy The above config enables the following: Runs nri-discovery-kubernetes to query the data for the node we are currently on. Parses the data that comes back and looks for any Kubernetes pod that has a Kubernetes container with an app= label with value nginx. For any matches, it attempts to run the NGINX integration. The status URL is built from: The pod's IP address The status page is pulled from the label on K8s pod called status_url This automatic discovery works the same as the container auto-discovery used by the infrastructure agent. For more advanced options, see Container auto-discovery. Add a service YAML to the Kubernetes integration config It's best practice to configure enabled integrations alongside the Kubernetes integration configuration. This is easier than maintaining configuration files for every single service/integration instance. Below is an example of a Kubernetes integration's ConfigMap. The highlighted section shows where an integration configuration YAML (in this case, NGINX) is placed. For more information on discovery:, see Container auto-discovery for on-host integrations. --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 Copy This configuration map can then be referenced in the DaemonSet, the same as the one that was generated via the command line. Make sure the namespace used is the same one used by the Kubernetes integration manifest. If you haven't changed it in the downloaded manifest file, the value is default. Add multiple services to the same config You can monitor several services using the same Kubernetes integration config file. To do this, add another integration configuration YAML to the same Kubernetes integration config file. Below is the Kubernetes config created in the last section, with a new section for the Cassandra integration's config (highlighted). --- apiVersion: v1 kind: ConfigMap metadata: name: nri-integration-cfg namespace: default data: nginx-config.yml: | --- # Run auto discovery to find pods with label \"app=nginx\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: nginx integrations: - name: nri-nginx env: # If you're using ngx_http_api_module be certain to use the full path up to and including the version number # Use the discovered IP as the host address STATUS_URL: http://${discovery.ip}/status # Comma separated list of ngx_http_api_module, NON PARAMETERIZED, Endpoints # endpoints: /nginx,/processes,/connections,/ssl,/slabs,/http,/http/requests,/http/server_zones,/http/caches,/http/upstreams,/http/keyvals,/stream,/stream/server_zones,/stream/upstreams,/stream/keyvals,/stream/zone_sync # Name of Nginx status module OHI is to query against. discover | ngx_http_stub_status_module | ngx_http_status_module | ngx_http_api_module STATUS_MODULE: discover METRICS: 1 cassandra-configuration.yml: | --- # Run auto discovery to find pods with label \"app=cassandra\" # https://docs.newrelic.com/docs/integrations/host-integrations/installation/container-auto-discovery discovery: command: # Run discovery for Kubernetes. Use the following optional arguments : # --namespaces: Comma separated list of namespaces to discover pods on # --tls: Use secure (TLS) connection # --port: Port used to connect to the kubelet. Default is 10255 exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls match: label.app: cassandra integrations: - name: nri-cassandra env: # Use the discovered IP as the host address HOSTNAME: ${discovery.ip} PORT: 7199 USERNAME: cassandra PASSWORD: cassandra METRICS: 1/mark Copy The Kubernetes integration config is now set up to monitor these two services. Additionally, depending on your environment, there may be some additional service-specific configuration you must do. When you've completed configuration, our infrastructure agent looks for any pod with a label cassandra and runs the integration against it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.52673,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Learn <em>more</em>",
        "body": " <em>more</em> resources than what is set in the resource limits of the Kubernetes integration config file. If this becomes an issue, raise the limit in the resources <em>section</em>. The Kubernetes integration does not automatically update. For best results, regularly update. Monitor services in our Kubernetes"
      },
      "id": "6044e50c196a676012960f35"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/dropdown-section/",
      "sections": [
        "DropdownSection",
        "Usage",
        "Props",
        "Type definitions",
        "Cursor"
      ],
      "published_at": "2021-10-10T01:49:50Z",
      "title": "DropdownSection",
      "updated_at": "2021-09-30T18:32:11Z",
      "type": "developer",
      "external_id": "013f52f99c588b0e1205778bf08efcece91c363c",
      "document_type": "page",
      "popularity": 1,
      "body": "Usage import { DropdownSection } from 'nr1' Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed inside (or returned by the render callback) are of type <DropdownItem>. The recommendation is to use the render callback when a large number of items is provided, since the item list will be virtualized by the component, thus increasing the performance. classNamestring Appends class names to the component. Should be used only for positioning and spacing purposes. itemsarray Items to render, in the shape of a list of objects. Usually, each item in the items array contains the required data to generate the corresponding <DropdownItem>. This prop is required when rendering items with the render callback (function as children). onLoadMorefunction Callback fired when more items must be loaded. This happens when you're lazy loading the items and the items that are about to render cannot be found in the items array. This callback should be used to fetch/load the missing items from the backend or other sources. The returned Promise should be resolved once item data has finished loading. It will be used to determine when to refresh the list with the newly-loaded data. This callback may be called multiple times in reaction to a single scroll event. function ( cursor : Cursor Items to load. ) rowCountnumber Number of rows. By default it's equal to length of array passed in the items prop. You should specify the rowCount when you know the total number of items but you want to lazy load them while scrolling. styleobject Inline style for custom styling. Should be used only for positioning and spacing purposes. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and e2e tests. titlestring DEFAULT \"\" Section title. Type definitions Cursor { startIndex : number, First index of the range of items to load. stopIndex : number, Last index of the range of items to load. }",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.50804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "Usage import { Dropdown<em>Section</em> } from &#x27;nr1&#x27; Copy Props childrenrequirednode|function This component can render either declaratively, by directly passing a set of children or virtualized, by passing a render callback (function as children). The only items allowed inside (or returned by the render"
      },
      "id": "6091f874e7b9d283a05068f0"
    }
  ],
  "/docs/style-guide/writing-guidelines/pricing-language-guidelines": [
    {
      "sections": [
        "Query and alert on billing/usage data",
        "Available data types",
        "Query examples",
        "Data usage queries",
        "Daily data usage",
        "Daily usage by source",
        "Metrics ingest by source",
        "Month-to-date data usage",
        "Month-to-date estimated data cost",
        "User count queries",
        "Month-to-date full users",
        "Projected monthly full user count",
        "Count full users and basic users",
        "Set usage alerts",
        "Caution",
        "Ingested gigabytes exceed a fixed value",
        "Usage exceeds fixed threshold for GBs",
        "Usage exceeds fixed threshold for users",
        "Usage exceeds fixed threshold for estimated cost",
        "Available attributes"
      ],
      "title": "Query and alert on billing/usage data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "a214c27cab73c790ac6ce947a0c189db9677d215",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-users/usage-queries-alerts/",
      "published_at": "2021-10-07T07:16:33Z",
      "updated_at": "2021-10-07T07:16:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For accounts on our New Relic One pricing plan, we provide a View your usage UI for understanding billing-related usage and a Manage your data UI for managing billing-related data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert conditions to get notifications about changes in your usage. Note that account hierarchy may affect queried data. See Account structure. Available data types Usage data is attached to these events: NrConsumption records usage every hour, and is the equivalent of \"real-time\" usage. Use this event to observe usage trends over time. NrMTDConsumption generates aggregate values from the NrConsumption event. Use this event to see usage or estimated cost for a billing period. NrUsage records usage every hour and is used to see usage reported per product. To see changes made to your account (for example, user management changes), you can query NrAuditEvent. Query examples The View your usage UI displays your data usage and billable user count. If you need more detail than that UI provides, you can use these NRQL queries. For definitions of some of the attributes used in these queries, see Attributes. Data usage queries Here are some data usage query examples: Daily data usage This query totals your billable ingested data, and displays a daily value for the past three months: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago TIMESERIES 1 day Copy Daily usage by source This query totals your billable ingested data, and displays a daily value for the past three months faceted by the source: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago FACET usageMetric TIMESERIES 1 day Copy Metrics ingest by source This query breaks down Metric data by the top ten metric names. You could also facet by appName or host to adjust the analysis. FROM Metric SELECT bytecountestimate()/10e8 as 'GB Estimate' SINCE '2021-04-01' UNTIL '2021-04-08' FACET metricName LIMIT 10 TIMESERIES 1 day Copy Month-to-date data usage This query shows the current full user count. In other words, it shows how much you'd be billed for your data for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE this month Copy Month-to-date estimated data cost This query shows the estimated cost of your ingested data: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy User count queries Here are some user-related query examples. For details on how users are counted, see User count calculations. Month-to-date full users This query shows the billable full users for the month. In other words, it shows how much you'd be billed for your users for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(usersBillable) SINCE this month Copy This query shows how many full users were counted by hour. This is useful for seeing how the full user count changed over time. from NrConsumption SELECT max(FullUsers) SINCE 10 days ago TIMESERIES 1 hour Copy Projected monthly full user count This query shows a projected count of monthly users. This query would not be good for using in a dashboard; it requires values based on a) the days remaining in the month, b) the start of the month. Here's an example querying the projected end-of-month count with 10 days left in that month: FROM NrMTDConsumption SELECT predictLinear(FullUsers, 10 days) SINCE '2020-09-01' Copy Count full users and basic users The usage UI shows the count of full users and basic users. The query used is: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric Copy To see the count of full and basic users over time: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric TIMESERIES 1 hour Copy Set usage alerts To help manage your billable data, you can set alerts to notify you of unexpected increases in usage. Learn how to create alerts with NRQL queries here. Caution When creating alert conditions, you should use the Event Timer method, which works very well with infrequent data. Here are some NRQL alert condition examples. For attribute definitions, see Attributes. Ingested gigabytes exceed a fixed value This query will create an alert when your hourly usage exceeds a fixed value: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy If you have multiple child accounts, you may want to set threshold alerts for a specific subaccount: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' AND consumingAccountId = YOUR_CHILD-ACCOUNT_ID Copy Usage exceeds fixed threshold for GBs This query will create an alert when your usage exceeds fixed monthly threshold for GBs: FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy Usage exceeds fixed threshold for users This query will create an alert when your usage exceeds fixed monthly threshold for billable users: FROM NrMTDConsumption SELECT latest(usersBillable) Copy Usage exceeds fixed threshold for estimated cost This query will create an alert when your usage exceeds fixed threshold for estimated cost: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy Available attributes Below are some of the important attributes attached to usage events. Attribute Description productLine The category of usage. There are four options: DataPlatform, FullStackObservability, IncidentIntelligence, or ProactiveDetection. For more details about these categories, see New Relic platform. metric Consolidates multiple categories of usage into a single metric. Helpful when faceting by productLine. consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. estimatedCost Calculates a cost estimate based on usage and metric cost. This is an estimate of costs to date, not your monthly invoice. For more attributes, see the data dictionary.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.14804,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query and alert on <em>billing</em>&#x2F;usage data",
        "sections": "Query and alert on <em>billing</em>&#x2F;usage data",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": "For accounts on our New Relic One <em>pricing</em> plan, we provide a View your usage UI for understanding <em>billing</em>-<em>related</em> usage and a Manage your data UI for managing <em>billing</em>-<em>related</em> data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert"
      },
      "id": "6043f69ae7b9d2345b579a09"
    },
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-07T00:05:31Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-07T00:05:31Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. The user type (basic user or full user) determines whether a user has access to our Full Stack Observability features. A user's type is something you set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our Full-Stack Observability features and some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to our Full-Stack Observability features, which include curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. In short: basic users have access to our Telemetry Data Platform and some Applied Intelligence features, while full users have theoretical access to everything (dependent on any group-related restrictions). Another way to think about this is that full users are users with access to Full Stack Observability, which gates our more curated UI features. Features Full user Basic user Full-Stack Observability (Curated UI experiences) Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Telemetry Data Platform Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to Full Stack Observability features (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.17524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Understand user-<em>related</em> <em>billing</em>",
        "body": "-term based on that user&#x27;s expected New Relic responsibilities. Below are details on the two user types. Note that <em>billing</em>-<em>related</em> aspects only apply if you&#x27;re on New Relic One <em>pricing</em>. Basic user. Details: These users are free and have access to a wide range of features, including setting up"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    },
    {
      "sections": [
        "New Relic One pricing and billing",
        "Important",
        "How the New Relic One pricing plan works",
        "Billing and usage in the UI",
        "Billing calculation details",
        "Data usage calculation",
        "Incident Intelligence events",
        "Determine event source",
        "Stop reporting events",
        "Full user count billing details",
        "Data retention",
        "Billing periods",
        "Usage plan details",
        "Query and alert on usage data",
        "Free tier",
        "Non-profit use of New Relic",
        "Cancel or downgrade"
      ],
      "title": "New Relic One pricing and billing ",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "03d43f14ae24579c81b601571242aef540833c8c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/new-relic-one-pricing-billing/",
      "published_at": "2021-10-07T00:05:29Z",
      "updated_at": "2021-09-13T20:46:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "An explanation of how New Relic One pricing works, and how to view and manage billing. Important This document explains the New Relic One pricing plan. If you’re on our original pricing plan, see Original pricing. Not sure which you're on? See Overview of pricing. How the New Relic One pricing plan works Starting July 30, 2020, all of our new customers are on a pricing plan that we call New Relic One pricing. Customers on our original pricing plan are able to transition to this pricing. For New Relic One pricing, billing is based on these factors: The amount of data ingested. 100 GBs per month is free. $0.25 per GB ingested above that. The number of provisioned full users, defined as users with access to Full Stack Observability features. Basic users are free. The cost of each full user depends on your edition: Standard, Pro, or Enterprise. Standard edition includes one full user for free, and a max of five. Pro and Enterprise give access to more account and user management features, more support, longer data retention, and other features. For Applied Intelligence, our intelligent alert/detection system: the number of incident events above the free 1000 per month. (Note that our alerting functionality is available for free and doesn't count towards this limit.) For a summary of what's included for free, see Free edition. For an overview of pricing, see our Pricing page. Keep reading for details about New Relic One pricing and billing. Billing and usage in the UI For how to view and manage billing and usage in the UI, see Pricing and billing UI. If you need more detail than the usage UI shows, you can also run queries of your usage data and set up alerts. Billing calculation details For accounts on New Relic One pricing, some high-level billing information is displayed in the UI. Here are some more details about how billing works: Data usage calculation One pricing factor is your ingested data. In this context, “ingested” refers to the data actually saved to your account after we apply various data trimming and data transformation rules. In other words, it’s not the size of the raw data sent to New Relic, but the size of the data that actually ends up stored. To view and manage your usage, go to the usage UI. Other calculation details: In the context of our pricing plan, a GB is defined as 1 billion bytes. Monthly data ingested is rounded down to the nearest integer. For example, if your account uses 100.9 GBs during a month, that’s counted as 100 GBs. For more on how data is ingested, see Manage data ingest. For how to query usage, see Query and alert on usage. Incident Intelligence events One billing factor is how many incident events your organization sends to Incident Intelligence for correlation and analysis. If your organization is on New Relic One pricing, Incident Intelligence comes with a certain number of free incident events per month. (Our original pricing plan doesn't have a free tier.) You can track usage and cost in two places in the UI: In the usage UI From the Incident Intelligence system settings UI page: From one.newrelic.com, click Alerts & AI, then click Incident Intelligence, and then click System settings. Determine event source When you set up Incident Intelligence data sources, the incident events ingested by those sources are what count towards your total. To see the sources affecting your billing, go to the Sources page: From one.newrelic.com, click Alerts & AI, click Incident Intelligence, and then click Sources. Stop reporting events Go to the Incident Intelligence Sources UI page and disconnect all the sources you don’t want. If all sources are removed, no data is sent to Incident Intelligence. Full user count billing details For accounts with New Relic One pricing, the monthly count of provisioned full users is one billing factor. To give an example: if you're on the Pro pricing edition and your organization has 100 full users during the month of January, you'd be billed for 100 full users for that month. A full user counts as a billable user the moment they're added to a New Relic organization (provisioned), whether or not that user has logged into or used New Relic yet. A user's user type is meant to be long-term setting determined by a user's expected New Relic duties and responsibilities. Because user type is a billing factor, we have restrictions around how often a full user can be downgraded to a basic user: a full user can downgrade to a basic user a maximum of two times in a rolling 12-month period. If a full user has been changed to a basic user two times in that 12-month period, that user won't be able to return to being a basic user until the start of the next 12-month period. To learn reasons for assigning one user type or another, see Tips on assigning user type. Here are more user-related billing details and caveats: You can see your full user count in the UI. We de-duplicate users based on email address. If there are multiple users in an organization that have the same email address, those user records count as a single user for billing purposes. The count of full users is prorated based on the start of a New Relic subscription, or based on when a user is created as a full user or converted to a full user. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. For organizations on our original user model that have a parent/child account structure, the count of billable users in the UI may differ from the users you can see. For more on this, see User count discrepancy. The Standard edition of the New Relic One pricing plan includes one free full user. For organizations on our original user model, because the organization-related settings aren't as robust as on our newer model, a user may be set as a basic user in one account and as a full user in another account. In such cases, the full user status takes precedence and that user is considered a full user. For how to query usage data, see Query and alert on usage. For more on user capabilities, see Users and roles. Data retention See Data retention. Billing periods For pay-as-you-go customers, billing occurs at the end of the month (UTC), and you can see this tracked in the UI. When you input your credit card and start to be charged, your end-of-month bill will take into account all activity (billable data usage and users) that occurred since the beginning of that month. For example: if you input your credit card in the middle of the month, and so far at that point your account has 200 GBs of usage for that month, that 200 GBs counts towards your end-of-month bill. For how to query user-related usage, see Query and alert on usage. Usage plan details There are two New Relic One pricing usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel at any time. For details, see Usage plans. Annual pool of funds: This plan applies to some customers who have subscribed for a year or more. For details, see Usage plans. For some frequently asked questions, see Pricing FAQs. Query and alert on usage data To create detailed queries of your usage, and get notifications when you are close to hitting certain usage levels, see Query usage data. Free tier If your organization is on New Relic One pricing and on the Standard pricing edition for Full Stack Observability, you can use New Relic free, forever, if you stay under the free allowed limits. Here's a summary of what Standard edition gets access to for free: A single account (Pro and Enterprise Full Stack Observability editions can have multiple accounts per organization). Up to 100 GBs of ingested data per month. One full user, and unlimited basic users. Access to alerts and Applied Intelligence (up to 1,000 Incident Intelligence events per month). To upgrade to Pro or Enterprise, or to learn more about pricing, see New Relic pricing. Non-profit use of New Relic If you’re a non-profit and want to use New Relic at special pricing, see our Non-profit eligibility docs. Cancel or downgrade See Downgrade account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.436455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic One <em>pricing</em> and <em>billing</em> ",
        "sections": "New Relic One <em>pricing</em> and <em>billing</em>",
        "tags": "New Relic One <em>pricing</em> and <em>billing</em>",
        "body": " for that month, that 200 GBs counts towards your end-of-month <em>bill</em>. For how to query user-<em>related</em> usage, see Query and alert on usage. Usage plan details There are two New Relic One <em>pricing</em> usage plans: Pay-as-you-go: This plan bills at the end of each month. There are no commitments and you can cancel"
      },
      "id": "6043f69a64441f7b26378eda"
    }
  ],
  "/docs/style-guide/writing-guidelines/screenshots-images": [
    {
      "sections": [
        "Docs site edit checklist",
        "Title",
        "Introduction",
        "Headings (H2s)",
        "Text",
        "Procedures",
        "Structure"
      ],
      "title": "Docs site edit checklist",
      "type": "docs",
      "tags": [
        "Tech writer style guide",
        "Processes and procedures"
      ],
      "external_id": "6dcea91eb875e69ab1786a4b5787615be7964bfe",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/processes-procedures/docs-site-edit-checklist/",
      "published_at": "2021-10-08T04:44:25Z",
      "updated_at": "2021-09-13T22:05:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're creating a new doc, there's a lot to keep track of. You can use this checklist to make sure you've done everything. Title Check that: The doc's title effectively describes the contents. Procedural doc titles use active verbs; for example, Install not Installing. Introduction Check that: The introduction leads with an outcome and provides an overview of how to get there, so customers are confident they've found the right doc. It provides a short, readable overview of the doc's contents. Headings (H2s) Check that: Heading names are concise, yet provide information that helps readers to skim or skip to the section they want. Procedural H2s use active verbs, not the ing verb form. Text Check that the text: Optimizes for easier translation: Avoid idioms, slang, specific cultural references, etc. Tells a good story: Promotes the platform (other New Relic products, alerting, etc.). Includes examples and use cases, identifies personas, explains not only what it is or how to use it but why it matters. Includes hyperlinks in UI paths. Has no typos. Procedures Procedures use active voice and focus on steps (\"do this\"). Avoid burying tips or extra details in the steps. If the procedure includes prerequisites or background information, that information appears before (not buried inside) the ordered list of procedures. If a procedure or step branches, it splits the options so they are clearly visible as bullets, collapsers, etc. If the procedure says what not to do, it also describes what to do instead. Example: What not to do and what to do instead Do not monitor your own applications from the partnership owner account. Instead, create an account within the partnership, and monitor apps from that account. Structure The original tech writer or docs site contributor is the best judge of whether the draft doc is complete. However, in your peer edit, make notes if you have unanswered questions that aren't addressed within the doc or its cross references. Doc structure Comments Complete Check that the overall doc: Is complete, but stays on topic. Includes useful cross references, hyperlinks, and other suggestions to enhance the information, especially for SEO. Skimmable Readers can see at a glance what the doc is about and what to do. It's obvious what parts they can read and what parts they can skip. Visually clean The doc avoids excessive use of callouts, long sentences, or long paragraphs. Useful images For screenshots and images, check that: Full size images always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped images clearly show their relevance, with or without captions. In addition, make sure that screenshots and images follow the docs site's security guidelines, and that no private information related to customers or New Relic is displayed. Levels of detail The doc uses H2s, H3s, bullets, tables, and clamshells to organize complex levels of information.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 831.37946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "Processes <em>and</em> procedures",
        "body": " sentences, or long paragraphs. Useful <em>images</em> For <em>screenshots</em> and <em>images</em>, check that: Full size <em>images</em> always have captions to explain their relevance. UI paths in captions always have hyperlinks. Cropped <em>images</em> clearly show their relevance, with or without captions. In addition, make sure"
      },
      "id": "604220b2196a6775f5a83dc0"
    },
    {
      "sections": [
        "Capitalization",
        "Use sentence case in headings",
        "Important",
        "Products and features",
        "UI elements and UI page paths"
      ],
      "title": "Capitalization",
      "type": "docs",
      "tags": [
        "Basic style guide",
        "Style guide quick reference"
      ],
      "external_id": "7a4d6c67e7c4737414cc99d452577f79dfc79ffc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/style-guide/quick-reference/capitalization/",
      "published_at": "2021-10-07T02:07:33Z",
      "updated_at": "2021-09-14T05:24:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In general, we only capitalize things when we need to. Over use of capitalization is distracting and limits accessibility for our readers with vision impairment. Read on for some guidelines on how to decide what to capitalize in a document's title, headings, products, features, and other elements of the page. Use sentence case in headings Use sentence case for headings. This includes category headings and document titles. With sentence case, capitalize only the first letter of: The first word Proper nouns Acronyms and abbreviations We have some exceptions: If the heading is a code term, such as a variable or function, then capitalize it exactly as it's used in the code; for example: noticeError. If the heading includes a colon, follow the Microsoft Style Guide for titles and headings, and capitalize the first word that appears after the colon; for example: APM Error profiles: Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our Screenshots and images document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don't capitalize features (including features that used to be products). Use transaction traces to... not Use Transaction Traces to... Our infrastructure monitoring... not Our Infrastructure monitoring... UI elements and UI page paths Item Example We use sentence case and bold for UI elements, even if the UI element is in a different case in the UI. \"From the Transactions page, select Transaction traces and...\" We use sentence case and bold for each element in a path that references UI pages. Go to one.newrelic.com > APM > Transactions > Transaction traces > (select a trace) > Another thing.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 708.1824,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Products <em>and</em> features",
        "body": ": Troubleshoot trends. Important Use sentence case for graphical illustrations such as diagrams and figures. Explore our <em>Screenshots</em> and <em>images</em> document for more information on our image guidelines. Products and features Item Example We use title case for products. Full Stack Observability We don&#x27;t capitalize"
      },
      "id": "60421e50196a67d785a83d97"
    },
    {
      "sections": [
        "Update your Nerdpack's catalog information",
        "Update your CLI",
        "Check your permissions",
        "Publish your Nerdpack",
        "Update your Nerdpack's catalog metadata",
        "Update your Nerdpack's icons",
        "Resolve issues with submitting catalog information",
        "Resize your images",
        "Check the length of your strings"
      ],
      "title": "Update your Nerdpack's catalog information",
      "type": "developer",
      "tags": [
        "nerdpack",
        "catalog"
      ],
      "external_id": "dfee75ddee87a216eb9454abcaeabcc1ee0a8c7d",
      "image": "https://developer.newrelic.com/static/e79ab0693c4758e13b4d9d0e586bd3e8/0086b/published-app.png",
      "url": "https://developer.newrelic.com/build-apps/publish-deploy/catalog/",
      "published_at": "2021-10-10T01:43:32Z",
      "updated_at": "2021-09-30T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn to describe your Nerdpack in the Instant Observability catalog",
      "body": "Add screenshots, descriptions, and other metadata to your Nerdpack, and upload it all to Instant Observability. Update your CLI Before you run any commands, ensure that you have the latest version of the CLI: bash Copy $ nr1 update Check your permissions To publish your Nerdpack and update its catalog information, you need: Access to the account that published it The necessary permissions for managing Nerdpacks Publish your Nerdpack You need to publish Nerdpacks that you create before you can update their catalog information. Update your Nerdpack's catalog metadata After you've published your Nerdpack to the Instant Observability catalog, update the Nerdpack's metadata to let users know all about your Nerdlets or visualizations. Step 1 of 9 Go to New Relic: Step 2 of 9 Navigate to Instant Observability: Step 3 of 9 Find your published Nerdpack using the Apps filter or search bar: Notice that there is no information on the Instant Observability or details page other than the Nerdpack's name and the brief description found in nr1.json: There are no screenshots, icons, details, or what's new features. For these, you need to provide catalog information to your Nerdpack. Step 4 of 9 From the root of your Nerdpack, create catalog directories to house your Nerdpack's screenshots and metadata: bash Copy $ nr1 create --type catalog ✔ created: launchers/launcher/catalog ✔ created: nerdlets/home/catalog ✔ catalog created successfully! catalog is available at \"./catalog\" Inside your root catalog directory, you'll find specific files and directories for portraying information about your Nerdpack to your users: bash Copy $ ls catalog README.md additionalInfo.md config.json documentation.md screenshots File Description README.md A markdown file that instructs you how to use the information and metadata in catalog config.json A JSON file that contains the following fields: tagline: A brief headline for the application. This cannot exceed 30 characters. repository: The URL for the Nerdpack's remote repository. This cannot exceed 1000 characters. details: The purpose of the Nerdpack and how to use it. This cannot exceed 1000 characters. Use newlines for formatting, and don't include any markdown or HTML. support: An object that contains: issues: A URL for the repository's issues list. For example, the Issues tab if using GitHub. email: A valid email address for the team supporting the application community: A URL for a support thread, forum, or website for troubleshooting and usage support whatsNew: A bulleted list of changes in the current release version. This cannot exceed 500 characters. Use newlines for formatting, and don't include markdown or HTML. Check out our Pageview Map application's config.json to see a real-life implementation. documentation.md A markdown file that tells users how to use the Nerdpack's Nerdlets or visualizations. This shows in the detail view's Documentation tab. additionalInfo.md An optional markdown file for any additional information about using your application screenshots A directory that contains screenshots showcasing your Nerdpack, such as select images of Nerdlets or visualizations. This can contain no more than 6 images. All screenshots must meet the following criteria: 3:2 aspect ratio PNG format landscape orientation 1600 to 2400 pixels wide This command also generates a catalog directory for each launcher, Nerdlet, and visualization in your Nerdpack. Inside you'll find a directory that allows you to add screenshots for each Nerdpack item. bash Copy $ ls launchers/launcher/catalog screenshots $ ls nerdlets/home/catalog screenshots Step 5 of 9 Update your Nerdpack's documentation.md file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"\", 3 \"details\": \"\", 4 \"repository\": \"\", 5 \"whatsNew\": \"\", 6 \"support\": { 7 \"email\": { 8 \"address\": \"\" 9 }, 10 \"issues\": { 11 \"url\": \"\" 12 }, 13 \"community\": { 14 \"url\": \"\" 15 } 16 } 17 } catalog/config.json Copy Step 6 of 9 Update your config.json file: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Initial commit\" 6 } catalog/config.json Copy Step 7 of 9 Include screenshots in your root screenshots directory or any Nerdpack item screenshots directory. Step 8 of 9 Submit the information to the Instant Observability catalog: bash Copy $ nr1 catalog:submit Uploading screenshots from demo-app... ✔ Screenshots uploaded from: demo-app Uploading screenshots from demo-app/launchers/launcher... ✔ Screenshots uploaded from: demo-app/launchers/launcher Uploading screenshots from demo-app/nerdlets/home... ✔ Screenshots uploaded from: demo-app/nerdlets/home ✔ Updated metadata for DemoApp 1.0.0 Step 9 of 9 Go to Instant Observability to see your changes: Click your Nerdpack to see the new details: Update your Nerdpack's icons Within a Nerdpack, you can set two types of icons: One for your entire Nerdpack, which represents your Nerdpack in the catalog One for each of your launchers, which represents your Nerdlets Replace these icons and publish your Nerdpack to see the changes. Step 1 of 7 Update the icon.png in the root of your Nerdpack. This icon is used in the catalog and the Nerdpack's detail page. Step 2 of 7 If you're building a Nerdpack with one or more launchers, update the icon.png in each of your launcher's subfolders. Step 3 of 7 Update your package.json version: { \"private\": true, \"name\": \"demo-app\", \"version\": \"1.0.1\", \"scripts\": { \"start\": \"nr1 nerdpack:serve\", \"test\": \"exit 0\" }, \"nr1\": { \"uuid\": \"f2dbc999-e9a3-49b9-933d-5a704c6750bd\" }, \"dependencies\": { \"prop-types\": \"^15.6.2\", \"react\": \"^16.6.3\", \"react-dom\": \"^16.6.3\" }, \"browserslist\": [\"last 2 versions\", \"not ie < 11\", \"not dead\"] } package.json Copy This allows you to publish a new version of your Nerdpack. Step 4 of 7 Publish your Nerdpack: bash Copy $ nr1 nerdpack:publish Step 5 of 7 Update your whatsNew string in catalog/config.json: documentation.md config.json 1 Enter your first and last name into the fields provided. When you're done, press **Submit** to see a personalized \"Hello!\" message. catalog/documentation.md Copy 1 { 2 \"tagline\": \"Say hi!\", 3 \"details\": \"DemoApp says Hello to a user.\", 4 \"repository\": \"https://github.com/newrelic/developer-website\", 5 \"whatsNew\": \"feat: Add new icons\" 6 } catalog/config.json Copy This will tell users what you added in the latest version of your Nerdpack. Step 6 of 7 Submit this new metadata to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots from demo-app... ✔ Screenshots uploaded from: demo-app Uploading screenshots from demo-app/launchers/launcher... ✔ Screenshots uploaded from: demo-app/launchers/launcher Uploading screenshots from demo-app/nerdlets/home... ✔ Screenshots uploaded from: demo-app/nerdlets/home ✔ Updated metadata for DemoApp 1.0.1 Step 7 of 7 Go to the catalog and subscribe to your Nerdpack to see your new icon: Resolve issues with submitting catalog information Sometimes, when you work with catalog metadata, you may run into issues. Consider some common solutions for resolving these issues. Publish your Nerdpack Remember that you can only submit catalog metadata for Nerdpacks that have already been published. If you try to submit information for a Nerdpack that hasn't been published, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 1 error while updating DemoApp 1.0.0 › › Invalid Version: Nerdpack version 1.0.0 not found. Have you run `nr1 nerdpack:publish` yet? › Code: UNKNOWN Resize your images Screenshots for the catalog must meet the criteria specified previously in this guide. If they don't, the CLI will try to help: bash Copy $ nr1 catalog:submit Uploading screenshots... › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a size ratio of 4:2. Update size ratio to 3:2. › › catalog/screenshots/screenshot.png › Invalid Screenshot: screenshot.png has a width of 3054px. Update size to be between 1600px and 2400px. › Code: UNKNOWN Check the length of your strings Most of the content in config.json has string-length requirements. Make sure you review those requirements and adhere to them when you update your config.json file. Otherwise, you'll see errors when you try to submit your configuration to the catalog: bash Copy $ nr1 catalog:submit Uploading screenshots... ✔ Screenshots uploaded › Error: 2 errors while updating DemoApp 1.0.1 › › catalog/config.json › Invalid Metadata: `details` has a character length of 2204. Must be no longer than 1000 characters › › catalog/config.json › Invalid Metadata: `tagline` has a character length of 266. Must be no longer than 30 characters › Code: UNKNOWN",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.35657,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Resize your <em>images</em>",
        "body": " information about using your application <em>screenshots</em> A directory that contains <em>screenshots</em> showcasing your Nerdpack, such as select <em>images</em> of Nerdlets or visualizations. This can contain no more than 6 <em>images</em>. All <em>screenshots</em> must meet the following criteria: 3:2 aspect ratio PNG format landscape"
      },
      "id": "609c868664441f2bf22f3706"
    }
  ],
  "/docs/style-guide/writing-guidelines/user-related-language-guidelines": [
    {
      "image": "https://docs.newrelic.com/static/565d4ebddf52a4592c594032696516b9/c1b63/New-Relic-capabilities-UI-screenshot.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/new-relic-one-user-model-understand-user-structure/",
      "sections": [
        "Users, roles, permissions (New Relic One user model)",
        "Important",
        "Overview",
        "User type: basic and full",
        "Compare full vs basic capabilities",
        "Tips on choosing user type",
        "Understand user-related billing",
        "Have questions about why you can't access something?",
        "Default groups: Admin and User",
        "How do user type, roles, and groups relate to each other?",
        "Roles and capabilities",
        "Standard (default) roles",
        "Capabilities",
        "Manage users",
        "2020 user model changes"
      ],
      "published_at": "2021-10-07T00:05:31Z",
      "title": "Users, roles, permissions (New Relic One user model)",
      "updated_at": "2021-10-07T00:05:31Z",
      "type": "docs",
      "external_id": "169383c2678ce973404db07195b2dee6eda9163d",
      "document_type": "page",
      "popularity": 1,
      "body": "Your New Relic users can be on one of two user models: this doc explains the New Relic One user model. Important If your New Relic organization was created before July 30 2020 and you haven't gone through a user migration process, your users are likely on our original user model. For more on this, see User model changes. Overview This doc will explain the structure of the New Relic One user model, including: User type (basic user versus full user) Default user groups, including Admin and User Roles and capabilities For how to add and manage users in the UI, see User management. User type: basic and full Important This section is for users on our New Relic One user model. If you're on our original user model, see Original users. The user type (basic user or full user) determines whether a user has access to our Full Stack Observability features. A user's type is something you set long-term based on that user's expected New Relic responsibilities. Below are details on the two user types. Note that billing-related aspects only apply if you're on New Relic One pricing. Basic user. Details: These users are free and have access to a wide range of features, including setting up and configuring any New Relic data-reporting tool, running queries of your data, using our logs UI, making custom charts and dashboards, and setting up alerts. Unlike full users, they do not have access to our Full-Stack Observability features and some Applied Intelligence features (for a detailed comparison, see Capabilities). Basic users will see prompts to become a full user when they attempt to access unavailable features. For details, see Upgrade. Full user. Details: Full users have access to our Full-Stack Observability features, which include curated UI experiences like APM, infrastructure monitoring, browser monitoring, mobile monitoring, synthetic monitors, access to New Relic One apps, and more. For details, see Capabilities. Standard edition includes one free full user and up to five total full users. A full user can downgrade to a basic user twice in a 12-month period. To view and edit the user type of your users, use the User management UI. Learn more about basic user versus full user differences: Compare full vs basic capabilities Below is a table comparing what basic users and full users can do. In short: basic users have access to our Telemetry Data Platform and some Applied Intelligence features, while full users have theoretical access to everything (dependent on any group-related restrictions). Another way to think about this is that full users are users with access to Full Stack Observability, which gates our more curated UI features. Features Full user Basic user Full-Stack Observability (Curated UI experiences) Application performance monitoring (APM) UI Infrastructure monitoring UI Digital Experience Monitoring UI, which includes: Browser monitoring UI Mobile monitoring UI Synthetic monitoring UI Synthetics checks Serverless monitoring UI Logs in context Distributed tracing Infinite Tracing (Pro and Enterprise edition) Assorted UI experiences, including: Kubernetes cluster explorer UI Key transaction UI Workloads UI Manage other users Access to New Relic One apps Can build apps but can't access other apps Applied Intelligence Automatic anomaly detection Correlated alerts and events Anomaly/alert analysis Root cause details in issues Telemetry Data Platform Data ingest from any source (agents, integrations, APIs) Query your data Create custom charts and dashboards Alerts and notifications Our APIs, including NerdGraph (GraphQL) (with some restrictions) Query and chart log data Build New Relic One apps (but cannot access other apps) Encryption at rest Standard data retention Security and compliance Data management Note that the pricing edition (Standard, Pro, or Enterprise) will also affect what features you have access to. For organizations with New Relic One pricing, learn more about how full users impact billing. Tips on choosing user type A user's type (basic user vs full user) is meant to be a long-term assignment, based on the New Relic responsibilities that user is expected to perform. A full user can be downgraded to a basic user only twice in one year. Below are tips for why you'd choose full user versus basic user. Reasons to make someone a full user: They play a key role in the development, testing, deployment, and maintenance phases of the application development lifecycle. They break/fix code regularly; they are responsible for triaging workflows, troubleshooting, or managing users and roles for their team. They have DevOps practices (i.e. version control systems and implement CI/CD). They need to use New Relic's curated dashboards and experiences (not just the ability to create their own custom queries and charts); in other words, they need full access to our platform. They need to be able to manage users and/or billing. Reasons to make someone a basic user: They play a key role in the planning phase of the application development lifecycle. They use and configure New Relic agents, APIs, and integrations to send us data, and access, configure, and use alerts on such data (not necessarily responsible for triaging workflows, troubleshooting, or managing users and roles for their team). They want to see high-level analytics and business metrics for future planning (such as C-Suite executives). They do not need to use our curated experiences and dashboards, but would benefit from the ability to create their own custom queries and charts of data; in other words, they don't need full access to the platform. They don't manage users. For accounts on New Relic One pricing, learn more about user-related billing calculations. Understand user-related billing If you're on the New Relic One pricing plan, full users are billable, and there are restrictions around how often a full user can downgrade to a basic user. For details, see User count billing details. For how to query and alert on usage data, see Query usage data. Have questions about why you can't access something? See Factors affecting access. Default groups: Admin and User For users on our New Relic One user model, a \"group\" is what allows the grouping together and managing of multiple users at the same time. Your New Relic users are assigned to a group, and that group is granted access to specific roles on specific accounts. We have two default groups: User: This group allows a user to use and configure monitoring/analysis features but not perform account-related tasks like managing billing or users. It has access to the All product admin role, which gives access to our observability platform tools but not to the organization and user management capabilities governed by the Organization manager and Authentication manager roles. Admin: has full access and capabilities, including the organization-level admin abilities. This is the equivalent of having the All product admin, the Billing user, the Organization manager and the Authentication domain manager roles. These groups are added inside your default authentication domain, which includes the default settings of users a) being managed via New Relic and b) logging in via standard email and password. If you add other authentication domains (for SAML SSO and/or SCIM provisioning of users), you'd have new custom groups in those new domains to govern those users. Note that groups, whether default or custom, are not what limit a user's capabilities: it is the role that is assigned to that group (with any basic user restrictions on top of that). If your organization is Pro or Enterprise edition and you want to understand how users are granted access to specific roles and accounts, see Access grants. To change the group a user is in, use the User management UI. How do user type, roles, and groups relate to each other? For users on the New Relic One user model, here's a table explaining how user type (basic vs full user), roles, and groups relate to each other: Full user Basic user Group Full users can be assigned to default groups (User and Admin) or custom groups. When basic users are added to a group, that group's role-related restrictions apply. A basic user's capabilities can be restricted in that way, but a basic user can never be granted more capabilities than they start with. For Standard edition, basic users can't be assigned to groups. For Pro and Enterprise edition, they can. Role For an explanation of the roles our default groups have, see Default groups. Custom groups can have either our default standard roles, or custom roles. A basic user's abilities aren't directly defined by a specific role. A basic user can best be described as having the All product admin role but without access to Full Stack Observability features (learn more about user type). When basic users are added to a group, that group's role-related restrictions apply, but a basic user can never be granted more capabilities than they start with. Roles and capabilities For users on the New Relic One user model, a \"role\" can be defined as \"a set of capabilities.\" A capability is defined as the ability to do a specific New Relic task, like 'Delete alert conditions' (learn more about capabilities). Roles are assigned to user groups. Our default groups Admin and User already have our standard roles (defined below) assigned. Organizations on Pro or Enterprise edition can also create custom roles. Standard (default) roles Roles are sets of capabilities. We have several \"standard roles,\" which are roles that satisfy some commonly needed use cases. To view roles and their associated capabilities, use the Organization and access UI. Important Note that some of our standard roles have hidden, non-exposed capabilities that are not available for selection when creating a custom role. The only standard roles that can be replicated with a custom role are Standard user and Read only; all others have some hidden capabilities. Our standard roles include: Standard roles Scope Description All product admin Account Provides admin-level access to observability platform features but not organization-level and user management features. In other words, this role includes all New Relic capabilities with the exception of managing users (Authentication domain manager role), managing organization/account-structure settings (Organization manager role), and managing billing (Billing user role). Note: the Standard user role is essentially the All product admin role minus observability feature configuration capabilities. Standard user Account Provides access to observability platform features, but lacks permissions for configuring those features (for example, ability to configure synthetic monitor secure credentials) and lacks organization-level and user management permissions. Note: the Standard user role is essentially the All product admin role without that role's ability to configure platform features. Billing user Account Provides ability to manage subscriptions and billing setup, and read-only access to the rest of the platform. For organizations with multiple accounts, billing is aggregated in the primary (first-created) account, which is why assigning this role to that primary account grants billing permissions for the entire organization. Organization manager Organization Provides the ability to manage organization settings, including organization structure, name, and preferences. Due to our recent switch to the New Relic One user model, this role currently has few abilities but more will be added over time. For how to grant this role, see Add user management capability. Organization read only Organization Provides the ability to view organization-level settings. For how to grant this role, see Add user management capability. Authentication domain manager Organization Provides ability to add and manage users, and configure authentication domains for users on the New Relic One user model. For how to grant this role, see Add user management capability. Authentication domain read only Organization Provides the ability to view users in your organization and view the configuration of authentication domains. For how to grant this role, see Add user management capability. Read only Account Provides read-only access to the New Relic platform (except for synthetic monitor secure credentials). Manage v1 users Account For New Relic organizations that existed before July 30 2020 and have users on our original user model, this role lets you manage those \"v1\" users. For more about how you'd assign roles to groups and create custom roles, see the user management tutorial. Capabilities A role, whether one of our standard roles or a custom role, is defined as a set of capabilities. To view roles and their associated capabilities, use the Organization and access UI. Important Some of our standard roles have hidden capabilities that aren't available for selection when creating a custom role. For details, see Standard roles. A view of the capabilities associated with the All product admin role. When creating a custom role, you select a custom set of capabilities. Note that the capabilities we expose may change over time: this screenshot was taken in April of 2021. For how to set up roles with custom capabilities, see the user management tutorial. Manage users To learn how to add users, assign them to groups, and create custom groups and roles, see Manage users. 2020 user model changes If you'd like to understand how our user model changed in 2020 and what the impacts of that change were, see User model changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.06934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Users</em>, <em>roles</em>, permissions (New Relic One <em>user</em> model)",
        "sections": "How do <em>user</em> type, <em>roles</em>, and groups <em>relate</em> to each other?",
        "body": " as having the All product admin <em>role</em> but without access to Full Stack Observability features (learn more about <em>user</em> type). When basic <em>users</em> are added to a group, that group&#x27;s <em>role</em>-<em>related</em> restrictions apply, but a basic <em>user</em> can never be granted more capabilities than they start with. <em>Roles</em>"
      },
      "id": "603e88e328ccbcfcbaeba7a8"
    },
    {
      "sections": [
        "How to manage users",
        "Important",
        "Requirements",
        "Manage users in the UI",
        "Overview of user management concepts",
        "Common user management tasks",
        "Add, edit, and delete users",
        "Edit user type (basic user versus full user)",
        "Give users access to accounts and roles (access grants)",
        "Create new custom groups and roles",
        "Set up SAML SSO and/or SCIM provisioning",
        "Grant users ability to manage other users",
        "Control how basic users upgrade to full users",
        "Track changes",
        "User management terms and definitions"
      ],
      "title": "How to manage users",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "9e37836740ce56302734d4af636bdbe087b4dbc3",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/add-manage-users-groups-roles/",
      "published_at": "2021-10-07T01:22:54Z",
      "updated_at": "2021-10-07T01:22:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For users on our New Relic One user model, we provide various user management features, including the ability to: Use role based access control (RBAC) to assign default or custom roles to user groups Create custom user groups Grant user groups access to specific roles and accounts Important This doc applies to users on the New Relic One user model. For managing users on our original user model, see Original users. Not sure which user model you're on? See User models. Requirements To see if you can access these user management features, go to the user management UI and see what you have access to. Access requirements: These features allow managing of users on the New Relic One user model. To learn more, see User models. To avoid configuration conflicts, ensure that only one user is managing users at a time. Simultaneous configuration by more than one user may result in errors and unexpected results. Most capabilities require the Authentication domain manager role and some require the Organization manager role. For details, see Standard roles. Pricing edition requirements: To manage user groups, roles, and access grants: Pro or Enterprise edition is required. To import users from an identity provider: Enterprise is required. A New Relic user can have a maximum of either three concurrent active sessions, or three unique IP addresses in use at any given time. Manage users in the UI For users on the New Relic One user model, to find your user management options: From the account dropdown, select Administration. There are two user management UI pages there: User management: Use this to add users, update user type (basic versus full user) and other information, and approve user type upgrade requests. Organization and access: Use this page to create and manage groups, roles, and access grants, and to set up SAML SSO and SCIM provisioning. Want to see videos of the user management UI in action? See our user management videos. Important If you can't see these UI pages, it may be because you're on our original user model or because you don't have the required user management role. Overview of user management concepts If your organization has Pro or Enterprise edition, you can create and configure access grants. An access grant gives a group of users access to a specific role on a specific account. Here's a diagram showing how access grants work and how they relate to the broader organization: A diagram explaining the concept of how access grants give a user group access to a) a role on b) a specific account. (Note that this applies to users on our New Relic One user model (and not our original user model).) When your New Relic organization is created, it starts out with some default access grants for our default User or Admin groups. Each of these groups is assigned one or more roles and granted access to the primary (first created) account: A view of the Organization and access UI, showing the default access grants associated with our default groups. If you have a relatively flat organizational structure, and are okay with all or many of your users having wide administrative access and access to all accounts, you'll probably only need at most a few access grants. For example, you might decide to add new access grants to the existing default Admin or User groups, giving those roles access to other accounts. Or, if you need more granular definition over roles and permissions, you'd create access grants that define new groups that have access to specific roles (either our standard roles or custom-defined roles). For a tutorial on how to create access grants and create custom roles, see the User management tutorial. For other examples of some common user management tasks, see Example tasks. To see the UI in action, see our user management videos. Some tips on setting up access grants: It may help to first plan out how your access grants will be organized. How many accounts will you have? What user groups will get access to which roles and which accounts? Will you use our default groups and roles or create your own custom groups and roles? If you've used automated user management to provision users via SCIM, you will have to create access grants to give those users access. A common configuration for organizations with many accounts (roughly 20 or more) is setting up groups with the more organization-scoped roles (Organization manager, Authentication domain manager, and Billing user) on the primary account, and then on other accounts, setting up groups with the more product-scoped roles (like All product admin, Standard user, or custom roles). Common user management tasks In the Organization and access UI, you can create access grants, custom groups, custom roles, and configure an authentication domain. Here are some example user management procedures: Add, edit, and delete users See the user management tutorial. Edit user type (basic user versus full user) Note that there are limits around how many times full users can be changed to basic users. Important If you're using automated user management to provision and manage your users, you have other options for managing user type. To change the user type of one or more users: On the User management page, click the checkboxes for the users whose user type you want to edit. Once you start selecting users, an option will appear for Edit type. You can also edit the user type and group of a specific user by clicking on that user. Give users access to accounts and roles (access grants) See our user management tutorial. Create new custom groups and roles See the user management tutorial. Set up SAML SSO and/or SCIM provisioning See Get started with SAML SSO or SCIM. Grant users ability to manage other users To grant your users the ability to manage other users, you'll need to add users to a group that has the Authentication domain manager and Organization manager role. You have two options: From the User management UI, you can add a user to the default Admin group, which includes both of those roles. OR You can create a custom group and assign it these roles. For a tutorial on creating new access grants, groups, and roles, see the user management tutorial. Control how basic users upgrade to full users See the authentication domain settings. Track changes To see an audit log of changes to your account, including user management actions, you can query the NrAuditEvent. User management terms and definitions For an explanation of how user access to accounts and roles works, see User management concepts explained. Here are some definitions for the terms we use there: A New Relic organization is the representation of your organization, containing all your accounts, users, and data. For more information, see Organization and account structure. A capability is an ability to use or edit a specific, granular New Relic feature. Examples of capabilities: The ability to modify APM settings The ability to delete alert conditions A role is a set of capabilities. It is what gives a user their permissions. Our default standard roles have various capability sets, and you can create custom roles that have a custom set of capabilities. See some specific New Relic capabilities. A user group has one or more roles associated with it. You assign your users to a group. We have default user groups (Admin and User), and you can make your own groups. An access grant is what grants a user group access to roles and to specific New Relic accounts. An access grant essentially states, \"This group is assigned this role on this New Relic account.\" Adding a user to a group doesn’t do anything unless that group is included in an access grant. An authentication domain contains a set of users who are added to New Relic and who log in to New Relic in the same way. For example, you may have one authentication domain for users who log in via username/password and another authentication domain for users who log in via SAML. If a user is a basic user, this takes precedence over any role-related limitations. For more on this, see Basic user and roles.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 166.2148,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "How to manage <em>users</em>",
        "sections": "Give <em>users</em> access to accounts and <em>roles</em> (access grants)",
        "tags": "New Relic One <em>user</em> management",
        "body": ". For example, you may have one authentication domain for <em>users</em> who log in via username&#x2F;password and another authentication domain for <em>users</em> who log in via SAML. If a <em>user</em> is a basic <em>user</em>, this takes precedence over any <em>role</em>-<em>related</em> limitations. For more on this, see Basic <em>user</em> and <em>roles</em>."
      },
      "id": "603e7bce28ccbc415beba74c"
    },
    {
      "sections": [
        "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
        "Requirements",
        "Overview",
        "Add users",
        "View available accounts",
        "Grant access to accounts and roles",
        "Create custom role",
        "Add users to groups"
      ],
      "title": "Tutorials on user management tasks: access grants, custom roles, and adding users (New Relic One user model)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One user management"
      ],
      "external_id": "b1e5f303b6446f264c9d8c5020871a6990e052fd",
      "image": "https://docs.newrelic.com/static/a78dad5ff794da5deaaf3b514e334ea7/c1b63/new-relic-one-user-mgmt.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-user-management/tutorial-add-new-user-groups-roles-new-relic-one-user-model/",
      "published_at": "2021-10-07T07:18:06Z",
      "updated_at": "2021-10-07T07:18:06Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This tutorial will walk you through some common procedures for managing users on the New Relic One user model. Requirements Some notes on requirements: This tutorial is for users on our New Relic One user model. Creating access grants requires Pro or Enterprise edition. For details, see user management requirements. Role requirements: Using the Organization and access UI to manage group access requires Authentication domain manager and Organization manager roles. Using the User management UI to add/edit users requires Authentication domain manager role. Overview Before using this tutorial, we recommend you check out: Understand what an access grant is Videos that show the user management UI in action This tutorial will walk you through how to: Add users View available accounts Grant groups access to roles and accounts Create custom roles Add users to groups Add users Adding users to New Relic is a separate process from creating access grants. In other words, you can do either procedure first. The key point is that if you're trying to give a user access to a role or an account that they don't yet have, they won't have that access until they're both a) in a group and b) that group has the correct access grant (access to a specific role on a specific account). There are two ways to add users: With the user management UI (described below) With automated user management, also known as SCIM provisioning: use of this method means that groups are defined in your identity provider and so you can't edit a user's group from the New Relic UI. To add users from the UI: From the top right of the New Relic UI, click the account dropdown, click Administration, and click User management. If you have multiple authentication domains, choose one from the authentication domain dropdown. Click Add user. Complete the process, including choosing user type and user group. Relevant tips: For how to bulk edit users' user type, see Edit user type. When choosing a group, you can choose either one of our default groups or a custom group that you've defined an access grant for. For more on creating access grants, keep reading. View available accounts When thinking about creating access grants for granting access to different accounts, it can help you to understand what accounts there are in your organization. To view the accounts in your organization: go to the account dropdown, click Administration, click Organizations and access, and then click Accounts. Grant access to accounts and roles Groups are used to group your users and manage what your users are able to do in New Relic: by creating an access grant, you assign a group access to a) a specific role on b) a specific account. By default, organizations on the New Relic One user model have two available groups: Admin and User. These default groups automatically have access to specific standard roles and are assigned to the account in which they were initially added. To view existing access grants: from the account dropdown, click Administration, and then click Organization and access. Even if you haven't created any custom access grants, you will see the default-created grants there that are present for our default groups. This is what you might see when you go to the Organization and access UI and view groups. The default available groups of Admin and User have access grants automatically created that grant users in those groups access to the roles associated with those groups and to the initial account those users were added in. To create a new access grant that gives a user group access to a role and an account: From the Organization and access UI, click Group access. If you don't see that UI, it may be because you're logged in with an original user model record, or because you don't have the ability to manage users. For more on such factors, see Factors affecting access. Choose one of the following: Existing: If there is already a group you want to add an access grant to, you can use this. For example, if you want to gives users in the default Admin or User group access to new accounts, you might choose this and then select the Admin Default or Admin User role. New: If you need to create a new group, choose this. You'll also need to choose the authentication domain that group is inside of (for an explanation of what \"Default\" means, see Default groups. If your organization strategy requires a good amount of restrictions over access to accounts and access to roles, you'll probably need to create a good amount of access grants. Next, under Access grant, you'll choose one of following: Account: Choose this to be able to select from the roles that are account-scoped. These are the roles that have to do with using and configuring our platform features (and not about organization and user management). Organization: Choose this to be able to select from the roles that are organization-scoped. These are the roles that govern organization- and user management. (Note that these users must also already belong to an account-scoped role. This is true for most users but if it's not, you may see a message that the user doesn't belong to an organization.) Select the Role you want to assign. Roles are organization-wide, so regardless of the authentication domain you're in, you have access to our standard roles and any custom roles you've created. For tips on selecting roles, see the tips after these instructions. Select the Account you want to add access to from the dropdown. If you don't see an account that you'd expect to see, this may be for a few reasons. One is that you yourself don't have the proper permissions for that account. Another is that that account is not actually in your organization. For more information, see Factors affecting access. If you are still having problems, talk to your account representative. If you want to continue adding more grants for that same group, select Add another at the bottom before clicking Add access. When you're done, if your users are already in the group you've added the grant to, they should have access within a few minutes (although for EU region New Relic accounts, this can take up to twenty minutes or so). If your users are not yet in that group (which would be true if you just created an access grant with a new group), you'll need to go to the User management UI and add that group to those users. Some tips for using this UI: Note that if a user has the organization-scoped Organization manager and/or Authentication domain manager roles, which is true of users in the default Admin group, those users will always have those capabilities because those are organization-scoped abilities. This means that when you go to add those users to another account, you only have to add an account-scoped role, and not an organization-scoped role. In other words, once the users in a group have those organization-scoped roles, they will always have them in that organization unless removed. When selecting from amongst our standard roles, it's important to understand the difference between All product admin and Standard user. In short, All product admin is more popular a choice because it gives the ability to configure platform features. If you wanted to have your users be able to use platform features but not configure them, you'd choose Standard user. If your users are managed via automated user management, there are some restrictions that may apply. For example, you wouldn't be able to use the User management UI to add users to groups, because groups are managed and imported from your identity provider. If a group has basic users in it, their basic user status overrides any group-related restrictions. Create custom role When creating an access grant, you can use our standard roles, or you can create your own roles with unique sets of capabilities. To view existing roles: from the account dropdown, click Administration, then click Organization and access, and then click Roles. To create a custom role, click Add new custom role. Review the list of available capabilities and decide which ones your custom role needs. For more information about how roles and capabilities work, see Capabilities. Once you're finished creating a custom role, you will probably want to use it in a new access grant. Add users to groups In the user management UI, you can see your users and the groups they've been assigned to. Your users only have access to the access grants associated with the groups they've been added to. To view users and see their groups: from the account dropdown, click Administration, and click User management. If you don’t see that option, review the requirements. Groups reside within the boundaries of an authentication domain. If your organization has more than one authentication domain, the domain switcher in the top left will show which one you’re in. To add a user, click Add user. Complete the prompts in the UI, including choosing the user type and group. Any custom groups you’ve added should be available from the group dropdown. If the custom group you choose has been granted access to a role and an account, once you add the user to that group, that user will now have access. To edit a user’s group or other details: click on the user you want to edit and make changes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.15875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Tutorials on <em>user</em> management tasks: access grants, custom <em>roles</em>, and adding <em>users</em> (New Relic One <em>user</em> model)",
        "sections": "Tutorials on <em>user</em> management tasks: access grants, custom <em>roles</em>, and adding <em>users</em> (New Relic One <em>user</em> model)",
        "tags": "New Relic One <em>user</em> management",
        "body": " to add <em>users</em> to groups, because groups are managed and imported from your identity provider. If a group has basic <em>users</em> in it, their basic <em>user</em> status overrides any group-<em>related</em> restrictions. Create custom <em>role</em> When creating an access grant, you can use our standard <em>roles</em>, or you can create your own"
      },
      "id": "603e7d67196a671e26a83dc5"
    }
  ],
  "/docs/style-guide/writing-guidelines/voice-strategies-docs-sound-new-relic": [
    {
      "image": "https://developer.newrelic.com/static/developer-champions-c61b7fb3b08d228679edab34b2d15a0e.jpg",
      "url": "https://developer.newrelic.com/developer-champion/",
      "sections": [
        "New Relic Developer Champions",
        "What do Developer Champions do?",
        "Open-source contributions",
        "Content creation",
        "Community engagement",
        "Why should you join and how will we support?",
        "Developer Champions benefits:"
      ],
      "published_at": "2021-10-10T01:38:47Z",
      "title": "New Relic Developers",
      "updated_at": "2020-12-04T01:45:02Z",
      "type": "developer",
      "external_id": "2cef9996dadc081ed4331e85992a4af9defc87ff",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic Champions are the voice of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to New Relic product and engineering teams. Champions solve big problems using New Relic as their toolkit and are recognized as experts and leaders in the New Relic technical community. Nominate a developer champion What do Developer Champions do? New Relic Champions demonstrate expertise in using New Relic products by solving large problems and positioning New Relic as a central force in their strategies. The New Relic Champions is a recognition and partnership program designed to acknowledge the developers that are driving innovation within their companies and making top contributions to the developer community.They also commit to making their work public by: Open-source contributions Serving as an open-source author or maintainer for an accepted public project related to New Relic One Content creation Authoring two pieces of content in the New Relic Explorers Hub / Dev website Community engagement Delivering and/or organizing two events focused on an observability platform theme in which New Relic plays a crucial role Nominate a Developer Champion Why should you join and how will we support? As a benefit of being a Developer Champion, New Relic provides unique access to our Developer Advocacy team and the resources of our product organization, as well as specialized recognition and rewards. Developer Champions benefits: Formal, specialized access to the New Relic Product organization Champions have direct access to the New Relic’s Developer Ecosystem team Custom badge to wear with pride at events Public recognition on the New Relic Developer website and badging in the New Relic Explorers Hub as a Champion Exclusive Champion-only swag Early access program for some of our products (under NDA) Priority access to off-site FutureHack events (including when Lew is participating) Increased Explorer’s Hub support SLA Access to private Developer Champion Explorer’s Hub group",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 72.676796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>New</em> <em>Relic</em> Developers",
        "sections": "<em>New</em> <em>Relic</em> Developer Champions",
        "body": "<em>New</em> <em>Relic</em> Champions are the <em>voice</em> of the developer community. As experts and innovators, they are given the resources to not only share the newest product innovations and updates but also to provide feedback of the community back to <em>New</em> <em>Relic</em> product and engineering teams. Champions solve big"
      },
      "id": "5efa993c64441fc2a25f7e65"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/",
      "sections": [
        "Collect data",
        "Guides to collect data",
        "Add custom attributes",
        "Collect data - any source",
        "Create custom events",
        "Build queries with NerdGraph",
        "Monitor your network devices with New Relic",
        "Query data with NRQL"
      ],
      "published_at": "2021-10-10T01:39:54Z",
      "title": "Collect data",
      "updated_at": "2021-10-01T02:12:43Z",
      "type": "developer",
      "external_id": "fb5d6f75b61858b09e3e8c63f3b2af97813f47b6",
      "document_type": "page",
      "popularity": 1,
      "body": "Through our opensource agents or APIs, New Relic makes it easy to collect data from any source. The guides in this section provide strategies for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add custom attributes   Use custom attributes for deeper analysis Collect data - any source 15 min APIs, agents, OS emitters - get any data Create custom events 5 min Define, visualize, and get alerts on the data you want using custom events Build queries with NerdGraph 25 min Try NerdGraph and build the queries you need Monitor your network devices with New Relic 45 min Monitor your network devices with New Relic Query data with NRQL 10 min Query default data, custom events, and attributes",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 67.14844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Monitor your network devices with <em>New</em> <em>Relic</em>",
        "body": "Through our opensource agents or APIs, <em>New</em> <em>Relic</em> makes it easy to collect data from any source. The guides in this section provide <em>strategies</em> for collecting and querying data for use in your existing implementation, or in apps you build. The opportunities are endless. Guides to collect data Add"
      },
      "id": "6091fa38196a67a932d52a29"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own/",
      "sections": [
        "Step 4: Instrument your own Lambda functions",
        "Important",
        "Deployment strategies",
        "newrelic-lambda CLI quickstart",
        "Continuous deployment",
        "CloudFormation / SAM templates",
        "Serverless Framework",
        "Install the plugin",
        "Terraform",
        "Unusual integrations",
        "CloudWatch telemetry",
        "Manual process: Stream CloudWatch logs to New Relic Lambda",
        "Lambda console UI configuration",
        "Layer customization",
        "What's next?"
      ],
      "published_at": "2021-10-07T07:22:32Z",
      "title": "Step 4: Instrument your own Lambda functions",
      "updated_at": "2021-10-07T07:22:32Z",
      "type": "docs",
      "external_id": "4d7711d76722259efc97da6aa41d521459894178",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. Important Because there are several steps to integration, it's important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment strategies There are many different deployment strategies for Lambda functions. New Relic offers direct support for several, but we cannot cover every option. At its core, New Relic Lambda instrumentation relies on the Lambda service itself, rather than any particular deployment strategy or tool, so we're confident that it can be made to work in your use case. newrelic-lambda CLI quickstart The CLI tool that we recommended for setting up the account link can also reconfigure your Lambda functions to use New Relic. To install or upgrade the New Relic instrumentation layer, run: newrelic-lambda layers install --nr-account-id YOUR_NR_ACCOUNT_ID --function my-function --upgrade Copy This command automatically finds the newest available layer for your Lambda's region and runtime. This is a great way to quick-start instrumentation, and this tool can easily be integrated into your existing CI/CD processes. However, since it modifies existing Lambda function resources, when you deploy a code update to your function, you may inadvertently remove the New Relic instrumentation. Be sure to re-run the command above after every update, or (even better) integrate the layer and associated configuration with your existing deployment process. Note that the CLI can operate on many functions in a batch: use --function all, --function installed, or --function not-installed to operate on all functions in a region, or only those with or without existing New Relic instrumentation. Continuous deployment In the long term, it's usually less work to integrate New Relic into your existing continuous deployment process. Instead of running the CLI after updating your function, you can integrate New Relic into your continuous deployment framework. CloudFormation / SAM templates AWS's Serverless Application Model, or SAM is a variant of CloudFormation templates that simplifies relating functions to the resources they depend on, and managing the lifecycle of an entire application. We use SAM and CloudFormation for most of our Lambda example functions, and many other tools are built on top of CloudFormation templates, providing an addition layer of abstraction. At its core, CloudFormation is a way to express the target state of an AWS Resource (such as a Lambda function) using YAML or JSON, and an execution service that makes API calls to other services (such as AWS Lambda) to achieve that target state. Here's an example of a simple CloudFormation template for a NodeJS Lambda function: AWSTemplateFormatVersion: '2010-09-09' Transform: AWS::Serverless-2016-10-31 Description: And example of a simple instrumented NodeJS Lambda Resources: NewRelicExample: Type: AWS::Serverless::Function Properties: # In this example, we're using the SAM CLI to package and deploy our lambda. SAM will transform this value during the publish step. CodeUri: newrelic-example-node/ # The handler for your function needs to be the one provided by the instrumentation layer, below. Handler: newrelic-lambda-wrapper.handler Runtime: nodejs12.x Environment: Variables: # For the instrumentation handler to invoke your real handler, we need this value NEW_RELIC_LAMBDA_HANDLER: app.lambdaHandler # Distributed tracing needs your account ID, and your trusted account ID NEW_RELIC_ACCOUNT_ID: YOUR_ACCOUNT_ID_HERE # If your New Relic account has a parent account, this value should be that account ID. Otherwise, just # your account id. NEW_RELIC_TRUSTED_ACCOUNT_KEY: YOUR_PARENT_ACCOUNT_ID_HERE Layers: # This layer includes the New Relic Lambda Extension, a sidecar process that sends telemetry, # as well as the New Relic Agent for Node.js, and a handler wrapper that makes integration easy. - !Sub arn:${AWS::Partition}:lambda:${AWS::Region}:451483290750:layer:NewRelicNodeJS12X:34 Policies: # This policy allows the lambda to know the value of the New Relic licence key. We need this so # that we can send telemetry back to New Relic - AWSSecretsManagerGetSecretValuePolicy: SecretArn: !ImportValue NewRelicLicenseKeySecret-NewRelic-LicenseKeySecretARN Copy Conventionally, you'll have a file named template.yaml that describes your function, and its resources. Serverless Framework Serverless Framework is a popular development and deployment tool for serverless applications. It's written in NodeJS, and for AWS, acts mostly as a higher-level abstraction on top of CloudFormation templates. It works well for Node, Python and Java functions. New Relic offers a Serverless Framework Plugin to simplify instrumentation of your Serverless Framework application. Install the plugin First, npm install --save-dev serverless-newrelic-lambda-layers Copy Or, alternatively, yarn add --dev serverless-newrelic-lambda-layers Copy Find your New Relic Account ID, your New Relic Personal API Key Then add the following to your serverless.yaml file: plugins: - serverless-newrelic-lambda-layers custom: newRelic: accountId: your-new-relic-account-id-here apiKey: your-new-relic-personal-api-key-here Copy Terraform Terraform is a popular general-purpose infrastructure as code tool. It can be used to manage AWS resources, as well as many other things. We offer some examples of New Relic instrumented Lambda functions deployed using Terraform scripts. Unusual integrations For most, one of the options above will work well. There's a chance that you can't use any of these solutions though. For guidance on how to customize your integration to fit your needs, read on. CloudWatch telemetry As mentioned previously we used to recommend sending your telemetry through CloudWatch Logs. This path can still work, though it is deprecated. Disable the extension by adding the NEW_RELIC_LAMBDA_EXTENSION_ENABLED environment variable to your function, with the value false. Create a CloudWatch Logs subscription filter, to invoke the newrelic-log-ingestion function with the logs for your function. The CLI can do this for you: newrelic-lambda subscriptions install --function <var>FUNCTION_NAME</var> Alternatively, use the AWS Console to create a subscription filter from your function's CloudWatch Log Group to invoke the newrelic-log-ingestion lambda function. See below. Manual process: Stream CloudWatch logs to New Relic Lambda Open CloudWatch and select Logs in the left-hand menu, and then select the log group for the function you are monitoring. Select Actions > Subscription filters > Create Lambda subscription filter. Under Lambda function, select the newrelic-log-ingestion function. Set the Log format to JSON. Set the Subscription filter pattern to ?REPORT ?NR_LAMBDA_MONITORING ?\"Task timed out\" ?RequestId. Alternatively, if you are using the LOGGING_ENABLED environment variable stream all your logs to our Logs, leave this field blank. See notes and caveats about this procedure. Important Make sure the newrelic-log-ingestion Lambda function you select in the method above is in the same AWS region as your Lambda function. Lambda console UI configuration While it is more error prone and labor intensive than the approaches above, it's possible to manually alter the configuration of a Lambda function to use New Relic from the AWS Lambda Console, for NodeJS, Python and Java. Find the layer that matches your runtime and region. Copy the Amazon Resource Name (ARN) of the most recent version and add it in the AWS Lambda console for your function. Update your function's handler to point to the newly attached layer in the console for your function: Python: newrelic_lambda_wrapper.handler (underscores) Node: newrelic-lambda-wrapper.handler (hyphens) Java: RequestHandler implementation: com.newrelic.java.HandlerWrapper::handleRequest RequestStreamHandlerWrapper implementation: com.newrelic.java.HandlerWrapper::handleStreamsRequest Add these environment variables to your Lambda console: NEW_RELIC_ACCOUNT_ID: Your account ID NEW_RELIC_LAMBDA_HANDLER: Path to your initial handler. Modify the Execution Role to allow access to the New Relic License Key secret Find the ARN of the secret named NEW_RELIC_LICENSE_KEY Add a new inline policy in the function's execution role that looks like this (replacing the SECRET_ARN with the value you found above): \"Statement\": [ { \"Action\": [ \"secretsmanager:GetSecretValue\" ], \"Resource\": \"SECRET_ARN\", \"Effect\": \"Allow\" } ] Copy Note that for Go and .NET, you must make source code changes to your Lambda function to instrument it. Configuration changes are not enough. Layer customization The layer contains several components, depending on your runtime: For all runtimes, the extension executable is packaged in the layer. For Python, NodeJS and Java, we also include: The New Relic Agent The AWS SDK instrumentation package for the New Relic Agent A handler wrapper, which configures the agent, and intercepts invocations, to start the instrumentation process, then invokes your handler. If you need a different wrapper, you can build your own layer, based on ours. See our newrelic-lambda-layers GitHub repo for the code contained in our wrapper function. By creating your own layer with a replacement wrapper, and applying it after ours, your wrapper will overwrite the one we supply. Similarly, you can include your custom wrapper directly in your function. Similarly, if you are testing a custom build of the agent, perhaps to address some bug, you could modify our layer packaging scripts above to package your agent build, and build your own layer. We explicitly do not recommend that you package the agent with your Lambda function. While this is possible, it makes it difficult for you to upgrade the agent and receive bug fixes. The layer may conflict with your vendored agent. Such a configuration should be regarded as unsupported, though it can work. What's next? After you complete these steps, here's what you can do next: See data reporting in the Lambda monitoring UI. If you're having trouble finding your data, see Lambda enable troubleshooting.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 58.87519,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Deployment <em>strategies</em>",
        "body": "This is one step of enabling <em>New</em> <em>Relic</em>&#x27;s AWS Lambda monitoring. Important Because there are several steps to integration, it&#x27;s important that you test your account link by deploying and testing an example function before instrumenting your own code. Deployment <em>strategies</em> There are many different"
      },
      "id": "605aa8a064441f453b868bb9"
    }
  ],
  "/docs/synthetics/index": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 73.03094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>",
        "body": " the key for existing private location: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 54.651413,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> monitoring: Aggregate monitor metrics",
        "sections": "<em>Synthetic</em> monitoring: Aggregate monitor metrics",
        "tags": "<em>Synthetics</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 51.482582,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetics</em>"
      },
      "id": "6045269d64441fcdc1378ecf"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/pages/synthetics-results-access-individual-monitor-runs": [
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.08495,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-10-07T18:43:29Z",
      "updated_at": "2021-08-27T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). You can also access it from one.newrelic.com > Synthetics > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.2744,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-10-07T18:44:24Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors, go to one.newrelic.com > Explorer > Synthetic monitors. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from synthetic monitors to applications, hosts, or custom groupings of any elements. Alternatively, you can go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27406,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/new-relic-synthetics/synthetics-api/synthetics-rest-api-version-1": [
    {
      "sections": [
        "Manage synthetic monitors via REST API",
        "Features",
        "Monitor types in API",
        "Use the API",
        "Caution",
        "Get all monitors",
        "Get a specific monitor",
        "Create a monitor",
        "Update an existing monitor",
        "Patch an existing monitor",
        "Delete an existing monitor",
        "Get a list of valid locations",
        "Script API for scripted browser and API test monitors",
        "Get monitor script",
        "Add scripted monitor",
        "Update monitor script",
        "Using private location scripts with verified script execution",
        "Important",
        "Scripted browser example",
        "Scripted browser API example",
        "Bash script example",
        "Tip"
      ],
      "title": "Manage synthetic monitors via REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "83a3e8ad751c7f0865785a1c2fad193604a7f7da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/manage-synthetics-monitors-rest-api/",
      "published_at": "2021-10-07T04:22:48Z",
      "updated_at": "2021-09-14T18:17:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Synthetics REST API to create and manage synthetic monitors of all types: ping, simple browser, scripted browser, and API test monitors. All synthetic monitoring data is available via the REST API. To use the Synthetics REST API, you must have a user role that allows that capability and a user key. For an overview of all available New Relic APIs, see Intro to APIs. Features The newest version of the Synthetics API (v3) adds these features: Synthetics API (v3) Features Options field for POST and PUT request You can specify the options for SIMPLE and BROWSER type monitors, similar to the way these options are available in the UI. PATCH request You can update only the fields of a monitor you want to change, rather than having to specify the entire monitor entity in a PUT. You can also specify the OPTION, assuming you are using the appropriate type of monitor. More detail with 400 Bad Request errors As of v3, the Synthetics API attempts to return as much information as possible when a validation failure occurs. This will help you figure out what might be wrong with the request. The API runs all validations and returns any failed validation messages, rather than failing on the first validation error as occurred in previous API versions. Pagination Large API responses are properly paginated. You can also use NRQL queries to analyze past changes made via the API. Monitor types in API These are the monitor types and how they're referred to in the API: Monitor type API name Ping SIMPLE Simple browser BROWSER Scripted browser SCRIPT_BROWSER API test SCRIPT_API Use the API To use the Synthetics REST API, you must have the ability to manage synthetics monitors and use a user key (the REST API key won't work). This API can be used for all Synthetics monitors. (Additional API methods for scripted browser and API test monitors are also available to update the script associated with those monitors.) All Synthetics data is available via the API. API examples show cURL commands. For US-based accounts, use the following endpoint: https://synthetics.newrelic.com/synthetics/api Copy For EU-based accounts, use the following endpoint: https://synthetics.eu.newrelic.com/synthetics/api Copy Caution The Synthetics REST API limits an account's rate of requests to three requests per second. Requests made in excess of this threshold will return a 429 response code. Get all monitors To view a list of all the monitors in your New Relic account, send a GET request to $API_ENDPOINT/v3/monitors. For example: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"monitors\": [ { \"id\": \"2a1bc369-7654-489d-918e-f6g135h7i2jk\", \"name\": \"monitor1\", \"type\": \"BROWSER\", \"frequency\": 60, \"uri\": \"http://example.com\", \"locations\": [ \"AWS_US_WEST_1\" ], \"status\": \"DISABLED\", \"slaThreshold\": 7, \"options\": {}, \"modifiedAt\": \"2016-09-26T23:12:46.981+0000\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"userId\": 0, \"apiVersion\": \"0.2.2\" } ], \"count\": 1 } Copy Query arguments: offset: The monitor count offset. Defaults to 0. For example, if you have 40 monitors and you use an offset value of 20, it will return monitors 21-40. limit: The number of results per page, maximum 100. Defaults to 50. You can include these in your cURL command as follows: curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors \\ -G -d 'offset=20&limit=100' Copy The headers include a Link to help you easily page your monitors. For example: <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=0&limit=20>; rel=\"first\", <https://synthetics.newrelic.com/synthetics/api/v3/monitors/?offset=40&limit=20>; rel=\"last\" Copy Get a specific monitor To view a single Synthetics monitor, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. curl -v \\ -H 'Api-Key:$API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"id\": UUID, \"name\": string, \"type\": string, \"frequency\": integer, \"uri\": string, \"locations\": array of strings, \"status\": string, \"slaThreshold\": double, \"userId\": integer, \"apiVersion\": string } Copy An invalid monitor ID will return 404 Not Found: The specified monitor doesn't exist. Create a monitor To add a new monitor to your Synthetics account, send a POST request to $API_ENDPOINT/v3/monitors with a JSON payload that describes the monitor. All fields in the following example are required unless stated otherwise: { \"name\": string [required], \"type\": string (SIMPLE, BROWSER, SCRIPT_API, SCRIPT_BROWSER) [required], \"frequency\": integer (minutes) [required, must be one of 1, 5, 10, 15, 30, 60, 360, 720, or 1440], \"uri\": string [required for SIMPLE and BROWSER type], \"locations\": array of strings [at least one required], \"status\": string (ENABLED, MUTED, DISABLED) [required], \"slaThreshold\": double, \"options\": { \"validationString\": string [only valid for SIMPLE and BROWSER types], \"verifySSL\": boolean (true, false) [only valid for SIMPLE and BROWSER types], \"bypassHEADRequest\": boolean (true, false) [only valid for SIMPLE types], \"treatRedirectAsFailure\": boolean (true, false) [only valid for SIMPLE types] } } Copy In addition, to add the script for a scripted monitor via the REST API, call an additional API endpoint to send the script for the monitor just created. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Replace the Synthetics REST API attributes in the following example with your specific values: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors \\ -d '{ \"name\" : \"monitor1\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"type\" : \"browser\", \"status\" : \"enabled\", \"slaThreshold\" : \"1.0\"}' Copy A successful request will return a 201 Created response, with the URI of the newly-created monitor specified in the location header. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example: the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 402 Payment Required: Creating the monitor will increase your scheduled checks past your account's purchased check limit. Update an existing monitor To update an existing monitor in New Relic, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. In addition, for scripted monitors, follow the procedures to update the BASE64 encoded script. All fields are required. However, the TYPE of the monitor cannot be changed. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\", \"type\": \"monitor type\", \"frequency\" : 15, \"uri\" : \"http://my-uri.com/\", \"locations\" : [ \"AWS_US_WEST_1\" ], \"status\" : \"enabled\", \"slaThreshold\": \"7.0\" }' Copy PUT requests are intended to replace target entities, so all attributes required in the JSON payload when creating a new monitor are also required when updating an existing monitor. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Patch an existing monitor To patch an existing monitor in New Relic, send a PATCH request to $API_ENDPOINT/v3/monitors/$MONITOR_ID. Use a specific monitor ID, and replace the Synthetics REST API attributes with your specific values. curl -v \\ -X PATCH -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' $API_ENDPOINT/v3/monitors/$MONITOR_ID \\ -d '{ \"name\" : \"updated monitor name\" }' Copy PATCH requests are intended to update individual attributes of your New Relic Synthetics monitor rather than updating the entire entity, so you may provide only the attributes you want to update. A successful request will return a 204 No Content response, with an empty body. Possible error codes include: 400 Bad Request: One or more of the monitor values is invalid, or the format of the request is invalid. For example, the frequency is out of bounds, or one or more of the specified locations is invalid. (See the error message in the body of the response.) 404 Not Found: The specified monitor does not exist. Delete an existing monitor To delete an existing monitor in New Relic Synthetics, send a DELETE request to $API_ENDPOINT/v3/monitors/$MONITOR_ID: curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE $API_ENDPOINT/v3/monitors/$MONITOR_ID Copy A successful request will return a 204 No Content response, with an empty body. An unsuccessful request will return the response 404 Not Found: The specified monitor does not exist. Get a list of valid locations To retrieve the list of valid locations in New Relic Synthetics, use the following command: curl -v \\ -X GET -H 'Api-Key:$API_KEY' $API_ENDPOINT/v1/locations Copy Script API for scripted browser and API test monitors In addition to the general API, there are several API methods for the scripted browsers (SCRIPT_BROWSER) and API test browsers (SCRIPT_API). These examples show cURL commands. Get monitor script To view the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a GET request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script. For example: curl -v -H 'Api-Key: $API_KEY' $API_ENDPOINT/v3/monitors/$MONITOR_ID/script Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"scriptText\": BASE64 encoded string } Copy Possible error codes include: 403 Forbidden: The specified monitor is not of type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor doesn't exist or the script associated with the monitor doesn't exist. Add scripted monitor To add a new scripted monitor to New Relic Synthetics with the REST API: Follow standard API procedures to add a new monitor, and identify the type as a SCRIPT_BROWSER or SCRIPT_API. Update the new monitor with a BASE64 encoded version of the script to the $MONITOR_UUID/script endpoint. For more information, refer to the example. If you are using private locations with verified script execution enabled, see script locations with verified script execution. Update monitor script To update the script associated with a specific SCRIPT_BROWSER or SCRIPT_API monitor in New Relic Synthetics for your account, send a PUT request to $API_ENDPOINT/v3/monitors/$MONITOR_ID/script with a JSON payload that contains the scriptText (required). scriptPayload='{\"scriptText\":BASE64 encoded string}' curl -v -X PUT \\ -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' \\ $API_ENDPOINT/v3/monitors/$MONITOR_UUID/script \\ -d $scriptPayload Copy If you are using private locations with verified script execution enabled, see script locations with verified script execution. A successful request will return a 204 No Content response with an empty body. Possible error codes include: 400 Bad Request: Invalid BASE64 encoded string for scriptText or hmac. 403 Forbidden: The specified monitor is not of the type SCRIPT_BROWSER or SCRIPT_API. 404 Not Found: The specified monitor does not exist. Using private location scripts with verified script execution When creating or updating monitors for private locations that have verified script execution turned on, you must use scriptLocations to set the password: { \"scriptText\": BASE64 encoded String, \"scriptLocations\": [ { \"name\": Location name, \"hmac\" BASE64 encoded String of SHA256 HMAC for location } ] } Copy The password used to generate the HMAC string must match the password set for the private location. If you have multiple locations with Verified script execution enabled each location must have the HMAC calculated. When generating the HMAC string, use the SHA256 algorithm with the script and password. Here's an example for the script: var assert = require('assert'); assert.equal('1', '1'); Copy This example uses password as the password for the scriptLocation: curl -v -X PUT -H 'Api-Key: '$API_KEY' -H 'content-type: application/json' $API_ENDPOINT}/v3/monitors/$MONITOR_ID/script -d '{ \"scriptText\": \"dmFyIGFzc2VydCA9IHJlcXVpcmUoJ2Fzc2VydCcpOw0KYXNzZXJ0LmVxdWFsKCcxJywgJzEnKTs=\",\"scriptLocations\": [ { \"name\": \"my_vse_enabled_location\", \"hmac\": \"MjhiNGE4MjVlMDE1N2M4NDQ4MjNjNDFkZDEyYTRjMmUzZDE3NGJlNjU0MWFmOTJlMzNiODExOGU2ZjhkZTY4ZQ==\"} ]}' Copy Important You must remove the last newline character from both the script and the calculated HMAC value before encoding in BASE64. Calculation steps: Calculate the HMAC value from the script. One way is to use: cat script | openssl dgst -sha256 -hmac \"password\" > hmac Remove the newline character if one was added by openssl. Encode the HMAC in BASE64 without line breaks. Scripted browser example Here is an example of using New Relic's REST API and the bash script to create a scripted browser monitor. Scripted browser API example The following example shows cURL commands to create a scripted browser monitor. At the top of the script, replace the variables with your specific values. For the scriptfile variable, identify the filename for the script to be created. Here is a sample script that can be saved as sample_synth_script.js to use in the example: var assert = require(\"assert\"); $browser.get(\"http://example.com\").then(function(){ // Check the H1 title matches \"Example Domain\" return $browser.findElement($driver.By.css(\"h1\")).then(function(element){ return element.getText().then(function(text){ assert.equal(\"Example Domain\", text, \"Page H1 title did not match\"); }); }); }).then(function(){ // Check that the external link matches \"http://www.iana.org/domains/example\" return $browser.findElement($driver.By.css(\"div > p > a\")).then(function(element){ return element.getAttribute(\"href\").then(function(link){ assert.equal(\"http://www.iana.org/domains/example\", link, \"More information link did not match\"); }); }); }); Copy Bash script example This example shows the bash script that will create the SCRIPTED_BROWSER monitor. Tip In some cases you may want to use -w 0, which will disable line wrapping: base64 -w 0 $scriptfile #!/bin/bash # API key from your account settings API_KEY='' # Other attributes found at https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/attributes-synthetics-rest-api#api-attributes monitorName='Test API Script' monitorType='SCRIPT_BROWSER' frequency=1440 locations='\"AWS_US_WEST_1\", \"AWS_US_EAST_1\"' slaThreshold=7.0 # Location of the file with your script scriptfile=sample_synth_script.js # Test that the script file exists (does not validate content) if [ -e \"$scriptfile\" ] then script=$(cat \"$scriptfile\") payload=\"{ \\\"name\\\" : \\\"$monitorName\\\", \\\"frequency\\\" : $frequency, \\\"locations\\\" : [ $locations ], \\\"status\\\" : \\\"ENABLED\\\", \\\"type\\\" : \\\"$monitorType\\\", \\\"slaThreshold\\\" : $slaThreshold, \\\"uri\\\":\\\"\\\"}\" echo \"Creating monitor\" # Make cURL call to API and parse response headers to get monitor UUID shopt -s extglob # Required to trim whitespace; see below while IFS=':' read key value; do # trim whitespace in \"value\" value=${value##+([[:space:]])}; value=${value%%+([[:space:]])} case \"$key\" in location) LOCATION=\"$value\" ;; HTTP*) read PROTO STATUS MSG <<< \"$key{$value:+:$value}\" ;; esac done < <(curl -sS -i -X POST -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' https://synthetics.newrelic.com/synthetics/api/v3/monitors -d \"$payload\") # Validate monitor creation & add script unless it failed if [ $STATUS = 201 ]; then echo \"Monitor created, $LOCATION \" echo \"Uploading script\" # base64 encode script encoded=`echo \"$script\" | base64` scriptPayload=\"{\\\"scriptText\\\":\\\"$encoded\\\"}\" curl -s -X PUT -H \"Api-Key:$API_KEY\" -H 'Content-Type:application/json' \"$LOCATION/script\" -d $scriptPayload echo \"Script uploaded\" else echo \"Monitor creation failed\" fi else echo \"script file not found, not creating monitor\" fi Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.8526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "sections": "Manage <em>synthetic</em> <em>monitors</em> via <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " will disable line wrapping: base64 -w 0 $scriptfile #!&#x2F;bin&#x2F;bash # <em>API</em> key from your account settings <em>API</em>_KEY=&#x27;&#x27; # Other attributes found at https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;<em>apis</em>&#x2F;<em>synthetics</em>-<em>rest</em>-<em>api</em>&#x2F;<em>monitor</em>-<em>examples</em>&#x2F;attributes-<em>synthetics</em>-<em>rest</em>-<em>api</em>#<em>api</em>-attributes <em>monitor</em>Name=&#x27;Test <em>API</em> Script&#x27; <em>monitor</em>"
      },
      "id": "60440d4628ccbc74532c606a"
    },
    {
      "sections": [
        "Payload attributes for the Synthetics REST API",
        "Synthetic monitoring attributes",
        "Specific monitor endpoint",
        "For more help"
      ],
      "title": "Payload attributes for the Synthetics REST API",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Monitor examples"
      ],
      "external_id": "ed3202f6715ae367d5c7c58d63a332d073535995",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/monitor-examples/payload-attributes-synthetics-rest-api/",
      "published_at": "2021-10-07T18:20:11Z",
      "updated_at": "2021-03-11T11:46:10Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For REST API requirements for synthetics, see Use the API. Synthetic monitoring attributes Here are the attributes that can be used when creating and managing monitors with the Synthetics REST API: Synthetics API attribute Definition apiVersion String: The version number. count Integer: The number of monitors returned. emails Array of strings: Email addresses for alert notifications with New Relic. frequency Integer: Number of minutes between checks. Valid values include 1, 5, 15, 30, 60, 360, 720, and 1440. id The UUID for the specific synthetic monitor. locations Array of strings: Array of locations by full label. name String: The monitor's name. scriptLocations String: The name and hmac values for private locations using Verified Script Execution. scriptText String: The BASE64 encoded text for scripted monitors. slaThreshold Double: Value for the Synthetics SLA report, in seconds. status String: Valid values include ENABLED, MUTED, and DISABLED. type String: Type of monitor. Valid values include: SIMPLE (Ping) BROWSER SCRIPT_BROWSER SCRIPT_API uri String: The URI for SIMPLE and BROWSER monitor types; for example, http://my-site.com. Optional for SCRIPT_BROWSER and SCRIPT_API. userID Integer: The specific user ID. options Object: options for SIMPLE and BROWSER monitor types. Options include: validationString: string verifySSL: boolean (true, false) bypassHEADRequest: boolean (true, false) treatRedirectAsFailure: boolean (true, false) Specific monitor endpoint When making REST API calls for a specific monitor, include the monitor_uuid as part of the endpoint. The monitor_uuid is the GUID which is part of the URL. For example, a selected synthetic monitor has this URL: https://synthetics.newrelic.com/accounts/nnnn/monitors/ab123-c456d-e78-90123-f45g Copy The monitor_uuid is the value that follows /monitors/. For more help Additional documentation resources include: Manage synthetic monitors via the REST API (API procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the REST API (REST API calls for email alerts for synthetic monitors) Use synthetics label APIs (REST API calls for labels and categories used by synthetic monitors)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.97354,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "sections": "Payload attributes for the <em>Synthetics</em> <em>REST</em> <em>API</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": " The <em>monitor</em>_uuid is the value that follows &#x2F;monitors&#x2F;. For more help Additional documentation resources include: Manage synthetic monitors via the <em>REST</em> <em>API</em> (<em>API</em> procedures for synthetic simple and scripted monitors) Manage synthetic alert notifications via the <em>REST</em> <em>API</em> (<em>REST</em> <em>API</em> calls for email alerts for synthetic monitors) Use <em>synthetics</em> label <em>APIs</em> (<em>REST</em> <em>API</em> calls for labels and categories used by synthetic monitors)"
      },
      "id": "6043f9ae28ccbc98002c607a"
    },
    {
      "sections": [
        "Use synthetic monitoring secure credentials APIs",
        "Requirements and rules",
        "API examples",
        "Add a secure credential",
        "Get all secure credentials",
        "Get a specific secure credential",
        "Update an existing secure credential",
        "Delete an existing secure credential",
        "For more help"
      ],
      "title": "Use synthetic monitoring secure credentials APIs",
      "type": "docs",
      "tags": [
        "APIs",
        "Synthetics REST API",
        "Secure credentials examples"
      ],
      "external_id": "bd66e43160c1fd4c9f66bfdfa2d9a3223eb5d4d7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/synthetics-rest-api/secure-credentials-examples/use-synthetics-secure-credentials-apis/",
      "published_at": "2021-10-07T18:20:11Z",
      "updated_at": "2021-03-13T05:09:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With the Synthetics REST API, you can make API calls to change or retrieve secure credentials data. This document explains the API requirements and contains API curl command examples. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials. Requirements and rules For general rules about this feature, see the secure credentials requirements. API requirements and rules include: See general Synthetics REST API requirements. An account's rate of requests is limited to three requests per second. Requests that exceed this threshold will return a 429 response code. A key's value cannot be accessed via the API; an unauthorized user would not have access to the secure key values. API examples Add a secure credential To send a secure credential to your New Relic account, send a POST request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials with a JSON payload that describes the secure credential. Here's an example: { \"key\": string [required, 1-64 characters uppercase], \"value\": string [required, 1-3,000 characters], \"description\": string [optional] } Copy Here's an example of doing this with a curl command: curl -v \\ -X POST -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy A successful request will return a 201 Created response, with the URI of the newly-created secure credential specified in the location header. Possible error codes include: 303 See Other: The specified key already exists. The returned location header will contain the URI to the key. 400 Bad Request: Key too long or missing, value too long or missing, non-parsable JSON payload. Get all secure credentials To view a list of all the secure credentials in your New Relic account, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials. For example: curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"secureCredentials\": [ { \"key\": \"MYKEY1\", \"description\": \"Description of MYKEY1\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" }, { \"key\": \"MYKEY2\", \"description\": \"Description of MYKEY2\", \"createdAt\": \"2016-09-26T23:12:46.981+0000\", \"lastUpdated\": \"2016-09-26T23:12:46.981+0000\" } ], \"count\": 2 } Copy Get a specific secure credential To view a single secure credential, send a GET request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy A successful request will return a 200 OK response. The data returned will be a JSON object in the following format: { \"key\": string, \"description\": string, \"createdAt\": date,​ \"lastUpdated\": date } Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Update an existing secure credential To update an existing credential in New Relic, send a PUT request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -X PUT -H 'Api-Key:$API_KEY' \\ -H 'Content-Type: application/json' https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY \\ -d '{ \"key\": \"MYKEY\", \"value\": \"my value\", \"description\": \"Description of MYKEY\" }' Copy An invalid key will return 404 Not Found: The specified key doesn't exist. Delete an existing secure credential To delete an existing credential in New Relic, send a DELETE request to https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY. curl -v \\ -H 'Api-Key:$API_KEY' \\ -X DELETE https://synthetics.newrelic.com/synthetics/api/v1/secure-credentials/$KEY Copy Please note that if the specified key does not exist, no error will occur. For more help",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 101.23957,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "sections": "Use <em>synthetic</em> <em>monitoring</em> secure credentials <em>APIs</em>",
        "tags": "<em>Synthetics</em> <em>REST</em> <em>API</em>",
        "body": "With the <em>Synthetics</em> <em>REST</em> <em>API</em>, you can make <em>API</em> calls to change or retrieve secure credentials data. This document explains the <em>API</em> requirements and contains <em>API</em> curl command <em>examples</em>. For general guidelines for setting secure credentials and setting them in the UI, see Secure credentials"
      },
      "id": "6044070d196a67b171960f76"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91093,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-10-07T09:06:27Z",
      "updated_at": "2021-08-08T21:09:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, we'll attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-10-07T18:41:18Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.47012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/identify-synthetic-monitoring-requests-your-app": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-10-07T09:06:27Z",
      "updated_at": "2021-08-08T21:09:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, we'll attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Compare page load performance in browser and synthetic monitoring",
        "Compare performance and trends",
        "What you need",
        "Enable comparison data",
        "Enable comparative charting from Synthetics UI",
        "Enable comparative charting from browser monitoring UI",
        "View comparison data",
        "Hide or return comparison data",
        "Data sources"
      ],
      "title": "Compare page load performance in browser and synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "a789c407a0fecbd2ce888fdee7805abe8152f0a4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring/",
      "published_at": "2021-10-07T18:40:36Z",
      "updated_at": "2021-07-09T23:24:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring regularly checks your websites, critical business transactions, and API endpoints to measure optimal performance. Browser monitoring tracks the actual results of webpage performance across all variations of devices, browsers, and connection speeds. Used together, they provide a direct page load time comparison between real user (browser) interactions and the synthetic monitors. Compare performance and trends New Relic's comparative charting feature helps operations managers and teams by providing: Benchmarks for page load times Additional insights to help you plan where to optimize your site Comparisons of synthetic trends vs. actual browser performance without needing to switch between our monitoring capabilities. For example, during a page outage, you can compare synthetic monitoring trends to actual browser monitoring comparisons to see if an issue is also visible in Synthetics UI, or if it is caused by variables outside of New Relic. This helps you more efficiently know where to take action. What you need The comparative charting feature requires: Browser monitoring enabled with the browser SPA agent (version 885 or higher). A synthetic browser or scripted monitor with one or more tests on the same URLs monitored by the browser agent. After you enable the comparative charting feature either from synthetic or from browser monitoring, no additional setup is required. The comparative charting feature will appear when New Relic finds matching URLs. Enable comparison data After you enable the comparative charting feature from either synthetic or browser monitoring, no additional setup is required. The comparative charting feature will appear whenever synthetics or browser monitoring finds matching URLs. Enable comparative charting from Synthetics UI To enable the comparative charting feature from Synthetics UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. Above the selected monitor's Availability chart, select the ellipsis icon. Select Enable Synthetics comparison. Enable comparative charting from browser monitoring UI To enable the comparison data feature from browser monitoring: Go to one.newrelic.com > Browser > (select a browser app) > Page views. Select a page monitored by synthetic monitoring. From the selected page's Performance tab, select the ellipsis icon. Select Enable Synthetics comparison. View comparison data The comparative charting feature appears whenever synthetic monitoring identifies a URL match with browser monitoring and can compare it. You can compare browser and synthetic's performance either from the synthetic monitoring Summary page or from the browser monitoring Page views page (for browser apps or single page apps) without needing to switch between New Relic capabilities. Based on the selected data sources, the summary shows: Overall speed percentage comparison between browser (real user) page views and any matching URLs found in synthetic monitors that the user has permissions to view Number of URLs found in synthetic monitors that match the browser rollup URL To view the comparative charting summary: From synthetic monitoring UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. OR From browser monitoring UI: Go to one.newrelic.com > Browser > (select a browser app) > Page views, then select a page monitored by synthetic monitoring. Review the comparative charting feature's summary of overall speed percentage and number of matching URLs. To view additional details, select the summary's right arrow icon. Please note that in some cases the simple browser monitor ends before the browser agent has had a chance to collect the BrowserInteraction event. In this case, no comparative charting data is displayed in the UI. In order to resolve this issue, create a scripted browser monitor instead, and add a call to wait (sleep) after the page is loaded. Here is an example: $browser.get('https://www.mywebsite.com').then(function(){ return $browser.sleep(1000); }) Copy Hide or return comparison data To hide the comparative charting feature, select the ellipsis icon. To keep it visible but move it away from the top of the page, select Move to bottom. To return it to its original place on the page, select Move to top. To remove it from the page, select Hide all Synthetics/Browser comparisons. To return it to the page after removing it, follow standard procedures to enable comparison charting. Data sources New Relic uses these data sources for the synthetics and browser comparison in the UI. For deeper analysis of the comparative chart data you see in the UI, use the query builder to run NRQL queries. Variable Description Monitor account ID The account from which you are running the monitor: SELECT monitorAccountId FROM BrowserInteraction Copy Monitor ID The unique ID assigned to your synthetic monitor: SELECT monitorId FROM BrowserInteraction Copy Monitor job ID The ID of a single synthetics monitor run, which began at a specific time and originated from a specific location: SELECT monitorJobId FROM BrowserInteraction LIMIT 1 Copy Real user average The average page load time for real users viewing your website (excludes synthetic monitors). Real user page views Page view details coming from visitors to your website (exclude synthetic monitors). Synthetic's average The average page load time from the synthetic simple or scripted monitors that ran on your website. Synthetic's page views Only traffic generated by synthetic simple or scripted monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "sections": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " permissions to view Number of URLs found in <em>synthetic</em> monitors that match the browser rollup URL To view the comparative charting summary: From <em>synthetic</em> <em>monitoring</em> UI: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; (select a <em>monitor</em>) &gt; Summary. OR From browser <em>monitoring</em> UI: Go to one.newrelic.com &gt; Browser"
      },
      "id": "604525b7e7b9d251f85799e1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-10-07T09:06:27Z",
      "updated_at": "2021-08-08T21:09:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, we'll attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Compare page load performance in browser and synthetic monitoring",
        "Compare performance and trends",
        "What you need",
        "Enable comparison data",
        "Enable comparative charting from Synthetics UI",
        "Enable comparative charting from browser monitoring UI",
        "View comparison data",
        "Hide or return comparison data",
        "Data sources"
      ],
      "title": "Compare page load performance in browser and synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "a789c407a0fecbd2ce888fdee7805abe8152f0a4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring/",
      "published_at": "2021-10-07T18:40:36Z",
      "updated_at": "2021-07-09T23:24:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring regularly checks your websites, critical business transactions, and API endpoints to measure optimal performance. Browser monitoring tracks the actual results of webpage performance across all variations of devices, browsers, and connection speeds. Used together, they provide a direct page load time comparison between real user (browser) interactions and the synthetic monitors. Compare performance and trends New Relic's comparative charting feature helps operations managers and teams by providing: Benchmarks for page load times Additional insights to help you plan where to optimize your site Comparisons of synthetic trends vs. actual browser performance without needing to switch between our monitoring capabilities. For example, during a page outage, you can compare synthetic monitoring trends to actual browser monitoring comparisons to see if an issue is also visible in Synthetics UI, or if it is caused by variables outside of New Relic. This helps you more efficiently know where to take action. What you need The comparative charting feature requires: Browser monitoring enabled with the browser SPA agent (version 885 or higher). A synthetic browser or scripted monitor with one or more tests on the same URLs monitored by the browser agent. After you enable the comparative charting feature either from synthetic or from browser monitoring, no additional setup is required. The comparative charting feature will appear when New Relic finds matching URLs. Enable comparison data After you enable the comparative charting feature from either synthetic or browser monitoring, no additional setup is required. The comparative charting feature will appear whenever synthetics or browser monitoring finds matching URLs. Enable comparative charting from Synthetics UI To enable the comparative charting feature from Synthetics UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. Above the selected monitor's Availability chart, select the ellipsis icon. Select Enable Synthetics comparison. Enable comparative charting from browser monitoring UI To enable the comparison data feature from browser monitoring: Go to one.newrelic.com > Browser > (select a browser app) > Page views. Select a page monitored by synthetic monitoring. From the selected page's Performance tab, select the ellipsis icon. Select Enable Synthetics comparison. View comparison data The comparative charting feature appears whenever synthetic monitoring identifies a URL match with browser monitoring and can compare it. You can compare browser and synthetic's performance either from the synthetic monitoring Summary page or from the browser monitoring Page views page (for browser apps or single page apps) without needing to switch between New Relic capabilities. Based on the selected data sources, the summary shows: Overall speed percentage comparison between browser (real user) page views and any matching URLs found in synthetic monitors that the user has permissions to view Number of URLs found in synthetic monitors that match the browser rollup URL To view the comparative charting summary: From synthetic monitoring UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. OR From browser monitoring UI: Go to one.newrelic.com > Browser > (select a browser app) > Page views, then select a page monitored by synthetic monitoring. Review the comparative charting feature's summary of overall speed percentage and number of matching URLs. To view additional details, select the summary's right arrow icon. Please note that in some cases the simple browser monitor ends before the browser agent has had a chance to collect the BrowserInteraction event. In this case, no comparative charting data is displayed in the UI. In order to resolve this issue, create a scripted browser monitor instead, and add a call to wait (sleep) after the page is loaded. Here is an example: $browser.get('https://www.mywebsite.com').then(function(){ return $browser.sleep(1000); }) Copy Hide or return comparison data To hide the comparative charting feature, select the ellipsis icon. To keep it visible but move it away from the top of the page, select Move to bottom. To return it to its original place on the page, select Move to top. To remove it from the page, select Hide all Synthetics/Browser comparisons. To return it to the page after removing it, follow standard procedures to enable comparison charting. Data sources New Relic uses these data sources for the synthetics and browser comparison in the UI. For deeper analysis of the comparative chart data you see in the UI, use the query builder to run NRQL queries. Variable Description Monitor account ID The account from which you are running the monitor: SELECT monitorAccountId FROM BrowserInteraction Copy Monitor ID The unique ID assigned to your synthetic monitor: SELECT monitorId FROM BrowserInteraction Copy Monitor job ID The ID of a single synthetics monitor run, which began at a specific time and originated from a specific location: SELECT monitorJobId FROM BrowserInteraction LIMIT 1 Copy Real user average The average page load time for real users viewing your website (excludes synthetic monitors). Real user page views Page view details coming from visitors to your website (exclude synthetic monitors). Synthetic's average The average page load time from the synthetic simple or scripted monitors that ran on your website. Synthetic's page views Only traffic generated by synthetic simple or scripted monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "sections": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " permissions to view Number of URLs found in <em>synthetic</em> monitors that match the browser rollup URL To view the comparative charting summary: From <em>synthetic</em> <em>monitoring</em> UI: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; (select a <em>monitor</em>) &gt; Summary. OR From browser <em>monitoring</em> UI: Go to one.newrelic.com &gt; Browser"
      },
      "id": "604525b7e7b9d251f85799e1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-monitoring-audit-log-track-changes-made-users": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-10-07T09:06:27Z",
      "updated_at": "2021-08-08T21:09:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, we'll attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Compare page load performance in browser and synthetic monitoring",
        "Compare performance and trends",
        "What you need",
        "Enable comparison data",
        "Enable comparative charting from Synthetics UI",
        "Enable comparative charting from browser monitoring UI",
        "View comparison data",
        "Hide or return comparison data",
        "Data sources"
      ],
      "title": "Compare page load performance in browser and synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "a789c407a0fecbd2ce888fdee7805abe8152f0a4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring/",
      "published_at": "2021-10-07T18:40:36Z",
      "updated_at": "2021-07-09T23:24:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring regularly checks your websites, critical business transactions, and API endpoints to measure optimal performance. Browser monitoring tracks the actual results of webpage performance across all variations of devices, browsers, and connection speeds. Used together, they provide a direct page load time comparison between real user (browser) interactions and the synthetic monitors. Compare performance and trends New Relic's comparative charting feature helps operations managers and teams by providing: Benchmarks for page load times Additional insights to help you plan where to optimize your site Comparisons of synthetic trends vs. actual browser performance without needing to switch between our monitoring capabilities. For example, during a page outage, you can compare synthetic monitoring trends to actual browser monitoring comparisons to see if an issue is also visible in Synthetics UI, or if it is caused by variables outside of New Relic. This helps you more efficiently know where to take action. What you need The comparative charting feature requires: Browser monitoring enabled with the browser SPA agent (version 885 or higher). A synthetic browser or scripted monitor with one or more tests on the same URLs monitored by the browser agent. After you enable the comparative charting feature either from synthetic or from browser monitoring, no additional setup is required. The comparative charting feature will appear when New Relic finds matching URLs. Enable comparison data After you enable the comparative charting feature from either synthetic or browser monitoring, no additional setup is required. The comparative charting feature will appear whenever synthetics or browser monitoring finds matching URLs. Enable comparative charting from Synthetics UI To enable the comparative charting feature from Synthetics UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. Above the selected monitor's Availability chart, select the ellipsis icon. Select Enable Synthetics comparison. Enable comparative charting from browser monitoring UI To enable the comparison data feature from browser monitoring: Go to one.newrelic.com > Browser > (select a browser app) > Page views. Select a page monitored by synthetic monitoring. From the selected page's Performance tab, select the ellipsis icon. Select Enable Synthetics comparison. View comparison data The comparative charting feature appears whenever synthetic monitoring identifies a URL match with browser monitoring and can compare it. You can compare browser and synthetic's performance either from the synthetic monitoring Summary page or from the browser monitoring Page views page (for browser apps or single page apps) without needing to switch between New Relic capabilities. Based on the selected data sources, the summary shows: Overall speed percentage comparison between browser (real user) page views and any matching URLs found in synthetic monitors that the user has permissions to view Number of URLs found in synthetic monitors that match the browser rollup URL To view the comparative charting summary: From synthetic monitoring UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. OR From browser monitoring UI: Go to one.newrelic.com > Browser > (select a browser app) > Page views, then select a page monitored by synthetic monitoring. Review the comparative charting feature's summary of overall speed percentage and number of matching URLs. To view additional details, select the summary's right arrow icon. Please note that in some cases the simple browser monitor ends before the browser agent has had a chance to collect the BrowserInteraction event. In this case, no comparative charting data is displayed in the UI. In order to resolve this issue, create a scripted browser monitor instead, and add a call to wait (sleep) after the page is loaded. Here is an example: $browser.get('https://www.mywebsite.com').then(function(){ return $browser.sleep(1000); }) Copy Hide or return comparison data To hide the comparative charting feature, select the ellipsis icon. To keep it visible but move it away from the top of the page, select Move to bottom. To return it to its original place on the page, select Move to top. To remove it from the page, select Hide all Synthetics/Browser comparisons. To return it to the page after removing it, follow standard procedures to enable comparison charting. Data sources New Relic uses these data sources for the synthetics and browser comparison in the UI. For deeper analysis of the comparative chart data you see in the UI, use the query builder to run NRQL queries. Variable Description Monitor account ID The account from which you are running the monitor: SELECT monitorAccountId FROM BrowserInteraction Copy Monitor ID The unique ID assigned to your synthetic monitor: SELECT monitorId FROM BrowserInteraction Copy Monitor job ID The ID of a single synthetics monitor run, which began at a specific time and originated from a specific location: SELECT monitorJobId FROM BrowserInteraction LIMIT 1 Copy Real user average The average page load time for real users viewing your website (excludes synthetic monitors). Real user page views Page view details coming from visitors to your website (exclude synthetic monitors). Synthetic's average The average page load time from the synthetic simple or scripted monitors that ran on your website. Synthetic's page views Only traffic generated by synthetic simple or scripted monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "sections": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " permissions to view Number of URLs found in <em>synthetic</em> monitors that match the browser rollup URL To view the comparative charting summary: From <em>synthetic</em> <em>monitoring</em> UI: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; (select a <em>monitor</em>) &gt; Summary. OR From browser <em>monitoring</em> UI: Go to one.newrelic.com &gt; Browser"
      },
      "id": "604525b7e7b9d251f85799e1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Compare page load performance in browser and synthetic monitoring",
        "Compare performance and trends",
        "What you need",
        "Enable comparison data",
        "Enable comparative charting from Synthetics UI",
        "Enable comparative charting from browser monitoring UI",
        "View comparison data",
        "Hide or return comparison data",
        "Data sources"
      ],
      "title": "Compare page load performance in browser and synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "a789c407a0fecbd2ce888fdee7805abe8152f0a4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring/",
      "published_at": "2021-10-07T18:40:36Z",
      "updated_at": "2021-07-09T23:24:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring regularly checks your websites, critical business transactions, and API endpoints to measure optimal performance. Browser monitoring tracks the actual results of webpage performance across all variations of devices, browsers, and connection speeds. Used together, they provide a direct page load time comparison between real user (browser) interactions and the synthetic monitors. Compare performance and trends New Relic's comparative charting feature helps operations managers and teams by providing: Benchmarks for page load times Additional insights to help you plan where to optimize your site Comparisons of synthetic trends vs. actual browser performance without needing to switch between our monitoring capabilities. For example, during a page outage, you can compare synthetic monitoring trends to actual browser monitoring comparisons to see if an issue is also visible in Synthetics UI, or if it is caused by variables outside of New Relic. This helps you more efficiently know where to take action. What you need The comparative charting feature requires: Browser monitoring enabled with the browser SPA agent (version 885 or higher). A synthetic browser or scripted monitor with one or more tests on the same URLs monitored by the browser agent. After you enable the comparative charting feature either from synthetic or from browser monitoring, no additional setup is required. The comparative charting feature will appear when New Relic finds matching URLs. Enable comparison data After you enable the comparative charting feature from either synthetic or browser monitoring, no additional setup is required. The comparative charting feature will appear whenever synthetics or browser monitoring finds matching URLs. Enable comparative charting from Synthetics UI To enable the comparative charting feature from Synthetics UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. Above the selected monitor's Availability chart, select the ellipsis icon. Select Enable Synthetics comparison. Enable comparative charting from browser monitoring UI To enable the comparison data feature from browser monitoring: Go to one.newrelic.com > Browser > (select a browser app) > Page views. Select a page monitored by synthetic monitoring. From the selected page's Performance tab, select the ellipsis icon. Select Enable Synthetics comparison. View comparison data The comparative charting feature appears whenever synthetic monitoring identifies a URL match with browser monitoring and can compare it. You can compare browser and synthetic's performance either from the synthetic monitoring Summary page or from the browser monitoring Page views page (for browser apps or single page apps) without needing to switch between New Relic capabilities. Based on the selected data sources, the summary shows: Overall speed percentage comparison between browser (real user) page views and any matching URLs found in synthetic monitors that the user has permissions to view Number of URLs found in synthetic monitors that match the browser rollup URL To view the comparative charting summary: From synthetic monitoring UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. OR From browser monitoring UI: Go to one.newrelic.com > Browser > (select a browser app) > Page views, then select a page monitored by synthetic monitoring. Review the comparative charting feature's summary of overall speed percentage and number of matching URLs. To view additional details, select the summary's right arrow icon. Please note that in some cases the simple browser monitor ends before the browser agent has had a chance to collect the BrowserInteraction event. In this case, no comparative charting data is displayed in the UI. In order to resolve this issue, create a scripted browser monitor instead, and add a call to wait (sleep) after the page is loaded. Here is an example: $browser.get('https://www.mywebsite.com').then(function(){ return $browser.sleep(1000); }) Copy Hide or return comparison data To hide the comparative charting feature, select the ellipsis icon. To keep it visible but move it away from the top of the page, select Move to bottom. To return it to its original place on the page, select Move to top. To remove it from the page, select Hide all Synthetics/Browser comparisons. To return it to the page after removing it, follow standard procedures to enable comparison charting. Data sources New Relic uses these data sources for the synthetics and browser comparison in the UI. For deeper analysis of the comparative chart data you see in the UI, use the query builder to run NRQL queries. Variable Description Monitor account ID The account from which you are running the monitor: SELECT monitorAccountId FROM BrowserInteraction Copy Monitor ID The unique ID assigned to your synthetic monitor: SELECT monitorId FROM BrowserInteraction Copy Monitor job ID The ID of a single synthetics monitor run, which began at a specific time and originated from a specific location: SELECT monitorJobId FROM BrowserInteraction LIMIT 1 Copy Real user average The average page load time for real users viewing your website (excludes synthetic monitors). Real user page views Page view details coming from visitors to your website (exclude synthetic monitors). Synthetic's average The average page load time from the synthetic simple or scripted monitors that ran on your website. Synthetic's page views Only traffic generated by synthetic simple or scripted monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "sections": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " permissions to view Number of URLs found in <em>synthetic</em> monitors that match the browser rollup URL To view the comparative charting summary: From <em>synthetic</em> <em>monitoring</em> UI: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; (select a <em>monitor</em>) &gt; Summary. OR From browser <em>monitoring</em> UI: Go to one.newrelic.com &gt; Browser"
      },
      "id": "604525b7e7b9d251f85799e1"
    },
    {
      "sections": [
        "Upcoming synthetic monitor public minion IP addresses",
        "US public minions: Upcoming IP addresses",
        "EU public minions: Upcoming IP addresses"
      ],
      "title": "Upcoming synthetic monitor public minion IP addresses",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "81c0e0d3f87a627ad01f220f215f7b848f54608d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/new-synthetic-public-minion-ips/",
      "published_at": "2021-10-07T18:41:18Z",
      "updated_at": "2021-04-04T20:14:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "On July 15 2021, we'll be adding new IP addresses for several synthetics locations for both US locations and EU locations. To ensure your monitors are not affected by these changes, please add the appropriate IP addresses to your firewalls allow list. For the current list of IP addresses and more about this topic, see Synthetic monitor public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 54.250.11.193 3.113.102.86 52.193.74.189 18.177.40.17 ec2-54-250-11-193.ap-northeast-1.compute.amazonaws.com ec2-3-113-102-86.ap-northeast-1.compute.amazonaws.com ec2-52-193-74-189.ap-northeast-1.compute.amazonaws.com ec2-18-177-40-17.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 3.34.173.249 52.79.48.153 ec2-3-34-173-249.ap-northeast-2.compute.amazonaws.com ec2-52-79-48-153.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 65.1.222.35 ec2-65-1-222-35.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 52.76.41.181 54.179.195.220 18.138.16.42 ec2-52-76-41-181.ap-southeast-1.compute.amazonaws.com ec2-54-179-195-220.ap-southeast-1.compute.amazonaws.com ec2-18-138-16-42.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 3.96.243.128 3.97.226.155 ec2-3-96-243-128.ca-central-1.compute.amazonaws.com ec2-3-97-226-155.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.94.27.80 18.229.241.206 ec2-54-94-27-80.sa-east-1.compute.amazonaws.com ec2-18-229-241-206.sa-east-1.compute.amazonaws.com AWS_US_WEST_2 \"Portland, OR, USA\" 44.236.111.66 54.203.108.135 ec2-44-236-111-66.us-west-2.compute.amazonaws.com ec2-54-203-108-135.us-west-2.compute.amazonaws.com EU public minions: Upcoming IP addresses The following table lists the upcoming IP addresses that will be added to public minions on July 15 2021 for EU customers. Public minion location Location label New IP addresses New DNS addresses AWS_AP_NORTHEAST_1 \"Tokyo, JP\" 35.72.129.240 35.73.187.89 ec2-35-72-129-240.ap-northeast-1.compute.amazonaws.com ec2-35-73-187-89.ap-northeast-1.compute.amazonaws.com AWS_AP_NORTHEAST_2 \"Seoul, KR\" 13.125.155.211 15.164.119.0 ec2-13-125-155-211.ap-northeast-2.compute.amazonaws.com ec2-15-164-119-0.ap-northeast-2.compute.amazonaws.com AWS_AP_SOUTH_1 \"Mumbai, IN\" 15.207.93.61 ec2-15-207-93-61.ap-south-1.compute.amazonaws.com AWS_AP_SOUTHEAST_1 \"Singapore, SG\" 3.0.28.216 ec2-3-0-28-216.ap-southeast-1.compute.amazonaws.com AWS_CA_CENTRAL_1 \"Montreal, Quebec, CA\" 99.79.17.185 ec2-99-79-17-185.ca-central-1.compute.amazonaws.com AWS_SA_EAST_1 \"São Paulo, BR\" 54.207.198.234 ec2-54-207-198-234.sa-east-1.compute.amazonaws.com",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.47012,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "sections": "Upcoming <em>synthetic</em> <em>monitor</em> public minion IP addresses",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " about this topic, see <em>Synthetic</em> <em>monitor</em> public minion IPs. US public minions: Upcoming IP addresses The following table lists the IP addresses that will be added on July 15 2021 to public minions for US customers. Public minion location Location label New IP addresses New DNS addresses"
      },
      "id": "606a1e4364441fbec2617a7c"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/administration/user-roles-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 178.91075,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic monitor public minion IPs",
        "IP addresses are not personal data",
        "Daily JSON listings for IP addresses",
        "Important",
        "Tip",
        "Public minion locations and location labels"
      ],
      "title": "Synthetic monitor public minion IPs",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "773534b4f076c3b421b6e0ca0dfc26f1e1ef6f73",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/synthetic-public-minion-ips/",
      "published_at": "2021-10-07T09:06:27Z",
      "updated_at": "2021-08-08T21:09:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic uses a group of minions to execute your synthetic monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses are publicly available in JSON format, so you can easily read and parse them. Recommendation: For easier maintenance, use these options: Automate your rules for your allow list based on these files. Add the IP addresses to your allow list by using a custom header. IP addresses are not personal data Minions are deployed on servers, and the agents are expected to be activated using non-personal credentials. IP addresses associated with minions running on servers are not personal data under data protection and privacy laws. For more information, see the Synthetic's security documentation. Daily JSON listings for IP addresses IP addresses for released locations are subject to change. If a change is needed, we'll attempt to proactively notify customers prior to any changes via e-mail. You can also check the Explorers Hub for updates. Important Synthetics is adding new IP addresses on July 15 2021. Tip In the S3 URL paths for this feature, production represents US-based accounts and eu represents EU-based accounts. US accounts IP-only list DNS name-only list IP and DNS name list EU accounts IP-only list DNS name-only list IP and DNS name list Public minion locations and location labels The following table cross-references the synthetic's public minion locations with their location labels. You can query the location and locationLabel attributes from the SyntheticCheck and SyntheticRequest events. Public minion location Location label AWS_AP_EAST_1 \"Hong Kong, HK\" AWS_AP_SOUTH_1 \"Mumbai, IN\" AWS_AP_SOUTHEAST_1 \"Singapore, SG\" AWS_AP_NORTHEAST_2 \"Seoul, KR\" AWS_AP_NORTHEAST_1 \"Tokyo, JP\" AWS_AP_SOUTHEAST_2 \"Sydney, AU\" AWS_US_WEST_1 \"San Francisco, CA, USA\" AWS_US_WEST_2 \"Portland, OR, USA\" AWS_US_EAST_2 \"Columbus, OH, USA\" AWS_US_EAST_1 \"Washington, DC, USA\" AWS_CA_CENTRAL_1 \"Montreal, Québec, CA\" AWS_SA_EAST_1 \"São Paulo, BR\" AWS_EU_WEST_1 \"Dublin, IE\" AWS_EU_WEST_2 \"London, England, UK\" AWS_EU_WEST_3 \"Paris, FR\" AWS_EU_CENTRAL_1 \"Frankfurt, DE\" AWS_EU_NORTH_1 \"Stockholm, SE\" AWS_EU_SOUTH_1 \"Milan, IT\" AWS_ME_SOUTH_1 \"Manama, BH\" AWS_AF_SOUTH_1 \"Cape Town, ZA\"",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15736,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "sections": "<em>Synthetic</em> <em>monitor</em> public minion IPs",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "New Relic uses a group of minions to execute your <em>synthetic</em> monitors. These minions are deployed in different data centers around the globe, and they are in charge of actually running your monitors. Because of this, ensure your firewall allows their network requests through it. Minion IP addresses"
      },
      "id": "6045257d28ccbcdc552c60a5"
    },
    {
      "sections": [
        "Compare page load performance in browser and synthetic monitoring",
        "Compare performance and trends",
        "What you need",
        "Enable comparison data",
        "Enable comparative charting from Synthetics UI",
        "Enable comparative charting from browser monitoring UI",
        "View comparison data",
        "Hide or return comparison data",
        "Data sources"
      ],
      "title": "Compare page load performance in browser and synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Administration"
      ],
      "external_id": "a789c407a0fecbd2ce888fdee7805abe8152f0a4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/administration/compare-page-load-performance-browser-synthetic-monitoring/",
      "published_at": "2021-10-07T18:40:36Z",
      "updated_at": "2021-07-09T23:24:04Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring regularly checks your websites, critical business transactions, and API endpoints to measure optimal performance. Browser monitoring tracks the actual results of webpage performance across all variations of devices, browsers, and connection speeds. Used together, they provide a direct page load time comparison between real user (browser) interactions and the synthetic monitors. Compare performance and trends New Relic's comparative charting feature helps operations managers and teams by providing: Benchmarks for page load times Additional insights to help you plan where to optimize your site Comparisons of synthetic trends vs. actual browser performance without needing to switch between our monitoring capabilities. For example, during a page outage, you can compare synthetic monitoring trends to actual browser monitoring comparisons to see if an issue is also visible in Synthetics UI, or if it is caused by variables outside of New Relic. This helps you more efficiently know where to take action. What you need The comparative charting feature requires: Browser monitoring enabled with the browser SPA agent (version 885 or higher). A synthetic browser or scripted monitor with one or more tests on the same URLs monitored by the browser agent. After you enable the comparative charting feature either from synthetic or from browser monitoring, no additional setup is required. The comparative charting feature will appear when New Relic finds matching URLs. Enable comparison data After you enable the comparative charting feature from either synthetic or browser monitoring, no additional setup is required. The comparative charting feature will appear whenever synthetics or browser monitoring finds matching URLs. Enable comparative charting from Synthetics UI To enable the comparative charting feature from Synthetics UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. Above the selected monitor's Availability chart, select the ellipsis icon. Select Enable Synthetics comparison. Enable comparative charting from browser monitoring UI To enable the comparison data feature from browser monitoring: Go to one.newrelic.com > Browser > (select a browser app) > Page views. Select a page monitored by synthetic monitoring. From the selected page's Performance tab, select the ellipsis icon. Select Enable Synthetics comparison. View comparison data The comparative charting feature appears whenever synthetic monitoring identifies a URL match with browser monitoring and can compare it. You can compare browser and synthetic's performance either from the synthetic monitoring Summary page or from the browser monitoring Page views page (for browser apps or single page apps) without needing to switch between New Relic capabilities. Based on the selected data sources, the summary shows: Overall speed percentage comparison between browser (real user) page views and any matching URLs found in synthetic monitors that the user has permissions to view Number of URLs found in synthetic monitors that match the browser rollup URL To view the comparative charting summary: From synthetic monitoring UI: Go to one.newrelic.com > Synthetics > (select a monitor) > Summary. OR From browser monitoring UI: Go to one.newrelic.com > Browser > (select a browser app) > Page views, then select a page monitored by synthetic monitoring. Review the comparative charting feature's summary of overall speed percentage and number of matching URLs. To view additional details, select the summary's right arrow icon. Please note that in some cases the simple browser monitor ends before the browser agent has had a chance to collect the BrowserInteraction event. In this case, no comparative charting data is displayed in the UI. In order to resolve this issue, create a scripted browser monitor instead, and add a call to wait (sleep) after the page is loaded. Here is an example: $browser.get('https://www.mywebsite.com').then(function(){ return $browser.sleep(1000); }) Copy Hide or return comparison data To hide the comparative charting feature, select the ellipsis icon. To keep it visible but move it away from the top of the page, select Move to bottom. To return it to its original place on the page, select Move to top. To remove it from the page, select Hide all Synthetics/Browser comparisons. To return it to the page after removing it, follow standard procedures to enable comparison charting. Data sources New Relic uses these data sources for the synthetics and browser comparison in the UI. For deeper analysis of the comparative chart data you see in the UI, use the query builder to run NRQL queries. Variable Description Monitor account ID The account from which you are running the monitor: SELECT monitorAccountId FROM BrowserInteraction Copy Monitor ID The unique ID assigned to your synthetic monitor: SELECT monitorId FROM BrowserInteraction Copy Monitor job ID The ID of a single synthetics monitor run, which began at a specific time and originated from a specific location: SELECT monitorJobId FROM BrowserInteraction LIMIT 1 Copy Real user average The average page load time for real users viewing your website (excludes synthetic monitors). Real user page views Page view details coming from visitors to your website (exclude synthetic monitors). Synthetic's average The average page load time from the synthetic simple or scripted monitors that ran on your website. Synthetic's page views Only traffic generated by synthetic simple or scripted monitors.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 151.79878,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "sections": "Compare page load performance in browser and <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " permissions to view Number of URLs found in <em>synthetic</em> monitors that match the browser rollup URL To view the comparative charting summary: From <em>synthetic</em> <em>monitoring</em> UI: Go to one.newrelic.com &gt; <em>Synthetics</em> &gt; (select a <em>monitor</em>) &gt; Summary. OR From browser <em>monitoring</em> UI: Go to one.newrelic.com &gt; Browser"
      },
      "id": "604525b7e7b9d251f85799e1"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.44215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-10-07T18:42:29Z",
      "updated_at": "2021-07-27T18:44:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. It does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.72054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-10-07T07:37:11Z",
      "updated_at": "2021-07-27T17:34:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Assert text Assert title Assert an element Click an element Dismiss a modal Double click an element Hover an element Navigate to a URL Secure a credential Select from a dropdown Type text Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.7112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.44215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-10-07T01:56:23Z",
      "updated_at": "2021-07-27T18:43:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.72043,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ") to provide testing that mirrors your users&#x27; actions. Detailed results view <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific"
      },
      "id": "6045257e64441fa637378efe"
    },
    {
      "sections": [
        "Types of synthetic monitors",
        "Types of monitors"
      ],
      "title": "Types of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "f7fe7faff740058c77bdf27b2c1bfb5c6a206b40",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors/",
      "published_at": "2021-10-07T07:37:11Z",
      "updated_at": "2021-07-27T17:34:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can proactively monitor your website or API endpoints with synthetic monitors. Depending on the type of monitor, you can: Add and edit monitors. Use the Synthetics REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host not reporting feature in infrastructure monitoring. This allows you to take advantage of enhanced monitoring options and be notified when New Relic has stopped receiving data from your hosts. Types of monitors These are the seven types of synthetic monitors: Type of synthetic monitor Description Broken links monitor Provide a url and this monitor will test all the links on the page for success. If a failure is detected you can view the individual non-successful links that caused the failure. Certificate check monitor Proactively ping your domain certificates based on a configurable threshold. Pair with an alert to ensure you are notified when your certificates need renewed. Ping monitor API name: SIMPLE Ping monitors are the simplest type of monitor. They simply check to see if an application is online. The synthetic ping monitor uses a simple Java HTTP client to make requests to your site. For consistency with other synthetic monitor types, the user agent is identified as Google Chrome. However, the HTTP client is not a full browser, and it does not execute JavaScript. If you need JavaScript functionality, use a simple browser monitor. Step monitor API name: STEP_MONITOR Step monitors are advanced monitors which require no code to set up. The monitor can be configured to: Assert text Assert title Assert an element Click an element Dismiss a modal Double click an element Hover an element Navigate to a URL Secure a credential Select from a dropdown Type text Simple browser monitors API name: BROWSER Simple browser monitors essentially are simple, pre-built scripted browser monitors. They make a request to your site using an instance of Google Chrome. Compared to a simple ping monitor, this is a more accurate emulation of an actual customer visit. The user agent is identified as Google Chrome. Scripted browser monitors API name: SCRIPT_BROWSER Scripted browser monitors are used for more sophisticated, customized monitoring. You can create a custom script that navigates your website, takes specific actions, and ensures specific resources are present. The monitor uses Google Chrome browser. You can also use a variety of third-party modules to build your custom monitor. API tests API name: SCRIPT_API API tests are used to monitor your API endpoints. This can ensure that your app server works in addition to your website. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.7112,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Types of <em>synthetic</em> <em>monitors</em>",
        "sections": "Types of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can proactively <em>monitor</em> your website or API endpoints with <em>synthetic</em> monitors. Depending on the type of <em>monitor</em>, you can: Add and edit monitors. Use the <em>Synthetics</em> REST API to manage monitors. Set up monitors from specific locations or for private servers. You can also use the host"
      },
      "id": "603e873864441f3e154e888f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/getting-started/types-synthetic-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.44208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Start</em> the CPM",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Security for synthetic monitoring",
        "What we do",
        "What you can do"
      ],
      "title": "Security for synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "c36cbaf0bec47e56e54e66f7eb39484a3ef7f426",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/security-synthetic-monitoring/",
      "published_at": "2021-10-07T18:42:29Z",
      "updated_at": "2021-07-27T18:44:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's synthetic monitoring uses monitors distributed throughout data centers around the world. By design, it captures what is essentially performance data for simulated traffic. It does not capture or handle any personal data by default. All data handled by synthetic monitors is expected to be non-personal. This document provides additional details about what we do to ensure data privacy and security with synthetic monitoring, plus additional options you can use. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. What we do Here's a summary of the data privacy and security measures that New Relic provides for you. Data privacy and security Comments No personal data By definition, all data collected through synthetic monitoring is test data created for the purpose of monitoring. None of this data includes personal data from any individual. TLS TLS encryption is required for all domains. This applies to public locations and private locations. Authentication Synthetic monitoring supports a variety of authentication mechanisms, including Basic, Digest, NTLM, and NTLMv2. Available options depend on the type of monitor you choose. Data collection The data transferred to the synthetic endpoint includes: Monitor run results, including full request and response headers of all requests, a complete HAR file of the session, and any screenshots captured (on failure or manually) Polling for available jobs in the private location's queue Private minion \"heartbeat\" every 30 seconds The SyntheticsPrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the synthetic monitoring endpoint contains the scheduled check's details. This includes the information necessary to complete the check for the minion: Target URL Validation text Full script (for synthetic scripted browser monitors) Data storage location Data collected by synthetic monitoring is stored in the region selected by each customer for their account (US or EU). Monitor configuration details (including frequency, check locations, target URL, and the full script for any scripted browser or API test monitors) are stored on our end. We also store all monitor check results for each monitor type. Data storage by monitor type For ping monitors, data storage includes the HAR file, which includes all requests and responses made during the check. For simple browsers, scripted browsers, and API tests, data storage includes the following: The HAR file includes full request and response headers for all requests made during the check. Any screenshots taken during the check are automatically included for simple and scripted browser monitors only on failure. However, you can manually configure this with scripting. The browser log (JS console) is automatically included for simple and scripted browsers. Any script output is included for scripted browsers and API test monitors. Response bodies New Relic never stores response bodies from requests originated by synthetic monitoring, unless you have manually configured a monitor script to do so. IP addresses Synthetic public minions are expected to be activated using non-personal credentials. Their IP addresses are not defined as personal data under data protection and privacy laws. What you can do For additional levels of security and data privacy, consider using these options. Additional measures Comments User access To control which of your users can access your monitors and private locations, set up role-based synthetic monitoring permissions and user groups. In addition, to track and be notified about changes, use audit logs and alert notifications. Passwords, API keys, user names, etc. To securely store sensitive information, use secured credentials for scripted browsers and API tests. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). Sites behind firewalls To control what sites you want to monitor behind your firewall, you can: Add the synthetic public minion IP addresses to your allow list or deny list. Use private locations to monitor sites or endpoints. This can provide an extra layer of security when monitoring your internally hosted sites and services. Web pages behind login pages If you configure synthetic monitoring to track website areas that are located behind a login page, be sure to create a non-personal login specifically for this purpose. This unique login will reduce the risk of unintended personal data exposure. Proxy configuration Aside from the target URLs monitored by New Relic, private minions will regularly send data to and receive from the synthetic monitoring endpoint. To configure a proxy for all traffic to and from this endpoint, set the MINION_API_PROXY environment variable on the minion host. Private minions security To ensure that only the scripts you intend to run are allowed to run on private minions, use verified script execution.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.72054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for <em>synthetic</em> <em>monitoring</em>",
        "sections": "Security for <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " for available jobs in the private location&#x27;s queue Private minion &quot;heartbeat&quot; every 30 seconds The <em>Synthetics</em>PrivateMinion event contains basic minion status, including job success and failure counts, queue size, minion version, etc. Data received Data received from the <em>synthetic</em> <em>monitoring</em> endpoint"
      },
      "id": "604525b8e7b9d270a35799c8"
    },
    {
      "sections": [
        "Get started with synthetic monitoring",
        "Why it matters",
        "Advanced testing",
        "Enhanced monitoring and reporting",
        "Additional features",
        "Data protection and privacy",
        "Compatibility and requirements",
        "Important",
        "Permissions"
      ],
      "title": "Get started with synthetic monitoring",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Getting started"
      ],
      "external_id": "0e5bba5ee7c140314180bff96253dce241ced14f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/",
      "published_at": "2021-10-07T01:56:23Z",
      "updated_at": "2021-07-27T18:43:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring is a suite of automated, scriptable tools to monitor your websites, critical business transactions, and API endpoints. You can simulate user traffic to proactively detect and resolve outages and poor performance of critical endpoints before your customers notice. Why it matters With synthetic monitoring, you can: Get the context of failures by connecting the availability and performance of endpoints to the underlying applications and infrastructure. Easily diagnose if an issue stems from the network or AWS location, a slow third party resource, or the health of backend services or infrastructure. Add synthetic monitoring into build automation and CI/CD pipelines to automatically track performance and check functionality for each deployment. Expand your monitoring further with real, Selenium-powered scripted browsers, which test login procedures, searches, and other critical business transactions. Monitor your API endpoints with API tests Advanced testing Synthetic monitoring allows you to proactively monitor your website or API endpoint to ensure your content is not only available, but fully functional. Synthetic monitoring browser tests send real, Selenium-powered Google Chrome browsers to your site from locations around the world to ensure your content is always up, everywhere. Scripted browsers expand your testing capabilities, so you can test uncommon user flows or beta-test complex procedures. For example, ensure your users are able to sign up for your newsletter, add an item to their cart, or search for and find a piece of critical content with a simple JavaScript-like language. Test your backend with API monitors, which allow you to run scripted tests against any API endpoint. Enhanced monitoring and reporting Synthetic monitoring aggregates the results of each check into metrics, allowing you to see patterns and identify causes of poor performance. Synthetic monitoring also stores each and every monitor result, so you can see exactly where your website broke down. Alerts notify you if your website or API endpoint is inaccessible. You can even expand your geographical coverage or monitor internal websites by creating private locations. You can also query your monitor results for a closer look. New Relic retains monitor results for thirteen months, ensuring you can compare usage year over year. Additional features Synthetic monitoring includes the following features: Feature Description Real browsers With simple browser and scripted browser monitors, synthetic monitoring doesn't simply check that your host is up. It loads the actual page content in a real, fully virtualized Google Chrome browser (powered by Selenium) to provide testing that mirrors your users' actions. Detailed results view Synthetic monitoring stores every single run of your monitor for 13 months, so you can view a detailed breakdown of each and every check. You can get a snapshot of your website's performance and availability, or hunt down specific problems. Comparative charts with browser monitoring Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the synthetic monitors. For example, during a page outage, you can compare trends to see if an issue is also visible in synthetic monitoring, or if it is caused by other variables. Advanced scripted monitoring Use scripted browsers to run complex test cases against your website. Ensure critical processes like checkout and login are always running smoothly, and build a baseline to compare against when things go wrong. With a built-in scripting IDE based on Node.js, create scripts quickly without leaving your browser. Global test coverage Check coverage from locations around the world to ensure your users can access your website from anywhere, anytime. Monitor sites behind your firewall by adding the synthetic monitoring static IP addresses to your allow list. Use private locations to monitor internal sites or to expand your coverage to new locations. Compatibility with popular analytics platforms Synthetic monitoring specifically excludes scripts for popular analytics services, like Google Analytics. This ensures your analytics tools continue to receive the exact same data, even with thousands of monitors checking your website each month. You can unblock any of the services blocked by default, or block additional services. REST API functions Synthetic monitoring includes a REST API, which you can use to manage: Simple monitors and scripted monitors Categories and labels for monitors Alert notifications Data protection and privacy The data from synthetic monitoring is test data, representing typical interaction with the webpage or application. It is never actual data from human beings. The data collected when you use synthetic monitoring therefore is not personal data. For more information, see the Synthetic monitoring security documentation. Compatibility and requirements Synthetic monitoring does not require any software except a supported browser. Important To monitor a site behind your firewall, add the synthetic monitoring public minion IP addresses to your allow list. Permissions By default, all users in your account can: View synthetic monitoring pages. Add, edit, and delete monitors. For more fine-grained control, you can enable the optional permissions system. The permissions system allows you to manage the level of access for users to view and edit within synthetic monitoring (for example, monitors and private locations).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 135.72041,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>synthetic</em> <em>monitoring</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ") to provide testing that mirrors your users&#x27; actions. Detailed results view <em>Synthetic</em> <em>monitoring</em> stores every single run of your <em>monitor</em> for 13 months, so you can view a detailed breakdown of each and every check. You can <em>get</em> a snapshot of your website&#x27;s performance and availability, or hunt down specific"
      },
      "id": "6045257e64441fa637378efe"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics": [
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-10-07T18:43:29Z",
      "updated_at": "2021-08-27T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). You can also access it from one.newrelic.com > Synthetics > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27437,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-10-07T18:44:24Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors, go to one.newrelic.com > Explorer > Synthetic monitors. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from synthetic monitors to applications, hosts, or custom groupings of any elements. Alternatively, you can go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary": [
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.08481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-10-07T18:44:24Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors, go to one.newrelic.com > Explorer > Synthetic monitors. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from synthetic monitors to applications, hosts, or custom groupings of any elements. Alternatively, you can go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-troubleshoot-downtime": [
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.08481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-10-07T18:43:29Z",
      "updated_at": "2021-08-27T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). You can also access it from one.newrelic.com > Synthetics > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-10-07T18:44:24Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors, go to one.newrelic.com > Explorer > Synthetic monitors. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from synthetic monitors to applications, hosts, or custom groupings of any elements. Alternatively, you can go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-understand-load-times": [
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.08481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-10-07T18:43:29Z",
      "updated_at": "2021-08-27T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). You can also access it from one.newrelic.com > Synthetics > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Index of synthetic monitors",
        "View the monitors index",
        "Understand monitor metrics",
        "Use index functions"
      ],
      "title": "Index of synthetic monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "31ee0cdc58c68b1783c782f5b1fd63a3b9b23823",
      "image": "https://docs.newrelic.com/static/d4e13d397c055e8164da62aadeda4f1f/c1b63/monitor-index.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index/",
      "published_at": "2021-10-07T18:44:24Z",
      "updated_at": "2021-08-27T06:57:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In our synthetic monitoring tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each monitor's performance over the last 24 hours. Select an individual monitor to view a Summary page and get a deeper insight into its performance over time. Or, filter the list to quickly compare the performance of similar monitors. View the monitors index To access an index (or list) of your monitors, go to one.newrelic.com > Explorer > Synthetic monitors. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from synthetic monitors to applications, hosts, or custom groupings of any elements. Alternatively, you can go to one.newrelic.com > Synthetics. You can check the status and main metrics of your synthetic monitors at a glance thanks to the Monitors index. You can also use the explorer to view a list of all monitors associated with your New Relic account, along with a quick snapshot of each monitor's performance. To access an index (or list) of your monitors: Go to one.newrelic.com > Explorer > Synthetic monitors. one.newrelic.com > Explorer > Synthetic monitors: Use the monitors index to access any of your Synthetics monitors, and to view a quick snapshot of their performance. Understand monitor metrics Use the monitors index to access your monitors and view a quick snapshot of monitor performance. The index includes the following metrics: Alert status: Indicates the status of any alerts on the monitor: Green: No open violations Red: Critical violation in progress Grey: No alert conditions defined with New Relic Alerts Monitor status: Indicates a status has been applied to the monitor, such as Mute or Disabled. Success rate: The percentage of monitor checks that end in success. A multi-step monitor that does not complete all steps is considered a failure. Locations failing: The number of locations that have failed during the given timeframe. Period: How often the monitor checks run. Monitor type: The selected monitor type. Use index functions The monitors index supports the following features: If you want to... Do this... Sort the monitor list Select a column label to sort the list based on that metric. Select the label again to change the sort order from ascending to descending. Filter the monitor list Type your keyword in the search box to filter by name, tags, or entitiy type. Add to favorites To favorite a monitor, select the star star icon icon. Favorite monitors appear at the top of the monitor list. To remove a monitor from your favorites, select the star icon again.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27403,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Index of <em>synthetic</em> <em>monitors</em>",
        "sections": "Index of <em>synthetic</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In our <em>synthetic</em> <em>monitoring</em> tool, the monitors index lists all monitors associated with your New Relic account, and gives you a quick snapshot of each <em>monitor</em>&#x27;s performance over the last 24 hours. Select an individual <em>monitor</em> to view a Summary <em>page</em> and get a deeper insight into its performance over"
      },
      "id": "60455a8464441f3f23378ebd"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/pages/synthetic-monitors-index": [
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.0848,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    },
    {
      "sections": [
        "Synthetic monitoring: Summary page",
        "View the Summary page",
        "Understand the Summary page",
        "Use page functions",
        "Legacy charts",
        "Important",
        "For more help"
      ],
      "title": "Synthetic monitoring: Summary page",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "342483d007728143c635a8ba0c2b5c76b9b18133",
      "image": "https://docs.newrelic.com/static/a390d7ca2a89356a923a9d457c9d6acf/8c557/summary-page.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-summary/",
      "published_at": "2021-10-07T18:43:29Z",
      "updated_at": "2021-08-27T06:58:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Summary page of synthetic monitoring gives you an at-a-glance understanding of your website's performance. You can look for trends in request/response times, connection times, and errors. Use the filter to narrow data to attributes or values of interest, or recheck failed monitors. View the Summary page To access your monitor's Summary page: Go to one.newrelic.com > Explorer > Synthetic monitors > (select a monitor). You can also access it from one.newrelic.com > Synthetics > (select a monitor). The Summary page gives you a high-level view of your website's performance, and has shortcuts to location checks, alert violations, and your monitor's metadata. Understand the Summary page Use the Summary page to understand your website's performance: Synthetics Summary charts Description Success and failure rate This shows the monitor's overall success rate and total number of check failed during the given timeframe, the number of locations that are failing, and the error message for the last error detected. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Page load time and availability This shows the page load times and availability, the percentage of monitor runs that were successful, for each monitor location. The timeframe displayed will vary depending on the frequency of the monitor: 1 minutes = 30 minutes 5 minutes = 1.5 hours 15 minutes = 7.5 hours 30 minutes = 15 hours 1 hour = 30 hours 6 hours = 7.5 days 12 hours = 15 days 24 hours = 30 days Request/response times This shows the time that it took the ping monitor to send and receive a response, and is broken down into duration sent, duration wait, and duration received. Durations can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Connection times This shows the breakdown for the network connections to be established for this monitor, and is broken down into the DNS, SSL, and connection durations. Duration can be displayed as Average, Median, or 95th Percentile. For more information see, Percentiles: Ranking data. This is only available for ping monitor results. Non-200 response codes This shows any (non-200) error response code that were received as a result of running this monitor. This is only available for ping monitor results. Activity panel Displays any recent activity associated with the monitor, including: Monitor name Number of open violations Activity on the monitor, including recent open and closed violations and audit events. Metadata and tags. Monitored entities: This is any New Relic entity that is observed when this monitor runs and includes the entity alert status. Selecting an entity status will navigate to the monitored entity summary page. Use page functions The Summary page supports the following functions: If you want to... Do this... View a result in detail To view exact metrics, hover the mouse over the chart. Re-run a monitor check Click the Run check button to recheck any failed monitor. View detailed about an alert violation In the Activity panel, click on the displayed alert to go directly to the alert incident page. Quickly access another monitor At the top of the screen, click on the name of the current monitor to open the dropdown menu. Select from the list of recent monitors, or enter a name in the search field to search for a specific monitor. Change the time frame Use the time picker to adjust the number of results returned for the following charts: Request/response times Connection times Non-200 response codes This is only available for ping monitor results. Legacy charts Important The following table applies to the old view of the synthetic monitoring summary page. Click Show new view to access a new curated summary experience. Synthetic chart Description Load time chart This shows the load times for each monitor location. When you select a short time frame (such as 30 minutes), Synthetics displays the exact load time for each run of your monitor from each location. With longer time frames, Synthetics adjusts the resolution to show averages. To toggle the visibility of a location, select its label. Availability This shows the percentage of monitor runs that were successful. For a scripted monitor, the entire script must complete for the run to be considered a success. Above the selected monitor's Availability chart, an ellipsis icon appears. Use New Relic's comparative charting feature for a direct page load time comparison between real user (browser monitoring) interactions and the Synthetics monitors. Average load size This chart shows the amount of data (in kilobytes or megabytes) consumed in each run of the monitor. For scripted monitors, the entire script is included in the average load size graph. For example, a monitor that loads three pages will measure the size of all assets on all three pages. If your site is static, the average load size will be very consistent. For dynamic sites such as a news site, the average load size will vary as your page content changes. Slowest results This lists the five slowest results for the selected time frame. To view the performance breakdown, select a result. Monitor downtimes This lists the most recent monitor downtime incidents. To view additional details, select a downtime incident. For more help Additional documentation resources include: Results (full list of monitor results) Resources page (load times for each element on a monitored page) Failures (list of downtime incidents, and individual downtimes for in-depth analysis)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.27435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Summary <em>page</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " <em>monitoring</em> summary <em>page</em>. Click Show new view to access a new curated summary experience. <em>Synthetic</em> chart Description Load time chart This shows the load times for each <em>monitor</em> location. When you select a short time frame (such as 30 minutes), <em>Synthetics</em> displays the exact load time for each run"
      },
      "id": "604525b7196a67d21b960f6f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.63013,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.55281,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-maintenance-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.62994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.5528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms": [
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.5528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.77501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/monitor-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.6298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.5528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.6298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.77501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/troubleshoot-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.6298,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.5528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Verified script execution for private locations",
        "Passphrase security",
        "Important",
        "Enable verified script execution",
        "Change your passphrase",
        "Disable verified script execution",
        "Other (legacy)"
      ],
      "title": "Verified script execution for private locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "84a4f617447ed6f360feafc8432540025546dde8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations/",
      "published_at": "2021-10-07T18:47:25Z",
      "updated_at": "2021-08-02T05:08:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To prevent others from using your private minions to assign scripted browsers or API tests, add verified script execution. Then, any changes to your minions will require a passphrase that is known only to you. The private locations list in New Relic's UI includes a VSE column. A lock icon indicates that verified script execution has been set up for that location. Passphrase security Be sure to safeguard your private minion's passphrase. No other users on your account can view it, and it is never stored in New Relic's collector. Important This restriction includes New Relic support personnel. Because our collector never stores your passphrase, our support team cannot recover or reset your passphrase for you. If you forget your passphrase, you will need to change it in the minion Overview page, and then update each monitor assigned to that private location. Enable verified script execution Do the following to enable verified script execution for containerized private minions. Be sure to record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, and then save. Set the passphrase in your Docker or Kubernetes environment: Docker: Add the MINION_VSE_PASSPHRASE environment variable to the Docker run command used to start your private minion: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Set the synthetics.minionVsePassphrase value in the Helm install or upgrade command: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Be sure to record your passphrase in a secure place. Repeat steps 3 and 4 for each monitor you want to assign to your location. Change your passphrase To change your passphrase, do the following. Be sure to record your passphrase in a secure place. Update the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion. Then use the Docker run command to start a new minion with your updated MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e MINION_PRIVATE_LOCATION_KEY=\"YOUR_PRIVATE_LOCATION_KEY\" \\ -e MINION_VSE_PASSPHRASE=\"YOUR_PASSPHRASE\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command to set your updated synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY --set synthetics.minionVsePassphrase=YOUR_PASSPHRASE Copy Go to one.newrelic.com > Synthetics > (assigned monitor) > Settings > General. From the list of private locations, select your location, type your new passphrase, and save. Repeat steps 2 and 3 for each monitor assigned to your location. Disable verified script execution To disable verified script execution for containerized private minions: Remove the passphrase in your Docker or Kubernetes environment: Docker: Stop your current minion container. Then use the Docker run command to start a new minion without the MINION_VSE_PASSPHRASE environment variable: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Kubernetes: Use the Helm upgrade command without the --set synthetics.minionVsePassphrase value: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Clear the Enable verified script execution checkbox, then save. Other (legacy) If you are not using containerized private minions, do the following to enable verified script execution. Be sure to record your passphrase in a secure place. In your web browser, navigate to the minion Overview page at https://MINION_IP_ADDRESS (for example, https://1.2.3.4). Select the pencil icon, then select Advanced settings (optional). Select the Verified script execution checkbox. Type a passphrase, then save. Record your passphrase in a secure place. Go to one.newrelic.com > Synthetics > Private locations > (select a private location). Select the private location's ellipses icon, and click Edit. Enable verified script execution, then save. From the Synthetics UI, select a monitor assigned to that location. Then select Settings > General. From the list of private locations, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each monitor you want to assign to your location. To change your passphrase or disable verified script execution, follow the same basic process to go to your minion's IP address and update its Advanced settings. Then go to one.newrelic.com to complete the process.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.22089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Verified script execution for <em>private</em> <em>locations</em>",
        "sections": "Verified script execution for <em>private</em> <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " verified script execution, then save. From the <em>Synthetics</em> UI, select a <em>monitor</em> assigned to that location. Then select Settings &gt; General. From the list of <em>private</em> <em>locations</em>, select your location, type your passphrase, and save. Repeat steps 4 through 6 for each <em>monitor</em> you want to assign to your location"
      },
      "id": "60452628e7b9d217695799ee"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/private-locations/verified-script-execution-private-locations": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 321.62964,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Install containerized <em>private</em> minions (CPMs)",
        "sections": "<em>Private</em> <em>location</em> key",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized <em>private</em> minions (CPM). These are Docker container-based <em>private</em> minions that accept and execute <em>synthetic</em> monitors against your <em>private</em> <em>locations</em>. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Private locations overview: Monitor internal sites and add new locations",
        "What you need",
        "Create a private location",
        "Tip",
        "Ping monitor checks",
        "Add jobs to the location queue",
        "Manage private locations",
        "Set proxy configuration"
      ],
      "title": "Private locations overview: Monitor internal sites and add new locations",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "169a071fc32eb5229ebc4e32deac6eb53481e61d",
      "image": "https://docs.newrelic.com/static/e24392abbb29035544f7fc902cf3deea/8c557/screen-assign-to-private-location-synthetics-monitor_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/private-locations-overview-monitor-internal-sites-add-new-locations/",
      "published_at": "2021-10-07T18:46:29Z",
      "updated_at": "2021-08-09T07:42:18Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In synthetic monitoring, a private location is a collection of private minions. A minion is a containerized application that receives and manages jobs set up through the Synthetics UI. A private location can contain any number of private minions. Private locations allow you to extend your synthetic monitoring coverage to new geographical locations, and to monitor websites behind your firewall (like an intranet site). What you need To use private locations, first review these requirements and other factors: Compatibility for... Requirements Check budget Checks from a private location count against your budget. Synthetics horde endpoint For US-based accounts: https://synthetics-horde.nr-data.net/ For EU-based accounts: https://synthetics-horde.eu01.nr-data.net/ Outbound network access The minion needs to connect to the synthetic monitoring's horde endpoint to receive and process jobs. If your firewall rules don't permit direct access, you must configure proxy access. Test your connection to the horde endpoint with a successful response from the following command: curl -X GET https://synthetics-horde.nr-data.net/synthetics/api/v1/ping Copy Account access and permissions How access works depends on your user model: Original user model: If a private location is set up by an account with child accounts, it can be used by users with access to those child accounts. But if it's set up on a child account, it can only be used by users in that account. New Relic One user model: user access to an account depends on whether they've been granted access to that account. Create a private location one.newrelic.com > Synthetics > Private Locations: Use the Private Locations page to create, edit, and delete private locations. Before installing private minions, you need to create a private location. To create a new private location: Ensure you meet the requirements, including activating the feature by contacting your account representative. Go to one.newrelic.com > Synthetics > Private locations. Then select Create private location. Tip The Private locations sub menu becomes available after you create your first monitor. Type a location name. Optional: Configure these additional settings: Description: Describe your private location for other account users. Verified script execution: Require a passphrase when assigning scripts to this location, or when adding minions to the location. Select Create. After creating the location, Synthetics lists your Private location key so you can install a private minion. Ping monitor checks Each minion can run about 200 ping monitor checks per minute (about 8,640,000 checks per month). If the job queue for a particular location is growing, add additional minions. The exact capacity of the minions can vary, depending on: Your network performance The complexity of your scripts The hardware configuration for the private minion Add jobs to the location queue To add jobs to the queue for your location, follow standard procedures to add or edit a monitor, and select your location from the Private locations list. To assign an existing monitor, edit that monitor's settings. one.newrelic.com > Synthetics > Create monitor: To assign new jobs to your private location and its minions, select its name from the Create monitor page. Manage private locations Tip If you can't access this feature, check the Factors affecting access to features and data. Synthetic monitoring includes tools to manage locations and individual minions. You can also install new minions, and clear the job queue if it backs up. To access these tools, go to one.newrelic.com > Synthetics > Private locations. Then follow the steps: If you want to... Do this... Clear the job queue Click the icon, and select Clear queue. This is useful when the number of scheduled jobs has increased faster than the minions can process them, such as when the minion is offline. View the status of an individual minion Select the parent location's name from the list. The green health status indicator identifies active minions. You can also view the last reported time for each minion, and check whether the minion software is out of date. Change location or view the private location key Click the icon, and select Edit. Delete a location Click the icon for the location, and select Delete. This does not shut down any minions assigned to that location. The minions must be shut down manually or reassigned. Enable or disable verified script execution Legacy minions: Verified script execution requires that you set up a passphrase on the minion before assigning any scripts to the location. CPM: You need to pass the MINION_VSE_PASSPHRASE variable to the minion. Then, at the Private locations tab, click on Edit and, in the menu, enable the Verified script execution option. Set proxy configuration You can set proxy server configuration for synthetic scripted monitors that run from local private locations. For more information, see Synthetic's proxy settings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 186.5528,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "sections": "<em>Private</em> <em>locations</em> overview: <em>Monitor</em> internal sites and add new <em>locations</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "In <em>synthetic</em> <em>monitoring</em>, a <em>private</em> location is a collection of <em>private</em> minions. A minion is a containerized application that receives and manages jobs set up through the <em>Synthetics</em> UI. A <em>private</em> location can contain any number of <em>private</em> minions. <em>Private</em> <em>locations</em> allow you to extend your <em>synthetic</em>"
      },
      "id": "604525f1e7b9d2d88d579a1c"
    },
    {
      "sections": [
        "Containerized private minion (CPM) configuration",
        "Guidelines for mounting volumes",
        "Custom npm modules",
        "Custom module directory",
        "Node version-specific overrides",
        "Docker",
        "Kubernetes",
        "Change package.json for custom modules",
        "Caution",
        "Permanent data storage",
        "User-defined environment variables for scripted monitors",
        "Mounting JSON file",
        "Passing as an environment variable",
        "Tip",
        "Accessing user-defined environment variables from scripts",
        "Environment variables",
        "Docker environment configuration",
        "Kubernetes environment configuration"
      ],
      "title": "Containerized private minion (CPM) configuration",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "5c65dd79f361d23da2154f6a4227515a40dae944",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/containerized-private-minion-cpm-configuration/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-06-09T08:46:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn how to configure your containerized private minion (CPM). You can do the following to customize your CPMs: Set up custom modules for scripted browsers in New Relic. Preserve launch data with permanent data storage. Use environment variables in your configuration. You may not modify any CPM files and New Relic is not liable for any modifications you make. Guidelines for mounting volumes All directories and files must be assigned group ownership as 3729 with read/write permissions. This ensures that the Runner, which uses uid: 1000 and gid: 3729, has access to all the mounted volumes. However, the Minion is able to run as root (uid: 0) or with any uid between the range of [2000, 4000], inclusive. For more information, see running as non-root in Kubernetes or Docker. Docker Directories are mounted onto a container as volumes by specifying a -v argument within docker run For example, docker run ... -v /path/to/src:/path/to/dest:rw Kubernetes It is possible to add a directory onto a persistent volume (PV) by using kubectl cp. However, alternative approaches are supported as long as the file permissions are set appropriately. For example, kubectl cp /path/to/src <POD_NAME>:/path/to/dest will add a directory onto each PV in the specified pod Each PV must have a separate copy of the directories. For example, a cluster with n Minion replicas must have n PVs, each with their own copy of directories The directories and files must be added prior to the Minion boot up, otherwise the Minion must be restarted to detect the updates Custom npm modules Custom npm modules are exclusive to the CPM. They allow you to provide an arbitrary set of npm modules, and make them available for scripted monitors in Synthetics. To set up the modules: Create a directory which contains a package.json, following the npm official guidelines, in the root of the directory. Anything contained in the dependencies field will be installed by the CPM at start, and made available when running monitors on that private minion. Optionally, you can override the root level package.json with a Node version-specific directory. This allows a script to be updated per monitor runtime if a Node version of a runtime is no longer compatible with your dependencies. See an example of this below. Custom module directory In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file Copy The package.json defines dependencies as both a local module (i.e. counter) and an npm hosted modules (i.e. async version ^2.6.1): { \"name\": \"custom-modules\", \"version\": \"1.0.0\", ⇦ optional \"description\": \"example custom modules directory\", ⇦ optional \"dependencies\": { \"async\": \"^2.6.1\", ⇦ npm hosted module \"counter\": \"file:./counter\" ⇦ Local module } } Copy Node version-specific overrides You can declare a package.json per Node version that will override the root level package.json. This allows a monitor script to be updated per monitor runtime in the event that the Node version of a runtime is no longer compatible with your dependencies. As shown in the first example, local modules can still be defined within a version specific directory. If a package.json is not defined for a specific Node version, then the root level package.json will be used to install dependencies. In this example, a custom module directory is used with the following structure: /example-custom-modules-dir/ ├── 6.11.2 ⇦ optional Node specific directory │ └── package.json └── 10.15.0 ⇦ optional Node specific directory │ └── package.json ├── counter │ ├── index.js │ └── package.json └── package.json ⇦ the only mandatory file ​ Copy Once you create the custom modules directory and the package.json you can apply it to your CPM for Docker and Kubernetes. Docker For Docker, launch CPM mounting the directory at /var/lib/newrelic/synthetics/modules. For example: docker run ... -v /example-custom-modules-dir:/var/lib/newrelic/synthetics/modules:rw ... Copy Kubernetes Complete the following: Launch the CPM, setting a value for the persistence.customModules configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where your custom modules files exist. For example: helm install ... --set persistence.customModules=<custom-modules-subpath> ... Copy Make sure that your custom modules directory is available on the Minion Pod. You can use kubectl cp as one method to copy the directory from your host to the Minion. For example: kubectl cp /example-custom-modules-dir <namespace>/<pod_name>:/var/lib/newrelic/synthetics/modules Copy Look at the CPM logs for \"... Initialization of Custom Modules ...\" to see if the modules were installed properly, or if there were any errors. The npm installation logs will be shown. Now you can add \"require('async');\" into the script of monitors you send to this private location. Change package.json for custom modules Along with npm modules, you can also use Node.js modules. To change the custom modules used by your CPM, modify package.json and reboot the CPM. It will detect the change in configuration during the reboot, and then clean up and re-install. Caution Local modules: While your package.json can include any local module, these modules must reside inside the tree under your custom module directory. If stored outside the tree, the initialization process will fail and you will see an error message in the docker logs after launching CPM. Permanent data storage CPM is a stateless application and does not preserve information from prior requests or sessions by default. However, you can preserve data between launches by enabling permanent data storage. For example, you can permanently set how the minion identifies itself (for example, Minion_ID), and use it to associate the data visible in Synthetics and Insights events with the exact minion that produced it. To set permanent data storage on Docker: Create a directory. Launch the CPM, mounting the directory at /var/lib/newrelic/synthetics. Example: docker run ... -v /example-permanent-dir:/var/lib/newrelic/synthetics:rw ... Copy To set permanent data storage on Kubernetes: Launch the CPM, setting a value for the persistence.permanentData configuration value either in the command line or in a YAML file during installation. The value should specify the subpath on your Minion's Persistent Volume where you want the data to be saved. Example: helm install ... --set persistence.permanentData=<permanent-data-subpath> ... Copy User-defined environment variables for scripted monitors Containerized private minions let you configure environment variables for use in scripted monitors. These variables are hosted locally on the CPM and can be accessed via $env.USER_DEFINED_VARIABLES. There are two ways to set user-defined variables: by mounting a JSON file or by supplying an environment variable to the CPM on launch. If both are provided, the CPM will use values provided from the environment only. Mounting JSON file The JSON file must have read permissions and contain a JSON formatted map. Example user-defined variable file: { \"KEY\" : \"VALUE\", \"User_Name\": \"MINION\", \"My_Password\": \"PASSW0RD 1 2 3\", \"my_URL\": \"https://newrelic.com/\", \"ETC\" : \"ETC\" } Copy The file must be available or mounted to the path in your container: /var/lib/newrelic/synthetics/variables/user_defined_variables.json Docker example: docker run ... -v /example-user-defined-variables.json:/var/lib/newrelic/synthetics/variables/user_defined_variables.json:rw ... Copy Kubernetes example: When mounting a JSON file to your Minion Pod in Kubernetes, you can either copy the file directly to the Minion Pod or to a Pod that has access to the same Persistent Volume and Persistent Volume Claim that the Minion will use. After successfully loading the file, you may need to restart your Minion Pod for the change to take effect. kubectl cp path/to/user_defined_variables.json <namespace>/<pod_name>:/var/lib/newrelic/synthetics/variables/user_defined_variables.json Copy Passing as an environment variable Use the -e flag to set up an environment variable named MINION_USER_DEFINED_VARIABLES and give it a value of a JSON formatted map string. docker run ... -e MINION_USER_DEFINED_ENV_VARIABLES='{\"KEY\":\"VALUE\",\"NAME\":\"MINION\",\"ETC\":\"ETC\"}' ... Copy Tip The CPM on Kubernetes does not currently support loading user-defined environment variables via environment variable. You will have to configure your Kubernetes CPM by mounting a JSON file. Accessing user-defined environment variables from scripts To reference a configured user-defined environment variable, use the reserved $env.USER_DEFINED_VARIABLES followed by the name of a given variable with dot notation. For example, $env.USER_DEFINED_VARIABLES.MY_VARIABLE Caution User-defined environment variables are not sanitized from logs. For sensitive information, consider using the secure credentials feature. Environment variables Environmental variables allow you to fine-tune the CPM configuration to meet your specific environmental and functional needs. Docker environment configuration The variables are provided at startup using the -e, --env argument. The following table shows all the environment variables that CPM supports. MINION_PRIVATE_LOCATION_KEY is required, and all other variables are optional. Name Description MINION_PRIVATE_LOCATION_KEY REQUIRED. UUID of the Private Location, as found on the Private Location Web page. DOCKER_API_VERSION Format: \"vX.Y\" API version to be used with the given Docker service. Default: v1.35. DOCKER_HOST Points the minion to a given DOCKER_HOST. If absent, the default value is /var/run/docker.sock. MINION_API_ENDPOINT For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. MINION_DOCKER_RUNNER_REGISTRY_ENDPOINT The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic). MINION_API_PROXY Format: \"host:port\". MINION_API_PROXY_AUTH Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. MINION_API_PROXY_SELF_SIGNED_CERT Acceptable values: true, 1, or yes (any case). MINION_CHECK_TIMEOUT The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. MINION_DOCKER_API_VERSION Synonym of DOCKER_API_VERSION. MINION_DOCKER_HOST Synonym of DOCKER_HOST. MINION_RUNNER_APPARMOR (CPM version > 3.0.2) OR MINION_DOCKER_RUNNER_APPARMOR (CPM version <= 3.0.2) The AppArmor profile name, if it has been applied to Docker containers running monitor scripts (for example, Docker Runner). The AppArmor profile name must exist and be set up on the machine to work. MINION_JVM_MB Default: \"2560\" (2.5GB). MINION_JVM_OPTS Passes command line options to the internal JVM. See Oracle's Java documentation for more information. Default: -server. MINION_LOG_LEVEL When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. MINION_NETWORK_HEALTHCHECK_DISABLED (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. MINION_USER_DEFINED_ENV_VARIABLES Format: Example. A locally hosted set of user defined key value pairs. MINION_HEAVY_WORKERS The number of workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. MINION_LIGHTWEIGHT_WORKERS The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * NUM_CPUS where NUM_CPUS is the number of CPUs available to the minion. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of Synthetics monitors. MINION_VSE_PASSPHRASE If set, enables verified script execution and uses this value as a passphrase. Kubernetes environment configuration The variables are provided at startup using the --set argument. The following list shows all the environment variables that CPM supports. synthetics.privateLocationKey is required, and all other variables are optional. Name Description synthetics.privateLocationKey REQUIRED. UUID of the Private Location, as found on the Private Location Web page. replicaCount Number of replicas to maintain with your StatefulSet installation Default: 1. synthetics.minionApiEndpoint For US-based accounts, the endpoint is: https://synthetics-horde.nr-data.net. For EU-based accounts, the endpoint is: https://synthetics-horde.eu01.nr-data.net/ Ensure your CPM can connect to the appropriate endpoint in order to serve your monitor. synthetics.minionDockerRunnerRegistryEndpoint The Docker Registry and Organization where the Minion Runner image is hosted. Use this to override quay.io/newrelic as the default (for example, docker.io/newrelic) synthetics.minionApiProxy Format: \"host:port\". synthetics.minionApiProxyAuth Format: \"username:password\" - Support HTTP Basic Auth + additional authentication protocols supported by Chrome. synthetics.minionApiProxySelfSignedCert Acceptable values: true, 1, or yes (any case). synthetics.minionCheckTimeout The maximum amount of seconds that your monitor checks are allowed to run. This value must be an integer between 0 seconds (excluded) and 900 seconds (included) (for example, from 1 second to 15 minutes). Default: 65 seconds for ping monitors, 180 seconds for the other monitor types. synthetics.minionLogLevel When contacting New Relic Support, they may ask you to increase this to \"DEBUG\" or \"TRACE\". Default: INFO. synthetics.minionNetworkHealthCheckDisabled (CPM version >= 3.0.11) The Minion Network Healthcheck disabled state, to manage the CPM check for public internet access. Default is 'false', when set as 'true' the CPM will bypass this healthcheck. synthetics.minionUserDefinedEnvVariable Format: Example. A locally hosted set of user defined key value pairs. synthetics.heavyWorkers The number of concurrent workers the minion will use to run heavy jobs (BROWSER, SCRIPT_BROWSER, SCRIPT_API). If undefined, the minion will use the value 2. The maximum allowed value for this variable is 50. For more information on monitor types, see Types of Synthetics monitors. synthetics.lightweightWorkers The number of workers the minion will use to run lightweight jobs (SIMPLE ping jobs). If undefined, the minion will use 25 * synthetics.heavyWorkers. Where synthetics.heavyWorkers is number defined in the previous environment variable. The maximum allowed value for this variable is 1250. For more information on monitor types, see Types of synthetic monitors. synthetics.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name that will be applied to the Minion and Runner pods. If set, then the AppArmor profile must exist on the Kubernetes node(s) for this to work. podSecurityContextRunAsUser A UID that can be set to either 0 (root) or between [2000, 4000], inclusive. If set, runs the CPM as the given UID. Default: 2379",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.77501,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Containerized <em>private</em> minion (CPM) configuration",
        "sections": "Containerized <em>private</em> minion (CPM) configuration",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " variable. The maximum allowed value for this variable is 1250. For more information on <em>monitor</em> types, see Types of <em>synthetic</em> monitors. <em>synthetics</em>.minionVsePassphrase If set, enables verified script execution and uses this value as a passphrase. appArmorProfileName The AppArmor profile name"
      },
      "id": "603ea540196a67e50da83d95"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/add-custom-attributes-synthetic-monitoring-data": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.39693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/import-nodejs-modules": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04395,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.39693,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0062,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/introduction-scripted-browser-monitors": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04393,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.39691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00612,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/scripted-browser-examples": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.0439,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.39691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00604,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors": [
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.39691,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00595,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic scripted browser reference (monitor versions 0.4.x or lower)",
        "Overview",
        "Top-level functions: Build your script",
        "Disallow list: Wildcard use",
        "Options: Manage the browser instance",
        "Locators: Find page elements",
        "WebElement: Interact with page elements",
        "ActionSequence: Link multiple actions",
        "Promises: Link actions into sequences",
        "Navigate: Move through browser history",
        "Conditions: Pause and wait for conditions",
        "For more help"
      ],
      "title": "Synthetic scripted browser reference (monitor versions 0.4.x or lower)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "8a611db3cb5dbef143f77936e67a50e87a5c5809",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower/",
      "published_at": "2021-10-08T11:19:46Z",
      "updated_at": "2021-07-10T02:09:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for synthetic monitor versions 0.4.x or lower. See also the documentation for Synthetic monitor versions 0.5 or higher. Overview Synthetic scripted browsers provide you access to the Selenium Webdriver APIs 2.47.0 via the variables $driver and $browser. In particular: $driver provides all the exports from the selenium-webdriver module (for example, ActionSequence, Button, By, WebElement, etc.). $browser is a synthetic-flavored instance of selenium-webdriver.WebDriver(): it exposes the main basic WebDriver APIs like get() and findElement(), as well as some synthetic custom APIs. This document describes the functions available for synthetic scripted browser monitors version 0.4.0 or lower. For the newest monitor documentation, see monitor version 0.5.0+ documentation. Other relevant documentation: For more on synthetic scripting, see Write scripted browsers. For example scripts, see Scripted browser examples. For more information about monitor versions and runtime differences, see Runtime environments. To view and share scripted browser examples, check out topics tagged synthetic-script in New Relic's Explorers Hub. Top-level functions: Build your script New Relic calls top-level functions directly from your $browser instance. These provide a wide range of functionality that covers many basic scriptable actions. Function Return value $browser.actions() Creates a new action sequence using this driver. For a list of available actions, see ActionSequence: Link multiple actions. void $browser.addHeader(headerKey: string, headerValue: string) Adds header headerKey with value headerValue to the runtime. void $browser.addHeaders(headers: ?) Adds a map of headers to the runtime. void $browser.deleteHeader(header: string) Deletes a specific header from the runtime. void $browser.deleteHeaders(header: [string]) Deletes all headers in argument from runtime. void $browser.addHostnameToBlacklist(hostname: string) Disallows a hostname. Allows use wildcards. void $browser.addHostnamesToBlacklist(hostnameArr: [string]) Disallows all hostnames in an array of arguments. Allows use wildcards. void $browser.addHostnameToWhitelist(hostname: string) Allows a hostname blocked by default in synthetic monitoring. void $browser.addHostnamesToWhitelist(hostnameArr: [string]) Allows all hostnames in argument. void $browser.deleteHostnameFromBlacklist(hostname: string) Removes a hostname from this browser instance's blacklist. void $browser.deleteHostnamesFromBlacklist(hostnameArr: [string]) Removes all hostnames in argument from the disallowed list. void $browser.deleteHostnameFromWhitelist(hostnameArr: [string]) Removes a hostname from this browser instance's allowed list. void $browser.deleteHostnamesFromWhitelist(hostnameArr: [string]) Removes all hostnames in argument from this browser instance's allowed list. void $browser.executeAsyncScript(script: ?, var_args: ?) Schedules a command to execute asynchronous JavaScript in the context of the currently selected frame or window. promise $browser.executeScript(script: ?, var_args: ?) Schedules a command to execute JavaScript in the context of the currently selected frame or window. promise $browser.findElement(locator: $driver.Locator) Schedule a command to find an element on the page. If not found, New Relic returns an error. WebElement $browser.findElements(locator: $driver.Locator) Schedule a command to search for multiple elements on the page. promise $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) Schedule a command to wait for and find an element on the page, and another command to wait for it to be visible. If not found, New Relic returns an error. The timeout value is an optional one, and gets applied separately to both tasks of finding the element and waiting for its visibility. This means at worst case, this method can take up to twice the provided timeout value. The default timeout value is 1000 ms (1 second). promise $browser.get(url: string) Loads a webpage in a synthetic browser. promise $browser.getAllWindowHandles() Schedules a command to retrieve the current list of available window handles. promise $browser.getCapabilities() A promise that will resolve with the instance's capabilities. promise $browser.getCurrentUrl() Schedules a command to retrieve the URL of the current page. promise $browser.getHeaders() Returns a map of currently configured headers. map $browser.getPageSource() Schedules a command to retrieve the current page's source. The page source returned is a representation of the underlying DOM; do not expect it to be formatted or escaped in the same way as the response sent from the web server. promise $browser.getSession() A promise for this client's session. promise $browser.getTitle() Schedules a command to retrieve the current page's title. promise $browser.getWindowHandle() Schedules a command to retrieve the current window handle. promise $browser.isElementPresent(locatorOrElement: $driver.Locator) Schedules a command to test if an element is present on the page. If given a DOM element, this function will check if it belongs to the document the driver is currently focused on. Otherwise, the function will test if at least one element can be found with the given search criteria. promise $browser.manage() The options interface for this instance. You can manage cookies, timeouts, and other window options. void $browser.navigate() The navigation interface (history of browser functions) for this instance. void $browser.schedule(command: ?, description: string) Schedules a command to be executed by this driver's CommandExecutor. promise $browser.sleep() Schedules a command to make the driver sleep for the given amount of time. promise $browser.switchTo() The target locator interface for this instance. void $browser.takeScreenshot() Schedule a command to take a screenshot. promise $browser.wait(fn: $driver.until.Condition, timeout: number, opt_message: string) Schedules a command to wait for a condition to hold, as defined by some user supplied function. webElement $browser.waitForPendingRequests(timeout: number) Causes the script to wait for requests that have been initiated to return, up to the timeout. Useful for tracking non-blocking resources. promise Disallow list: Wildcard use Disallowing domains for your browser instance requires wildcards to match the URL syntax of the URL to be blocked. An overall .com disallowed list needs to contain these functions: Function Blocking action $browser.addHostnameToBlacklist('*.com'); a.com $browser.addHostnameToBlacklist('*.*.com'); a.b.com $browser.addHostnameToBlacklist('*.*.*.com'); a.b.c.com $browser.addHostnameToBlacklist('www.*.com'); www.a.com $browser.addHostnameToBlacklist('www.*.*.com'); www.a.b.com $browser.addHostnameToBlacklist('www.*.*.*.com'); www.a.b.c.com Options: Manage the browser instance These functions manage options for your browser instance such as cookies, timeouts and window size. Access these options through the $browser.manage() function. Function Return value $browser.manage().addCookie(name: string, value: string, opt_path: string, opt_domain: string, opt_isSecure: boolean, opt_expiry: number) Schedules a command to add a cookie. promise $browser.manage().deleteAllCookies() Schedules a command to delete all cookies visible to the current page. promise $browser.manage().deleteCookie(name: string) Schedules a command to delete the cookie with the given name. This command is a no-op if there is no cookie with the given name visible to the current page. promise $browser.manage().getCookie(name: string) Schedules a command to retrieve the cookie with the given name. Returns null if there is no such cookie. The cookie will be returned as a JSON object as described by the WebDriver wire protocol. promise $browser.manage().getCookies() Schedules a command to retrieve all cookies visible to the current page. New Relic Syntheticcs returns each cookie as a JSON object as described by the WebDriver wire protocol. promise $browser.manage().timeouts().implicitlyWait(ms: number) Specifies the amount of time the driver should wait when searching for an element if it is not immediately present. Setting the wait timeout to 0 disables implicit waiting. Be careful increasing the wait timeout, as it will increase test run time, especially with slower location strategies like XPath. Default is 10 seconds. promise $browser.manage().timeouts().pageLoadTimeout(ms: number) Sets the amount of time to wait for a page load to complete before returning an error. If the timeout is negative, page loads may last up to 180 seconds. Default is 60 seconds. promise $browser.manage().timeouts().setScriptTimeout(ms: number) Sets the amount of time to wait, in milliseconds, for an asynchronous script to finish execution before returning an error. Default is 30 seconds. promise $browser.manage().window().getPosition() Retrieves the window's current position, relative to the top left corner of the screen. promise $browser.manage().window().getSize() Retrieves the window's current size. promise $browser.manage().window().maximize() Maximizes the current window. promise $browser.manage().window().setPosition(x: number, y: number) Repositions the current window. promise $browser.manage().window().setSize(width: number, height: number) Resizes the current window. promise Locators: Find page elements Locators are a collection of factory functions for creating locator instances. Locators find DOM elements, which can be passed to functions such as $browser.findElement or $browser.isElementPresent. Call them through $driver.By. Function Return value $driver.By.className(className: string) Locates an element that has a specific class name. The returned locator is equivalent to searching for elements with the CSS selector .clazz. locator $driver.By.css(cssName: string) Locates an element using a CSS selector. locator $driver.By.id(id: string) Locates an element by its ID. locator $driver.By.linkText(linkText: string) Locates link elements whose visible text matches the given string. locator $driver.By.js(js: string) Locates an element by evaluating a JavaScript expression. locator $driver.By.name(name: string) Locates elements whose name attribute has the given value. locator $driver.By.partialLinkText(partialLinkText: string) Locates link elements whose getText visible contains the given substring. locator $driver.By.tagName(tagName: string) Locates elements with a given tag name. The returned locator is equivalent to using the getElementsByTagName DOM function. locator $driver.By.xpath(xpath: string) Locates elements matching a XPath selector. locator WebElement: Interact with page elements When a function such as $browser.findElement or $browser.waitForAndFindElement returns a WebElement reference, these functions can be used to interact with that element. Using these, you can click on buttons, sent text to form inputs, and get attributes of elements to test. Function Return value click() Clicks on this element. void sendKeys(var_args: ?) Schedules a command to type a sequence on the DOM element represented by this instance. WebElement getTagName() Schedules a command to query for the tag/node name of this element. WebElement getCssValue(name: string) Schedules a command to query for the computed style of the element represented by this instance. If the element inherits the named style from its parent, the parent will be queried for its value. Where possible, color values will be converted to their hex representation (for example, #00ff00 instead of rgb(0, 255, 0)). promise getAttribute(name: string) Schedules a command to query for the value of the given attribute of the element. promise getText(name: string) Get the visible (not hidden by CSS) innerText of this element, including sub-elements, without any leading or trailing white space. promise getSize() Schedules a command to compute the size of this element's bounding box, in pixels. promise getLocation() Schedules a command to compute the location of this element, in page space. promise isEnabled() Schedules a command to query whether the DOM element represented by this instance is enabled, as dictated by the disabled attribute. promise isSelected() Schedules a command to query whether this element is selected. promise submit() Schedules a command to submit the form containing this element (or this element if it is a FORM element). This command is a no-op if the element is not contained in a form. promise clear() Schedules a command to clear the value of this element. promise isDisplayed() Schedules a command to test whether this element is currently displayed. promise getOuterHtml() Schedules a command to retrieve the outer HTML of this element. promise getInnerHtml() Schedules a command to retrieve the inner HTML of this element. promise ActionSequence: Link multiple actions Action sequences can create complex user interactions with your website. To create a new action sequence, use $browser.actions(). To link multiple actions together into a sequence, include perform() after each. This executes and then terminates individual sequences, including single-action sequences. The following table contains a list of available actions. For more information, see the WebDriver ActionSequence documentation. Function Return value click(opt_elementOrButton: ?, opt_button: ?) Clicks a mouse button. If an element is provided, the mouse will first be moved to the center of that element. This is equivalent to WebElement.click(). actionsequence doubleClick(opt_elementOrButton: ?, opt_button: ?) Double-clicks a mouse button. If an element is provided, the mouse will first be moved to the center of that element. actionsequence dragAndDrop(element: ?, location: ?) Convenience function for performing a \"drag and drop\" maneuver. The target element may be moved to the location of another element, or by an offset (in pixels). The location is an object with two properties x and y: {x: x_offset, y: y_offset}. actionsequence keyDown(key: ?) Performs a modifier key press. Must be one of ALT, CONTROL, SHIFT, COMMAND, or META. The modifier key is not released until keyUp() or sendKeys() is called. The key press will be targeted at the currently focused element. actionsequence keyUp(key: ?) Performs a modifier key release. The release is targeted at the currently focused element. actionsequence mouseDown(opt_elementOrButton: ?, opt_button: ?) Presses a mouse button. The mouse button will not be released until mouseUp is called, regardless of whether that call is made in this sequence or another. The behavior for out-of-order events (such as calling mouseDown() or click() when the button is already held down) is undefined. actionsequence mouseUp(opt_elementOrButton: ?, opt_button: ?) Releases a mouse button. Behavior is undefined for calling this function without a previous call to mouseDown(). actionsequence mouseMove(location: ?, offset: ?) Moves the mouse. The location to move to may be specified in terms of the mouse's current location, an offset relative to the top-left corner of an element, or an element (in which case the middle of the element is used). actionsequence perform() Executes this action sequence. promise sendKeys(args: ?) Simulates typing multiple keys. Each modifier key encountered in the sequence will not be released until it is encountered again. All key events will be targeted at the currently focused element. For a full list of supported non-alphanumeric keys, see the WebDriver enum key documentation. actionsequence Promises: Link actions into sequences You can also execute functions directly on promises. Synthetic monitoring is a native Node.js environment and uses standard Node.js promises. These functions evaluate the status of promises, cancel them, and more. In particular, you can create sequences of actions with the then() function and its siblings, thenFinally() and thenCatch(). For more information, see Sequence actions. Function Return value cancel(string: reason) Cancels the computation of this promise's value, rejecting the promise in the process. This method is a no-op if the promise has already been resolved. void isPending() Whether this promise's value is still being computed. boolean then(opt_callback: fn(T: ?), opt_errback: fn()) Registers listeners for when this instance is resolved. This is the basic function used to link synchronous actions in your script. promise thenFinally(callback: fn()) Registers a listener to invoke when this promise is resolved, regardless of whether the promise's value was successfully computed. promise thenCatch(callback: fn()) Registers a listener for when this promise is rejected. promise Navigate: Move through browser history The $browser.navigate() function exposes a number of functions that allow you to move backwards and forwards through your browser history, refresh your page and navigate to new pages. Function Return value back() Move back by one step in the browser's history. void forward() Move forward by one step in the browser's history. void refresh() Refresh the current page. void to(string: url) Load a new webpage in the current browser window. $browser.navigate().to() is equivalent to $browser.get(). void Conditions: Pause and wait for conditions Used with $browser.wait, until pauses your script execution until the condition is matched. For more information on explicit and implicit waits, see the WebDriver documentation. For .wait and .until usage examples, see Webdriver.wait examples. The following are available functions for $driver.until.Condition: Function Return value ableToSwitchToFrame(frame: ?) Creates a condition that will wait until the input driver is able to switch to the designated frame. The target frame may be specified as: A numeric index into window.frames for the current frame A webdriver.WebElement, which must reference a FRAME or IFRAME element on the current page A locator which may be used to first locate a FRAME or IFRAME on the current page before attempting to switch to it Upon successful resolution of this condition, the driver will be left focused on the new frame. condition alertIsPresent() Creates a condition that waits for an alert to be opened. Upon success, the returned promise will be fulfilled with the handle for the opened alert. condition elementIsDisabled(element: $driver.WebElement) Creates a condition that will wait for the given element to be disabled. condition elementIsEnabled(element: $driver.WebElement) Creates a condition that will wait for the given element to be enabled. condition elementIsNotVisible(element: $driver.WebElement) Creates a condition that will wait for the given element to be in the DOM, yet not visible to the user. condition elementIsVisible(element: $driver.WebElement) Creates a condition that will wait for the given element to become visible. condition elementIsSelected(element: $driver.WebElement) Creates a condition that will wait for the given element to be selected. condition elementLocated(element: $driver.Locator) Creates a condition that will loop until an element is found with the given locator. condition elementsLocated(element: $driver.Locator) Creates a condition that will loop until at least one element is found with the given locator. condition elementTextContains(element: $driver.WebElement, substr: string) Creates a condition that will wait for the given element's visible text to contain the given substring. condition elementTextIs(element: $driver.WebElement, text: string) Case sensitive. Creates a condition that will wait for the given element's visible text to match the given text exactly. condition elementTextMatches(element: $driver.WebElement, regex: string) Creates a condition that will wait for the given element's visible text to match a regular expression. condition stalenessOf(element: $driver.WebElement) Creates a condition that will wait for the given element to become stale. An element is considered stale once it is removed from the DOM, or a new page has loaded. condition titleContains(substr: string) Creates a condition that will wait for the current page's title to contain the given substring. condition titleIs(title: string) Creates a condition that will wait for the current page's title to match the given value. condition titleMatches(regex: string) Creates a condition that will wait for the current page's title to match the given regular expression. condition For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Scripted browser examples (example code for scripted browsers, including comments, with examples like searching a website and waiting for results to load)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.23534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>scripted</em> browser reference (<em>monitor</em> versions 0.4.x or lower)",
        "sections": "<em>Synthetic</em> <em>scripted</em> browser reference (<em>monitor</em> versions 0.4.x or lower)",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " APIs. This document describes the functions available for <em>synthetic</em> scripted browser <em>monitors</em> version 0.4.0 or lower. For the newest <em>monitor</em> documentation, see <em>monitor</em> version 0.5.0+ documentation. Other relevant documentation: For more on <em>synthetic</em> <em>scripting</em>, see Write scripted browsers. For example"
      },
      "id": "6045266428ccbc04a2336a71"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.3969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00589,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetics-scripted-browser-reference-monitor-versions-050": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Write synthetic API tests",
        "Tip",
        "Use API http-request module",
        "Important",
        "Configure request options",
        "Using optional metadata",
        "Using a SSL option or agentOptions",
        "Send a GET request",
        "Insights GET example",
        "Send a POST request",
        "Custom event POST example",
        "Validate results",
        "Event API validation example"
      ],
      "title": "Write synthetic API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "236593e91fbe7bb6af91ca5f10db1c01d2df0396",
      "image": "https://docs.newrelic.com/static/1f9113bc9e00a2a14593e27718f45c7c/baaa6/api-test-snap_0.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests/",
      "published_at": "2021-10-07T04:49:51Z",
      "updated_at": "2021-08-27T01:16:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use synthetic monitoring's API tests to monitor your API endpoint to ensure it is functioning correctly. New Relic uses the http-request module internally to make HTTP calls to your endpoint and validate the results. Here we present some example functions showing how to use the $http object to submit your request. For detailed documentation on the options available for this object, see the http-request readme. Tip To view and share other API test examples, visit the synthetics scripts section in Explorers Hub. Use API http-request module API tests are powered by the http-request module, which is available through the $http object. Once each frequency interval, New Relic queries your endpoint from each of your selected locations. For instructions on creating a monitor, see Adding monitors. Read on to learn how to define metadata for your request, make a GET request, make a POST request, and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the script. one.newrelic.com > Synthetics > Create monitor: The script editor suggests functions, selectors, and other elements to simplify scripting commands (available in GitHub). Configure request options To start your script: Declare a variable (such as options) to store your request options object. Define request options such as the URL endpoint, and custom headers. If you're setting SSL or agent options, see SSL and agentOptions requirements. Tip For a full list of supported request options, see request(options, callback) in the http-request documentation on GitHub. Here's an example of optional metadata in the options object: Using optional metadata //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } }; Copy For SSL and agentOptions: If you are setting SSL options or providing an agentOptions object, the agent property in the request options object will need to be set to $globalAgents.https or $globalAgents.http to ensure your HTTP requests use the instrumented global agent. Here's an example of using a SSL option or agentOptions: Using a SSL option or agentOptions This example uses agentOptions: //Declare optional metadata var options = { //Specify the endpoint URL url: 'https://api-endpoint.example.com', //Specify optional headers headers: { 'Endpoint-Key': 'uqNTC57Phe72pnnB8JuJmwAr7b09nKSKSz', 'Additional-Header': 'Additional-Header-Data' } //Specify global agent as the http agent agent: $globalAgents.https, //Set SSL option strictSSL: true, //Specify http agent options agentOptions: { ​maxVersion: 'TLSv1.1' }, }; Copy Send a GET request To make a GET request, use the $http.get method to submit your request. Define your request options, make your request using $http.get, then validate the response to ensure your endpoint is returning the correct results. Insights GET example This example queries the Insights API by using GET: //Define your authentication credentials var myAccountID = '{YOUR_ACCOUNT_ID}'; var myQueryKey = '{YOUR_QUERY_KEY}'; var options = { //Define endpoint URI uri: 'https://insights-api.newrelic.com/v1/accounts/'+myAccountID+'/query?nrql=SELECT%20average(amount)%20FROM%20SyntheticsEvent', //Define query key and expected data type. headers: { 'X-Query-Key': myQueryKey, 'Accept': 'application/json' } }; //Define expected results using callback function. function callback (err, response, body){ //Log JSON results from endpoint to Synthetics console. console.log(JSON.parse(body)); console.log('done with script'); } //Make GET request, passing in options and callback. $http.get(options,callback); Copy Send a POST request To make a POST request, use the $http.post method to submit your request. Define your request options, make your request using $http.post, then validate the response to ensure your endpoint is returning the correct results. Custom event POST example This example POSTs a custom event containing static integers to the Event API: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the 'assert' module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; //Define expected results using callback function. function callback(error, response, body) { //Log status code to Synthetics console. console.log(response.statusCode + \" status code\") //Verify endpoint returns 200 (OK) response code. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); //Parse JSON received from Insights into variable. var info = JSON.parse(body); //Verify that `info` contains element named `success` with a value of `true`. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); //Log end of script. console.log(\"End reached\"); } //Make POST request, passing in options and callback. $http.post(options, callback); Copy Validate results To validate your results, import the assert module to define your test case. Call an assert method to validate your endpoint's response. If any assert functions fail, the entire monitor will be considered a failed check. This may trigger alert notifications and affect your metrics. Important Synthetic monitoring does not allow thrown exceptions. Thrown exceptions result in script failure. Use the assert module to validate your results, and use console.log() to log results to the synthetic's console. Event API validation example This example POSTs to the Event API, then validates that the response is {\"success\":true}: //Define your authentication credentials. var myAccountID = '{YOUR_ACCOUNT_ID}'; var myLicenseKey = '{YOUR_LICENSE_KEY}'; //Import the `assert` module to validate results. var assert = require('assert'); var options = { //Define endpoint URL. url: \"https://insights-collector.newrelic.com/v1/accounts/\"+myAccountID+\"/events\", //Define body of POST request. body: '[{\"eventType\":\"SyntheticsEvent\",\"integer1\":1000,\"integer2\":2000}]', //Define New Relic license key and expected data type. headers: { 'Api-Key': myLicenseKey, 'Content-Type': 'application/json' } }; $http.post(options, function(error, response, body) { //Log status code to Synthetics console. The status code is logged before the `assert` function, //because a failed assert function ends the script. console.log(response.statusCode + \" status code\") //Call `assert` method, expecting a `200` response code. //If assertion fails, log `Expected 200 OK response` as error message to Synthetics console. assert.ok(response.statusCode == 200, 'Expected 200 OK response'); var info = JSON.parse(body); //Call `assert` method, expecting body to return `{\"success\":true}`. //If assertion fails, log `Expected True results in Response Body,` plus results as error message to Synthetics console. assert.ok(info.success == true, 'Expected True results in Response Body, result was ' + info.success); }); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.3969,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Write <em>synthetic</em> API tests",
        "sections": "Write <em>synthetic</em> API tests",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", and how to validate the results. Important After a maximum run time of three minutes, New Relic manually stops the <em>script</em>. one.newrelic.com &gt; <em>Synthetics</em> &gt; Create <em>monitor</em>: The <em>script</em> editor suggests functions, selectors, and other elements to simplify <em>scripting</em> commands (available in GitHub"
      },
      "id": "603ecf4328ccbc9c48eba78f"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/scripting-monitors/write-synthetic-api-tests": [
    {
      "sections": [
        "Set proxy settings and properties for scripted monitors",
        "Proxy settings API for scripted monitors",
        "Important",
        "$network.setProxy(string or object PROXY URL)",
        "Returns",
        "Parameters",
        "Examples",
        "$network.setProxyForHttp(string or object PROXY URL)",
        "Tip",
        "$network.setProxyForHttps(string or object PROXY URL)",
        "$network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT)",
        "$network.setProxyAdvanced(object PROXY RULES OBJECT)",
        "$network.clearProxy()",
        "$network.getProxy()",
        "Proxy properties",
        "For more help"
      ],
      "title": "Set proxy settings and properties for scripted monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "f8a45f39f13ea831a481fc293531b95674c17844",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/set-proxy-settings-properties-scripted-monitors/",
      "published_at": "2021-10-08T11:18:55Z",
      "updated_at": "2021-09-21T06:41:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Read on to learn about synthetic monitoring's proxy settings and properties. Proxy settings API for scripted monitors Important You can set proxy server configuration for synthetic scripted monitors for monitor versions 0.4.0 or higher. The global object $network allows you to control the network configuration used by your synthetic scripted monitors. The following are applicable for both scripted browsers and API tests, unless otherwise stated. $network.setProxy(string or object PROXY URL) Sets a proxy server to be used for all per-URL requests (HTTP, HTTPS, and FTP). Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxy('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxy('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttp(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTP traffic. Sets a proxy server to be used for all HTTP requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the port would be 80. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTP protocol on port 1234 with no authentication: $network.setProxyForHttp('http://host.com:1234') Copy An example of setting a proxy server with HTTP protocol with authentication credentials. $network.setProxyForHttp('http://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyForHttps(string or object PROXY URL) Tip This call is exactly the same as the per-URL setProxy call, except that it applies to HTTPS traffic. Sets a proxy server to be used for all HTTPS requests. Additional notes: The port is optional. If not provided, it will be derived from the scheme. For example, for HTTP the default port would be 443. The username and password are assumed to be the result of a call to encodeURIComponent(). Special characters like @ and : in the username and/or the password must be escaped. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description proxyURL | proxyUrlParsed String or Object The URL to connect to the proxy server. A string containing a proxyURL (for example, http://proxy_host:8888) or a plain object in the same format as defined by Node's url.parse(urlString) method. Examples An example of setting a proxy server with HTTPS protocol on port 1234 with no authentication: $network.setProxyForHttps('https://host.com:1234') Copy An example of setting a proxy server with HTTPS protocol with authentication credentials. $network.setProxyForHttps('https://proxyUsername:proxyPassword@proxyHost:1234') Copy $network.setProxyPAC(string PAC SCRIPT URL, object AUTH OBJECT) Sets a proxy server via a proxy auto-config (PAC) script and returns a promise. This function is only available for scripted browser monitors. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description scriptURL String The URL of the PAC script. authCredentialsMap Object Map of authentication credentials to be provided to the proxy server(s), keyed by the hostnames of the proxy server. Values of this map must be defined in the format {username: 'authUsername', password: 'authPassword'} Examples An example of setting a proxy server via a proxy auto-config (PAC) script: var authCredentialsMap = { 'example.com': {username: 'authUsername', password: 'authPassword'}, } Copy $network.setProxyAdvanced(object PROXY RULES OBJECT) Tip This method is Chrome-specific: it only applies to scripted browser monitor types. It can be used to allow for a more flexible and complex proxy configuration. In most cases, this method will not be needed. Sets the proxy configuration using the format supported by Chrome Extension API for Proxying. The input is a ProxyRules object, as defined by the Chrome Extension API to configures proxies. You can add authCredentials for proxies that need it. See Parameters for more details. Returns This method returns a Promise that will resolve once the configuration has been applied. Parameters Parameter Data Type Description ProxyRules Object Object The proxyRulesObject is a plain object that follows the format ProxyRules as defined by the Chrome Extension API to configures proxies. This object is \"flavoured\" to fit our runtime: users can define an additional property, authCredentials, for the Proxy server objects to provide authentication credentials for a specific proxy server. authCredentials is an object in the format {username: 'authUsername', password: 'authPassword'}. Examples Here's an example of creating a proxyRules with authCredentials: var proxyRules = { singleProxy: { host:\"example.com\", authCredentials: { username: 'authUsername', password: 'authPassword' } } }; Copy Here's an example of setting up a proxied network with mixed network zone assets: var proxyRules = {singleProxy: {host:\"http://entproxy.mycompany.com\"}, bypassList:['s3.amazonaws.com','*.localcdn.com'] } $network.setProxyAdvanced(proxyRules) Copy $network.clearProxy() Clears/removes the current proxy configuration. Returns This method returns a Promise that will resolve once the configuration has been applied. $network.getProxy() This method returns the current proxy configuration. It must be synchronized in a promise callback. Examples An example of synchronizing getProxy with $network.setProxy(); and $network.clearProxy();: var assert = require('assert'); $network.setProxy(\"http://user:password@myproxyurl.com\") .then(function () { console.log('Proxy configuration applied'); //Note: $network.getProxy() is not synchronized with the webdriver Control Flow. //To make sure we get the proxy configuration after the call to setProxy() above // succeeds we need to use a promise callback var proxyData = $network.getProxy(); console.log(proxyData); }) .then(function () { // Again: getProxy() is not synchronized with the Webdriver Control Flow: we //need this promise callback otherwise clearProxy() might be called before the call // to getProxy() above returns return $network.clearProxy(); }) .then(function () { console.log('Proxy configuration cleared'); // We need this promise callback for reasons explained above var proxyData = $network.getProxy(); assert.equal(proxyData.rules, null); }); Copy Proxy properties Important This proxy information applies only to these versions: API monitors: 0.4.0, 0.2.2, 0.2.1, 0.1.0 Scripted monitors: 0.1.0 In order to analyze and collect your HTTP traffic metrics, New Relic must ensure the traffic passes through a conceptual funnel. Our synthetic monitoring includes a software funnel component capable of analyzing the HTTP requests or responses and then recording the information. New Relic's scripted browser monitors (versions 0.4.x and lower) include a mechanism to do this analysis without needing an HTTP proxy, so you don't have to configure anything. New Relic's API test (versions 0.4.x and lower) provides an $http object that is pre-configured to make the requests pass through the internal HTTP proxy. This allows you to write your test without including any proxy settings. If you want to use some other way to generate HTTP traffic while still collecting the HTTP traffic metrics, you can use $env.PROXY_HOST and $env.PROXY_PORT. To record traffic metrics, be sure to include these properties in your script. For more help Additional documentation resources include: Write scripted browsers (how to write scripted browsers for synthetic monitoring) Write API tests (how to write API tests for synthetic monitoring) Add and edit monitors (how to create virtual browser monitors in New Relic)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.04384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "sections": "Set proxy settings and properties for <em>scripted</em> <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Read on to learn about <em>synthetic</em> <em>monitoring</em>&#x27;s proxy settings and properties. Proxy settings API for scripted <em>monitors</em> Important You can set proxy server configuration for <em>synthetic</em> scripted <em>monitors</em> for <em>monitor</em> versions 0.4.0 or higher. The global object $network allows you to control the network"
      },
      "id": "6045269d64441fcdc1378ecf"
    },
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can use New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Synthetic scripted browser reference (monitor versions 0.4.x or lower)",
        "Overview",
        "Top-level functions: Build your script",
        "Disallow list: Wildcard use",
        "Options: Manage the browser instance",
        "Locators: Find page elements",
        "WebElement: Interact with page elements",
        "ActionSequence: Link multiple actions",
        "Promises: Link actions into sequences",
        "Navigate: Move through browser history",
        "Conditions: Pause and wait for conditions",
        "For more help"
      ],
      "title": "Synthetic scripted browser reference (monitor versions 0.4.x or lower)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Scripting monitors"
      ],
      "external_id": "8a611db3cb5dbef143f77936e67a50e87a5c5809",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/scripting-monitors/synthetic-scripted-browser-reference-monitor-versions-04x-or-lower/",
      "published_at": "2021-10-08T11:19:46Z",
      "updated_at": "2021-07-10T02:09:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document is for synthetic monitor versions 0.4.x or lower. See also the documentation for Synthetic monitor versions 0.5 or higher. Overview Synthetic scripted browsers provide you access to the Selenium Webdriver APIs 2.47.0 via the variables $driver and $browser. In particular: $driver provides all the exports from the selenium-webdriver module (for example, ActionSequence, Button, By, WebElement, etc.). $browser is a synthetic-flavored instance of selenium-webdriver.WebDriver(): it exposes the main basic WebDriver APIs like get() and findElement(), as well as some synthetic custom APIs. This document describes the functions available for synthetic scripted browser monitors version 0.4.0 or lower. For the newest monitor documentation, see monitor version 0.5.0+ documentation. Other relevant documentation: For more on synthetic scripting, see Write scripted browsers. For example scripts, see Scripted browser examples. For more information about monitor versions and runtime differences, see Runtime environments. To view and share scripted browser examples, check out topics tagged synthetic-script in New Relic's Explorers Hub. Top-level functions: Build your script New Relic calls top-level functions directly from your $browser instance. These provide a wide range of functionality that covers many basic scriptable actions. Function Return value $browser.actions() Creates a new action sequence using this driver. For a list of available actions, see ActionSequence: Link multiple actions. void $browser.addHeader(headerKey: string, headerValue: string) Adds header headerKey with value headerValue to the runtime. void $browser.addHeaders(headers: ?) Adds a map of headers to the runtime. void $browser.deleteHeader(header: string) Deletes a specific header from the runtime. void $browser.deleteHeaders(header: [string]) Deletes all headers in argument from runtime. void $browser.addHostnameToBlacklist(hostname: string) Disallows a hostname. Allows use wildcards. void $browser.addHostnamesToBlacklist(hostnameArr: [string]) Disallows all hostnames in an array of arguments. Allows use wildcards. void $browser.addHostnameToWhitelist(hostname: string) Allows a hostname blocked by default in synthetic monitoring. void $browser.addHostnamesToWhitelist(hostnameArr: [string]) Allows all hostnames in argument. void $browser.deleteHostnameFromBlacklist(hostname: string) Removes a hostname from this browser instance's blacklist. void $browser.deleteHostnamesFromBlacklist(hostnameArr: [string]) Removes all hostnames in argument from the disallowed list. void $browser.deleteHostnameFromWhitelist(hostnameArr: [string]) Removes a hostname from this browser instance's allowed list. void $browser.deleteHostnamesFromWhitelist(hostnameArr: [string]) Removes all hostnames in argument from this browser instance's allowed list. void $browser.executeAsyncScript(script: ?, var_args: ?) Schedules a command to execute asynchronous JavaScript in the context of the currently selected frame or window. promise $browser.executeScript(script: ?, var_args: ?) Schedules a command to execute JavaScript in the context of the currently selected frame or window. promise $browser.findElement(locator: $driver.Locator) Schedule a command to find an element on the page. If not found, New Relic returns an error. WebElement $browser.findElements(locator: $driver.Locator) Schedule a command to search for multiple elements on the page. promise $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) Schedule a command to wait for and find an element on the page, and another command to wait for it to be visible. If not found, New Relic returns an error. The timeout value is an optional one, and gets applied separately to both tasks of finding the element and waiting for its visibility. This means at worst case, this method can take up to twice the provided timeout value. The default timeout value is 1000 ms (1 second). promise $browser.get(url: string) Loads a webpage in a synthetic browser. promise $browser.getAllWindowHandles() Schedules a command to retrieve the current list of available window handles. promise $browser.getCapabilities() A promise that will resolve with the instance's capabilities. promise $browser.getCurrentUrl() Schedules a command to retrieve the URL of the current page. promise $browser.getHeaders() Returns a map of currently configured headers. map $browser.getPageSource() Schedules a command to retrieve the current page's source. The page source returned is a representation of the underlying DOM; do not expect it to be formatted or escaped in the same way as the response sent from the web server. promise $browser.getSession() A promise for this client's session. promise $browser.getTitle() Schedules a command to retrieve the current page's title. promise $browser.getWindowHandle() Schedules a command to retrieve the current window handle. promise $browser.isElementPresent(locatorOrElement: $driver.Locator) Schedules a command to test if an element is present on the page. If given a DOM element, this function will check if it belongs to the document the driver is currently focused on. Otherwise, the function will test if at least one element can be found with the given search criteria. promise $browser.manage() The options interface for this instance. You can manage cookies, timeouts, and other window options. void $browser.navigate() The navigation interface (history of browser functions) for this instance. void $browser.schedule(command: ?, description: string) Schedules a command to be executed by this driver's CommandExecutor. promise $browser.sleep() Schedules a command to make the driver sleep for the given amount of time. promise $browser.switchTo() The target locator interface for this instance. void $browser.takeScreenshot() Schedule a command to take a screenshot. promise $browser.wait(fn: $driver.until.Condition, timeout: number, opt_message: string) Schedules a command to wait for a condition to hold, as defined by some user supplied function. webElement $browser.waitForPendingRequests(timeout: number) Causes the script to wait for requests that have been initiated to return, up to the timeout. Useful for tracking non-blocking resources. promise Disallow list: Wildcard use Disallowing domains for your browser instance requires wildcards to match the URL syntax of the URL to be blocked. An overall .com disallowed list needs to contain these functions: Function Blocking action $browser.addHostnameToBlacklist('*.com'); a.com $browser.addHostnameToBlacklist('*.*.com'); a.b.com $browser.addHostnameToBlacklist('*.*.*.com'); a.b.c.com $browser.addHostnameToBlacklist('www.*.com'); www.a.com $browser.addHostnameToBlacklist('www.*.*.com'); www.a.b.com $browser.addHostnameToBlacklist('www.*.*.*.com'); www.a.b.c.com Options: Manage the browser instance These functions manage options for your browser instance such as cookies, timeouts and window size. Access these options through the $browser.manage() function. Function Return value $browser.manage().addCookie(name: string, value: string, opt_path: string, opt_domain: string, opt_isSecure: boolean, opt_expiry: number) Schedules a command to add a cookie. promise $browser.manage().deleteAllCookies() Schedules a command to delete all cookies visible to the current page. promise $browser.manage().deleteCookie(name: string) Schedules a command to delete the cookie with the given name. This command is a no-op if there is no cookie with the given name visible to the current page. promise $browser.manage().getCookie(name: string) Schedules a command to retrieve the cookie with the given name. Returns null if there is no such cookie. The cookie will be returned as a JSON object as described by the WebDriver wire protocol. promise $browser.manage().getCookies() Schedules a command to retrieve all cookies visible to the current page. New Relic Syntheticcs returns each cookie as a JSON object as described by the WebDriver wire protocol. promise $browser.manage().timeouts().implicitlyWait(ms: number) Specifies the amount of time the driver should wait when searching for an element if it is not immediately present. Setting the wait timeout to 0 disables implicit waiting. Be careful increasing the wait timeout, as it will increase test run time, especially with slower location strategies like XPath. Default is 10 seconds. promise $browser.manage().timeouts().pageLoadTimeout(ms: number) Sets the amount of time to wait for a page load to complete before returning an error. If the timeout is negative, page loads may last up to 180 seconds. Default is 60 seconds. promise $browser.manage().timeouts().setScriptTimeout(ms: number) Sets the amount of time to wait, in milliseconds, for an asynchronous script to finish execution before returning an error. Default is 30 seconds. promise $browser.manage().window().getPosition() Retrieves the window's current position, relative to the top left corner of the screen. promise $browser.manage().window().getSize() Retrieves the window's current size. promise $browser.manage().window().maximize() Maximizes the current window. promise $browser.manage().window().setPosition(x: number, y: number) Repositions the current window. promise $browser.manage().window().setSize(width: number, height: number) Resizes the current window. promise Locators: Find page elements Locators are a collection of factory functions for creating locator instances. Locators find DOM elements, which can be passed to functions such as $browser.findElement or $browser.isElementPresent. Call them through $driver.By. Function Return value $driver.By.className(className: string) Locates an element that has a specific class name. The returned locator is equivalent to searching for elements with the CSS selector .clazz. locator $driver.By.css(cssName: string) Locates an element using a CSS selector. locator $driver.By.id(id: string) Locates an element by its ID. locator $driver.By.linkText(linkText: string) Locates link elements whose visible text matches the given string. locator $driver.By.js(js: string) Locates an element by evaluating a JavaScript expression. locator $driver.By.name(name: string) Locates elements whose name attribute has the given value. locator $driver.By.partialLinkText(partialLinkText: string) Locates link elements whose getText visible contains the given substring. locator $driver.By.tagName(tagName: string) Locates elements with a given tag name. The returned locator is equivalent to using the getElementsByTagName DOM function. locator $driver.By.xpath(xpath: string) Locates elements matching a XPath selector. locator WebElement: Interact with page elements When a function such as $browser.findElement or $browser.waitForAndFindElement returns a WebElement reference, these functions can be used to interact with that element. Using these, you can click on buttons, sent text to form inputs, and get attributes of elements to test. Function Return value click() Clicks on this element. void sendKeys(var_args: ?) Schedules a command to type a sequence on the DOM element represented by this instance. WebElement getTagName() Schedules a command to query for the tag/node name of this element. WebElement getCssValue(name: string) Schedules a command to query for the computed style of the element represented by this instance. If the element inherits the named style from its parent, the parent will be queried for its value. Where possible, color values will be converted to their hex representation (for example, #00ff00 instead of rgb(0, 255, 0)). promise getAttribute(name: string) Schedules a command to query for the value of the given attribute of the element. promise getText(name: string) Get the visible (not hidden by CSS) innerText of this element, including sub-elements, without any leading or trailing white space. promise getSize() Schedules a command to compute the size of this element's bounding box, in pixels. promise getLocation() Schedules a command to compute the location of this element, in page space. promise isEnabled() Schedules a command to query whether the DOM element represented by this instance is enabled, as dictated by the disabled attribute. promise isSelected() Schedules a command to query whether this element is selected. promise submit() Schedules a command to submit the form containing this element (or this element if it is a FORM element). This command is a no-op if the element is not contained in a form. promise clear() Schedules a command to clear the value of this element. promise isDisplayed() Schedules a command to test whether this element is currently displayed. promise getOuterHtml() Schedules a command to retrieve the outer HTML of this element. promise getInnerHtml() Schedules a command to retrieve the inner HTML of this element. promise ActionSequence: Link multiple actions Action sequences can create complex user interactions with your website. To create a new action sequence, use $browser.actions(). To link multiple actions together into a sequence, include perform() after each. This executes and then terminates individual sequences, including single-action sequences. The following table contains a list of available actions. For more information, see the WebDriver ActionSequence documentation. Function Return value click(opt_elementOrButton: ?, opt_button: ?) Clicks a mouse button. If an element is provided, the mouse will first be moved to the center of that element. This is equivalent to WebElement.click(). actionsequence doubleClick(opt_elementOrButton: ?, opt_button: ?) Double-clicks a mouse button. If an element is provided, the mouse will first be moved to the center of that element. actionsequence dragAndDrop(element: ?, location: ?) Convenience function for performing a \"drag and drop\" maneuver. The target element may be moved to the location of another element, or by an offset (in pixels). The location is an object with two properties x and y: {x: x_offset, y: y_offset}. actionsequence keyDown(key: ?) Performs a modifier key press. Must be one of ALT, CONTROL, SHIFT, COMMAND, or META. The modifier key is not released until keyUp() or sendKeys() is called. The key press will be targeted at the currently focused element. actionsequence keyUp(key: ?) Performs a modifier key release. The release is targeted at the currently focused element. actionsequence mouseDown(opt_elementOrButton: ?, opt_button: ?) Presses a mouse button. The mouse button will not be released until mouseUp is called, regardless of whether that call is made in this sequence or another. The behavior for out-of-order events (such as calling mouseDown() or click() when the button is already held down) is undefined. actionsequence mouseUp(opt_elementOrButton: ?, opt_button: ?) Releases a mouse button. Behavior is undefined for calling this function without a previous call to mouseDown(). actionsequence mouseMove(location: ?, offset: ?) Moves the mouse. The location to move to may be specified in terms of the mouse's current location, an offset relative to the top-left corner of an element, or an element (in which case the middle of the element is used). actionsequence perform() Executes this action sequence. promise sendKeys(args: ?) Simulates typing multiple keys. Each modifier key encountered in the sequence will not be released until it is encountered again. All key events will be targeted at the currently focused element. For a full list of supported non-alphanumeric keys, see the WebDriver enum key documentation. actionsequence Promises: Link actions into sequences You can also execute functions directly on promises. Synthetic monitoring is a native Node.js environment and uses standard Node.js promises. These functions evaluate the status of promises, cancel them, and more. In particular, you can create sequences of actions with the then() function and its siblings, thenFinally() and thenCatch(). For more information, see Sequence actions. Function Return value cancel(string: reason) Cancels the computation of this promise's value, rejecting the promise in the process. This method is a no-op if the promise has already been resolved. void isPending() Whether this promise's value is still being computed. boolean then(opt_callback: fn(T: ?), opt_errback: fn()) Registers listeners for when this instance is resolved. This is the basic function used to link synchronous actions in your script. promise thenFinally(callback: fn()) Registers a listener to invoke when this promise is resolved, regardless of whether the promise's value was successfully computed. promise thenCatch(callback: fn()) Registers a listener for when this promise is rejected. promise Navigate: Move through browser history The $browser.navigate() function exposes a number of functions that allow you to move backwards and forwards through your browser history, refresh your page and navigate to new pages. Function Return value back() Move back by one step in the browser's history. void forward() Move forward by one step in the browser's history. void refresh() Refresh the current page. void to(string: url) Load a new webpage in the current browser window. $browser.navigate().to() is equivalent to $browser.get(). void Conditions: Pause and wait for conditions Used with $browser.wait, until pauses your script execution until the condition is matched. For more information on explicit and implicit waits, see the WebDriver documentation. For .wait and .until usage examples, see Webdriver.wait examples. The following are available functions for $driver.until.Condition: Function Return value ableToSwitchToFrame(frame: ?) Creates a condition that will wait until the input driver is able to switch to the designated frame. The target frame may be specified as: A numeric index into window.frames for the current frame A webdriver.WebElement, which must reference a FRAME or IFRAME element on the current page A locator which may be used to first locate a FRAME or IFRAME on the current page before attempting to switch to it Upon successful resolution of this condition, the driver will be left focused on the new frame. condition alertIsPresent() Creates a condition that waits for an alert to be opened. Upon success, the returned promise will be fulfilled with the handle for the opened alert. condition elementIsDisabled(element: $driver.WebElement) Creates a condition that will wait for the given element to be disabled. condition elementIsEnabled(element: $driver.WebElement) Creates a condition that will wait for the given element to be enabled. condition elementIsNotVisible(element: $driver.WebElement) Creates a condition that will wait for the given element to be in the DOM, yet not visible to the user. condition elementIsVisible(element: $driver.WebElement) Creates a condition that will wait for the given element to become visible. condition elementIsSelected(element: $driver.WebElement) Creates a condition that will wait for the given element to be selected. condition elementLocated(element: $driver.Locator) Creates a condition that will loop until an element is found with the given locator. condition elementsLocated(element: $driver.Locator) Creates a condition that will loop until at least one element is found with the given locator. condition elementTextContains(element: $driver.WebElement, substr: string) Creates a condition that will wait for the given element's visible text to contain the given substring. condition elementTextIs(element: $driver.WebElement, text: string) Case sensitive. Creates a condition that will wait for the given element's visible text to match the given text exactly. condition elementTextMatches(element: $driver.WebElement, regex: string) Creates a condition that will wait for the given element's visible text to match a regular expression. condition stalenessOf(element: $driver.WebElement) Creates a condition that will wait for the given element to become stale. An element is considered stale once it is removed from the DOM, or a new page has loaded. condition titleContains(substr: string) Creates a condition that will wait for the current page's title to contain the given substring. condition titleIs(title: string) Creates a condition that will wait for the current page's title to match the given value. condition titleMatches(regex: string) Creates a condition that will wait for the current page's title to match the given regular expression. condition For more help Additional documentation resources include: Writing scripted browsers (how to build WebDriverJS scripts for multi-step monitoring) Scripted browser examples (example code for scripted browsers, including comments, with examples like searching a website and waiting for results to load)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.23534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>scripted</em> browser reference (<em>monitor</em> versions 0.4.x or lower)",
        "sections": "<em>Synthetic</em> <em>scripted</em> browser reference (<em>monitor</em> versions 0.4.x or lower)",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " APIs. This document describes the functions available for <em>synthetic</em> scripted browser <em>monitors</em> version 0.4.0 or lower. For the newest <em>monitor</em> documentation, see <em>monitor</em> version 0.5.0+ documentation. Other relevant documentation: For more on <em>synthetic</em> <em>scripting</em>, see Write scripted browsers. For example"
      },
      "id": "6045266428ccbc04a2336a71"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/monitor-produces-no-traffic": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-10-07T09:43:54Z",
      "updated_at": "2021-07-10T02:12:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a scripted browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.50073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-10-07T09:44:51Z",
      "updated_at": "2021-07-10T02:11:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple browser and scripted browser monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.50063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00565,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-10-07T09:43:54Z",
      "updated_at": "2021-07-10T02:12:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a scripted browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.500725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.65822,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/private-location-hmac-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-10-07T09:43:54Z",
      "updated_at": "2021-07-10T02:12:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a scripted browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.500725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-10-07T09:44:51Z",
      "updated_at": "2021-07-10T02:11:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple browser and scripted browser monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.50063,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-10-07T09:44:51Z",
      "updated_at": "2021-07-10T02:11:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple browser and scripted browser monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.500626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    },
    {
      "sections": [
        "Synthetic monitoring: Aggregate monitor metrics",
        "View synthetic monitoring SLA reports",
        "Understand SLA report metrics",
        "Use page functions",
        "Generate SLA values",
        "For more help"
      ],
      "title": "Synthetic monitoring: Aggregate monitor metrics",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Pages"
      ],
      "external_id": "bbead36a5b36d126243f0beb2d60e9ccf23763f5",
      "image": "https://docs.newrelic.com/static/d0dc46884c112568daf4e491098e1951/c1b63/sla-report.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/pages/synthetic-monitoring-aggregate-monitor-metrics/",
      "published_at": "2021-10-07T06:39:24Z",
      "updated_at": "2021-09-20T19:33:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View synthetic monitoring SLA reports To view your account-wide SLA report: Go to one.newrelic.com > Synthetics > SLA Report. Choose from reports aggregated by day, week, or month by selecting Daily, Weekly, or Monthly as appropriate. You can also view SLA reports for individual monitors: Go to one.newrelic.com > Synthetics > (select a monitor) > SLA. one.newrelic.com > Synthetics > SLA Report: Use SLA reports to understand your monitors' performance over time. Understand SLA report metrics Use SLA reports to view aggregated performance metrics for a single monitor, or for all your monitors from the account-wide SLA Reports page. SLA reports include the following metrics: Duration: The average duration across all monitor results. Uptime: The percentage of all monitor results that ended successfully. For example, Monitor A might check 50 times per day, and Monitor B might check 150 times per day. If Monitor A has 29 successes out of 50 and Monitor B has 148 successes out of 150, the Uptime would be 88.5: (29+148)/(50+150)=88.5 For individual SLA reports, the uptime score only includes the selected monitor. Apdex: The average Apdex across all monitors. Monitors have a default Apdex T of 7 seconds, but you can customize Apdex T for individual monitors by editing their settings. Apdex F, which defines a frustrating result, is always four times Apdex T. For more information about Apdex, see Apdex: Measuring user satisfaction. For individual SLA reports, the Apdex score only includes the selected monitor. % Satisfied: The percentage of monitor results which complete in a \"satisfying\" time. A satisfying time is defined as a monitor result that completes in Apdex T or less. % Toleration: The percentage of monitor results which complete in a \"tolerable\" time. A tolerable time is greater than Apdex T, but less than Apdex F (four times Apdex T). % Frustrated: The percentage of monitor results which complete in a \"frustrating\" time. A frustrating time is greater than Apdex F (four times Apdex T). The account-wide SLA report includes all monitor types (ping, simple browser, scripted browser, and API test). Use page functions SLA reports support the following features: If you want to... Do this... View the report in Excel or an external program Select Download this report as .csv to download a copy of your SLA data. Open the file in Excel, Google Drive, or another spreadsheet editor to analyze your data. Change your Apdex targets The default Apdex T for all monitors is 7 seconds. You can customize your Apdex T target for individual monitors by editing your monitor. Change the time frame Choose from daily, weekly, or monthly aggregation by selecting the appropriate tab. Make the report public Change the Public SLA setting to ON to allow non-authenticated users to view the report. Select Share Report to get the public URL to share. Generate SLA values The values in the SLA report are generated from Insights queries against the available synthetic monitoring data. You can easily recreate these values and modify the queries to meet your needs. This query returns the average duration, the apdex, and the uptime. Substitute your values for the variables highlighted and described below. SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod Copy Variable Value t: Supply the Apdex T that you would like to calculate your apdex against. The duration attribute in the SyntheticCheck event is stored in milliseconds, so an Apdex T value of 7 seconds should be included as 7000. timeperiod This is the period that you would like to calculate on. For a daily report, facet on dateOf(timestamp), for a weekly report facet on weekOf(timestamp) and for a monthly report facet on monthOf(timestamp). NRQL queries default to querying against the last hour of data. In order to widen the scope of your data you will need to include a SINCE clause at the end of your query. Example #1: Daily report for the last week To generate a daily report for the last week you would add SINCE 1 week ago: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET dateOf(timestamp) SINCE 1 week ago Copy Example #2: Report for a particular monitor To scope the results to a particular monitor you can edit the above query to include a specific monitor name: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName = 'mymonitorname' Copy Example #3: Report for multiple monitors To scope the results to a collection of monitors: SELECT average(duration), apdex(duration, t:), percentage(count(*), WHERE result='SUCCESS') FROM SyntheticCheck FACET timeperiod WHERE monitorName IN ('mymonitor1', 'mymonitor2', 'mymonitor3') Copy For more help Additional documentation resources include: Access your monitors (view your list of monitors, and view current summary statistics for each monitor) Add and edit monitors (edit your monitor settings to customize Apdex targets for individual monitors) APM SLA reports (SLA reporting for your APM application)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 115.65819,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "sections": "<em>Synthetic</em> <em>monitoring</em>: Aggregate <em>monitor</em> metrics",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Use SLA reports to view summary performance metrics across time or multiple monitors. Compare your current performance to historical metrics with daily, weekly, and monthly reporting. View <em>synthetic</em> <em>monitoring</em> SLA reports To view your account-wide SLA report: Go to one.newrelic.com &gt; <em>Synthetics</em>"
      },
      "id": "603ec399196a67e073a83d96"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/troubleshooting/troubleshoot-isolated-monitor-failures": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " is then dedicated to run a check associated with the <em>synthetic</em> <em>monitor</em> running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at &#x2F;tmp. The writable directory"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Simple, scripted, or scripted API (non-ping) errors",
        "Problem",
        "Solutions",
        "Simple or scripted browser errors",
        "Element A is not clickable at point (X, Y). Other element would receive the click: Element B",
        "Solution",
        "Tip",
        "Cause",
        "Error: element not visible",
        "Error: no such element: Unable to locate element: <LOCATOR>",
        "JobTimeoutError: Job timed-out after 180s",
        "NetworkError: Monitor produced no traffic",
        "ReferenceError: $network is not defined",
        "ScriptTimeoutError",
        "StaleElementReferenceError: element is not attached to the page document",
        "TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR>",
        "TimeoutError: Page load timed-out (unable to finish all network requests on time)",
        "TypeError: $browser.isElementPresent is not a function",
        "Scripted API monitor errors",
        "SyntaxError: Unexpected token <",
        "SyntaxError: Unexpected token u in JSON at position 0",
        "TypeError: Cannot read property 'statusCode' of undefined"
      ],
      "title": "Simple, scripted, or scripted API (non-ping) errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "cc45967d186d8847e1755948d22477ac3dd84e60",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/simple-scripted-or-scripted-api-non-ping-errors/",
      "published_at": "2021-10-07T09:43:54Z",
      "updated_at": "2021-07-10T02:12:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your New Relic's synthetic Simple, Scripted, or Scripted API (non-ping) monitor reported an error, but the application appears to have loaded correctly. For ping and simple monitor errors, see non-scripted monitor errors. Solutions Below are some of the most common non-ping monitor error messages. Simple or scripted browser errors Element A is not clickable at point (X, Y). Other element would receive the click: Element B Problem The synthetic script is attempting to .click() an element (Element A) at point (X,Y), but another element (Element B) is obscuring the target element. Solution Set a custom wait time, allowing time for a specific condition to be met. In this case, until the loading animation is no longer visible: .then(function() { return $browser.wait($driver.until.elementIsNotVisible($browser.findElement($driver.By.id('LOADING'))), 10000); }) Copy Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Tip This will not correct .click() issues caused by sticky headers or footers. In these instances, you may need to scroll manually to bring the target into view. Cause This happens if the target element, at the time of the .click() function, is obscured by: A loading overlay, modal, or pop-up An animation that reveals the target element A sticky header or footer Error: element not visible Problem The targeted element is not visible to the Selenium WebDriver. Solution Verify that the targeted element does not have the CSS properties of display: none or visibility: hidden applied. Cause Any element that has a CSS property of display: none or visibility: hidden will not be found by the Selenium WebDriver, as the script will only look for elements that are actually visible to a user. Error: no such element: Unable to locate element: <LOCATOR> Problem The Selenium WebDriver was unable to find this element in the visible DOM. Solution To resolve this problem: Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath where possible as it is rigidly tied to the page’s DOM structure, and can easily become out-of-date when there are updates on the page. If element is in an iframe, use $browser.switchTo().frame(<index or element reference>. Tip See the Selenium documentation for more information on switchTo() and TargetLocator() functions. Cause Common reasons for this error include: The targeted element is unable to be located by functions such as: $browser.findElement(locator: $driver.Locator) or $browser.waitForAndFindElement(locator: $driver.Locator [ , timeout: number This may be due to a timing issue. For example, the WebDriver is attempting to locate the element before the page has been loaded. Element is in an iframe, which is a separate document context. JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by synthetic monitoring, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the monitor's settings. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. StaleElementReferenceError: element is not attached to the page document Problem The target page has loaded, but there was a change to an element between the execution of an element locator and an action being executed on the element. Solution Set your scripted browser to wait until the page is settled before performing a findElement() action. This can be accomplished by setting a custom wait time, using the $browser.wait(fn, timeout) function prior to the findElement call, to wait for a condition that indicates a settled page state. This will make it less likely for DOM manipulation to cause a reference to go stale. Alternatively, you can set a custom sleep delay using $browser.sleep(sleeptime_ms), stalling script execution for a specified amount of time. As this is a fixed amount of wait-time, which does not account for increased network latency or degraded site performance, we recommend using the .wait() function instead. Cause This error typically happens when the script attempts to .click() an element after using either the findElement() or waitForAndFindElement() function. If the DOM has changed between when the element locator was generated and the action was executed against the element, this error will occur because the actual element has changed. For example: the findElement() function is used to generate an element reference while the page’s script is actively manipulating the DOM. The DOM is then changed, causing the previously generated reference to become stale. The now out-of-date reference is used in an attempt to perform a .click() action, resulting in this monitor failure. Tip For more information, see the Selenium documentation on Stale Element Reference Exceptions. TaskTimedOut: task timed-out waiting for element to be located using: <LOCATOR> Problem The waitForAndFindElement(<locator>, <timeout>) function failed to locate an element within the provided timeout. Solution Confirm that the element locator being used for the target element is accurate. Avoid using By.XPath() where possible, as it is rigidly tied to the page’s DOM structure and can easily become out-of-date when there are updates on the page. Cause The target element did not exist on the page when the waitForAndFindElement(<locator>, <timeout>) function was called. This may be caused by the target page not being in the expected state. Common reasons for this error include: There is a legitimate issue with the target site. The element locator being used is incorrect. The target site has changed, requiring the revision of the Synthetics script. The previous action in the script did not successfully complete, causing the page to be in an unexpected state when the subsequent waitForAndFindElement() call was initiated. TimeoutError: Page load timed-out (unable to finish all network requests on time) Problem The target page loaded successfully, but returned the error: TimeoutError: Page load timed-out (unable to finish all network requests on time) Solution If the failures began suddenly, investigate any requests that could be blocking or delaying the page load event. If you are unsure which request is causing the error, use the timeline view to identify any long running HTTP requests. If the page is frequently unable to fully load within the current timeout, set a custom page load timeout using the $browser.manage().timeouts().pageLoadTimeout(ms: number) function. Cause The target page loaded successfully, but the page load event was not fired within the page load timeout set in the .pageLoadTimeout() function. There are a number of reasons you could see this error message, including: A blocked resource request on the page held up the page load. A resource request processed slower than normal due to an underlying network issue. A dependent resource on the page blocked the iframe load event. TypeError: $browser.isElementPresent is not a function Problem The function isElementPresent(), used by Synthetics monitors with a runtime >= 0.5.0, has been deprecated in Selenium 3. Solution To continue to use this function after depreciation you will need to create a custom version of this function, such as: return $browser.findElements(ele).then(function(found) { return found.length > 0; }); } Copy Example usage, which would return true: $browser .get(\"https://www.newrelic.com\") .then(function() { return isElementPresent($driver.By.id(\"nav_signup\")); }) .then(function(found) { return console.log(found); }); Copy Cause This can occur when attempting to use a scripted browser monitor script from an older monitor ( < = 0.4.1 runtime) with a newer monitor ( >= 0.5.0) runtime. Scripted API monitor errors JobTimeoutError: Job timed-out after 180s Problem The scripted monitor run reached the 180 second non-configurable timeout threshold, and the run was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assign the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. NetworkError: Monitor produced no traffic Problem The API test or scripted browser monitor appears to be running but is returning this error. Solution Ensure that $http.get() or $browser.get() are being called appropriately and are generating traffic. For Scripted API monitors, if you are using a request option to spin up an un-instrumented HTTP agent under the hood, specify one of our instrumented HTTP agents using either of the agent request options below: $globalAgents.http $globalAgents.https Example: var options = { uri: 'https://www.newrelic.com', agent: $globalAgents.https, agentOptions: { 'rejectUnauthorized': false }, strictSSL: false }; function callback(err, res, body) { ... }; $http.get(options, callback); Copy Cause This occurs in scripted monitor runs when the HTTP client ($http in scripted api monitors) or Chrome browser ($browser in scripted browser monitors) is not used to generate HTTP traffic. In some cases, certain request options in API monitors may force a new HTTP agent, one that is not instrumented by Synthetics, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting monitor proxies is not available for that monitor’s runtime. Solution If your monitor was created before the 0.4.0 runtime release, create a new monitor to take advantage of the latest runtime. Your monitor’s current runtime version is shown at the top of the Monitor Settings page. For more information, see Scripted monitor version runtime environments. Cause This error occurs when attempting to use $network on a monitor with a runtime at or below 0.2.2. Proxying monitor traffic was introduced in monitor runtime version 0.4.0, causing this method to be evaluated as undefined on earlier monitor runtimes. ScriptTimeoutError Problem This error indicates that the job has reached the Docker container timeout threshold, and the script was terminated. Solution If this is a frequent error, consider breaking up the scripted tasks into a separate scripted monitors. If it appears that a specific task is causing the job to wait an unacceptable amount of time, consider changing the method by which you’re accomplishing that task. For example, changing $browser.findElement(locator: $driver.Locator) to $browser.waitForAndFindElement(locator: $driver.Locator [, timeout: number) would assigned the task its own configurable timeout. If you have multiple steps where the $browser.waitForAndFindElement(locator, timeout) function is called, ensure that the the sum of the provided timeouts to these steps does not exceed 180 seconds. If you’re finding it difficult to accomplish this, then that is a sign that the monitor should probably be broken up into separate monitor scripts. Cause All synthetic scripted monitors have a non-configurable maximum global 180s timeout for running a script. If a script has not completed after 180 seconds, the job is terminated. If this happens consistently it could be a sign of a script that is taking too long to complete, or that the job is waiting an extended period of time while attempting to perform a scripted task. SyntaxError: Unexpected token < Problem JSON.parse() was passed a string that begins with the < character and is likely HTML, instead of JSON. Solution Ensure the target endpoint is returning the expected response body. You can do this by logging the response body in the callback, before attempting to parse. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(body); // Log HTML response body, don't parse as JSON }); Copy Depending on the target API endpoint, you may need to include specific request headers to ensure that JSON is returned. Cause The script is attempting to use JSON.parse() on a response body after a request is made and is expecting the endpoint to return JSON, but HTML was returned instead. SyntaxError: Unexpected token u in JSON at position 0 Problem JSON.parse() was passed an undefined parameter, but expected a JSON string. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } var bodyJson = JSON.parse(body); console.log(bodyJson); // Log response body }); Copy Cause This can occur in Scripted API monitors when a performing an API request, then attempting to parse the request response within the callback function. The response body is passed to JSON.parse() without checking if the response body is undefined first. An undefined response body is often caused by a request error. If there is no error handling to prevent code that parses the response body, this monitor failure will occur. TypeError: Cannot read property 'statusCode' of undefined Problem The response object (and thus response.statusCode) in an API request callback is undefined. Solution Troubleshoot the cause of the request error. Details on what is causing request errors can be found in the error object passed to the request callback function. Example: $http.get('http://www.newrelic.com', function(error, response, body) { if (error) { throw new Error(error); } console.log(response.statusCode); }); Copy Cause This error occurs when there was an error completing the API request (for example, unable to reach server, unable to resolve DNS). In these instances, the request was not completed so the response object in the callback function arguments is undefined. If there is no error handling to prevent code that checks response status code, this monitor failure will occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.500725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "NetworkError: <em>Monitor</em> produced no traffic",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " that is not instrumented by <em>synthetic</em> <em>monitoring</em>, to be used to collect HTTP traffic. ReferenceError: $network is not defined Problem The $network object used for setting <em>monitor</em> proxies is not available for that <em>monitor</em>’s runtime. Solution If your <em>monitor</em> was created before the 0.4.0 runtime release"
      },
      "id": "603ea832196a67c147a83de7"
    },
    {
      "sections": [
        "Non-scripted monitor errors",
        "Problem",
        "Solutions",
        "ERROR: Job timed out after 65 seconds",
        "Solution",
        "Cause",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out",
        "NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused",
        "HTTPError: Server replied with HTTP XXX response code",
        "SSLVerificationError: (ERROR)",
        "ResponseValidationError: Response did not contain the expected string",
        "NetworkError: Read timed out",
        "NetworkError: Socket is closed",
        "NetworkError: No route to host (Host unreachable)",
        "HTTPError: Server sent us too many redirects (20)",
        "NetworkError: DNS resolution failed for host: (HOST)",
        "BlockedRequestError: (URL)"
      ],
      "title": "Non-scripted monitor errors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Troubleshooting"
      ],
      "external_id": "156625f0d6481bdcabd07d6101ffbd3db2d184c3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/troubleshooting/non-scripted-monitor-errors/",
      "published_at": "2021-10-07T09:44:51Z",
      "updated_at": "2021-07-10T02:11:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Problem Your synthetic ping or simple monitor reported one of these errors. For scripted monitor errors, see non-ping errors. Solutions These are some of the most common non-scripted monitor error messages. ERROR: Job timed out after 65 seconds Problem Your ping timed out after 65 seconds, the non-configurable check duration time limit. Solution The 65 second time limit is non-configurable. Pings exceeding 65 seconds may be a result of latency from the target server. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause Ping monitors will first perform a HEAD request. If this request fails for any reason, or reaches the 30 second HTTP connect timeout for ping monitors, then a subsequent GET request is performed. This error happens when both the HEAD and GET request exceed 30 seconds, usually due to server latency. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: connect timed out Problem HTTP requests during the check exceeded the non-configurable 30 second TCP connection timeout limit. Solution The 30 second time limit is non-configurable. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This failure indicates an issue reaching your site from the location where the synthetic's check was performed. NetworkError: Connect to (HOST) [HOST./IP ADDRESS] failed: Connection refused Problem The target server refused connection from the synthetic ping monitor HTTP client. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause The target server is likely blocking or rate-limiting synthetic's traffic. HTTPError: Server replied with HTTP XXX response code Problem The synthetic monitor encountered an unsuccessful status code, usually a response code that is not in the 2XX/3XX range. Solution Check your server-side logging to determine why the response code was sent. To assist with identifying synthetic's traffic on your server, all synthetic monitoring traffic includes an X-Abuse-Info HTTP request header and we provide a list of origin IP addresses for all synthetic monitoring traffic. Cause The cause depends on the response code sent. SSLVerificationError: (ERROR) Problem Your monitor returns an SSLVerificationError. Solution Go to one.newrelic.com > Synthetics > (select a monitor) > Settings > General > Advanced options, then disable the Verify SSL check. Cause SSLVerificationError failures are a result of the optional Verify SSL check failing against the target host. SSL verification failed during execution for domain <TARGET_URL> failures indicate that the URL provided is not HTTPS or does not redirect to an HTTPS endpoint. SSLVerificationError: (<ERROR CODE>) <ERROR> errors are retrieved directly from the openssl command and often indicate a legitimate SSL configuration issue on the target site. ResponseValidationError: Response did not contain the expected string Problem The string value included in the synthetic monitor’s optional Response Validation field was not found in the target server’s response. Solution To troubleshoot: Check the failed results timeline to ensure the endpoint where the response validation text is expected, is the last endpoint being requested. Attempt a curl request against the target endpoint to see if the expected response body is returned. Ensure your endpoint doesn't have policies that will return different content depending on header content or request activity. If so, use a scripted browser to spoof a specific header string. If you’re using a simple browser to monitor a page whose content is loaded via JavaScript after the page’s load event is fired, consider using a scripted browser monitor instead. You can program scripted browsers to wait for specific elements to appear on a page before interacting with them. Cause The cause depends on the monitor type: Ping monitors: The string value must be present in the first 1MB (10^6 bytes) of the response body. Simple browsers: The string must be visible on the page when the page’s load event is fired. NetworkError: Read timed out Problem The monitor client was able to establish an HTTP connection to the target site, but then exceeded the 30 second read timeout while waiting for a response. Solution To troubleshoot: Investigate the target server's performance during the time period the issue was observed. Investigate potential issues along the network path between our servers and yours, as this may indicate an issue experienced by real users of your application. Cause This indicates an issue with the target server responding to the synthetic monitor HTTP client, or network latency between your server and ours. NetworkError: Socket is closed Problem The synthetic monitor's HTTP client was able to establish a connection to the target server. The target server then closed the connection without a response. Solution Add our synthetic monitoring IP addresses to your allow list, to ensure traffic from our synthetic monitors can reach the target server. Cause Edge infrastructure sometimes implements measures such as this for an application endpoint to handle traffic that violates behavior policies like rate limiting. NetworkError: No route to host (Host unreachable) Problem The synthetic monitoring client was able to resolve the target host’s IP address, but it was unable to find a route to the target host to establish a connection. Solution If the failure is occurring on a public synthetic monitoring's location, ensure that the DNS records for this host are resolving to a reachable IP address. If the failure is occurring on a synthetic monitoring's private location, ensure the private minion’s network configuration is properly configured and that the target hostname is resolvable and reachable via the private minion virtual command line interface. Cause This occurs when the target hostname resolves to a non-routable IP address per RFC 1918. HTTPError: Server sent us too many redirects (20) Problem The synthetic monitor client was redirected (observing 301 or 302 response codes) 20 times when performing a request to the target endpoint. Solution Ensure that the target endpoint redirects client requests less than 20 times. If this is only occurring within New Relic, recreate the issue outside New Relic to troubleshoot the root cause. Use a similar client to perform requests against the target endpoint: Ping monitors: HTTP client similar to curl. Simple browser and scripted browser monitors: Chrome 60 instance in an Ubuntu 14.04.5 VM. Scripted API monitors: Use the request HTTP client for Node.js. Cause This occurs when the monitored endpoint effectively serves a redirect loop to the synthetic monitor: The initial response redirects to another URL which redirects to another URL, etc. NetworkError: DNS resolution failed for host: (HOST) Problem The target hostname was not able to be resolved by the synthetic monitor’s HTTP client. Solution Private synthetic monitoring's locations: Confirm that the network configuration for the minion is correct. If the target hostname is an internal one, ensure that the minion is using your network’s internal DNS service that is able to resolve the host. The containerized private minion and the runner containers it spawns on host (to run non-ping checks) should inherit DNS configuration from the host /etc/resolv.conf. Docker: Network arguments like –dns or -network used in the Docker run command on the containerized private minion will only be used by the minion container but not the runner containers. If the DNS points to the loopback interface such as 127.0.0.1, define a DNS config at the Docker daemon level, or use a tool like dnsmasq to make sure the runner will forward DNS requests on the Docker bridge interface. Public synthetic monitoring locations: Ensure that the target site’s DNS record can be looked up by public DNS services such as Google public DNS and Amazon-provided DNS. Cause Our public synthetic monitoring locations use Google public DNS and Amazon-provided DNS. If DNS resolution of the target host is failing on our public synthetic monitoring locations, this is likely an issue other users are facing. If you are seeing DNS resolution related monitor failures on a synthetic monitoring private location, this is often caused by the private minion for that location having an invalid network configuration. BlockedRequestError: (URL) Problem The target domain is blocked by synthetic monitoring. Solution To unblock domains, you must use a scripted browser monitor and manually make calls in your script. Cause Synthetic monitoring specifically exclude scripts for popular analytics services such as Google Analytics. This ensures your analytics tools continue to receive accurate data, even with thousands of monitors checking your website each month.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 116.500626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Non-scripted <em>monitor</em> errors",
        "sections": "Non-scripted <em>monitor</em> errors",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " ADDRESS] failed: Connection refused Problem The target server refused connection from the <em>synthetic</em> ping <em>monitor</em> HTTP client. Solution Add our <em>synthetic</em> <em>monitoring</em> IP addresses to your allow list, to ensure traffic from our <em>synthetic</em> monitors can reach the target server. Cause The target server"
      },
      "id": "603eb369e7b9d20e922a07d6"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0054,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.01262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-10-07T04:44:53Z",
      "updated_at": "2021-07-21T06:16:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). You can set secure credentials in New Relic One or with the API. Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. Follow the UI instructions to add, edit, or delete a secure credential, then save any additions or changes you make. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials user interface shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.76787,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", the Secure credentials user interface shows how many scripted <em>monitors</em> <em>use</em> that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the script When <em>using</em> the <em>Synthetics</em> UI editor to create scripted browsers or API test"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/alerts-synthetic-monitoring": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.4106,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.01262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/collect-synthetic-transaction-traces": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.01262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/handle-sites-authentication": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.01262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/manage-monitor-runtimes": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.01262,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.0051,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41058,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Store secure credentials for scripted browsers and API tests",
        "Requirements and limits",
        "Add or update secure credentials",
        "Update the script",
        "Security for secure credentials",
        "Redacted information"
      ],
      "title": "Store secure credentials for scripted browsers and API tests",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "ee8bec412a7cb3223e6164d653ca9fc9307e672a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/",
      "published_at": "2021-10-07T04:44:53Z",
      "updated_at": "2021-07-21T06:16:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use secure credentials with synthetic monitoring to store critical information, such as passwords, API keys, usernames, etc. This prevents scripted monitor users from viewing, updating, or deleting these values unless they have explicit permissions in New Relic. The credentials are securely stored using AES-GCM 256-bit encryption at rest with keys managed by Amazon AWS Key Management Service (KMS). You can set secure credentials in New Relic One or with the API. Requirements and limits Before using secure credentials, review these requirements and guidelines: Secure credentials Comments Applicable monitors The secure credentials feature is available only for synthetic scripted browsers and API test monitors. Permissions Account administrators can control which users can create, view, or delete secure credentials by managing users' permissions. Limit You can have a maximum of 1,000 secure credentials. Add or update secure credentials You can add or update secure credentials using the UI or the Synthetics REST API. To add, view, edit, or delete a secure credential for a scripted browser or API test monitor from the UI: Go to one.newrelic.com > Synthetics > Secure credentials. Follow the UI instructions to add, edit, or delete a secure credential, then save any additions or changes you make. Tips for creating the Key: choose a username or other meaningful key name to identify the secure credential. Use alphanumeric or underscore _ characters. Key names must be UPPERCASE. Tips for creating the Value: Use any combination of alphanumeric or special characters. 10000 characters maximum. This field is not accessible via the API. Associate the secure credential with a scripted browser or API test by editing the script. After you add the secure credential to the script, the Secure credentials user interface shows how many scripted monitors use that credential. This number is approximate and only updates after a monitor with a secure credential has actually been run. Update the script When using the Synthetics UI editor to create scripted browsers or API test monitors, follow these guidelines: Script Guidelines Format Anywhere in the script where you reference the secure credential, it is accessed via the reserved New Relic $secure JavaScript object with dot notation. For example, $secure.MY_SECURE_CREDENTIAL. Properties on $secure are not accessible through bracket notation. Existing credentials To view or select from a list of available secure credentials: Type $secure. OR Select from the dropdown in the editor UI. Validation To validate the secure credential, follow standard procedures to test the script or write an API test. Any changes to the secure credential's value will automatically take effect across all monitors that use it. You do not need to also update the script. Exception: If you update the script and jobs are already processing, the secure credential change will not take effect until the next time the job begins. Security for secure credentials To ensure the security of your secure credentials, New Relic scrubs the secure value out of all data that goes to results in synthetic monitoring data and alerts. New Relic employees cannot access secure credential values and must be added to the account to be able to view secure credentials. Example A secure credential is named PASSWORD and the value is Pass123!. New Relic replaces Pass123! with _SECURECREDENTIAL_ For example, a script includes: $browser.get(\"https://example.com/\" + $secure.PASSWORD) Copy The script results will show that New Relic Synthetics went to https://example.com/_SECURECREDENTIAL_, even though it actually went to https://example.com/Pass123!. This ensures the value of the secure credential will not appear in the results. Redacted information We currently redact the following from the results of your monitor: The exact values of your secure credentials Any percent-encoded values of your secure credentials",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.76785,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": ", the Secure credentials user interface shows how many scripted <em>monitors</em> <em>use</em> that credential. This number is approximate and only updates after a <em>monitor</em> with a secure credential has actually been run. Update the script When <em>using</em> the <em>Synthetics</em> UI editor to create scripted browsers or API test"
      },
      "id": "60452772196a67195c960f3b"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/recheck-failed-monitors": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.005,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41057,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.0126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.0126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/synthetic-monitoring-response-codes": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.0126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-ping-monitor-results": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00485,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.0126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/synthetics/synthetic-monitoring/using-monitors/view-simple-scripted-monitor-results": [
    {
      "sections": [
        "Install containerized private minions (CPMs)",
        "General private minion features",
        "Kubernetes-specific features",
        "System requirements and compatibility",
        "Caution",
        "Docker container system environment requirements",
        "Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher)",
        "Private location key",
        "Sandboxing and Docker dependencies",
        "Docker dependencies",
        "Install and update CPM versions",
        "Start the CPM",
        "Docker start procedure",
        "Kubernetes start procedure",
        "Stop or delete the CPM",
        "Docker stop procedure",
        "Kubernetes delete procedure",
        "Show help and examples",
        "Show license information",
        "Configure CPM",
        "Networks",
        "Security, sandboxing, and running as non-root",
        "Run as non-root user for Docker",
        "Docker image repository",
        "Additional considerations for CPM connection"
      ],
      "title": "Install containerized private minions (CPMs)",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Private locations"
      ],
      "external_id": "c3d19e2e7c99b15e05add0810342d1464e68b2f1",
      "image": "https://docs.newrelic.com/static/img-integration-k8-f16fcb798b1f0f56aa1be798a28c2b0b.png",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/private-locations/install-containerized-private-minions-cpms/",
      "published_at": "2021-10-07T06:55:16Z",
      "updated_at": "2021-10-07T06:55:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use New Relic's containerized private minions (CPM). These are Docker container-based private minions that accept and execute synthetic monitors against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system environment. The CPM will auto-detect its environment to select the appropriate operating mode. General private minion features Because the CPM operates as a container instead of a virtual machine, it delivers many features: Easy to install, start, and update Runs on: Linux macOS Windows Enhanced security and support for non-root user execution Ability to leverage a Docker container as a sandbox environment Customizable monitor check timeout Custom provided modules for scripted monitor types Kubernetes-specific features Also, the CPM delivers the following features in a Kubernetes environment: Integrates with the Kubernetes API to delegate runtime lifecycle management to Kubernetes Does not require privileged access to the Docker socket Supports hosted and on-premise Kubernetes clusters Supports various container engines such as Docker and Containerd Deployable via Helm charts as well as configuration YAMLs Allows job (ping vs. non-ping checks) based resource allocation for optimum resource management Observability offered via the New Relic One Kubernetes cluster explorer System requirements and compatibility To host CPMs, your system must meet the minimum requirements for the chosen system environment. Caution Do not modify any CPM files. New Relic is not liable for any modifications you make. For more information, contact your account representative or a New Relic technical sales rep. Docker container system environment requirements Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Memory 2.5 GiB of RAM per CPU core (dedicated) Disk space A minimum of 10 GB per host Docker version Docker 17.12.1-ce or higher Private location key You must have a private location key Caution The Docker CPM is not designed for use with container orchestrators like AWS ECS, Docker Swarm, Apache Mesos, Azure Container Instances, etc. Running the Docker CPM in a container orchestrator will result in unexpected issues because it is itself a container orchestrator. If you're using container orchestration, see our Kubernetes CPM requirements. Kubernetes container orchestration system environment requirements (CPM v3.0.0 or higher) Compatibility for Requirements Operating system Linux kernel: 3.10 or higher macOS: 10.11 or higher Windows: Windows 10 64-bit or higher Processor A modern, multi-core CPU Minion pod CPU (vCPU/Core): 0.5 up to 0.75 Memory: 800 Mi up to 1.6 Gi Resources allocated to a Minion pod are user configurable. Runner pod CPU (vCPU/Core): 0.5 up to 1 Memory: 1.25 Gi up to 3 Gi For a scripted API check, 1.25 Gi will be requested with a limit of 2.5 Gi. For a simple browser or scripted browser check, 2 Gi will be requested with a limit of 3 Gi. Additional considerations: Resources allocated to a runner pod are not user configurable. The maximum limit-request resource ratio for both CPU and memory is 2. Disk space Persistent volume (PV) of at least 10 Gi in size Note that if a ReadWriteOnce (RWO) PV is provided to the minion, an implicit node affinity will be established to ensure the minion and the runner containers are scheduled on the same node. This is required to allow the minion and the associated runners access to the PV, as an RWO PV can be accessed only by a single node in the cluster. Kubernetes version We recommend that your Kubernetes cluster supports Kubernetes v1.15. Caution We have identified a compatibility issue with Kubernetes v1.21+. A workaround is available by disabling the BoundServiceAccountTokenVolume feature gate on the cluster. Private location key You must have a private location key Helm Follow installation instructions for Helm v3 for your OS. Kubectl Follow installation instructions for Kubectl for your OS. To view versions, dependencies, default values for how many runner pods start with each minion, the Persistent volume access mode, and more, please see Show help and examples below. Private location key Before launching CPMs, you must have a private location key. Your CPM uses the key to authenticate against New Relic and run monitors associated with that private location. To find the key for existing private location: Go to one.newrelic.com > Synthetics > Private locations. In the Private locations index, locate the private location you want your CPM to be assigned to. Note the key associated with the private location with the key icon. Sandboxing and Docker dependencies Sandboxing and Docker dependencies are applicable to the CPM in a Docker container system environment. Docker dependencies The CPM runs in Docker and is able to leverage Docker as a sandboxing technology. This ensures complete isolation of the monitor execution, which improves security, reliability, and repeatability. Every time a scripted or browser monitor is executed, the CPM creates a brand new Docker container to run it in called a runner. The minion container needs to be configured to communicate with the Docker engine in order to spawn additional runner containers. Each spawned container is then dedicated to run a check associated with the synthetic monitor running on the private location the minion container is associated with. There are two crucial dependencies at launch. To enable sandboxing, ensure that: Your writable and executable directory is mounted at /tmp. The writable directory can be any directory you want the CPM to write into, but New Relic recommends the system's own /tmp to make things easy. Your writable Docker UNIX socket is mounted at /var/run/docker.sock or DOCKER_HOST environment variable. For more information, see Docker's Daemon socket option. Caution Core count on the host determines how many runner containers the CPM can run concurrently on the host. Since memory requirements are scaled to the expected count of runner containers, we recommend not running multiple CPMs on the same host to avoid resource contention. For additional information on sandboxing and running as a root or non-root user, see Security, sandboxing, and running as non-root. Install and update CPM versions Both installing and updating the CPM use the same command to pull the latest Docker image from the Quay.io repository where the CPM Docker image is hosted. Go to quay.io/repository/newrelic/synthetics-minion for a list of all the releases. CPM images are also hosted on Docker Hub. Go to hub.docker.com/r/newrelic/synthetics-minion/tags for a list of all the releases. Start the CPM To start the CPM, follow the applicable Docker or Kubernetes instructions. Docker start procedure Locate your private location key. Ensure you've enabled Docker dependencies for sandboxing and installed CPM on your system. Run the appropriate script for your system. Tailor the common defaults for /tmp and /var/run/docker.sock in the following examples to match your system. Linux/macOS: docker run \\ --name YOUR_CONTAINER_NAME \\ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" \\ -v /tmp:/tmp:rw \\ -v /var/run/docker.sock:/var/run/docker.sock:rw \\ -d \\ --restart unless-stopped \\ quay.io/newrelic/synthetics-minion:latest Copy Windows: docker run ^ --name YOUR_CONTAINER_NAME ^ -e \"MINION_PRIVATE_LOCATION_KEY=YOUR_PRIVATE_LOCATION_KEY\" ^ -v /tmp:/tmp:rw ^ -v /var/run/docker.sock:/var/run/docker.sock:rw ^ -d ^ --restart unless-stopped ^ quay.io/newrelic/synthetics-minion:latest Copy View the logs for your minion container: docker logs --follow YOUR_CONTAINER_NAME Copy When a message similar to Synthetics Minion is ready and servicing location YOUR_PRIVATE_LOCATION_LABEL appears, your CPM is up and ready to run monitors assigned to that location. Kubernetes start procedure Locate your private location key. Set up the a namespace for the CPM in your Kubernetes cluster: kubectl create namespace YOUR_NAMESPACE Copy Copy the Helm charts from the New Relic Helm repo. If you are copying the charts for the first time: helm repo add YOUR_REPO_NAME https://helm-charts.newrelic.com Copy If you previously copied the Helm charts from the New Relic Helm repo, then get the latest: helm repo update Copy Install the CPM with the following Helm command: For a fresh installation of the CPM: helm install YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy To update an existing CPM installation: helm upgrade YOUR_CPM_NAME YOUR_REPO_NAME/synthetics-minion -n YOUR_NAMESPACE --set synthetics.privateLocationKey=YOUR_PRIVATE_LOCATION_KEY Copy Check if the minion pod is up and running: kubectl get -n YOUR_NAMESPACE pods Copy Once the status attribute of each pod is shown as running, your CPM is up and ready to run monitors assigned to your private location. Stop or delete the CPM On a Docker container system environment, use the Docker stop procedure to stop the CPM from running. On a Kubernetes container orchestration system environment, use the Kubernetes delete procedure to stop the CPM from running. Docker stop procedure You can stop a Docker container either by the container name, or the container ID. Container name stop for Linux, macOS, and Windows: docker stop YOUR_CONTAINER_NAME docker rm YOUR_CONTAINER_NAME Copy Container ID stop for Linux/macOS: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. CONTAINER_ID=$(docker ps -aqf name=YOUR_CONTAINER_NAME) docker stop $CONTAINER_ID docker rm $CONTAINER_ID Copy Container ID stop for Windows: In the examples the container is stopped and removed. To only stop the container, omit docker rm $CONTAINER_ID. FOR /F \"tokens=*\" %%CID IN ('docker ps -aqf name=YOUR_CONTAINER_NAME') do (SET CONTAINER_ID=%%CID) docker stop %CONTAINER_ID% docker rm %CONTAINER_ID% Copy Kubernetes delete procedure Get the MINION_POD_INSTALLATION_NAME of the minion pod you want to delete: helm list -n YOUR_NAMESPACE Copy Delete the minion pod: helm uninstall -n YOUR_NAMESPACE MINION_POD_INSTALLATION_NAME Copy Delete the namespace set up for the CPM in your Kubernetes cluster: kubectl delete namespace YOUR_NAMESPACE Copy Show help and examples Use these options as applicable: To get a list of the most commonly used run options directly in the command line interface, run the show help command. To show CPM usage examples as well as the list of all the available run options, run this command: docker run quay.io/newrelic/synthetics-minion:latest help Copy To keep track of Docker logs and verify the health of your monitors, see Containerized private minion (CPM) maintenance and monitoring. For a CPM in the Kubernetes container orchestration system environment, the following Helm show commands can be used to view the chart.yaml and the values.yaml, respectively: helm show chart YOUR_REPO_NAME/synthetics-minion Copy helm show values YOUR_REPO_NAME/synthetics-minion Copy Show license information To show the licensing information for the open source software that we use in the CPM, run the LICENSE command. Run this command to view license information for CPM versions 2.2.27 or higher: docker run quay.io/newrelic/synthetics-minion:latest LICENSE Copy Some of our open-source software is listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Our license information is also available in the our licenses documentation. Configure CPM You can configure the containerized private minion with custom npm modules, preserve data between launches, use environment variables, and more. For more information, see CPM configuration. Networks For both Docker and Kubernetes, the CPM and its runner containers will inherit network settings from the host. For an example of this on a Docker container system environment, see the Docker site. A new bridge network is created for each runner container. This means networking command options like --network and --dns passed to the CPM container at launch (such as through Docker run commands on a Docker container system environment) are not inherited or used by the runner containers. When these networks are created, they pull from the default IP address pool configured for daemon. For an example of this on a Docker container system environment, see the Docker site. Typically, the runner network is removed after the check is completed. However, if a CPM exits while a check is still running, or exits in another unexpected circumstance, these networks may get orphaned. This can potentially use up IP address space that is available to the Docker daemon. If this happens, you may see INTERNAL ENGINE ERROR code: 31 entries in your CPM logging when trying to create a new runner container. To clean these up in Docker container system environments only, run docker network prune. Security, sandboxing, and running as non-root By default, the software running inside a CPM is executed with root user privileges. This is suitable for most scenarios, as the execution is sandboxed. In a Docker container system environment: To change the default AppArmor profile used by containers that CPM spawns to run monitors, see the environment variable MINION_RUNNER_APPARMOR (CPM version 3.0.3 or higher) or MINION_DOCKER_RUNNER_APPARMOR (CPM version up to v3.0.2). To run the CPM as a non-root user, additional steps are required: Run as non-root user for Docker For more information, see Docker's official documentation about security and AppArmor security profiles. If your environment requires you to run the CPM as a non-root user, follow this procedure. In the following example, the non-root user is my_user. Ensure that my_user can use the Docker engine on the host: Verify that my_user belongs to the \"docker\" system group. OR Enable the Docker TCP socket option, and pass the DOCKER_HOST environment variable to CPM. Verify that my_user has read/write permissions to all the directories and volumes passed to CPM. To set these permission, use the chmod command. Get the uid of my_user for use in the run command: id -u my_user. Once these conditions are met, use the option \"-u <uid>:<gid>\" when launching CPM: docker run ... -u 1002 ... Copy OR docker run ... -u 1002 -e DOCKER_HOST=http://localhost:2375 ... Copy Docker image repository A single CPM Docker image serves both the Docker container system environment and Kubernetes container orchestration system environment. The Docker image is hosted on quay.io. To make sure your Docker image is up-to-date, see the quay.io newrelic/synthetics-minion repository. Additional considerations for CPM connection Connection Description CPMs without Internet access A CPM can operate without access to the internet, but with some exceptions. The public internet health check can be disabled using the environment variables named MINION_NETWORK_HEALTHCHECK_DISABLED for a Docker container system environment or synthetics.minionNetworkHealthCheckDisabled for a Kubernetes container orchestration system environment. The CPM needs to be able to contact the \"synthetics-horde.nr-data.net\" domain. This is necessary for it to report data to New Relic and to receive monitors to execute. Ask your network administration if this is a problem and how to set up exceptions. Communicate with Synthetics via a proxy To set up communication with New Relic by proxy, use the environment variables named MINION_API_PROXY*. Arguments passed at launch This applies to a Docker container environment only. Arguments passed to the CPM container at launch do not get passed on to the containers spawned by the CPM. Docker has no concept of \"inheritance\" or a \"hierarchy\" of containers, and we don't copy the configuration that is passed from CPM to the monitor-running containers. The only shared configuration between them is the one set at the Docker daemon level.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.00476,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Run as non-root <em>user</em> for Docker",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "You can <em>use</em> New Relic&#x27;s containerized private minions (CPM). These are Docker container-based private minions that accept and execute <em>synthetic</em> <em>monitors</em> against your private locations. The CPM can operate in a Docker container system environment or a Kubernetes container orchestration system"
      },
      "id": "603ea47f28ccbcf987eba775"
    },
    {
      "sections": [
        "Add and edit monitors",
        "Add a monitor",
        "Add a ping or simple browser monitor",
        "Add a scripted browser or API test monitor",
        "Tip",
        "Add a step monitor",
        "Add a certificate check monitor",
        "Add a broken links monitor",
        "Edit a monitor",
        "Important",
        "Delete a monitor",
        "Monitor settings",
        "Type",
        "Monitor name",
        "Location",
        "Frequency",
        "Alerts",
        "Apdex T",
        "Response Validation (optional)",
        "See a history of monitor changes"
      ],
      "title": "Add and edit monitors",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "72465a40555ae7b882953091b08d3af1f9fd1102",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/",
      "published_at": "2021-10-07T02:55:32Z",
      "updated_at": "2021-09-02T11:43:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitors are API checks or virtual browser instances that monitor your website, recording each check in detail. They can also capture aggregate numbers, including an overview, or summary for ping monitors, detailed statistics for each page resource, and downtime incidents. Synthetic monitoring also collects custom response codes for more detail on your monitor runs. For a description of synthetic monitor types, see Types of monitor. Add a monitor There are several types of synthetic monitor to add. Ping monitors ensure your website is responding, while simple browser monitors send real browsers to check your website. For more complex monitoring, scripted browser monitors verify that specific resources are present, while API tests verify your API endpoint. Add a ping or simple browser monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type, name, and URL. Optional: Add a validation string or Advanced options: A validation string is available for ping and simple browser. This option enables substring monitoring for response validation. Verify SSL is available for ping and simple browser. This option verifies the validity of the SSL certificate chain. It can be duplicated by running the following syntax: openssl s_client -servername {YOUR_HOSTNAME} -connect {YOUR_HOSTNAME}:443 -CApath /etc/ssl/certs -verify_hostname {YOUR_HOSTNAME} > /dev/null Copy If a non-zero exit code is returned, the monitor will fail. The Bypass HEAD request option is available for ping. This option skips the default HEAD request and instead uses the GET verb with a ping check. Redirect is Failure is available for ping. If a redirect result occurs when Redirect is Failure is enabled, New Relic Synthetics will categorize the result as a failure, rather than following the redirect and checking the resulting URL. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a scripted browser or API test monitor Go to one.newrelic.com > Synthetics > Create monitor. Specify a monitor type and name. Select the locations from which you want your monitor to run. Choose a frequency to determine how often each location will run your monitor. Optional: Set up alert notifications. Select Next: Write your script to create a script for your scripted browser or API test, then select Validate to verify your syntax. Tip For complex scripts, validation may take up to one minute. Select Create my monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a step monitor Go to one.newrelic.com > Synthetics > Create monitor. Select step monitor as the monitor type. Specify a name and choose a frequency to determine how often each location will run your monitor. Select the locations from which you want your monitor to run. Build your monitor by selecting from the preconfigured steps at the bottom of the UI: Navigate to a URL Type text Click an element Assert text Assert an element Secure a credential Use the instructions on the right side of the UI to help locate elements by CSS class, HTML ID, link text, or XPath. Select Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a certificate check monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the certificate check monitor type. Specify a name and enter the domain you'd like to monitor. Enter the number of days it takes for your certificate to expire. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Add a broken links monitor Go to one.newrelic.com > Synthetics > Create monitor. Select the broken links check monitor type. Specify a name and enter the URL you'd like to monitor. Select the period to determine your monitor's frequency. Optional: Add tags to help you find this monitor later. Select the locations from which you want your monitor to run, and then click Save monitor to confirm. Wait a few minutes, then check your monitor from the Monitors index. Tip You can also use the Synthetics REST API to add monitors. For example, you can create a GET request to the monitor you want to use as the source for configuration, then use those key values to use in a POST to \"copy\" and create a new monitor. Edit a monitor To edit an existing monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. In the side menu, select a link to change the following settings: Select Settings > General to edit name, Apdex T, URL, locations, frequency, and advanced options. For Scripted browser and API test monitors, select Settings > Script to edit your monitor script. For synthetic monitoring alerts, click Manage alerts. Select Save changes to confirm. Important You cannot change a monitor's type after the monitor is created. Delete a monitor To delete a monitor: From the Monitors tab in one.newrelic.com > Synthetics, select the monitor you want to edit. From the selected monitor, select Settings > General. Scroll to the bottom of the page and select the trash can icon. Tip You can also use the Synthetics REST API to delete a monitor. Monitor settings When configuring monitors, the following settings are available: Type Select the type of monitor you want to create. A monitor's type can't be changed after the monitor is created. Ping: Specify a single URL to monitor for availability. New Relic will check this URL via HEAD or GET requests. The non-configurable timeout for this monitor is 60 seconds. Simple browser: Specify a single URL to monitor via real browser. Once each frequency interval, New Relic will check this URL via a Selenium-powered Google Chrome browser. The non-configurable timeout for this monitor is 60 seconds. Scripted browser: Create a script to drive a Selenium-powered Google Chrome browser. The browser follows each step in the script to verify that complex behavior is working as expected (for example, searching a website, then clicking one of the search results). The non-configurable timeout for this monitor is 180 seconds. API test: Create an API script to ensure your API endpoint is working correctly. For more information, see Write API tests. The non-configurable timeout for this monitor is 180 seconds. Monitor name Defines a name for the monitor. Monitor names cannot contain unencoded angle brackets (< >). To include angle brackets in a monitor name, encode them as HTML bracket entities (&lt; &gt;) in the UI or API. Location Select the locations where you want your monitor to run. Select more locations to ensure that your application is available to users around the world. If you have any private locations, they will be listed here too. You can use the Synthetics API location endpoint to retrieve a list of valid locations for your account. Your monitor will run one check from each selected location during each frequency interval. For example, if you select three locations and define a frequency of 15 minutes, your monitor will run three checks in each 15 minute period (or 8,640 checks per month). Frequency Select how often the monitor runs, in increments of minutes, hours, or 1 day. This frequency applies to each location. For example, if you select three locations and a Frequency of 15 minutes, your monitor will run three checks, on average every 5 minutes, in each 15 minute period (or 8,640 checks per month). Alerts Specify an email address to receive alerts when a monitor fails. Or, attach a monitor to an existing alert policy for more notification options. For more information, see Alerting for synthetic monitoring. Apdex T Customize the Apdex T for this monitor. This setting is only available when editing the settings for an existing monitor, not when creating a new monitor. Change the Apdex T from the default 7 seconds for more accurate Apdex scores in your SLA reports. For example, if you have a very long scripted browser, you might adjust the Apdex T to 15 seconds to more closely reflect the usual completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When using simple browser or ping monitor types, there is a 1MB (10^6 bytes) limit on the page load. See a history of monitor changes You can use New Relic One to see a history of recent changes to synthetic monitors and what users changed them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.41055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add and edit <em>monitors</em>",
        "sections": "Add and edit <em>monitors</em>",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": " completion time. Similarly, a good Apdex T for a simple browser check might be only 2 seconds. Response Validation (optional) Specify text to search for on the page. When <em>using</em> simple browser or ping <em>monitor</em> types, there is a 1MB (10^6 bytes) limit on the page load. See a history of <em>monitor</em> changes You can <em>use</em> New Relic One to see a history of recent changes to <em>synthetic</em> <em>monitors</em> and what users changed them."
      },
      "id": "604526d064441f3ecc378f03"
    },
    {
      "sections": [
        "Monitor downtimes: Disable monitoring during scheduled maintenance times",
        "Important",
        "Tip",
        "Create recurring monitor downtimes",
        "Create a one-time monitor downtime",
        "View downtime monitors",
        "Delete a monitor downtime",
        "Edit a monitor downtime",
        "For more help"
      ],
      "title": "Monitor downtimes: Disable monitoring during scheduled maintenance times",
      "type": "docs",
      "tags": [
        "Synthetics",
        "Synthetic monitoring",
        "Using monitors"
      ],
      "external_id": "2d8db7bdaef28ad7b523a9e5b1ea209c24aed51b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/synthetics/synthetic-monitoring/using-monitors/monitor-downtimes-disable-monitoring-during-scheduled-maintenance-times/",
      "published_at": "2021-10-08T11:21:43Z",
      "updated_at": "2021-08-02T05:22:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Schedule monitor downtimes to specify times that your synthetic monitors cease alerting, while still preserving your SLA report metrics. Monitor downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During synthetic monitor downtimes, your selected monitors stop running until their scheduled end time. To temporarily disable alerts without pausing your monitors, mute them instead. Tip The ability to add, edit, or delete monitor downtimes depends on your access to features. Create recurring monitor downtimes Create recurring monitor downtimes for routine monitor maintenance or regularly scheduled outages. To create a recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the monitor downtime. Select a daily, weekly, or monthly frequency. Choose additional scheduling options, such as day of the week, time of day, and how long the window will last. Select the monitors that you would like to be included in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. Create a one-time monitor downtime For spontaneous maintenance or service interruptions, create one-time monitor downtimes that will not reoccur. To create a non-recurring monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Select Create monitor downtime. Specify a name for the new monitor downtime. Select once for the frequency, along with the date and start time for the monitor downtime. Select the monitors to include in the monitor downtime. There is no maximum for the amount of monitors that can be selected. Select Create. View downtime monitors Go to one.newrelic.com > Synthetics > (select your monitor) > Summary. When a monitor downtime occurs, it will be visible on your Summary page within the Load time chart as a yellow vertical line. To see which monitor downtime occurred within the chart, hover over the yellow line to view the monitor downtime name. You can view additional details in the Results and Resources sections. Tip If you are unable to delete a window, check your permissions. Delete a monitor downtime To delete an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be deleted in the index. Select the ellipsis icon, and then Delete. Edit a monitor downtime Tip If you are unable to edit a window, check your permissions. To edit an existing monitor downtime: Go to one.newrelic.com > Synthetics > Monitor downtime. Locate the monitor downtime to be edited in the monitor downtime index. Select the ellipsis icon for the downtime you want to edit. Edit the name or frequency of the monitor downtime. To remove a monitor from the list of targets, locate the monitor in the list of Selected targets and select the remove icon next to the monitor. Once you've finished editing, select Save. For more help Additional documentation resources include: Alerting for synthetic monitoring (receive notifications when a monitor fails) Private locations (extend synthetic monitoring coverage to new geographical locations)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 134.0126,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "sections": "<em>Monitor</em> downtimes: Disable <em>monitoring</em> during scheduled maintenance times",
        "tags": "<em>Synthetic</em> <em>monitoring</em>",
        "body": "Schedule <em>monitor</em> downtimes to specify times that your <em>synthetic</em> <em>monitors</em> cease alerting, while still preserving your SLA report metrics. <em>Monitor</em> downtimes are ideal for: Routine maintenance Planned outages Deployments Service interruptions Important During <em>synthetic</em> <em>monitor</em> downtimes, your selected"
      },
      "id": "603ed79b28ccbc8276eba76f"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics": [
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-10-07T16:30:12Z",
      "updated_at": "2021-08-09T00:27:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in that account that includes: The rule details A message about having too many facets A newRelicFeature attribute value of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.32713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    },
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "684976ba0b62b7510db8b856c3f04ea77f9cdcc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-10-07T16:14:58Z",
      "updated_at": "2021-05-15T10:04:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C” Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.45699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.83484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types": [
    {
      "sections": [
        "Creating metric rules: requirements and tips",
        "Metric aggregation",
        "Rule-creation limits",
        "Cardinality limits",
        "Multiple metrics from one rule",
        "Metric naming"
      ],
      "title": "Creating metric rules: requirements and tips",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "2a905f4fc51191fc432fcabfe2657934e052bb5b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips/",
      "published_at": "2021-10-07T16:30:12Z",
      "updated_at": "2021-08-09T00:27:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Here are some limits, requirements, and recommendations when you create metrics from events, logs, or spans. Metric aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate metrics: Function Comments summary Creates a summary metric data point for each time window (currently 1 minute). Use this if your NRQL query uses aggregator functions supported by the summary metric type, such as average, sum, min, or max. Example rule-creation query: SELECT summary(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy uniqueCount Creates a uniqueCount metric data point for each 1-minute time window. Use this if your NRQL query uses the uniqueCount aggregator type. Example rule-creation query: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy distribution Creates a distribution metric data point for each 1-minute time window. Use this if your NRQL query uses aggregator functions such as percentile, histogram, min, max, average, sum, or count. Use only the attribute of interest as the argument, and discard the rest of the arguments from percentile or histogram. The generated metric supports any argument on percentile or histogram. Example of creating a distribution rule: SELECT distribution(duration) AS 'service.responseTime' FROM Transaction WHERE appName = 'Data Points Staging' FACET name, appName, host Copy Simple count: summary(1) and sum If you want a metric that's a simple count of the events, logs, or spans that match a particular WHERE clause, use the summary(1) metric. This metric type counts the number of specified events, logs, or spans per minute. When querying the created metric, use the sum method to see the result. Example: If you want to create a metric named foo.count that counts the transactions named foo, the NRQL would look like this: FROM Transaction SELECT summary(1) AS 'foo.count' WHERE name = 'foo' Copy Then, you would query it like this: FROM Metric SELECT sum(foo.count) SINCE 30 minutes ago Copy For more information about metrics, see our documentation about metric types. Rule-creation limits These limits affect metric rules creation: Limits Comments Account limits An account can have a maximum of 1,000 metric-creation rules. Metric rule limits A rule can: Create a maximum of 10 metrics. Use only one type of data (events, logs, or spans). Select a maximum of 20 attributes (facets) to include on a metric. Time window limits 50K limit on unique metric-name/attribute-value combinations for a single metric in a 24-hour time window. If this limit is exceeded, the rule is disabled and an NrIntegrationError event is created in that account that includes: The rule details A message about having too many facets A newRelicFeature attribute value of eventToMetric Limits on metric name and attribute value combinations The limit on total unique metric name/attribute value combinations in a 24-hour time window for an account is: Equal to three times the purchased monthly average data points per minute Up to a maximum of 10M Cardinality limits Rule-creation limits include limits on the number of unique combinations of metric name and attribute values. This limit exists because a large number of attributes and/or attribute values can lead to an exponential increase in the size of data reported. Example metric creation rule that attaches five attributes: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName, entityName, processId Copy If each of the five attributes reported ten unique values within a one-minute time window, the number of unique metric-name/attribute combinations would theoretically have a maximum of 10x10x10x10x10, or 100,000. Multiple attributes with multiple unique values can lead to a large number of unique metric entries. In practice, this isn't usually the case, because attributes are often related. For example, if one attribute is hostname and another is awsRegion, when you see hostname A, it will always be in AWS region B; you'd never see hostname A and other AWS region values. This is why it's important, during the NRQL creation process, to use the uniqueCount function to verify how many unique metric-name/attribute-value combinations your NRQL query is generating. Multiple metrics from one rule A rule can create up to ten metrics. There are no functional differences between metrics created one at a time and those created with a single rule. Reasons for creating multiple metrics with a single rule: Less likely to reach rules-per-account limit. Easier to add the same attributes to multiple metrics. Example creating multiple metrics with a single rule: FROM Transaction SELECT uniqueCount(request.headers.userAgent) AS 'server.request.header.userAgent.uniqueCount', summary(duration) AS 'server.duration', summary(totalTime) AS 'server.totalTime' WHERE appName = 'Browser Monitoring Router' FACET httpResponseCode, name, appName, host Copy Metric naming A metric is given a name with the AS clause, as part of the NRQL rule-creation process. In the following NRQL example, the name of the metric is io.totalread.bytes: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName Copy If there is no name assigned with the AS clause, the metric name is the name of the queried attribute. In this example, if no name was assigned, the metric name would be ioTotalReadBytes. Metric names Requirements and recommendations Requirements Requirements for naming a metric: Less than or equal to 255 (UTF-16) 16-bit code units. One way to ensure you are under the limit is to keep each string under 127 of whatever is easiest to count. No spaces. Start with a letter. Examples of strong metric names: rubyvm.memory.heap_used redis.container.cpu.percent memcached.process_virtual_memory.bytes Length and structure Decide on a name and structure that makes it easy for others to find, understand, and use this metric. We recommend keeping your metric name under 40 characters for ideal readability. Longer names can get cut off or overlap with other names. Your metric naming scheme will depend on your business logic. You may want to use namespaces to prefix your metric name, or your names may need to be more general. Components within the name If you want to create components within your metric name (like the source of metrics and the thing you’re measuring), we recommend going from broad to specific (left to right): Use a dot to separate those components in order to be consistent with our New Relic metric names. Then, use an underscore to separate words within the dots. Example: application.page_view.duration Copy Attributes Avoid putting attributes in your metric name. Attributes are qualities of your metric that you can use to filter or facet your data, like cluster or availability zone. Example: If you included availability zone in your metric name, it would mean, for that metric, you wouldn’t be able to see results across all availability zones. Changing metric names If you change a metric name, historical data will not be updated to that new name. To query or chart that historical data, you will need to specify the older metric name.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 254.32713,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "sections": "Creating <em>metric</em> rules: requirements <em>and</em> tips",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Here are some limits, requirements, and recommendations when you create <em>metrics</em> from events, logs, or spans. <em>Metric</em> aggregation Your NRQL query must use one of the following summary, uniqueCount, or distribution functions to aggregate <em>metrics</em>: Function Comments summary Creates a summary <em>metric</em> <em>data</em>"
      },
      "id": "603e9b8164441fbcac4e88a6"
    },
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.45709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.83484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/convert-to-metrics/creating-metric-rules-requirements-tips": [
    {
      "sections": [
        "Analyze and monitor data trends with metrics",
        "Why create metrics from other data types?",
        "Available operations",
        "Mutations",
        "Create a rule",
        "Delete a rule",
        "Important",
        "Enable or disable a rule",
        "Queries",
        "List all rules for a New Relic account",
        "List rule by rule ID",
        "Use the NerdGraph GraphiQL API tool"
      ],
      "title": "Analyze and monitor data trends with metrics",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "e1cd71a03a83816741471dae4423128472e10fb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/analyze-monitor-data-trends-metrics/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-05-15T10:06:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can generate metric-type data from other types of data in New Relic, including events, logs, and spans. Metrics are aggregates of your data and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How to use our NerdGraph API tool to perform operations Why create metrics from other data types? Using metrics allows for more efficient data storage. This in turn allows you to query your data and build charts more easily. The difference between metrics and other types of data in New Relic is based on time. For more information, see Understand data types. Events, logs, spans: These types of data represent a single record at a specific moment in time. For example, you may have an event for every request to the system. This data is ideal for in-depth troubleshooting and analysis. Metrics: These provide an aggregated view of your events, logs, or spans. Metrics are better for showing trends over longer time ranges. For example, you can aggregate the total number of requests per service to one metric and then examine this information month over month. Why use metrics? Comments Flexibility Metrics are dimensional. You can choose what metadata (like host name or app name) is attached to them. Common metric measurements, like average, sum, minimum, and maximum, are already calculated. Data aggregation and retention The data has already been pre-aggregated into longer-period time buckets. Data retention is 13 months. Query capabilities You can query using the Metric data type. When you create metrics, this does not delete your events or other types of data. However, metrics are better for longer-range querying and charting. To get started converting your data to metrics, create a rule. Available operations To show, create, and delete rules for generating metrics from events, logs, or spans, use NerdGraph, our GraphQL-format API. Before performing any operation, we recommend reading Intro to NerdGraph and exploring your data with the GraphiQL API tool. These operations fall under two basic request types: Mutations, which are operations that make changes to existing rules or settings (for example, creating a new metrics rule). Queries, for fetching existing data (for example, fetching existing metrics rules). All operations are role-based in NerdGraph as the currently logged-in New Relic user. Mutations Mutation operations for events to metrics, logs to metrics, or spans to metrics include: Create a rule See Create metrics. Delete a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To delete a rule, you need the rule ID and the New Relic account ID. Example request: mutation { eventsToMetricsDeleteRule(deletes: {ruleId: \"12\", accountId: 123456}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsDeleteRule The method being called to delete a rule. deletes This takes two parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Example response for the request: { \"data\": { \"eventsToMetricsDeleteRule\": { \"failures\": [], \"successes\": [ { \"id\": \"12\", \"name\": \"Test Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } Copy Enable or disable a rule Important This operation modifies production settings, so we recommend thoroughly reviewing your changes before you run the operation. To enable or disable an existing rule for events to metrics, logs to metrics, or spans to metrics, use the same eventsToMetricsUpdateRule operation. The only difference is whether enabled is set to true or false. Example request to enable an existing metrics rule: mutation { eventsToMetricsUpdateRule(updates: {ruleId: \"12\", accountId: 123456, enabled: true}) { successes { id name nrql } failures { errors { description reason } submitted { ruleId accountId } } } } Copy In this request: Element Description mutation One of the basic API operation types. eventsToMetricsUpdateRule The method being called to update an existing rule and either enable it or disable it. updates This takes three required parameters: ruleId: The ID of the rule for events to metrics, logs to metrics, or spans to metrics. accountId: The New Relic account ID. enabled: To enable a disabled rule, set this to true. To disable a rule, set this to false. successes and submitted blocks Here you define the data returned by a success or failure. Available parameters for these blocks: id (or ruleId for submitted) name description nrql enabled accountId Queries Query operations include: List all rules for a New Relic account You can list all rules in a New Relic account or return a specific rule. Example listing all rules for account 123456: query { actor { account(id:123456) { eventsToMetrics{ allRules{ rules{ id name enabled nrql description } } } } } } Copy In this request: Element Description query One of the basic API operation types. Used to query but not make changes. actor This specifies the current New Relic user. account(id: 123456) Specify the ID for the New Relic account where to retrieve data. eventsToMetrics Scope the data only for events-to-metrics, logs-to-metrics, or spans-to-metrics rules. allRules Returns all rules for that account. rules In the rules block, you can define what data you want returned. Available fields include: id name description nrql accountId enabled Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"allRules\": { \"rules\": [ { \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"1\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" }, { \"description\": \"Metric for duration\", \"enabled\": true, \"id\": \"2\", \"name\": \"Duration Rule\", \"nrql\": \"select summary(duration) as 'server.responseTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy List rule by rule ID If you know the exact ID for a rule, then you can query for a specific rule. For example, you may have just created a rule and now you want to list its contents so you can review it. Example listing rule 36 for New Relic account 123456: query { actor { account(id: 123456) { eventsToMetrics { rulesById(ruleIds: \"36\") { rules { id name enabled nrql description accountId } } } } } } Copy For more details about the elements in this query, see List all rules. Example response: { \"data\": { \"actor\": { \"account\": { \"eventsToMetrics\": { \"rulesById\": { \"rules\": [ { \"accountId\": 123456, \"description\": \"Metric for total time\", \"enabled\": true, \"id\": \"36\", \"name\": \"Total Time Tx\", \"nrql\": \"select summary(totalTime) as 'server.totalTime' from Transaction where appName = 'Data Points Staging' facet name, appName, host\" } ] } } } } } } Copy Use the NerdGraph GraphiQL API tool You can use our GraphiQL tool to explore the data structure. You can also use it to build and run the operations to convert events, logs, and spans to metrics. To use this tool: Create the metrics operation's request with the required parameters. Go to api.newrelic.com/graphiql, and paste your query into the box. To execute the operation, press Play. Or, to get the cURL format, select Copy as cURL.) Validate the response in the response box. Optional: To verify that your rule-creation operation was performed successfully, run a list query for that rule ID.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.45709,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "sections": "Analyze <em>and</em> monitor <em>data</em> trends with <em>metrics</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "You can generate <em>metric</em>-type <em>data</em> from other types of <em>data</em> in New Relic, including events, logs, and spans. <em>Metrics</em> are aggregates of your <em>data</em> and are optimal for analyzing and monitoring trends over long time periods. This document explains: Reasons to use this feature Available operations How"
      },
      "id": "603eb239e7b9d2b99d2a07bb"
    },
    {
      "sections": [
        "Create metrics from other data types",
        "Create a metrics rule",
        "Step 1. Create NRQL query rule",
        "Tip",
        "Step 2. Create API request",
        "Example NerdGraph API request",
        "Example NerdGraph API response",
        "Step 3. Create a metrics rule with API request",
        "Query and chart your metrics",
        "Summary metric example",
        "Count metric example",
        "Distribution metric example",
        "Troubleshooting"
      ],
      "title": "Create metrics from other data types",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Convert data to metrics"
      ],
      "external_id": "684976ba0b62b7510db8b856c3f04ea77f9cdcc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/convert-to-metrics/create-metrics-other-data-types/",
      "published_at": "2021-10-07T16:14:58Z",
      "updated_at": "2021-05-15T10:04:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use New Relic's metrics API service to define rules for creating metrics from your other types of data, such as events, logs, or spans. Recommendation: Before you begin, review our requirements and tips for creating rules. Create a metrics rule To create a rule for creating metrics from events, logs, or spans: Construct the metrics rule using NRQL. Construct a NerdGraph (GraphQL format) API request that contains your NRQL rule. Create the metric by making the API request. Once a metric is created, you can query and chart it using NRQL. Step 1. Create NRQL query rule The most important part of creating a metrics rule is constructing the NRQL query that defines the metric for your data from events, logs, or spans. You can create up to 10 metrics with a single NRQL query by following this procedure: Using New Relic's NRQL interface, construct a query for the metric you want to create. For example: FROM ProcessSample SELECT average(ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy Edit the query to use one of the three available metric types: summary: Use if the query's function is min, max, sum, count, or average. uniqueCount: Use if the query's function is uniqueCount. distribution: Use if the query's function is percentile or histogram. This example query uses average, so use summary: FROM ProcessSample SELECT summary (ioTotalReadBytes) WHERE nr.entityType = 'HOST' Copy This example query uses count on a non-numeric field: FROM ProcessSample SELECT count(hostname) WHERE hostname LIKE '%prod%' Copy For summary on a non-numeric field use summary(1): FROM ProcessSample SELECT summary(1) WHERE hostname LIKE '%prod%' Copy Tip For more detailed information on using these metric types in rules, see Creating metric rules: requirements and tips. Decide on the attributes you want to attach to the metric, following the limits on the cardinality of unique metric-name/attribute-value combinations. Recommendation: Run a separate query to ensure this count isn't over 50,000 for a 24-hour window. For example: FROM ProcessSample SELECT uniqueCount(awsRegion, awsAvailabilityZone, commandName) WHERE nr.entityType = 'HOST' SINCE 1 DAY AGO Copy To be able to aggregate and filter your metrics, add the attributes you want to attach to the metric using the FACET clause. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Set the name of the metric using the AS function. For example: FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'HOST' FACET awsRegion, awsAvailabilityZone, commandName Copy Once your NRQL rule is complete, use it to create the API request. Step 2. Create API request After you build the NRQL rule to convert data from events, logs, or spans to metrics, continue with building the API request. You can use our NerdGraph API tool to explore the data structure and to construct and make your request. To check that the rule was created correctly, you can run a query to return that rule using its ID. For tips on querying the metrics you've created, see Query and chart your metrics. Example NerdGraph API request The following example NerdGraph API request uses the same NRQL rule from step 1. The IO Total Read Bytes Rule creates a metric named io.totalread.bytes. (The rule name can have spaces, which differs from the metric naming rules.) mutation { eventsToMetricsCreateRule(rules: { name: \"io.totalread.bytes for computeSample entities\", description:\"Created by Zach on March 27, 2019. Used by team Network.\", nrql:\"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\", accountId: 123456 }) { successes { id name nrql enabled } failures { submitted { name nrql accountId } errors { reason description } } } } Copy In this request: Request elements Description mutation One of the basic API operation types. eventsToMetricsCreateRule The method being called to create a rule. rules Takes four parameters: name: The name of the rule. description: Optional. The description of the rule. We recommend you include information about who created the metric data and who will be using the data. accountId: The New Relic account ID where the events, logs, or spans live and the metrics will be created. nrql: The NRQL query that creates the rule. For more on this, see Create NRQL query. successes and submitted blocks Here you define the data returned by a successful or failed response. Available parameters for these blocks include: id (ruleId for submitted) name description nrql enabled (enabled/disabled status) accountId ruleId and accountId If a failure occurs, then the submitted ruleId and accountId will be returned along with the error reason and error description. Example NerdGraph API response Here's an example of a returned response: { \"data\": { \"eventsToMetricsCreateRule\": { \"failures\": [], \"successes\": [ { \"enabled\": true, \"id\": \"46\", \"name\": \"io.totalread.bytes for computeSample entities\", \"nrql\": \"FROM ProcessSample SELECT summary(ioTotalReadBytes) AS 'io.totalread.bytes' WHERE nr.entityType = 'ComputeSample' FACET awsRegion, awsAvailabilityZone, commandName\" } ] } } } Copy Step 3. Create a metrics rule with API request When your API request is ready, you can use the NerdGraph API to make the request, which will create the metrics. Query and chart your metrics After you create a metrics rule to convert data for your events, logs, or spans, you can view the new metric data in the New Relic UI. To view your data: Go to New Relic's NRQL query interface. Run the following query to see the name of all your metrics: SELECT uniques(metricName) FROM Metric Copy Pick the metric of interest, then run the following query to see the available attributes: SELECT * FROM Metric where metricName = 'yourMetric' Copy If you don't see expected data, follow the troubleshooting procedures. The available NRQL aggregator functions depend on the metric type you created. Here are some examples. Summary metric example If you created a summary metric type, you can use the count, sum, max, min, and average aggregator functions, as shown in the following query: SELECT count(appStartResponseTime), sum(appStartResponseTime), max(appStartResponseTime), min(appStartResponseTime), average(appStartResponseTime) FROM Metric Copy Count metric example If you created a uniqueCount metric type, you can only use the uniqueCount function, as shown in the following query: SELECT uniqueCount(playbackErrorStreamUniqueCount) * 100 / uniqueCount(streamUniqueCount) AS '% of Streams Impacted' FROM Metric Copy Distribution metric example If you created a distribution metric type, use the percentile or histogram functions, as shown in the following queries: SELECT percentile(service.responseTime, 95) FROM Metric Copy OR SELECT histogram(service.responseTime, 10, 20) FROM Metric Copy Troubleshooting If your NerdGraph call is not constructed correctly, you may receive a message like this: Cannot parse the unexpected character \"\\u201C” Copy Verify the quotes in the NerdGraph call are not smart quotes (curly quotes). Our NerdGraph API only accepts straight quotes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.45699,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Create <em>metrics</em> from other <em>data</em> types",
        "sections": "Create <em>metrics</em> from other <em>data</em> types",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " the NerdGraph API to make the request, which will create the <em>metrics</em>. Query and chart your <em>metrics</em> After you create a <em>metrics</em> rule to <em>convert</em> <em>data</em> for your events, logs, or spans, you can view the new <em>metric</em> <em>data</em> in the New Relic UI. To view your <em>data</em>: Go to New Relic&#x27;s NRQL query interface. Run the following"
      },
      "id": "603ebfc8196a67cab0a83d96"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.83481,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.34088,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-07-09T23:43:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.80031,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:23Z",
      "updated_at": "2021-07-09T22:19:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.78883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-10-06T23:44:23Z",
      "updated_at": "2021-09-14T05:59:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.32443,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-07-09T23:43:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.8003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:23Z",
      "updated_at": "2021-07-09T22:19:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.78883,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.34055,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-10-06T23:44:23Z",
      "updated_at": "2021-09-14T05:59:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.32442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report mobile monitoring custom events and attributes",
        "Create custom attributes and events",
        "Mobile event and attribute query examples",
        "Custom event example: Track purchases",
        "Tip",
        "Attribute example: Track a specific user",
        "Attribute example: Track a specific store id",
        "Custom attribute example: Track a specific action",
        "Important",
        "Size limits and restricted characters",
        "Set the time to send data",
        "Privacy considerations"
      ],
      "title": "Report mobile monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "30a7ec0f78ddde237cb20265ab9702582f5bc2ba",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:23Z",
      "updated_at": "2021-07-09T22:19:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic sends some default event data from your mobile app to New Relic, such as data about interactions, sessions, crashes, and request errors. You can also create your own custom attributes and events for more detailed querying and analysis. Create custom attributes and events You can create custom session-level attributes for default mobile monitoring events using the mobile agent SDKs. For example, to record a username attribute for some part of your iOS or Android app, you would use the setAttribute API (Android | iOS). These attributes are session-related information and are shared by multiple mobile event types. You can also create entirely new custom event types and assign them their own custom attributes, using the recordCustomEvent API (Android | iOS). To help with crash analysis, you can use the SDK to create MobileBreadcrumb and MobileHandledException events. These events are available for querying and also displayed in the crash event trail UI. For more on creating custom attributes and custom events, see: Android SDK API guide iOS SDK API guide NRQL query examples MobileRequestError examples MobileRequest examples Limits and restricted characters Mobile event and attribute query examples Here are some examples of using NRQL to query your mobile app events and attributes: Custom event example: Track purchases To track purchases in your app, use recordCustomEvent to create an event type (such as \"UserAction\") and associate attributes such as \"name\" (with value \"Purchase\"), price, quantity, and SKU. Tip For performance reasons, you should limit the total number of event types to maybe one or two. The recordCustomEvent parameter eventType is meant to be used for high-level categories. For example, you might create an event typeGestures, and then create many different custom event names under the Gesture event type. Create an event on iOS: BOOL purchaseRecorded = [NewRelic recordCustomEvent:@\"UserAction\" attributes:@{@\"name\": @\"Purchase\", @\"sku\": @\"12345LPD\", @\"quantity\": @1, @\"unitPrice\": @99.99, @\"total\": @99.99}]; Copy Create an event on Android: Map<String, Object> userActionAttributes = new HashMap<String, Object>(); userActionAttributes.put(\"name\", \"Purchase\"); userActionAttributes.put(\"sku\", \"12345LPD\"); userActionAttributes.put(\"quantity\", 1); userActionAttributes.put(\"unitPrice\", 99.99); userActionAttributes.put(\"total\", 99.99); boolean userActionRecorded = NewRelic.recordCustomEvent(\"UserAction\", userActionAttributes); Copy New Relic reports a custom event of type UserAction and name Purchase, which allows you to query all purchases made in your app in the last day: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Replace deprecated recordEvent method: As of Android agent version 5.12.0 and iOS agent version 5.12.0, use the recordCustomEvent method to create these custom events. If you have replaced the deprecated recordEvent method for your custom events, be sure to also replace its corresponding NRQL query with the new format. Look for queries used with recordEvent method, such as this: SELECT * from Mobile where category = 'Custom' and name = 'Purchase' since 1 day ago Copy Replace them with the query format used with recordCustomEvent: SELECT * from UserAction where name = 'Purchase' since 1 day ago Copy Attribute example: Track a specific user You can create a custom attribute to track a custom user identifier across the session, and then query for all that user's interactions. To add an attribute for the userId, call the setUserId method: Set the userId on iOS: BOOL userIdWasSet = [NewRelic setUserId:@\"jsmith\"]; Copy Set the userId on Android: boolean userIdWasSet = NewRelic.setUserId(\"jsmith\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that username in the last day: SELECT * from Mobile WHERE userId = 'jsmith' since 1 day ago Copy Attribute example: Track a specific store id You can create a custom attribute to track a store id across the session, and then query for all that store's interactions. To add an attribute for the storeId, call the setAttribute method: Set the storeId on iOS: BOOL attributeSet = [NewRelic setAttribute:@\"storeId\" value:@\"NY0531\"]; Copy Set the storeId on Android: boolean attributeSet = NewRelic.setAttribute(\"storeId\", \"NY0531\"); Copy With this attribute, you can use a WHERE clause to see all actions performed by that storeId in the last day: SELECT * from Mobile WHERE storeId = 'NY0531' since 1 day ago Copy Custom attribute example: Track a specific action You can use custom attributes to track the number of times that a specific action occurs in your application. For example, you can track the number of times a button was clicked or the number of times a level was completed in a game. To track completing a game level, call incrementAttribute with no value specified. This creates an attribute with a default value of 1: Create a counter on iOS: BOOL levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Create a counter on Android: boolean levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Each subsequent call to incrementAttribute adds 1 to the attribute level: Increment a counter on iOS: levelIncremented = [NewRelic incrementAttribute@\"level\"]; Copy Increment a counter on Android: levelIncremented = NewRelic.incrementAttribute(\"level\"); Copy Important Be sure to reset the value to 0 when starting over. To reset the level back to 1 or 0, call setAttribute: Reset a counter on iOS: levelReset = [NewRelic setAttribute:@\"level\" value:@1]; Copy Reset a counter on Android: levelReset = NewRelic.setAttribute(\"level\", 1); Copy When querying, use this level attribute to filter your data. For example, if you have a username and level attribute, use the max() function to find the highest level the user had reached: SELECT max(level) from Mobile where username = 'jsmith' Copy Size limits and restricted characters Limits for custom attributes added to default mobile events: Attributes: 128 maximum String attributes: 4 KB maximum length (empty string values are not accepted) Limits for custom events: Attributes: 254 maximum per event (number includes default session attributes) String attributes: 4 KB maximum length (empty string values are not accepted) Naming syntax and rules: See Rules for custom data. Set the time to send data By default, New Relic transmits event data in any of these situations: A session has been ongoing for 600 seconds. The app session ends by backgrounding. The app crashes. If the app crashes, New Relic gathers the attributes and events for that session and sends them to Insights. (On iOS, this happens the next time the app is launched). You can then use Insights to query and analyze the event and attribute data. To set the maximum time (in seconds) that the agent will store events in memory, use the following SDK calls: iOS method: + (void) setMaxEventBufferTime:(unsigned int)seconds; Copy Android method: public static void setMaxEventBufferTime(int maxBufferTimeInSec); Copy Privacy considerations If you want to collect personal data via custom attributes, please consult with your privacy or legal teams. Be sure to follow your organization's obligations for notices and consent regulations.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.78882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report mobile monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Mobile monitoring in New Relic sends some default <em>event</em> <em>data</em> from your mobile app to New Relic, such as <em>data</em> about interactions, sessions, crashes, and request errors. You can also create your own <em>custom</em> attributes and <em>events</em> for more detailed querying and analysis. Create <em>custom</em> attributes"
      },
      "id": "609fa5cf28ccbc508d9832d3"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data": [
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-10-06T23:44:23Z",
      "updated_at": "2021-09-14T05:59:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 958.72766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "APM: <em>Report</em> <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": ". Record <em>custom</em> <em>events</em> and <em>attributes</em> You can add your own <em>custom</em> APM <em>events</em> and <em>attributes</em>, which you can then use for querying and charting. This is one of several ways to <em>report</em> <em>custom</em> data. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> <em>attributes</em>"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "iOS SDK API guide",
        "Caution",
        "Install the SDK",
        "Automatically instrumented classes and methods",
        "Instrument your Objective-C code",
        "Important",
        "Create and complete interactions",
        "Rename a default interaction",
        "Set a custom application version",
        "Set a custom build identifier",
        "Create custom metrics",
        "Objective-C: Report custom attributes and events",
        "Objective-C: Track custom network requests",
        "Instrument your Swift code",
        "Create and complete Swift interactions",
        "Rename a default Swift interaction",
        "Set a custom application version with Swift",
        "Set a custom build identifier with Swift",
        "Create custom metrics with Swift",
        "Swift: Report custom attributes and events",
        "Swift: Track custom network requests"
      ],
      "title": "iOS SDK API guide",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "API guides"
      ],
      "external_id": "fe6ba3196a927fb8dee72f8bf777461c95f7505c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/api-guides/ios-sdk-api-guide/",
      "published_at": "2021-10-07T06:28:15Z",
      "updated_at": "2021-07-09T15:39:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the iOS SDK API to add custom data. For example: Instrument your own code. Start and stop interaction traces from events in your mobile app. Record custom metrics. Send custom attributes and events to Insights. Track networking from libraries not supported automatically. Set a custom identifier value with Objective-C or Swift to associate user sessions with analysis events and attributes (iOS SDK version 5.9.0 or higher). Caution Tracing is heavily optimized, but it does impose a performance overhead. Avoid instrumenting methods that are expected to be called hundreds of times. Install the SDK Ensure you have your app instrumented with the latest iOS SDK by going to one.newrelic.com > Add more data and following the instructions for iOS. This document contains the iOS SDK instrumentation requirements for: Objective C Swift For details about the available methods for custom attributes and events you can send to to New Relic Insights, see the iOS SDK API reference. You can also configure feature flags for: Objective-C Swift Automatically instrumented classes and methods The following methods (for the listed classes and their sub-classes) are already instrumented by New Relic. You do not need to add custom instrumentation to trace them. Classes Methods automatically instrumented by New Relic UIViewController viewDidLoad: viewWillAppear: viewDidAppear: viewWillDisappear: viewDidDisappear: viewWillLayoutSubviews: viewDidLayoutSubviews: UIImage imageNamed: imageWithContentsOfFile: imageWithData: imageWithData:scale: initWithContentsOfFile: initWithData: initWithData:scale: NSJSONSerialization JSONObjectWithData:options:error: JSONObjectWithStream:options:error: dataWithJSONObject:options:error: writeJSONObject:toStream:options:error: NSManagedObjectContext executeFetchRequest:error: processPendingChanges The agent aggregates performance for various methods into summary metrics that appear in the Interactions page. Summary categories include: View loading UI layout Database Images JSON Network Instrument your Objective-C code To have your own Objective-C code appear in interaction code breakdowns and timelines, add a _START call to the beginning of your method and a _STOP call to the end of it. Important Always include a _STOP for each _START, and only include one set of these commands in a given method. The trace system will automatically pick up the class and method name, and report performance metrics for your method to New Relic. - (void)myMethod { NR_TRACE_METHOD_START(0); // … existing code NR_TRACE_METHOD_STOP; } Copy If you are not using ARC, use this version of the _STOP macro to avoid memory leaks: NR_NONARC_TRACE_METHOD_STOP; Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the _START macro; for example: NR_TRACE_METHOD_START(NRTraceTypeDatabase); Copy Create and complete interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction with Objective-C, use these API calls: NSString* uniqueIdentifier = NR_START_NAMED_INTERACTION(@\"name\"); Copy This macro will automatically begin tracking the name interaction trace from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NR_INTERACTION_STOP(uniqueIdentifier); Copy This macro will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names with Objective-C, implement the - (NSString*) customNewRelicInteractionName instance method in your view controller, where the string returned becomes the interaction's name. Set a custom application version The New Relic iOS SDK allows you to set a custom application version string with Objective-C. Instead of using the string defined in CFBundleShortVersionString, call the +[NewRelic setApplicationVersion:] method and pass along the custom application version before calling +[NewRelic startWithApplicationToken:]; [NewRelic setApplicationVersion:(NSString*) appVersion]; Copy Set a custom build identifier As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in the Crash details page. Instead of using the CFBundleVersion string defined in Xcode with Objective-C, call the +[NewRelic setApplicationBuild:] method, and pass along the custom build identifier. [NewRelic setApplicationBuild:(NSString*) buildNumber]; Copy Create custom metrics Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Objective-C: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Objective-C, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Objective-C: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: [NewRelic noticeNetworkRequestForURL:(NSURL*)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer responseHeaders:(NSDictionary *)headers statusCode:(NSInteger)httpStatusCode bytesSent:(NSUInteger)bytesSent bytesReceived:(NSUInteger)bytesReceived responseData:(NSData *)responseData andParams:(NSDictionary *)params]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, the agent will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if the agent records server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: [NewRelic noticeNetworkFailureForURL:(NSURL *)url httpMethod:(NSString*)httpMethod withTimer:(NRTimer *)timer andFailureCode:(NSInteger)iOSFailureCode]; Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of supported codes, see NRConstants.h. Instrument your Swift code To have your own Swift code appear in interaction code breakdowns and timelines: Add a startTracingMethod() call to the beginning of your method. Add a endTracingMethodWithTimer() call to the end of it. Always include an endTracingMethodWithTimer() call for each startTracingMethod() reference. Include only one set of these commands in a given method. func myMethod(){ let timer = NRTimer(); NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeNone) // … existing code NewRelic.endTracingMethodWithTimer(timer) } Copy If you want your method’s performance to be included in the summary data on the APM Overview page, pass one of the NRTraceType enum values into the startTracingMethod() macro; for example: NewRelic.startTracingMethod(#selector(MyClass.myMethod), object: self, timer: timer, category: NRTraceTypeDatabase) Copy Create and complete Swift interactions By default, an interaction starts when a view controller is pushed. To manually start an interaction, use these API calls: let uniqueIdentifier = NewRelic.startInteraction(withName: \"My Interaction\") Copy This call will automatically begin tracking an interaction trace named My Interaction from the current line. It will also complete any previously running interaction. It returns a unique identifier that can be used to complete that interaction by using this API call: NewRelic.stopCurrentInteraction(uniqueIdentifier) Copy This method will complete the interaction associated with the uniqueIdentifier if that interaction has not already completed automatically. You do not need to call this method. Rename a default Swift interaction By default, the iOS agent will start an interaction trace when a new view controller is displayed. The interactions are named using the format Display <ViewController>. To change these default names, implement the @objc func customNewRelicInteractionName() -> String method in your view controller, where the string returned becomes the interaction's name. Set a custom application version with Swift The New Relic iOS SDK allows you to set a custom application version string. Instead of using the string defined in CFBundleShortVersionString, call the NewRelic.setApplicationVersion() method, and pass along the custom application version before calling NewRelic.startWithApplicationToken();. NewRelic.setApplicationVersion(String appVersion) Copy Set a custom build identifier with Swift As of version 5.1.0 of the New Relic iOS SDK, an API method allows you to set a custom build identifier that is displayed next to the application version in the Crash details page. Instead of using the CFBundleVersion string defined in Xcode, call the NewRelic.setApplicationBuild() method, and pass along the custom build identifier. NewRelic.setApplicationBuild(buildNumber) Copy Create custom metrics with Swift Custom metrics can help track high level events specific to your application. With the recordMetric API, you can record arbitrary numerical data and named events with Objective-C and Swift. You can also use several API calls to record custom metrics that provide different levels of detail. Swift: Report custom attributes and events Use methods in the NewRelic object to report custom attributes and events. For details about the available methods for custom attributes and events with Swift, see the iOS SDK API reference. Methods that return BOOL results return YES if they succeed, or NO if the operation did not complete. These methods are available in versions 5.0.0 or higher of the New Relic iOS SDK. The SDK can store up to 128 user-defined custom attributes at a time. If you attempt to store more than 128 attributes, the SDK returns NO. Custom attributes names should use the simplest format needed, and New Relic recommends single word attributes, containing no spaces. Attribute phrases can be formatted in camel case, so My Custom Attribute is better specified as myCustomAttribute. As with custom metrics: Avoid using the characters / ] [ | * when naming things. Avoid multi-byte characters. Swift: Track custom network requests If you can express a transactional network request in terms similar to an HTTP request, you can track it. Use URLs that are well-formed and do not include highly variable paths or hostnames. For requests that complete, use this method: NewRelic.noticeNetworkRequestForURL(url: NSURL!, httpMethod: String!, withTimer: NRTimer!, responseHeaders:[NSObject : AnyObject]!, statusCode: Int, bytesSent: UInt, bytesReceived: UInt, responseData: NSData!, andParams: [NSObject : AnyObject]!) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request headers A dictionary containing the HTTP response headers, if available httpStatusCode The response status code If the httpStatusCode is greater than or equal to 400, the agent will record a server error and may capture the responseData body if provided. bytesSent The size of the request body bytesReceived The size of the responseBody responseData The response body data, captured if the agent records Server error params params Additional parameters included in an HTTP error metric if the HTTP transaction is an error For requests that fail due to a socket or operating system error, use this method: NewRelic.noticeNetworkFailureForURL(url: NSURL!, httpMethod: NSString!, withTimer: NRTimer!, andFailureCode: Int) Copy Parameters include: Parameter Description url The URL of the request httpMethod The method type of the request; for example, POST, GET, etc. timer An NRTimer that timed the network request iOSFailureCode The failure code Failure codes are interpreted as NSURLError* code. To view a complete list of supported codes, see NRConstants.h.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 320.65915,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> <em>and</em> <em>events</em>",
        "body": ". You can also use several API calls to record <em>custom</em> metrics that provide different levels of detail. Objective-C: <em>Report</em> <em>custom</em> <em>attributes</em> and <em>events</em> Use methods in the NewRelic object to <em>report</em> <em>custom</em> <em>attributes</em> and <em>events</em>. For details about the available methods for <em>custom</em> <em>attributes</em> and <em>events</em>"
      },
      "id": "603eb3a2e7b9d264f02a07a8"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-07-09T23:43:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.81567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "sections": "<em>Report</em> browser monitoring <em>custom</em> <em>events</em> <em>and</em> <em>attributes</em>",
        "tags": "<em>Custom</em> <em>events</em>",
        "body": " to run and <em>report</em> relevant PageAction <em>events</em>. Run a NRQL query of the PageAction <em>event</em> that includes the actionName attribute you used to capture the <em>event</em> (and any associated <em>attributes</em> you sent along with the action). Add <em>custom</em> <em>attributes</em> to PageView <em>event</em> The PageView <em>event</em> is a default browser"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/custom-events/report-mobile-monitoring-custom-events-attributes": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 356.34036,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: Default <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from New Relic agents <em>Custom</em> <em>events</em> from <em>Insights</em> <em>custom</em> <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-10-06T23:44:23Z",
      "updated_at": "2021-09-14T05:59:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.3244,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "sections": "APM: Report <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": ". Record <em>custom</em> <em>events</em> and attributes You can add your own <em>custom</em> APM <em>events</em> and attributes, which you can then use for querying and charting. This is one of several ways to report <em>custom</em> <em>data</em>. To record a <em>custom</em> <em>event</em>, follow the procedures for your New Relic language agent. To add <em>custom</em> attributes"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    },
    {
      "sections": [
        "Report browser monitoring custom events and attributes",
        "Page actions and views",
        "Prerequisites",
        "Create PageAction events",
        "Add custom attributes to PageView event",
        "Use setCustomAttribute browser API call",
        "Forward custom attributes from APM data",
        "PageAction and PageView attributes",
        "Troubleshooting"
      ],
      "title": "Report browser monitoring custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "1b83d1fc94a08bad364d1e1d03156279e535104d",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-browser-monitoring-custom-events-attributes/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-07-09T23:43:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use browser monitoring in New Relic to add custom events and attributes. Page actions and views Use the browser API's addPageAction call to capture events, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an event named PageAction that contains the action name and any custom attribute names and values you capture along with it. The PageAction event also contains any custom attributes you added to the PageView event. Add custom attributes to the PageView event so you can query or filter your data to answer more questions about your application. Prerequisites In order to report PageAction events, verify these prerequisites: Requirement Comments Agent version Your browser monitoring agent version must be 593 or higher. Client browser version To record PageAction events, the browser must support cross-domain XHRs. Max events per cycle PageAction events are reported every 30 seconds, with a maximum of 120 events per 30-second harvest cycle, per browser. After the 120-event limit is reached, additional events are not captured for that cycle. Event/attribute naming, data type, size Ensure you follow general requirements around event/attribute naming syntax, data types, and size. Create PageAction events To create a PageAction event: Ensure the browser agent is installed for your app. Call the newrelic.addPageAction function in the relevant part of your application's JavaScript. Wait a couple minutes for the application to run and report relevant PageAction events. Run a NRQL query of the PageAction event that includes the actionName attribute you used to capture the event (and any associated attributes you sent along with the action). Add custom attributes to PageView event The PageView event is a default browser-reported event. You can add custom attributes to the PageView event. Any custom attributes you add to the PageView event are also automatically added to the PageAction event. There are two ways to add custom attributes to the PageView event: Use setCustomAttribute browser API call To add a custom attribute to the PageView event via the browser agent, use the setCustomAttribute browser API call. This allows you to capture an attribute to be annotated on any PageAction event. Forward custom attributes from APM data If you added custom attributes to the APM Transaction event via an APM agent, you can forward those custom attributes to the PageView event automatically: Insert custom attributes by following the agent-specific instructions. Enable attribute forwarding in your agent configuration file: Agent Enable attribute forwarding C SDK Not supported. Go To enable attributes, add this to your config (disabled by default): cfg.BrowserMonitoring.Attributes.Enabled = true Copy Then add the attributes you want to include: cfg.BrowserMonitoring.Attributes.Include = []string{\"request.*\"} Copy Java Add the attributes.enabled option in the browser_monitoring stanza and set it to true. .NET Add the <attributes enabled=\"true\"> element as a child of the browserMonitoring element: <configuration xmlns=\"urn:newrelic-config\"> ... <browserMonitoring autoInstrument=\"true\"> ... <attributes enabled=\"true\"> ... </attributes> </browserMonitoring> ... </configuration> Copy If you are using manual browser instrumentation the attribute needs to be created before the GetBrowserTimingHeader() call. Node.js Add attributes: {enabled: true} to the browser_monitoring: { section of your app's newrelicjs configuration file. PHP Add the newrelic.browser_monitoring.attributes.enabled option and set it to true. Python Add the browser_monitoring.attributes.enabled option and set it to true. Ruby Add the browser_monitoring.attributes.enabled option and set it to true. PageAction and PageView attributes To see the default attributes of PageAction and PageView, see Browser events. Troubleshooting Here are some troubleshooting tips: Problem Comments Custom attributes missing If your custom attributes do not appear on PageView events, verify you are calling setCustomAttribute before the Load event on your page. If the custom attribute is called after the page load occurs, it will not be visible on PageView. PageAction events If your PageAction events do not appear when you query, check that your account is compatible. If your account is compatible, check that you are not using reserved attribute names or invalid values.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.8003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "sections": "Report browser monitoring <em>custom</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "You can use browser monitoring in New Relic to add <em>custom</em> <em>events</em> and attributes. Page actions and views Use the browser API&#x27;s addPageAction call to capture <em>events</em>, actions, route changes, or any end-user interactions with your application. The addPageAction call adds an <em>event</em> named PageAction"
      },
      "id": "609fa5cfe7b9d2c93dc3eb26"
    }
  ],
  "/docs/telemetry-data-platform/custom-data/intro-custom-data": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/report-custom-event-data/",
      "sections": [
        "Report custom events and attributes",
        "Requirements",
        "Avoid rate limits",
        "Example use cases",
        "Using custom attributes",
        "Using custom events",
        "Send custom events and attributes",
        "Extend data retention"
      ],
      "published_at": "2021-10-07T05:15:16Z",
      "title": "Report custom events and attributes",
      "updated_at": "2021-07-09T20:06:23Z",
      "type": "docs",
      "external_id": "e50a9be8b3df5859c6307c8642942006f537578d",
      "document_type": "page",
      "popularity": 1,
      "body": "One of the ways to report custom data to New Relic is with custom events and attributes. Have questions about why you'd use custom data? See Introduction to custom data. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits Reporting a large number of custom events and/or attributes can cause degraded query performance. It may also result in approaching or passing data collection rate limits. For optimal performance, first think about what data you want to analyze, and then create only the events and/or attributes necessary to meet these specific goals. Be aware of the following data and subscription requirements for inserting and accessing custom data: Ensure you follow limits and requirements around event/attribute data types, naming syntax, and size. The amount of data you have access to over time depends on your data retention policy. Example use cases Two popular custom data solutions are custom events and custom attributes. There are several ways to accomplish this (more on that later in this doc), depending on your New Relic implementation and tools. Here are some common use cases for implementing custom events and attributes. Using custom attributes Custom attributes are often used to add important business and operational context to existing events. Business context might include: Customer token Customer market segment Customer value classification Workflow control values not obvious in the URIStem User/product/account privilege context Operational context might include: Which feature flags were used What datastore was accessed What cache was accessed What errors were detected and ignored (fault partitioning) Using custom events Event data is one of New Relic's four core data types. We recommend reading that definition to understand what we mean by \"event\" and why that data type is most used for reporting specific types of activity. The use cases for custom events varies widely: basically they are used for any type of activity that an organization deems important and that is not already being monitored. A couple examples: An event might represent an activity involving multiple actions, like a customer purchasing a certain combination of products. An event might record backup activity. For example, they might set up reporting of events that represent production backups of their SOLR instances into an event table, with a timestamp of when it occurred, which cluster, and the duration. Send custom events and attributes Methods for sending custom events and attributes include: Source How to send custom data APM agent Use APM agent APIs to report custom events and custom attributes. Browser monitoring agent Add custom attributes to the PageView event via the browser API call addCustomAttribute. Send PageAction event and attributes via browser API. Forward APM agent custom attributes to PageView event. Event API To report custom events not associated with other New Relic products, use the Event API. Infrastructure monitoring agent Add custom attributes to default Infrastructure events. Use the Flex integration tool to report your own custom event data. Mobile monitoring agent Use the mobile agent API to send custom events and attributes. Synthetic monitoring Add custom attributes to the SyntheticCheck event via the $util.insights tools. For ways to report other types of custom data, see: Metric API Logs Trace API Extend data retention To learn how to extend how long events are retained in your account, see our documentation about event data retention.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 502.76807,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report <em>custom</em> events and attributes",
        "sections": "Report <em>custom</em> events and attributes",
        "body": "One of the ways to report <em>custom</em> <em>data</em> to New Relic is with <em>custom</em> events and attributes. Have questions about why you&#x27;d use <em>custom</em> <em>data</em>? See <em>Introduction</em> to <em>custom</em> <em>data</em>. Requirements For event and attribute formatting requirements and best practices, see Limits and requirements. Avoid rate limits"
      },
      "id": "609fa5fb64441f9ebfd2a1db"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.75398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for <em>custom</em> event <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for <em>custom</em> event <em>data</em>",
        "tags": "Event <em>data</em> sources",
        "body": " (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the <em>custom</em> PageAction event.) Mobile monitoring SDK General requirements When reporting <em>custom</em> events and attributes, follow these general requirements for supported <em>data</em> types, naming"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "APM: Report custom events and attributes",
        "Data considerations",
        "Tip",
        "Record custom events and attributes",
        "C SDK",
        "Go",
        "Java",
        ".NET",
        "Node.js",
        "PHP",
        "Python",
        "Ruby",
        "Timestamps",
        "Limits and restricted characters",
        "Reserved words"
      ],
      "title": "APM: Report custom events and attributes",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "bbb007a010108780f8c1131e08389b8ac26c4009",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/apm-report-custom-events-attributes/",
      "published_at": "2021-10-06T23:44:23Z",
      "updated_at": "2021-09-14T05:59:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If you have APM, you can report custom event data. You can then query and visualize your data in New Relic. Data considerations New Relic agents send event data to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot of events can increase the memory overhead of the agent. New Relic enforces an upper limit of 833 custom events every 5 seconds. Additionally, posts greater than 1MB (10^6 bytes) in size will not be recorded, regardless of the custom event limit. You can also send custom events using the Event API (without need for APM). However, be aware that custom events sent with the agent APIs are not compatible with high security mode. Tip For more information, check out New Relic University’s tutorial Adding custom data with the APM agent API. Or, go directly to the full online course Custom data with APM. Record custom events and attributes You can add your own custom APM events and attributes, which you can then use for querying and charting. This is one of several ways to report custom data. To record a custom event, follow the procedures for your New Relic language agent. To add custom attributes to APM events, you must first enable them for your APM agent, and then make an API call to record the attribute. Follow the agent-specific custom attribute procedures. When creating your own custom events and attributes, follow data requirements for: Size limits Attribute types Reserved words C SDK To add a custom event to apps monitored by the C SDK, start a transaction and use the newrelic_create_custom_event and newrelic_record_custom_event functions. For more information, see the Guide to using the C SDK API. You can then add custom attributes for your C SDK app. Go To add a custom event to apps monitored by the Go agent, use RecordCustomEvent. You can then add custom attributes for your Go app. Java Custom event collection is enabled by default in Java agent version 3.13.0 or higher. To send custom events, call recordCustomEvent. For example: Map<String, Object> eventAttributes = new HashMap<String, Object>(); NewRelic.getAgent().getInsights().recordCustomEvent(\"MyCustomEvent\", eventAttributes); Copy The first argument defines the name of your event type, and the second argument is a map with the attributes for your custom event. Event attributes must be strings or numbers. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Java agent via a configuration parameter in newrelic.yml. Specify the maximum number of events to record per minute as an integer. For example, if you want to send less than the default of 10000 events: custom_insights_events: max_samples_stored: 5000 Copy To disable custom events entirely, add the following to your newrelic.yml: custom_insights_events: enabled: false Copy You can then add custom attributes for your Java app. For Java agent versions prior to 4.1.0, use the following YAML configuration: custom_insights_events.enabled: true custom_insights_events.max_samples_stored: 5000 Copy .NET Custom event collection is enabled by default in .NET agent version 4.6.29.0 or higher. To send custom events, simply call RecordCustomEvent(). For example: var eventAttributes = new Dictionary<String, Object>(); NewRelic.Api.Agent.NewRelic.RecordCustomEvent('MyCustomEvent', eventAttributes); Copy The first argument defines the name of your event type, and the second argument is an IEnumerable with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your .NET app. You can turn off custom events entirely by setting customEvents.enabled to false in newrelic.config. Node.js Custom event collection is enabled by default in Node.js agent version 1.15.0 or higher. To send custom events, simply call the relevant API. For example: recordCustomEvent(eventType, attributes) Copy Use recordCustomEvent to record an event-based metric, usually associated with a particular duration. The eventType must be an alphanumeric string less than 255 characters. The attributes must be an object of key and value pairs. The keys must be shorter than 255 characters, and the values must be string, number, or boolean. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can then add custom attributes for your Node.js app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.js. PHP Custom event collection is enabled by default in PHP agent version 4.18 or higher. To send custom events, simply call the relevant API function. For example: newrelic_record_custom_event(\"WidgetSale\", array(\"color\"=>\"red\", \"weight\"=>12.5)); Copy The first argument defines the name of your event type, and the second argument is an array with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. By default, the maximum number of custom events recorded per minute is 10,000. This setting cannot be changed. You can then add custom attributes for your PHP app. To disable custom events entirely, add newrelic.custom_insights_events.enabled = false to your newrelic.ini and restart the agent. Python Custom event collection is enabled by default in Python agent version 2.60.0.46 or higher. To send custom events, simply call the relevant API. For example: newrelic.agent. record_custom_event (event_type, params, application=None) Copy The event_type defines the name (or type) of the custom event. Attributes of the custom event should be passed in as a dictionary via the params keyword argument. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For limits and restrictions on event_type and params, see our documentation about limits and restricted characters and reserved words If called outside of the context of a monitored web request or background task, the call will be ignored unless the application keyword argument is provided and an application object corresponding to the application against which the exception should be recorded is provided. A suitable application object can be obtained using the newrelic.agent.application() function. You can then add custom attributes for your Python app. To disable custom events entirely, set custom_insights_events.enabled to False in your newrelic.ini configuration file. Ruby Custom event collection is enabled by default in Ruby agent version 3.9.8.273 or higher. To send custom events, simply call the relevant API. For example: ::NewRelic::Agent.record_custom_event('WidgetSale', color: 'red', weight: 12.5) Copy The first argument defines the name of your event type, and the second argument is a hash with the attributes for your custom event. Ensure you limit the number of unique event type names that you create, and do not generate these names dynamically. For restrictions on event type names, see our documentation about limits and restricted characters and NRQL reserved words. You can change the maximum number of events recorded by the Ruby agent via a configuration parameter in newrelic.yml: Add custom_insights_events.max_samples_stored: to your configuration file. Specify the maximum number of events to record per minute as an integer. For example, if you want to be able to send up to 5000 events per minute, add: custom_insights_events.max_samples_stored: 5000 Copy You can then add custom attributes for your Ruby app. To disable custom events entirely, add custom_insights_events.enabled: false to newrelic.yml. Timestamps You may not specify a timestamp on events that are collected and recorded via the agent. The agent will automatically assign a timestamp to events based on when they are recorded via the API. Limits and restricted characters See Custom event data requirements for size limits, data types, and naming syntax requirements. Reserved words Before creating custom attributes, review New Relic's list of reserved terms used by NRQL. Otherwise unexpected results may occur.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 88.48831,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "APM: Report <em>custom</em> events and attributes",
        "sections": "APM: Report <em>custom</em> events and attributes",
        "tags": "Event <em>data</em> sources",
        "body": "If you have APM, you can report <em>custom</em> event <em>data</em>. You can then query and visualize your <em>data</em> in New Relic. <em>Data</em> considerations New Relic agents send event <em>data</em> to New Relic as part of the normal harvest cycle every five seconds for agent versions supporting real time streaming. Sending a lot"
      },
      "id": "609fa629e7b9d2fa8dc3eb04"
    }
  ],
  "/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.81586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.77493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Report custom data"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "1b20f81fa22784c5d22e4e51eb7c0bf26cbdb0b6",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-10-07T09:51:37Z",
      "updated_at": "2021-07-01T17:17:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our Telemetry Data Platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. To browse our solutions, see New Relic integrations. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 187.7597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>data</em> into New Relic",
        "sections": "<em>Get</em> <em>data</em> into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "There are many ways to <em>get</em> <em>data</em> into your New Relic account. Any New Relic user can use any of our <em>data</em> <em>ingest</em> methods to report <em>data</em> to our <em>Telemetry</em> <em>Data</em> <em>Platform</em>. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring"
      },
      "id": "603eae7b196a671ea3a83dc7"
    }
  ],
  "/docs/telemetry-data-platform/get-started/introduction-new-relic-data-ingest-apis-sdks": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.81583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.7749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-10-07T16:31:07Z",
      "updated_at": "2021-07-27T06:11:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.06204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "New Relic&#x27;s <em>Telemetry</em> <em>Data</em> <em>Platform</em> is the single source of truth for all your operational <em>data</em>, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/get-started/nrdb-horsepower-under-hood": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.81583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.7749,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Get to know the Telemetry Data Platform",
        "The value of New Relic",
        "Capabilities"
      ],
      "title": "Get to know the Telemetry Data Platform",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "c8ed537b435582de214dec3be89481afebb3c538",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/get-started/get-know-telemetry-data-platform/",
      "published_at": "2021-10-07T16:31:07Z",
      "updated_at": "2021-07-27T06:11:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Telemetry Data Platform is the single source of truth for all your operational data, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open, and unified telemetry platform. Automatic integrations for open-source tools enable easy setup, eliminating the cost and complexities of hosting, operating, and managing additional monitoring systems or data stores. With all of your telemetry data in one place, you can investigate your unknowns with confidence. The value of New Relic The Telemetry Data Platform: Provides an elastic, scalable, highly-performant data platform for your entire stack. Eliminates data silos, accelerates mean time to detection (MTTD) and resolution (MTTR), and enables tool consolidation by providing one place to collect and explore your metrics, events, logs, and traces. Accelerates time-to-value with an enterprise-grade SaaS platform that doesn’t require additional infrastructure, hardware, or experts to set up, operate, and maintain additional systems. Enables you to explore your operational data through easy-to-build charts and dashboards, including support for visualizing Prometheus data in Grafana. Provides over 350 automatic integrations for ingesting data from open source tools, such as Prometheus, Telegraf, FluentD, and Logstash, in addition to New Relic’s best-in-class agents. Empowers you to build New Relic One apps to connect system performance to unique business needs, such as business KPIs and customer engagement. Capabilities New Relic's capabilities are organized into several areas: Data: All of your systems’ telemetry data — metrics, events, logs, and traces — connected in one platform to eliminate silos and scale efficiently. Data is easily accessible from a single point at New Relic One's Browse data button. Analytics: Query any data collected with lightning fast response time, to get quick answers to questions as they arise, using familiar query patterns for the different data types. Dashboards: Visualize data in ways that help software development and IT teams ensure uptime and performance, gain operational efficiency, and accelerate time to market. Alerts: Find out about problems with real-time notifications based on metrics and thresholds you care about. Programmability: Build custom New Relic One apps to connect your system performance to unique business needs, such as business KPIs and customer engagement. For more on New Relic in general, including how to get started, see Introduction to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 193.06204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "sections": "<em>Get</em> to know the <em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "New Relic&#x27;s <em>Telemetry</em> <em>Data</em> <em>Platform</em> is the single source of truth for all your operational <em>data</em>, empowering you to ask and answer any question in milliseconds. Collect, explore, and alert on all your metrics, events, logs, and traces from any source with the world’s most powerful, managed, open"
      },
      "id": "603e9745196a672b90a83d98"
    }
  ],
  "/docs/telemetry-data-platform/index": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 885.5397,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>data</em> coming into New Relic",
        "sections": "Manage <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "When you connect your <em>data</em> to New Relic, we process what we receive and apply <em>data</em> dropping and transformation rules. Then we count the bytes needed to represent your <em>data</em> in a standard format, like JSON. If you&#x27;re on our New Relic One pricing plan, you&#x27;re charged by the number of bytes written"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 885.3725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-10-07T06:31:22Z",
      "updated_at": "2021-09-13T20:40:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing plan, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing plan. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 762.5147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/introduction-event-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one",
        "Integrations built with the Telemetry SDKs"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "759fd7fa58ab2e074d0ba50b30be8c1096698304",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-10-06T23:47:51Z",
      "updated_at": "2021-08-26T14:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our core data ingest APIs: the Metric API, Trace API, Log API, and Event API. We offer open-source integrations for telemetry tools like Prometheus, Istio, and OpenCensus that were created using our Telemetry SDKs. If those solutions (or our other integrations) don't meet your needs, you can use the Telemetry SDKs to create your own telemetry data solutions. Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications. Integrations built with the Telemetry SDKs To see the integrations built using our Telemetry SDKs, see Open source telemetry integrations. For all monitoring solutions, see our integrations page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.97525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our core <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. We offer open-source integrations for <em>telemetry</em> tools like Prometheus, Istio"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "6641228194261fb156e88acfed2dcd79754d2dc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard, OpenCensus, and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.78935,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", OpenCensus, and Prometheus). The Metric <em>API</em> is also used by our <em>Telemetry</em> SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "dc117e1fa9345c0d05e7a8274b31b92b29134f0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.95053,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report metrics via the Metric <em>API</em>",
        "sections": "Report metrics via the Metric <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Use the Metric <em>API</em> to send custom metrics to the New Relic <em>platform</em>. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one",
        "Integrations built with the Telemetry SDKs"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "759fd7fa58ab2e074d0ba50b30be8c1096698304",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-10-06T23:47:51Z",
      "updated_at": "2021-08-26T14:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our core data ingest APIs: the Metric API, Trace API, Log API, and Event API. We offer open-source integrations for telemetry tools like Prometheus, Istio, and OpenCensus that were created using our Telemetry SDKs. If those solutions (or our other integrations) don't meet your needs, you can use the Telemetry SDKs to create your own telemetry data solutions. Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications. Integrations built with the Telemetry SDKs To see the integrations built using our Telemetry SDKs, see Open source telemetry integrations. For all monitoring solutions, see our integrations page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.97525,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our core <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. We offer open-source integrations for <em>telemetry</em> tools like Prometheus, Istio"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "dc117e1fa9345c0d05e7a8274b31b92b29134f0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.95052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report metrics via the Metric <em>API</em>",
        "sections": "Report metrics via the Metric <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Use the Metric <em>API</em> to send custom metrics to the New Relic <em>platform</em>. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.8157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api/metric-api-limits-restricted-attributes": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one",
        "Integrations built with the Telemetry SDKs"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "759fd7fa58ab2e074d0ba50b30be8c1096698304",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-10-06T23:47:51Z",
      "updated_at": "2021-08-26T14:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our core data ingest APIs: the Metric API, Trace API, Log API, and Event API. We offer open-source integrations for telemetry tools like Prometheus, Istio, and OpenCensus that were created using our Telemetry SDKs. If those solutions (or our other integrations) don't meet your needs, you can use the Telemetry SDKs to create your own telemetry data solutions. Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications. Integrations built with the Telemetry SDKs To see the integrations built using our Telemetry SDKs, see Open source telemetry integrations. For all monitoring solutions, see our integrations page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.97523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our core <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. We offer open-source integrations for <em>telemetry</em> tools like Prometheus, Istio"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "6641228194261fb156e88acfed2dcd79754d2dc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard, OpenCensus, and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.78934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", OpenCensus, and Prometheus). The Metric <em>API</em> is also used by our <em>Telemetry</em> SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "dc117e1fa9345c0d05e7a8274b31b92b29134f0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.9505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report metrics via the Metric <em>API</em>",
        "sections": "Report metrics via the Metric <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Use the Metric <em>API</em> to send custom metrics to the New Relic <em>platform</em>. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one",
        "Integrations built with the Telemetry SDKs"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "759fd7fa58ab2e074d0ba50b30be8c1096698304",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-10-06T23:47:51Z",
      "updated_at": "2021-08-26T14:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our core data ingest APIs: the Metric API, Trace API, Log API, and Event API. We offer open-source integrations for telemetry tools like Prometheus, Istio, and OpenCensus that were created using our Telemetry SDKs. If those solutions (or our other integrations) don't meet your needs, you can use the Telemetry SDKs to create your own telemetry data solutions. Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications. Integrations built with the Telemetry SDKs To see the integrations built using our Telemetry SDKs, see Open source telemetry integrations. For all monitoring solutions, see our integrations page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.97523,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our core <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. We offer open-source integrations for <em>telemetry</em> tools like Prometheus, Istio"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "6641228194261fb156e88acfed2dcd79754d2dc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard, OpenCensus, and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.78934,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", OpenCensus, and Prometheus). The Metric <em>API</em> is also used by our <em>Telemetry</em> SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.81566,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events": [
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one",
        "Integrations built with the Telemetry SDKs"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "759fd7fa58ab2e074d0ba50b30be8c1096698304",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-10-06T23:47:51Z",
      "updated_at": "2021-08-26T14:51:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our core data ingest APIs: the Metric API, Trace API, Log API, and Event API. We offer open-source integrations for telemetry tools like Prometheus, Istio, and OpenCensus that were created using our Telemetry SDKs. If those solutions (or our other integrations) don't meet your needs, you can use the Telemetry SDKs to create your own telemetry data solutions. Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications. Integrations built with the Telemetry SDKs To see the integrations built using our Telemetry SDKs, see Open source telemetry integrations. For all monitoring solutions, see our integrations page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.97522,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "sections": "<em>Telemetry</em> SDKs: Report custom <em>telemetry</em> <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Our <em>Telemetry</em> SDKs are an open source set of <em>API</em> client libraries that send <em>data</em> to the New Relic <em>platform</em>. Under the hood, these SDKs rely on our core <em>data</em> <em>ingest</em> <em>APIs</em>: the Metric <em>API</em>, Trace <em>API</em>, Log <em>API</em>, and Event <em>API</em>. We offer open-source integrations for <em>telemetry</em> tools like Prometheus, Istio"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "6641228194261fb156e88acfed2dcd79754d2dc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard, OpenCensus, and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.78932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", OpenCensus, and Prometheus). The Metric <em>API</em> is also used by our <em>Telemetry</em> SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "dc117e1fa9345c0d05e7a8274b31b92b29134f0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.9505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report metrics via the Metric <em>API</em>",
        "sections": "Report metrics via the Metric <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Use the Metric <em>API</em> to send custom metrics to the New Relic <em>platform</em>. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    }
  ],
  "/docs/telemetry-data-platform/ingest-apis/telemetry-sdks-report-custom-telemetry-data": [
    {
      "sections": [
        "Introduction to the Metric API",
        "What is the Metric API?",
        "Requirements",
        "Get started",
        "Find and use your data",
        "Alert on metric data",
        "Data retention",
        "Troubleshooting"
      ],
      "title": "Introduction to the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "6641228194261fb156e88acfed2dcd79754d2dc5",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/introduction-metric-api/",
      "published_at": "2021-10-07T02:25:37Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Metric API can be used to send metric data to New Relic from a variety of sources. This API is how metrics from some of our integrations and exporters get into New Relic. Want to try out our Metric API? Create a New Relic account for free! No credit card required. What is the Metric API? The Metric API is a way to get metric data into New Relic. The API works by sending a POST request to our HTTP endpoint with a JSON payload containing the metric data. The Metric API is how metrics are ingested from some of our integrations, including our open source exporters (like DropWizard, OpenCensus, and Prometheus). The Metric API is also used by our Telemetry SDKs, which are language-specific tools that make it easier to use our data-ingest APIs. The Metric API can be used to: Report metric data to New Relic without a New Relic agent. Integrate metric data from an open source or in-house developed tool, library, or framework. Fully control the metric data you're sending, including the resolution and associated dimensions. Leverage the power of NRQL, New Relic's query language, for querying your metric data. Set up alerts for your metric data. Requirements Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name metric-api.newrelic.com or metric-api.eu.newrelic.com. You'll need a New Relic license key for the New Relic account you want to send data to. For information on limits and restricted attributes, see Metric API requirements and limits. Get started If we don't have an existing integration that meets your metric-reporting needs, you have two options: Use our Telemetry SDKs, which are language-specific tools that help you send us metrics and other data. Use the Metric API directly. Find and use your data You can find data sent via the Metric API (including from integrations that use this API) in these locations: From one.newrelic.com, select Explorer and look for your service. By querying the Metric data type. For example, you can use NRQL to run: SELECT * FROM Metric Copy For more on querying, see Metric query examples. For information on querying in general, see Query data. Alert on metric data To alert on metrics created with the Metric API, use NRQL alert conditions: Select the NRQL category when defining your condition, then use the FROM Metric ... NRQL query syntax to express it. When you create these alert conditions, Alerts automatically uses the finest granularity data available (the raw metric data points) to evaluate alerts. Data retention All raw metric data points will be retained for 30 days. All additional aggregated data derived from the raw metric data points (for example, one-minute rollups) will be retained for 13 months. Any change to the retention period beyond such periods may result in a charge to you. Troubleshooting See Troubleshoot an NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.78932,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the Metric <em>API</em>",
        "sections": "Find <em>and</em> use your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ", OpenCensus, and Prometheus). The Metric <em>API</em> is also used by our <em>Telemetry</em> SDKs, which are language-specific tools that make it easier to use our <em>data</em>-<em>ingest</em> <em>APIs</em>. The Metric <em>API</em> can be used to: Report metric <em>data</em> to New Relic without a New Relic agent. Integrate metric <em>data</em> from an open source"
      },
      "id": "6107858fe7b9d2f9dcfc108e"
    },
    {
      "sections": [
        "Report metrics via the Metric API",
        "Quick start: Send metric data",
        "Endpoint URL",
        "Tip",
        "HTTP request headers",
        "HTTP request body",
        "Structure",
        "JSON payload creating two metrics",
        "Required key-value pairs",
        "JSON payload with three metric types",
        "Share attributes across metrics with common",
        "Example of common attributes",
        "Response validation and status codes",
        "Missing data with 202 response",
        "Status codes"
      ],
      "title": "Report metrics via the Metric API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "dc117e1fa9345c0d05e7a8274b31b92b29134f0c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/report-metrics-metric-api/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-27T01:24:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Metric API to send custom metrics to the New Relic platform. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric data. Quick start: Send metric data We report the metric types count, gauge, and summary. For more information on metrics see our documentation. Metric data is submitted to New Relic through an HTTP POST request. Each request is composed of one or more metric data points, which consist of a metric name, a timestamp, and a value. Follow this example to send your first metric data points to New Relic: Get the license key for the account you want to report data to. Insert the license key into the following JSON, and then send the JSON to our endpoint. This example creates a single metric data point for a metric named memory.heap, but you can create additional attributes or data points by specifying metric types or adding optional common blocks. curl -vvv -k -H \"Content-Type: application/json\" \\ -H \"Api-Key: NEW_RELIC_LICENSE_KEY\" \\ -X POST https://metric-api.newrelic.com/metric/v1 \\ --data '[{ \"metrics\":[{ \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":2.3, \"timestamp\":CURRENT_TIME, \"attributes\":{\"host.name\":\"dev.server.com\"} }] }]' Copy The metric should be available in New Relic in a few seconds. You can query the data from any NRQL interface using this query: FROM Metric SELECT max(memory.heap) TIMESERIES Copy For more on where data shows up, see Find Metric API data. Endpoint URL Use an HTTP POST when sending metric data to the metric API endpoint: https://metric-api.newrelic.com/metric/v1 Copy Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. HTTP request headers Include the following HTTP request headers with the POST request. You can send some parameters as query parameters instead of request headers. Header Send as a query parameter? Details Content-Type No Required. Must be application/json. Content-Length No Required (usually set automatically by the HTTP client). The length of the request body in octets (8-bit bytes) unless sent with chunked encoding. This header is generally set by default by the underlying HTTP client sending the data and in most cases should not require any additional effort by the end user. Api-Key Yes Required. A license key for the account you want to report data to. If this is provided as both a header and a query parameter, the values must match. Content-Encoding No Required if GZIP. The value must be GZIP or Identity. If no value is present, then Identity is assumed. x-request-id No Optional - Reserved for future use. The value must be a valid UUID4. The value is expected to be unique for each request. HTTP request body The body of the HTTP POST request must be in JSON format. The following describes the requirements and recommendations for the JSON payload. The payload must be encoded as UTF-8. Structure The JSON payload uses this structure: The JSON payload is an array of maps. Each map must contain a metrics key whose value is an array containing one or more metric data points. A metric data point is identified by a name, value, and timestamp along with an optional set of attributes. JSON payload creating two metrics This example payload creates two metrics. service.errors.all is a count metric with three attributes and service.memory is a gauge metric with two attributes. [ { \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"service.response.statuscode\": \"400\", \"host.name\": \"dev.server.com\", \"service.name\": \"foo\" } }, { \"name\": \"service.memory\", \"type\": \"gauge\", \"value\": 2.7, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Required key-value pairs Each metric data point map in the metrics array uses the following key-value structure: Key Description name string Required. The name of the metric. The value must be less than 255 characters. value number or map Required. The value varies depending on the metric type. For gauge and count the value should be a single number. For summary, the value should be a map with key-value pairs specifying the count, sum, min, and max. timestamp long Required. The metric's start time in Unix time. Defaults to the current time in UTC timezone. This field also support seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and query. Metrics reported with a timestamp older than 48 hours ago or newer than 24 hours from the time they are reported are dropped. interval.ms positive long Required for count and summary metric types. The length of the time window. type Recommended. This should be one of the supported metric types. If you do not specify a type, then this will default to a gauge. attributes strings, JSON numbers, or booleans Recommended. A map of key value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Keys are case-sensitive and must be less than 255 characters. JSON payload with three metric types Here's an example payload containing one metric data point for each metric type: [ { \"metrics\": [ { \"name\": \"cache.misses\", \"type\": \"count\", \"value\": 15, \"timestamp\": [CURRENT_TIME](#optional-map-attributes), \"interval.ms\": 10000, \"attributes\": { \"cache.name\": \"myCache\", \"host.name\": \"dev.server.com\" } }, { \"name\": \"temperature\", \"type\": \"gauge\", \"value\": 15, \"timestamp\": CURRENT_TIME, \"attributes\": { \"city\": \"Portland\", \"state\": \"Oregon\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"interval.ms\": 10000, \"timestamp\": CURRENT_TIME, \"attributes\": { \"host.name\": \"dev.server.com\", \"app.name\": \"foo\" } } ] } ] Copy Share attributes across metrics with common If you want to include a set of attributes on multiple metrics (and not add the same attributes for each metric), you can use the common block. This is an optional map that specifies information that applies to all associated metric data points. Values in the common section will be overridden if the same key exists on a metric data point. The block can include: Attribute Description timestamp long The metric's start time in Unix time. This defaults to the current time in the UTC timezone. This field also supports seconds, microseconds, and nanoseconds. However, the data will be converted to milliseconds for storage and later querying. interval.ms positive long Required for count and summary.The length of the time window. attributes strings, JSON numbers, or booleans A map of key-value pairs associated with this specific metric. Values can be strings, JSON numbers, or booleans. Example of common attributes In the following example payload, three metrics are sent. All three metrics share app.name and host.name attributes, specified in the common block. Each metric also has a unique value for another attribute, server.response.statuscode. [ { \"common\" : { \"timestamp\": 1531414060739, \"interval.ms\": 10000, \"attributes\": { \"app.name\": \"foo\", \"host.name\": \"dev.server.com\" } }, \"metrics\": [ { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 9, \"attributes\": { \"service.response.statuscode\": \"400\" } }, { \"name\": \"service.errors.all\", \"type\": \"count\", \"value\": 4, \"attributes\": { \"service.response.statuscode\": \"500\" } }, { \"name\": \"service.response.duration\", \"type\": \"summary\", \"value\": { \"count\": 5, \"sum\": 0.004382655, \"min\": 0.0005093, \"max\": 0.001708826 }, \"attributes\": { \"service.response.statuscode\": \"200\" } } ] } ] Copy Response validation and status codes The Metric API returns a 202 response code for successful requests. When your data is accepted, an HTTP 202 response code is returned with a response structure like this: HTTP/1.1 202 Accepted Content-Type: application/json; charset=UTF-8 Content-Length: 52 Access-Control-Allow-Methods: GET, POST, PUT, HEAD, OPTIONS Access-Control-Allow-Credentials: true Access-Control-Allow-Origin: * Connection: keep-alive {\"requestId\":\"f0e7bfff-001a-b000-0000-01682bcf4565\"} Copy Missing data with 202 response A 202 code indicates the API did receive your data, and that the data passed basic validation checks. Normally, your data will be available for querying within a few seconds. However, New Relic runs additional validation asynchronously after receiving your data. If you receive a 202 response but can't find your metric, this indicates that New Relic found an error during this asynchronous validation. You can find these errors by querying NrIntegrationError events in the account associated with the Insert API key you used. The requestId for each request will be tagged on the NrIntegrationError event. For more information, see Troubleshoot an NRIntegrationError event. Status codes The Metric API can return the following HTTP status codes: Status code Definition 202 Data accepted. 400 Structure of the request is invalid. 403 Authentication failure. 404 The request path is incorrect. 405 Used a request method other than POST. 408 The request took too long to reach the endpoint. 411 The Content-Length header wasn’t included. 413 The payload was too big. Payloads must be under 1MB (10^6 bytes). 414 The request URI was too long. 415 The Content-Type or Content-Encoding was invalid. 429 The request rate quota has been exceeded. 431 The request headers are too long. 5xx There was a server error (please retry).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.9505,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Report metrics via the Metric <em>API</em>",
        "sections": "Report metrics via the Metric <em>API</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "Use the Metric <em>API</em> to send custom metrics to the New Relic <em>platform</em>. This document includes a quick start to send your first custom metric, plus detailed information on how to format and send your metric <em>data</em>. Quick start: Send metric <em>data</em> We report the metric types count, gauge, and summary"
      },
      "id": "6107859064441f8baf47abd9"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.81558,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph": [
    {
      "sections": [
        "Drop data using Prometheus remote write",
        "Tip",
        "Drop entire metric data points from remote write integration",
        "Example",
        "Drop specific labels or attributes from data points",
        "Prometheus or NerdGraph?",
        "Considerations for the Prometheus config file method",
        "Considerations the NerdGraph method",
        "Learn more"
      ],
      "title": "Drop data using Prometheus remote write",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Install and configure remote write"
      ],
      "external_id": "f3e07dd4f6bbdb65881f13035af5af172c5409e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/install-configure/remote-write-drop-data/",
      "published_at": "2021-10-08T06:42:36Z",
      "updated_at": "2021-07-09T08:33:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can drop data you don't want to keep by changing the remote_write section of the YAML config file. Tip You can also drop remote write data using NerdGraph. For more information, see Drop data using NerdGraph. Drop entire metric data points from remote write integration If a target is sending a noisy metric that you don't want sent to New Relic, you can specify that New Relic should drop that data. Example Let's say you don't want to receive data for the metric node_memory_active_bytes from an instance running at localhost:9100. Using the write_relabel_config entry shown below, you can target the metric name using the __name__ label in combination with the instance name. remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - source_labels: ['__name__', 'instance'] regex: 'node_memory_active_bytes;localhost:9100' action: 'drop' Copy This tells Prometheus that you want to do some action against metrics with these labels. To limit which metrics with these labels are affected, you must include some value for regex. By default this value is set to .* and it will include all metrics. In this case, it will drop all metric data points coming out of Prometheus via remote write. Drop specific labels or attributes from data points If a target is sending specific labels or attributes you're not interested in receiving, you can drop these from the metrics you receive. Example Let's say one of your targets is sending a bunch of extra attributes you're not interested in receiving. These might include things like high cardinality attributes such as unique machine identifiers, JVM IDs, or similar. In this case, you need to change both the remote_write and the scrape_configs section of the YAML file. The result will look something like this: remote_write: - url: https://metric-api.newrelic.com/prometheus/v1/write?prometheus_server=macbook-server-cluster bearer_token: <redacted> write_relabel_configs: - regex: 'extraLabelToRemove.*' action: 'labeldrop' ... scrape_configs: # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config. - job_name: 'node' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9100'] labels: group: 'production' keepLabelName1: 'please-keep-me' extraLabelToRemove: 'please-remove-me' extraLabelToRemove1: 'please-remove-me' extraLabelToRemove2: 'please-remove-me' extraLabelToRemove4: 'please-remove-me' extraLabelToRemove3: 'please-remove-me' extraLabelToRemove5: 'please-remove-me' Copy Prometheus or NerdGraph? There are advantages to both dropping data using the method described on this page and using NerdGraph. This section is intended to help you figure out which method is better for your specific needs and preferences. Considerations for the Prometheus config file method With this method, your dropped data never leaves the associated Prometheus instance. This is a valuable feature if bytes transferred is a cost consideration on the app hosting side. However, this method may be less appealing than the NerdGraph option due to the following considerations: Maintained via config yaml files that need to be loaded onto each Prometheus instance (or via a shared storage mechanism) Requires access to Prometheus server, meaning that either: The server needs to be restarted Served must be be accessed at port with path /-/reload (assuming the server has lifecycle management enabled as described here in the Prometheus configuration docs. Considerations the NerdGraph method NerdGraph is a great option if you want to manage all your data dropping in a single place. It can also be updated easily via the API and requires no restart or interaction with Prometheus. However, this method applies rules to all incoming data points. This means that you should set up your rules with careful consideration using WHERE filtering. For more information, see Drop data using NerdGraph. Learn more Send Prometheus metric data to New Relic Prometheus High Availability (HA)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1741.3243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Drop</em> <em>data</em> <em>using</em> Prometheus remote write",
        "sections": "<em>Drop</em> <em>data</em> <em>using</em> Prometheus remote write",
        "body": "You can <em>drop</em> <em>data</em> you don&#x27;t want to keep by changing the remote_write section of the YAML config file. Tip You can also <em>drop</em> remote write <em>data</em> <em>using</em> <em>NerdGraph</em>. For more information, see <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. <em>Drop</em> entire metric <em>data</em> points from remote write integration If a target is sending"
      },
      "id": "60e809e4e7b9d298bafc1035"
    },
    {
      "sections": [
        "Security guide",
        "Tip",
        "Security Program",
        "Security Domains",
        "Security Certifications",
        "Data Control, Facilities, and Encryption",
        "Law Enforcement Request Report"
      ],
      "title": "Security guide",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "356f0d11ffcb62208a743a0a7c127f5f6da9c940",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-guide/",
      "published_at": "2021-10-07T02:08:45Z",
      "updated_at": "2021-09-19T15:21:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Last updated September 17, 2021. This is supplement to our security policy and serves as a guide to New Relic’s description of its Services, functionalities, and features. Tip We may update the URLs in this document without notice. Security Program New Relic follows \"privacy by design\" principles as described here: https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Security Domains New Relic’s policies and procedures cover industry-recognized security domains such as Endpoint Protection; Portable Media Security; Mobile Device Security; Wireless Security; Configuration Management; Vulnerability Management; Network Protection; Transmission Protection; Password Management; Access Control, Audit Logging & Monitoring; Education, Training, and Awareness; Third Party Assurance; Incident Management; Business Continuity and Disaster Recover; Risk Management; Data Protection & Privacy; and Service Management Systems. Security Certifications New Relic audits its Services against industry standards as described at https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/. Data Control, Facilities, and Encryption New Relic's customers can send data to New Relic's APIs by (1) using New Relic's software, (2) using vendor-neutral software that is managed and maintained by a third-party such as via OpenTelemetry instrumentation provided by opentelemetry.io, or (3) from third-party systems that customer's manage and/or control. New Relic's customers can use New Relic's Services such as NerdGraph to filter out and drop data. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/. New Relic's customers can adjust their data retention periods as appropriate for their needs. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-retention/#adjust-retention. New Relic Logs obfuscates numbers that match known patterns, such as bank card and social security numbers as described here: https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/. New Relic honors requests to delete personal data in accordance with applicable privacy laws. Please see https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Customers may use New Relic's APIs to query data, such as NerdGraph described here, and New Relic Services to export the data to other cloud providers. Customers can configure its log forwarder [https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/] before sending infrastructure logs to New Relic. For New Relic Customers in New Relic US, FedRAMP and HIPAA-enabled environments, Customer Data is replicated to the off-site backup system via Amazon Simple Storage Service (S3). Category of Customer Description FedRAMP HIPAA-enabled US Gen Pop EU Gen Pop Data is stored in Amazon Web Services (“AWS”). Limited Data is stored in IBM Data for New Relic Incident Intelligence is stored in Google Cloud New Relic regularly tests, assess, and evaluates its measures to ensure the security of processing using industry-recognized standards and uses independent third-party auditors as provided below: Annual SOC 2 Type 2 Annual FedRAMP assessment by an independent third-party pursuant to NIST 800-53 rev 4 Moderate authorization. Annual HITRUST-validated assessment by an independent third-party *Pursuing CY2021 Q4 ISO 27001 *Pursuing CY2021 TISAX *Pursuing CY2021 The Services that operate on Amazon Web Services (“AWS”) are protected by the security and environmental controls of AWS. Detailed information about AWS security is available at https://aws.amazon.com/security/ and http://aws.amazon.com/security/sharing-the-security-responsibility/. Data encryption at rest utilizes FIPS 140-2 compliant encryption methodology. For AWS SOC Reports, please see https://aws.amazon.com/compliance/soc-faqs/. The Services that operate on Google Cloud Platform (\"GCP\") are protected by the security and environmental controls of GCP. Detailed information about GCP security is available at https://cloud.google.com/docs/tutorials#security. For GCP reports, please see https://cloud.google.com/security/compliance/. IBM Deft Zayo QTS Law Enforcement Request Report New Relic has not to date received any request for customer data from a law enforcement or other government agency (including under any national security process), and has not made any corresponding disclosures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1465.6074,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Data</em> Control, Facilities, and Encryption",
        "body": " that customer&#x27;s manage and&#x2F;or control. New Relic&#x27;s customers can <em>use</em> New Relic&#x27;s Services such as <em>NerdGraph</em> to filter out and <em>drop</em> <em>data</em>. See https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;telemetry-<em>data</em>-platform&#x2F;manage-<em>data</em>&#x2F;<em>drop</em>-<em>data</em>-<em>using</em>-<em>nerdgraph</em>&#x2F;. New Relic&#x27;s customers can adjust their <em>data</em> retention periods as appropriate"
      },
      "id": "6147558128ccbc973a56a863"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-10-07T06:31:22Z",
      "updated_at": "2021-09-13T20:40:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing plan, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing plan. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1349.571,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage your <em>data</em>",
        "sections": "Manage your <em>data</em>",
        "tags": "Telemetry <em>Data</em> Platform",
        "body": " have a strategy for you. Learn about reducing the amount of <em>data</em> that comes into NRDB in Manage <em>data</em> coming into New Relic. Learn about customizing storage so you only store the <em>data</em> you want, for the period you want in Manage <em>data</em> stored in New Relic. Learn about dropping <em>data</em> in <em>Drop</em> <em>data</em> <em>using</em> <em>NerdGraph</em>. And for dropping log <em>data</em>, see <em>Drop</em> <em>data</em> with <em>drop</em> filter rules."
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic": [
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.2287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-10-07T06:31:22Z",
      "updated_at": "2021-09-13T20:40:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing plan, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing plan. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.67499,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB"
      },
      "id": "603e96ff28ccbcf8bceba796"
    },
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-08-09T00:31:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.16339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ". limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click <em>Manage</em> your <em>data</em> and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set"
      },
      "id": "60446a7c64441f48d7378f2b"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-data-retention": [
    {
      "sections": [
        "Security guide",
        "Tip",
        "Security Program",
        "Security Domains",
        "Security Certifications",
        "Data Control, Facilities, and Encryption",
        "Law Enforcement Request Report"
      ],
      "title": "Security guide",
      "type": "docs",
      "tags": [
        "Licenses",
        "License information",
        "Referenced policies"
      ],
      "external_id": "356f0d11ffcb62208a743a0a7c127f5f6da9c940",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/license-information/referenced-policies/security-guide/",
      "published_at": "2021-10-07T02:08:45Z",
      "updated_at": "2021-09-19T15:21:37Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Last updated September 17, 2021. This is supplement to our security policy and serves as a guide to New Relic’s description of its Services, functionalities, and features. Tip We may update the URLs in this document without notice. Security Program New Relic follows \"privacy by design\" principles as described here: https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Security Domains New Relic’s policies and procedures cover industry-recognized security domains such as Endpoint Protection; Portable Media Security; Mobile Device Security; Wireless Security; Configuration Management; Vulnerability Management; Network Protection; Transmission Protection; Password Management; Access Control, Audit Logging & Monitoring; Education, Training, and Awareness; Third Party Assurance; Incident Management; Business Continuity and Disaster Recover; Risk Management; Data Protection & Privacy; and Service Management Systems. Security Certifications New Relic audits its Services against industry standards as described at https://docs.newrelic.com/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services/. Data Control, Facilities, and Encryption New Relic's customers can send data to New Relic's APIs by (1) using New Relic's software, (2) using vendor-neutral software that is managed and maintained by a third-party such as via OpenTelemetry instrumentation provided by opentelemetry.io, or (3) from third-party systems that customer's manage and/or control. New Relic's customers can use New Relic's Services such as NerdGraph to filter out and drop data. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/drop-data-using-nerdgraph/. New Relic's customers can adjust their data retention periods as appropriate for their needs. See https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-retention/#adjust-retention. New Relic Logs obfuscates numbers that match known patterns, such as bank card and social security numbers as described here: https://docs.newrelic.com/docs/logs/log-management/get-started/new-relics-log-management-security-privacy/. New Relic honors requests to delete personal data in accordance with applicable privacy laws. Please see https://docs.newrelic.com/docs/security/security-privacy/data-privacy/data-privacy-new-relic/. Customers may use New Relic's APIs to query data, such as NerdGraph described here, and New Relic Services to export the data to other cloud providers. Customers can configure its log forwarder [https://docs.newrelic.com/docs/logs/enable-log-management-new-relic/enable-log-monitoring-new-relic/forward-your-logs-using-infrastructure-agent/] before sending infrastructure logs to New Relic. For New Relic Customers in New Relic US, FedRAMP and HIPAA-enabled environments, Customer Data is replicated to the off-site backup system via Amazon Simple Storage Service (S3). Category of Customer Description FedRAMP HIPAA-enabled US Gen Pop EU Gen Pop Data is stored in Amazon Web Services (“AWS”). Limited Data is stored in IBM Data for New Relic Incident Intelligence is stored in Google Cloud New Relic regularly tests, assess, and evaluates its measures to ensure the security of processing using industry-recognized standards and uses independent third-party auditors as provided below: Annual SOC 2 Type 2 Annual FedRAMP assessment by an independent third-party pursuant to NIST 800-53 rev 4 Moderate authorization. Annual HITRUST-validated assessment by an independent third-party *Pursuing CY2021 Q4 ISO 27001 *Pursuing CY2021 TISAX *Pursuing CY2021 The Services that operate on Amazon Web Services (“AWS”) are protected by the security and environmental controls of AWS. Detailed information about AWS security is available at https://aws.amazon.com/security/ and http://aws.amazon.com/security/sharing-the-security-responsibility/. Data encryption at rest utilizes FIPS 140-2 compliant encryption methodology. For AWS SOC Reports, please see https://aws.amazon.com/compliance/soc-faqs/. The Services that operate on Google Cloud Platform (\"GCP\") are protected by the security and environmental controls of GCP. Detailed information about GCP security is available at https://cloud.google.com/docs/tutorials#security. For GCP reports, please see https://cloud.google.com/security/compliance/. IBM Deft Zayo QTS Law Enforcement Request Report New Relic has not to date received any request for customer data from a law enforcement or other government agency (including under any national security process), and has not made any corresponding disclosures.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 593.90857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Data</em> Control, Facilities, and Encryption",
        "body": " that customer&#x27;s <em>manage</em> and&#x2F;or control. New Relic&#x27;s customers can use New Relic&#x27;s Services such as NerdGraph to filter out and drop <em>data</em>. See https:&#x2F;&#x2F;docs.newrelic.com&#x2F;docs&#x2F;telemetry-<em>data</em>-platform&#x2F;<em>manage</em>-<em>data</em>&#x2F;drop-<em>data</em>-using-nerdgraph&#x2F;. New Relic&#x27;s customers can adjust their <em>data</em> <em>retention</em> periods as appropriate"
      },
      "id": "6147558128ccbc973a56a863"
    },
    {
      "sections": [
        "Introduction to New Relic NerdGraph, our GraphQL API",
        "What is NerdGraph?",
        "Important",
        "Use the GraphiQL explorer",
        "Requirements and endpoints",
        "What can you do with NerdGraph?",
        "NerdGraph terminology",
        "Tips on using the GraphiQL explorer",
        "Query accounts a New Relic user can access",
        "Query user, account, and NRQL in one request"
      ],
      "title": "Introduction to New Relic NerdGraph, our GraphQL API",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Get started"
      ],
      "external_id": "e8e96c16cd75f494ebfacb3bc53b4ee9ccf1c727",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/get-started/introduction-new-relic-nerdgraph/",
      "published_at": "2021-10-07T00:31:14Z",
      "updated_at": "2021-08-27T08:50:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NerdGraph is our GraphQL-format API that lets you query New Relic data and configure some New Relic features. What is NerdGraph? New Relic has several APIs. NerdGraph is the API we recommend for querying New Relic data and for performing some specific configurations (learn more about features). NerdGraph provides a single API interface for returning data from New Relic’s various APIs and microservices. Over time, other configuration capabilities will be added to NerdGraph. Important NerdGraph isn’t used for data ingest. For that, you'd use our data ingest APIs. NerdGraph is built using GraphQL, which is an open source API format that allows you to request exactly the data needed, with no over-fetching or under-fetching. For a lesson in how to use NerdGraph, watch this 7-minute video: Want to watch more video tutorials? Go to the New Relic University’s Intro to NerdGraph. Or see the online course on New Relic APIs. Use the GraphiQL explorer To get started using GraphQL, we recommend playing around with our GraphiQL explorer (GraphiQL is an open source graphical interface for using GraphQL). You can use it to explore our data schema, to read built-in object definitions, and to build and execute queries. To use GraphQL, you’ll need a user-specific New Relic API key called a user key. You can generate one or find an existing one from the GraphiQL explorer’s API key dropdown. To find the GraphiQL explorer: If your New Relic account uses an EU data center, go to api.eu.newrelic.com/graphiql. Otherwise use api.newrelic.com/graphiql. For tips on how to build queries, see Build queries. Requirements and endpoints To use NerdGraph, you need a New Relic user key, which can be generated and accessed from the GraphiQL explorer. The endpoints are: Main endpoint: https://api.newrelic.com/graphql Endpoint for accounts using EU data center: https://api.eu.newrelic.com/graphql To access the endpoint, use the following cURL command: curl -X POST https://api.newrelic.com/graphql \\ -H 'Content-Type: application/json' \\ -H 'API-Key: YOUR_NEW_RELIC_USER_KEY' \\ -d '{ \"query\": \"{ requestContext { userId apiKey } }\" } ' Copy What can you do with NerdGraph? NerdGraph functionality can be broken down into two main categories: Querying New Relic data. You can fetch data for a variety of purposes, including using it in a programmatic workflow, or building a New Relic One app for custom data visualizations. Configuring New Relic features. There are a variety of configurations available and more will be added over time. You can do things like add tags, configure workloads, or customize \"golden metrics.\" You can use NerdGraph to return a wide range of New Relic data but we’ve created some tutorials for common use cases: Topic Tutorials Your monitored entities Get data about entities Understand entity relationships and dependencies (used to build service maps) Query and configure \"golden metrics\" (important entity metrics) Querying data Query using NRQL (our query language) Tags Add and manage tags Dashboards Create dashboards Export dashboards to other accounts Export dashboards as files Migrate from Insights Dashboard API to NerdGraph Alerts See all alert-related tutorials Applied Intelligence View and configure topology Workloads View and configure workloads Manage keys Create and manage keys (license keys used for data ingest, and user keys) Manage data Convert event data to metric data Drop data Distributed tracing Query distributed tracing data Configure Infinite Tracing New Relic One apps Build a New Relic One app Cloud integrations (AWS, Azure, GCP) Configure cloud integrations Partners and resellers Manage subscriptions (only for partners using original pricing plan) Data partitions Manage data partitions Date retention Manage data retention NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term Definition Queries and mutations There are two classes of GraphQL operations: Queries are basic requests used only to fetch data. These queries are not static, meaning that you can ask for more data or less data, depending on your needs. For each query, you can specify exactly what data you want to retrieve, as long as it is supported by the schema. Mutations are requests that perform an action, such as creating a resource or changing configuration. Mutations require the keyword mutation, as well as the name of the mutation. Type Data in GraphQL is organized into types. Types can be scalars (like strings, numbers, or booleans) or object types. An object type is a custom type made up of a collection of fields. For example, an object type called User may represent a user in a system. Field A field represents a piece of information on an object type that can be queried. Fields can be scalars, lists, or objects. For example, a User object type could have a string field called name. Interface An interface is an abstract type that represents a collection of common fields that other object types can implement. Tips on using the GraphiQL explorer You can make queries with the NerdGraph GraphiQL explorer. The explorer provides built-in schema definitions and features, including auto-complete and query validation. Query accounts a New Relic user can access You can query for the name of an account that an actor (a New Relic authorized user) has access to: query { actor { account(id: YOUR_ACCOUNT_ID) { name } } } Copy The response will mirror the query structure you defined in the request, making it easy to ask for the specific data that you want. { \"data\": { \"actor\": { \"account\": { \"name\": \"Data Nerd\" } } } } Copy Query user, account, and NRQL in one request The graph structure shows its capabilities when queries become more complex. For example, you can query for user information, account information, and make a NRQL query with one request. With REST API, this would take three different requests to three different endpoints. query { actor { account(id: YOUR_ACCOUNT_ID) { name nrql(query: \"SELECT * FROM Transaction\") { results } } user { name id } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 450.52823,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " cloud integrations Partners and resellers <em>Manage</em> subscriptions (only for partners using original pricing plan) <em>Data</em> partitions <em>Manage</em> <em>data</em> partitions Date <em>retention</em> <em>Manage</em> <em>data</em> <em>retention</em> NerdGraph terminology The following are terms that originate with GraphQL (the API format NerdGraph uses). Term"
      },
      "id": "6043ff97196a67d0a0960f55"
    },
    {
      "sections": [
        "Event data retention (original pricing plan)",
        "Important",
        "Data retention UI",
        "Overview of event data retention",
        "Extend your event retention",
        "Insights Pro",
        "How number of events stored is calculated",
        "Insights Pro event overage example",
        "Disable/enable Transaction and Pageview event reporting",
        "Tip",
        "Flexible data retention",
        "How it works",
        "Manage retention via UI",
        "Glossary",
        "For more help"
      ],
      "title": "Event data retention (original pricing plan)",
      "type": "docs",
      "tags": [
        "Accounts",
        "Original accounts and billing",
        "Original data retention"
      ],
      "external_id": "76d1289aad7de08b355bb8c313f9e7a42a5779d8",
      "image": "https://docs.newrelic.com/static/e53a1e416eb6116545627d3ec880d08e/e9c9b/flex-2.png",
      "url": "https://docs.newrelic.com/docs/accounts/original-accounts-billing/original-data-retention/event-data-retention-original-pricing-plan/",
      "published_at": "2021-10-07T11:11:22Z",
      "updated_at": "2021-08-27T08:49:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This doc is for accounts on our original pricing plan, not our New Relic One pricing plan. Not sure which you're on? See Overview of pricing plans. For organizations on New Relic One pricing, our various New Relic products report a wide range of event data. Different products have different data retention periods, and different ways to extend event data retention. You can customize the length of your event data retention through flexible event retention. Data retention UI For how to find the data retention UI, see Manage data. Overview of event data retention All New Relic product subscriptions come with a certain level of data retention that governs how long different types of data are retained. One type of data governed by data retention rules is event data. Event data is available in some UI charts and tables, and also available for querying via NRQL, our querying language. There are events reported from products by default, and there are custom events: each have their own retention rules, depending on the product and subscription level. Here are some examples of how different product subscriptions can affect event data retention: Free/Lite APM subscription: default-reported events available for 1 day. No custom events available. Pro APM subscription: default-reported events available for 8 days. Custom events available for 1 day (and able to be extended with Insight Pro). To see your subscriptions, go to the Account summary page. Extend your event retention Product Method APM, Browser, and Mobile Event data retention can be extended with a paid subscription to these products (see product data retention). To extend retention of both default-reported events and custom events further, you need an Insights Pro subscription. Infrastructure Event data retention can be extended with a paid Infrastructure subscription. See Infrastructure data retention rules. Synthetics Event data retention can be extended with a paid Synthetics subscription. See Synthetics data retention rules. Custom events Custom events reported by agent APIs or the Event API: Extension requires an Insights Pro subscription. Insights Pro Important As of April 12, 2021, we are upgrading Insights to an improved web and mobile experience! All of your Insights URLs will be redirected automatically to the corresponding dashboards in New Relic One. For more details about this migration and how you can easily plan for this transition, see our Explorers Hub post. A paid Insights subscription is what governs the extension of event data retention for: Our APM, Browser, Mobile, and Serverless products Custom events that come from an agent API or from the Event API Important Note that having an Insights Pro subscription doesn't require use of the Insights UI (insights.newrelic.com) to query your data: there are other querying options available. To see the data retention governed by your Insights subscription: go to the usage UI and select Insights usage. With an Insights Pro subscription, you can use flexible retention to customize how your event data is retained. This lets you keep only the data you need, for as long as you need it. How number of events stored is calculated This is an explanation of how the number of stored events are calculated by default for an Insights Pro subscription. (Note that with flexible retention, you have more fine-grained control over the retention period.) The events stored is calculated based on 1) total events stored over time (calculated based on the events generated per week) and 2) the weeks of data retention available. This equation can be represented like this: events stored = (events generated per week) * (weeks of retention) Copy An Insights Pro subscription provides a given number of weeks of data retention as well as a given number of events over that retention period. For example: (200M transactions per week) * (4 weeks of retention) = 800M events stored in Insights (16M transactions per week) * (50 weeks of retention) = 800M events stored in Insights For Insights Pro subscriptions, data is purged based on retention window, not volume. It is deleted from the system once it's past the retention window. For example: If your Insights license is for 800 million events with a 4 week retention period, your data would start being purged after it is older than four weeks. Temporary spikes in data exceeding your subscription level will still be recorded, but consistent overage should be solved by upgrading your subscription level or decreasing data collected. For customers without an Insights Pro subscription, New Relic may throttle or downsample events to a limit of not more than than 4,000 events per host per minute. Insights Pro event overage example In this example, you have an Insights Pro subscription with a license for 800 million events over 4 weeks, a rate of 200 million events per week. You have APM Pro, Browser Pro, and Mobile Enterprise. A fifth week of data is added via your subscriptions, bumping you to a total of 1 billion events stored within your plan: If you are using 975 million events, you are not over your retention. If you are using 1.25 billion events, you are over your retention. Disable/enable Transaction and Pageview event reporting Tip Owners or Admins The Insights Data summary UI page is used to see the types of events being reported. You can also use this page to enable and disable the reporting of PageView and Transaction events. To view Data summary: Go to insights.newrelic.com > Manage data. Select the Summary tab. Note: if you disable PageView or Transaction event reporting, this can affect some New Relic UI elements. You may see some empty charts on some UI pages that rely on this data. Go to insights.newrelic.com > Manage data > Summary. From the Summary tab, select Configure data sources. Toggle the appropriate switch on or off, then save. Toggling Transaction on or off will cause reporting agents to restart themselves. For more about configuring event reporting, see Event data retention. Flexible data retention With an Insights Pro subscription, you get access to flexible retention, which lets you define how some types of event data are retained. This lets you keep only the event data you need, for as long as you need it. You can manage your flexible retention through the UI or through our GraphQL API. Requirements to use this feature: An Insights Pro subscription or equivalent trial. Applies only for events governed by an Insights Pro subscription. To use this feature, you must be an account Owner or data retention add-on manager for your account. How it works To understand how standard event data retention works, first read Event data retention. With flexible retention, you specify the data retention for applicable event namespaces across your accounts. This gives you per-event namespace control of your data. The retention that you specify for an event namespace will be shared by all the event types under that namespace. If some namespaces are not relevant to you, you can avoid collecting their event data entirely. Your retention value can’t be lower than the included retention or higher than the default retention. You can control data retention either in our UI or by API. Manage retention via UI You can control data retention either using our GraphQL API or in the UI. To do this with the UI, go to the data retention UI. Your retention changes take effect within 24 hours after updating. Glossary To understand the terms used with flexible retention, see the following: Term Description Event namespace An event's namespace corresponds to one or more event types that share a single data retention value. For more information, see Event namespaces (types). You can also use NerdGraph to get the list of customizable event namespaces. Retention value The number (in days) that specifies how long your event data is stored. Retention rule The event namespace and retention value pair that you specify to override the current retention. Licensed retention Retention period that’s determined in weeks by your Insights Pro subscription contract. Included retention Retention period for which your data is stored but not charged under the Insights Pro subscription. For details, see the data retention details for a specific product. Paid retention Retention period for which your data is stored and is charged under the Insights Pro subscription. By default, your licensed retention determines this value but Flexible retention lets you override it. Default retention Retention period that comes out of the box. This is based on the total of included retention plus licensed retention. For information on managing retention settings with APIs, see the Manage data retention documentation. For more help For details about the data retention of other products or integrations, see that specific documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 448.9897,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Event <em>data</em> <em>retention</em> (original pricing plan)",
        "sections": "<em>Manage</em> <em>retention</em> via UI",
        "tags": "Original <em>data</em> <em>retention</em>",
        "body": " different <em>data</em> <em>retention</em> periods, and different ways to extend event <em>data</em> <em>retention</em>. You can customize the length of your event <em>data</em> <em>retention</em> through flexible event <em>retention</em>. <em>Data</em> <em>retention</em> UI For how to find the <em>data</em> <em>retention</em> UI, see <em>Manage</em> <em>data</em>. Overview of event <em>data</em> <em>retention</em> All New Relic product"
      },
      "id": "6043f713e7b9d2ccee579a1d"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/manage-your-data": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.63486,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.22867,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-08-09T00:31:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.16339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ". limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click <em>Manage</em> your <em>data</em> and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set"
      },
      "id": "60446a7c64441f48d7378f2b"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/nrintegrationerror": [
    {
      "sections": [
        "Troubleshoot Metric API with NRIntegrationError events",
        "Problem",
        "Solution",
        "View error details",
        "Match errors to ingested payloads",
        "Programmatically retrieve NrIntegrationError events",
        "Tip"
      ],
      "title": "Troubleshoot Metric API with NRIntegrationError events",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "ccf8273cce7691e5789b0c0a5c409f02efa87da3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/metric-api/troubleshoot-nrintegrationerror-events/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-08-08T00:45:50Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You sent metric data points to the Metric API, and are not seeing what you expect when querying the data. Use the following checklist to determine the root cause: Make sure you are querying the data correctly. Check the HTTP status codes returned by the API. Issues like authorization failures can be diagnosed with HTTP status codes. If you are sending data from a Prometheus server via New Relic's remote_write endpoint, check your Prometheus server logs for errors or non-2xx HTTP responses from the New Relic endpoint. Query your account for NrIntegrationError events. New Relic's ingestion endpoints are asynchronous, meaning the endpoint verifies the payload after it returns the HTTP response. If any issues occur while verifying your payload, then an NrIntegrationError event will be created in your account. New Relic also uses NrIntegrationError events to notify customers when various rate limits have been reached. Solution View error details For an introduction to using the NrIntegrationError event, see NrIntegrationError. Here's an example NRQL for examining issues with Metric API ingest: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature = 'Metrics' facet category, message limit 100 since 24 hours ago Copy The category indicates the type of error and the message provides more detailed information about the error. If the category is rateLimit, then you should also examine the rateLimitType field for more information on the type of rate limiting. Category rateLimitType Description and solution BadRequest (not set) There is an issue with the JSON payload. These include JSON syntax errors, attribute names, or values that are too long. Check the message field to determine the exact issue. Then review the JSON payload, and update it to ensure it meets the proper semantic guidelines. RateLimit DatapointsPerMinute You are sending too many datapoints per minute. If you get this error, you can either send data less frequently, or request changes to your metric rate limits by contacting your New Relic account representative, or visiting our Support portal. RateLimit UniqueTimeseriesPerDay You have an attribute with a high number of unique values, like containerId or URI. To resolve this error, review any attributes that may be causing the issue and remove them. If desired, you can use a data dropping rule to remove attributes at ingest time. RateLimit UniquePrometheusTimeseries You have Prometheus servers reporting too many unique timeseries via New Relic's remote_write endpoint. Reduce the number of unique timeseries reported by modifying your Prometheus server configuration to reduce the number of targets being scraped, or by using relabel rules in the remote_write section of your server configuration to drop timeseries or highly unique labels. RateLimit RequestsPerMinute Too many requests per minute are being sent. To resolve this, put more datapoints in each request, and send them less frequently. RateLimit ErrorGroupsPerDay You have exceeded your daily error group limit. Incoming error groups will be dropped for the remainder of the day and will continue as normal after UTC midnight. To resolve this, reduce the amount of unique error messages collected by New Relic. Match errors to ingested payloads When an NrIntegrationError event is created as a result of a syntax issue with the HTTP request payload, then the event contains the attributes apiKeyPrefix and requestId. The apiKeyPrefix matches the first 6 characters of the API key used to send the data. The requestId matches the requestId sent in the HTTP response. To view these fields, run this NRQL query: SELECT message, apiKeyPrefix, requestId FROM NrIntegrationError limit 100 Copy To verify a specific requestId, run this NRQL query: SELECT * FROM NrIntegrationError where requestId ='REQUEST_ID' Copy Programmatically retrieve NrIntegrationError events To programmatically retrieve these errors: Ensure you have an Insights query API key (go to insights.newrelic.com > Manage data > API keys). Create an HTTP request as shown below: Tip If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. curl -H \"Accept: application/json\" -H \"X-Query-Key:YOUR_API_KEY_HERE\" \"https://insights-api.newrelic.com/v1/accounts/YOUR_ACCOUNT_HERE/query?nrql=SELECT%20*%20FROM%20NrIntegrationError%20where%20newRelicFeature='Metrics'\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.2224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot Metric API with <em>NRIntegrationError</em> <em>events</em>",
        "sections": "Troubleshoot Metric API with <em>NRIntegrationError</em> <em>events</em>",
        "tags": "<em>Ingest</em> and manage <em>data</em>",
        "body": " various rate limits have been reached. Solution View <em>error</em> details For an introduction to using the <em>NrIntegrationError</em> <em>event</em>, see <em>NrIntegrationError</em>. Here&#x27;s an example NRQL for examining issues with Metric API <em>ingest</em>: SELECT count(*) FROM <em>NrIntegrationError</em> WHERE newRelicFeature = &#x27;Metrics&#x27; facet"
      },
      "id": "610f2900196a678a5d38ad82"
    },
    {
      "sections": [
        "Introduction to the Event API",
        "Requirements",
        "Basic workflow",
        "Tip",
        "Get the license key",
        "Format the JSON",
        "JSON format guidelines",
        "JSON example",
        "Limits and restricted characters",
        "Submit the custom event",
        "Linux/bash example",
        "Windows/PowerShell example",
        "Important",
        "Verify or troubleshoot request response",
        "Success response code",
        "Submission errors",
        "Parsing errors",
        "Query and alert with NrIntegrationError",
        "Find your data",
        "Limit on HTTP requests"
      ],
      "title": "Introduction to the Event API",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "0e0f5ad678bc1756a2cf7db88a52df2c2983bbe4",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/ingest-apis/introduction-event-api/",
      "published_at": "2021-10-07T02:25:38Z",
      "updated_at": "2021-08-26T19:44:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Event API is one way to report custom events to New Relic. The Event API lets you send custom event data to your New Relic account with a POST command. These events are then queryable and chartable using NRQL. Want to try out our Event API? Create a New Relic account for free! No credit card required. Related content: Learn about all options for reporting custom events. For details about how event data is retained, see Event data retention. For how to add attributes to existing events, see Add custom attributes. Check out New Relic University’s tutorial Adding custom events with the Event API (aka the Insights API). Or, go directly to the full online course Custom data. Requirements For Event API limits and restricted attributes, see Limits. Ensure outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. The preferred configuration method is to use the DNS name insights-collector.newrelic.com or insights-collector.eu01.nr-data.net. Basic workflow The Event API is an asynchronous endpoint. This allows you to send a very large volume of POSTS, reliably, with very low response latency. Tip If your account hosts data in the EU data center, ensure you are using the proper API endpoints for EU region accounts. To send a custom event to a New Relic account: Get a license key for the account you want to report data to. Before creating custom events or attributes, review New Relic's list of reserved terms used by NRQL. Generate JSON for the event by instrumenting your application, querying an API, or some other method. Submit a compressed JSON payload (for example, gzip or deflate) to the HTTPS endpoint using curl in a POST request. Recommendation: Set up NRQL alert conditions to notify you when parsing errors occur. This method will send the events directly into your account, where they will be accessible from any NRQL interface or with the Query API. The Event API limits the size, rate, and characters allowed in custom events. Also, like other events available in NRQL, custom events cannot be updated or deleted after they are created. If you have problems with your custom event, follow the troubleshooting procedures or create a new custom event. Get the license key You'll need a license key. License keys are associated with an account, not a specific user. This means that anyone in the account with access to that key can use it. You can submit multiple event types to the same account with the same license key. However, to help ensure security, we recommend that you use different keys for different applications or data sources. Alternatively, you can use an Insights insert keyfor this API, but we recommend using a license key. Format the JSON The Event API accepts specific formats for attributes included in the payload. Only float or string values are allowed. JSON format guidelines When defining attributes for your custom events, follow these JSON format guidelines. Attributes JSON format guidelines eventType Required: The event's name. Float and string values Float value format: \"label\":value String value format: \"label\":\"value\" Data types The API only accepts key-value pairs, not map/object or array values. Supported data types for this API are strings and numbers (integers or floats). For more information, see Data requirements. Digits in strings For performance-related reasons, we do not cast values submitted to the API. For example, we treat 123 as a number and \"123\" as a string. The database will only store up to 64 bit numbers. Any numbers larger than 64 bits will be truncated. Dates For attributes that contain date information, use an unformatted Unix timestamp in the Insights data formatter. You can define the date attribute either in seconds or in milliseconds, both relative to the Unix epoch. Time Unless otherwise specified, the timestamp for a submitted event is the time it was submitted to New Relic. To specify a different time for the event, use the timestamp attribute. JSON example Here is an example of a typical JSON data set for sending with the API. This call sends two Purchase type events as a JSON array. You can add multiple events in a single HTTP call using a JSON array. [ { \"eventType\":\"Purchase\", \"account\":3, \"amount\":259.54 }, { \"eventType\":\"Purchase\", \"account\":5, \"amount\":12309, \"product\":\"Item\" } ] Copy When generating the JSON, make sure your attributes are properly formatted. Limits and restricted characters The following size and rate limits apply to events sent via the Event API: Max events per API call: 2K Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length There are rate limits on the number of HTTP requests per minute sent to the Event API. Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. appId: Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType: Can be a combination of alphanumeric characters, _ underscores, and : colons. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Submit the custom event Data submitted to the Event API uses a compressed JSON format in a simple HTTPS POST request. This example uses gzip, but you can also use deflate. Linux/bash example gzip -c example_events.json | curl -X POST -H \"Content-Type: application/json\" -H \"Api-Key: YOUR_LICENSE_KEY\" -H \"Content-Encoding: gzip\" https://insights-collector.newrelic.com/v1/accounts/YOUR_ACCOUNT_ID/events --data-binary @- Copy Windows/PowerShell example $accountId = \"YOUR_ACCOUNT_ID\" $insertkey = \"YOUR_LICENSE_KEY\" # Replace with your custom event for the body $body = '[{\"eventType\": \"powershell\", \"account\": 4, \"amount\": 123, \"fileLocation\": \"c:\\\\temp2\", \"zipped\": \"true\" }]' $headers = @{} $headers.Add(\"Api-Key\", \"$insertkey\") $headers.Add(\"Content-Encoding\", \"gzip\") $encoding = [System.Text.Encoding]::UTF8 $enc_data = $encoding.GetBytes($body) $output = [System.IO.MemoryStream]::new() $gzipStream = New-Object System.IO.Compression.GzipStream $output, ([IO.Compression.CompressionMode]::Compress) $gzipStream.Write($enc_data, 0, $enc_data.Length) $gzipStream.Close() $gzipBody = $output.ToArray() Invoke-WebRequest -Headers $headers -Method Post -Body $gzipBody \"https://insights-collector.newrelic.com/v1/accounts/$accountId/events\" Copy Important Always use compression with every payload. This allows you to send more data, and it saves resources during parsing. Before generating your HTTP request, make sure it is properly formatted, including: The Api-Key contains the correct license key. The Content-Type is application/json. The request uses POST only. The API does not accept PUT and GET requests. The API supports HTTP/1.1 persistent connections. This is helpful to manage client-side performance under heavy event loads. Verify or troubleshoot request response The Event API follows a two-step process to process requests: The Event API synchronously acknowledges or rejects the request based on validation of the headers and payload size. The Event API asynchronously parses the payload after a successful HTTP response is provided to the client. This may generate an error due to missing or malformed data. These are classified as submission errors or parsing errors. All successful submissions receive a 200 response, regardless of any data errors that may exist within the payload. The response includes a uuid, which is a unique ID created for each request. The uuid also appears in any error events created for the request. Other potential issues: 10-second timeout: API calls exceeding 10 seconds will time out. Large payloads: Payloads exceeding 100 KB may see increased response times. Recommendation: In addition to checking for a success message, create a NRQL query of your data to verify it's available. Success response code Success message Comments 200 {\"success\":true,\"uuid\":\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"} Copy Submission errors Payloads with submission errors are handled and returned to the sender through an HTTP response code. To troubleshoot payload submission errors, refer to these HTTP response codes. Submission errors Troubleshooting 400 Missing or invalid content length: Unable to process empty request. 403 Missing or invalid key: Invalid license key. Register a valid license key. 408 Request timed out: Request took too long to process. 413 Content too large: Request is too large to process. Refer to the limits and restricted characters to troubleshoot. 415 Invalid content type: Must be application/JSON. The Event API accepts any content type except multi-part/related and assumes it can be parsed to JSON. 429 Too many requests due to rate limiting. 503 Service temporarily unavailable: Retry request Parsing errors Parsing errors occur if: An event is sent within a payload, but it is either missing data or is exceeding maximum limits. New Relic will drop the individual event from the payload, generate an NrIntegrationError event, and process the rest. The JSON payload includes malformed JSON or missing required data. Payloads with parsing errors receive a 200 response to indicate a successful submission. To help resolve parsing errors, a new NrIntegrationError event type is created. All parsing errors are due to NRQL queries. For error messages related to dropped events, New Relic will include the number of events that were dropped as part of the message. To troubleshoot requests with parsing errors, refer to these error messages. Parsing errors Troubleshooting X event(s) rejected because attribute appId was not an integer An appId attribute has a non-integer value, such as a decimal value or string. X event(s) rejected because eventType cannot contain the following characters: [., \\] An eventType attributed included an invalid character, such as a period or backslash. X event(s) rejected because attribute is missing attribute name An attribute name was set to null or an empty string. X event(s) rejected because attribute name exceeded maximum length An attribute name has more than 255 characters. X event(s) rejected because attribute value exceeded maximum length An attribute value was longer than 4096 characters. X event(s) rejected because event exceeded maximum number of attributes An event has more than 255 attributes. X event(s) rejected because missing required attributes eventType The eventType attribute is required for the custom event. Error parsing JSON payload There was an error parsing the request JSON because of formatting problems or corrupted data. Query and alert with NrIntegrationError The NrIntegrationError event allows you to query and set alerts on custom data being sent to your New Relic account. Recommendation: To get alerts for parsing errors, create a NRQL alert condition for NrIntegrationError. Use this example NRQL query: SELECT message FROM NrIntegrationError WHERE newRelicFeature = 'Event API' AND category = 'EventApiException' Copy NrIntegrationError attributes Troubleshooting timestamp The timestamp when the request was received. The timestamp attribute takes a 64-bit integer Unix timestamp within the last 24 hours. You can define timestamps either in seconds or in milliseconds, both relative to the Unix epoch. Do not use a decimal for the timestamp. If a decimal is used, the attribute will default to the timestamp when the custom event was created. newRelicFeature The name of the feature experiencing errors. For all custom event parsing errors, this will be Event API. apiKeyPrefix The first six characters of the license key used for the request that generated an error. requestId The uuid returned by the the API for the request that generated an error. Category The category of the error. For custom events, this is EventApiException. Message Contents of the error message. Name The error's name. For custom events, this is always EventValidationException. eventTypeSample One of the event types that generated the error, when available. Find your data To find data sent via the Event API (and from integrations that use this API), you can query it. For example, to query a custom event using NRQL, you would run: SELECT * FROM YOUR_CUSTOM_EVENT Copy For more on how to query, see Query data. Limit on HTTP requests The Event API has a rate limit of 100,000 HTTP requests (POSTs) per minute, per account. (Note that this is not a limit on the number of events per minute; only on the number of POSTs per minute.) This limit helps ensure that large traffic spikes in accounts across our multi-tenant platform do not negatively affect how the service performs for you. If your API usage exceeds 100k POSTs in a 1-minute window, we will reject subsequent API requests with a 429 response code for the remainder of the 1-minute window. At the end of the 1-minute window, the counter will be reset and allow traffic to resume. This limit is intended to be an upper threshold that you shouldn't hit under normal scenarios. If you have a high number of 429 responses, consider using the API less. If you are expecting a higher-than-normal activity level in the near future and want to prepare for that, contact technical support.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 278.01266,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction <em>to</em> the <em>Event</em> API",
        "sections": "Introduction <em>to</em> the <em>Event</em> API",
        "tags": "<em>Ingest</em> and manage <em>data</em>",
        "body": " <em>event</em>. <em>Error</em> parsing JSON payload There was an <em>error</em> parsing the request JSON because of formatting <em>problems</em> or corrupted <em>data</em>. Query and alert with <em>NrIntegrationError</em> The <em>NrIntegrationError</em> <em>event</em> allows you to query and set alerts on custom <em>data</em> being sent to your New Relic account. Recommendation"
      },
      "id": "609fa5fb64441f9d9fd2a1e2"
    },
    {
      "sections": [
        "Rate limit errors (Prometheus integration)",
        "Problem",
        "Solution",
        "Cause"
      ],
      "title": "Rate limit errors (Prometheus integration)",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "Troubleshooting"
      ],
      "external_id": "3c8907d358e49c8dde5cab6dfa386deb5407d335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/integrations/prometheus-integrations/troubleshooting/rate-limit-errors-prometheus-integration/",
      "published_at": "2021-10-08T06:48:27Z",
      "updated_at": "2021-08-08T19:29:48Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Your Prometheus OpenMetrics integration for Docker or Kubernetes exceeded allowable metric rate limits. You want to see more details about why the NrIntegrationError event has been applied to your New Relic account. Solution To examine rate limit errors: Run a query of Prometheus metrics using the NrIntegrationError event, like this: FROM NrIntegrationError SELECT * WHERE newRelicFeature = 'Metrics' Copy Review additional troubleshooting procedures for NrIntegrationError events. To help prevent this from happening, you can use filters to control the types and amount of data that your integration sends to New Relic. For more information, see Ignore or include Prometheus metrics. Cause New Relic does a basic validation of your Prometheus OpenMetrics integration metrics when they are submitted. More extensive validation is performed asynchronously when processing the metrics. If New Relic finds errors during this asynchronous validation, the errors are put into an NrIntegrationError event in your New Relic account. For example, if you exceed the metric limits defined for Prometheus OpenMetrics integrations, New Relic will apply rate limits to your account and create an associated NrIntegrationError event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.2799,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Rate limit <em>errors</em> (Prometheus <em>integration</em>)",
        "sections": "Rate limit <em>errors</em> (Prometheus <em>integration</em>)",
        "tags": "<em>Integrations</em>",
        "body": " using the <em>NrIntegrationError</em> <em>event</em>, like this: FROM <em>NrIntegrationError</em> SELECT * WHERE newRelicFeature = &#x27;Metrics&#x27; Copy Review additional troubleshooting procedures for <em>NrIntegrationError</em> events. To help prevent this from happening, you can <em>use</em> filters to control the types and amount of <em>data</em> that your"
      },
      "id": "6045054528ccbc2c342c606b"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/query-limits": [
    {
      "sections": [
        "View system limits",
        "Responses to limit violations",
        "System limits UI",
        "Troubleshooting limits"
      ],
      "title": "View system limits",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "d6ff940e92c5d1a3ae34f391e9fa3be5dfa21c2f",
      "image": "https://docs.newrelic.com/static/8ee61e3091f6e044202cff92026afada/8c557/limits-graph.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/view-system-limits/",
      "published_at": "2021-10-07T10:45:22Z",
      "updated_at": "2021-08-09T00:31:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "To ensure our systems are always up and ready to support you, and to keep you from unintended use, we place limits on the amount of data you can send, query, and store. Responses to limit violations Limits are enforced per child account, and across our APIs. You might reach a limit if you start monitoring a new high-traffic application, or have a sudden data spike. When you do reach a limit, New Relic responds according to the type of data and the limit that’s reached. For example: We place a limit on the number of ingested requests per minute (RPM) per data type. When this limit is reached, we stop accepting data and return a 429 status code for the duration of the minute. For queries, we place limits on the number of queries per minute and the number of records inspected (see query limits). When the number of queries per minute limit is reached, New Relic will begin rejecting queries until the number of queries is below the limit. When the records inspected limit is reached, New Relic will reject traffic from the source scanning the largest number of records and attempt to allow traffic from other sources. For metrics, we place a limit on the number of unique timeseries (cardinality) per account and per metric. When this limit is reached, aggregated data is turned off for the rest of the UTC day. For every major limit violation, New Relic creates an NrIntegrationError event for that account, which has these limit-related attributes: Attribute Description category RateLimit or ApiLimit. The RateLimit category is used for limits based on a unit of time such as the number of requests ingested per minute. The ApiLimit is used for constant limits, such as the number of attributes on a record. limitName The name of the limit. message Describes the limit and the impact. limitValue The limit reached. System limits UI The system Limits page (from the account dropdown, click Manage your data and click Limits on the left) displays when your account has encountered a rate limit in the specified time period. The page displays a default period of 24 hours; you can set a custom range from the top-right of the page. Non-limit-related NrIntegrationError events are not displayed here. In addition, this page does not display information about limits you have not hit, or how close you are to reaching a limit. For more on creating queries and alerts for data ingest and billing metrics, see Query billing/usage data. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a chart on the Limits UI page displaying a cardinality violation limit issue. To add more detail, or build a dashboard, click the View NRQL button on the chart to see the NRQL powering this view. The graph displays each unique limit type that was reached during the selected time-period. This can help you find any trends based on time. The Limits page also provides a table where you can find the limit name, the limit event message associated with it, and last occurrence time and date. If you click a limit in the table, you see more about what happened, and when. one.newrelic.com > account dropdown > Manage your data > Limits: An example of a limit events table on the Limits UI page. Troubleshooting limits To troubleshoot limits when you reach them, click the limit info in the table, and then follow the docs link that's provided. Different limits have different solutions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 177.80164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>system</em> <em>limits</em>",
        "sections": "View <em>system</em> <em>limits</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": ". <em>limit</em>Value The <em>limit</em> reached. <em>System</em> <em>limits</em> UI The <em>system</em> <em>Limits</em> page (from the account dropdown, click <em>Manage</em> your <em>data</em> and click <em>Limits</em> on the left) displays when your account has encountered a rate <em>limit</em> in the specified time period. The page displays a default period of 24 hours; you can set"
      },
      "id": "60446a7c64441f48d7378f2b"
    },
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.03381,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " computation is an estimate. Set alerts for <em>data</em> use Query and alert on usage <em>data</em> describes how to set alerts to get notified if you&#x27;re nearing <em>data</em> <em>ingest</em> <em>limits</em> you don&#x27;t want to cross. For example, you might set an alert on logs, which can stack up quickly in an active <em>system</em>. Adjust your <em>data</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-10-07T06:31:22Z",
      "updated_at": "2021-09-13T20:40:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing plan, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing plan. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 139.5232,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. We invite you to send all your <em>metrics</em>, events, logs, and traces to NRDB"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/telemetry-data-platform/manage-data/view-system-limits": [
    {
      "sections": [
        "Manage data coming into New Relic",
        "Important",
        "Data ingestion sources",
        "Break down data to see what's contributing to your ingest",
        "How we break your ingest data down",
        "Set alerts for data use",
        "Adjust your data ingest"
      ],
      "title": "Manage data coming into New Relic",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "f6af5123503549262d48d7cc1cc609b506b0853a",
      "image": "https://docs.newrelic.com/static/82d3c36157005ac0efe40cd6e10fe06b/b23ad/data-facet.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-data-coming-new-relic/",
      "published_at": "2021-10-07T00:17:32Z",
      "updated_at": "2021-09-27T15:53:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you connect your data to New Relic, we process what we receive and apply data dropping and transformation rules. Then we count the bytes needed to represent your data in a standard format, like JSON. If you're on our New Relic One pricing plan, you're charged by the number of bytes written to our database, above and beyond the standard amount that’s free. Important This doc is for accounts on our New Relic One pricing plan. If you're on our original product-based pricing plan, see Original data retention. Not sure which you're on? See Overview of pricing and user model. The Data ingestion page shows your ingest rates for a period you specify on the top-right of the Data management hub. Since 30 days ago is the default setting, but you can also set a custom date span. The page shows your daily average GBs, and the total for the range you set. You can toggle between an overall ingest view and an account view to identify which of your accounts are sending the most data. The page also provides the current month-to-date, and the projected end-of-month total ingest rates. With this information, you can proactively drop data or turn off agents in order to manage ingest and, therefore, costs. If you want to take a look at how we query the data, click the ellipsis icon (just above the chart) to slide out the chart query and open it in our query builder. And If you want to drill down further into your data usage, check out the sample queries in the usage docs. From the Login drop-down, select Manage your data, and then select Data ingestion. This is the Data ingestion page with data source and account views. Data ingestion sources The Data ingestion page describes which of your data sources provide the most data on average and during specific data ranges. The sources are described here. Billable data sources Description Timeslices (1-minute) and Metric:Raw Metrics are timeslices + MetricRaw Metric group: MetricsBytes Metric timeslice data averages to one-hour periods after eight days. After 90 days, the permanent metric data continues to be stored in one-hour periods. We currently store the raw metric data for 30 days. You are only billed for the initial ingest volume. You are not billed for subsequent rollups. APM (transactions and errors) APM events Metric group: ApmEventsBytes InfraSamples:Raw Includes multiple Infrastructure events Infrastructure host data Metric group:InfraHostBytes Information related to your servers and virtual machines coming from infrastructure agents, including storage and network data Infrastructure process data stored in ProcessSample. Metric group: InfraProcessBytes Data are metrics related to each process running on the hosts running the Infrastructure agent. This feature is turned off by default. Infrastructure integrations Metric group: InfraIntegrationBytes Performance data related to applications and services, typically managed by the customer, including data related to Docker containers, Windows services, Nagios checks, and cloud integrations such as managed services in AWS, Azure, and GCP. Logging Includes logs and any Log_<value> custom data partition created Metric group: LoggingBytes Log records are stored into the Log event type by default. Additional custom data partitions will create new event types, which are always prefixed with Log_ and will be counted as part of the overall set of log data stored. With LogExtendedRecord, log messages longer than 4KB are split into multiple events that, when needed, are stitched together to display the original message; this reduces the size of message data. As of September 2021, log storage as blobs replaces LogExtendedRecord. With blob storage, NRDB can store up to 128,000 bytes for any attribute, not just messages. For more information, see our blobs documentation for logs. Default Custom events Metric group: CustomEventsBytes Mobile error Mobile general Breadcrumb crash event trails Mobile session Mobile exception Mobile crash Mobile events Metric group: MobileEventsBytes Tracing Metric group: TracingBytes TracingBytes includes Span and OpenTelemetry's SpanEvent. You are not charged for DistributedTraceSummary events. Browser:EventLog Browser Browser:JSErrors PcvPerf (PageView timing) Browser events Metric group: BrowserEventsBytes Lambda Serverless Metric group: ServerlessBytes Break down data to see what's contributing to your ingest You can inspect your data ingest to gain more information about your ingest health. This way, you'll know your baselines, and can more easily spot an anomaly like an ingest spike, as well as its source. To break down your ingested data, start from the chart on the Data ingestion page. Think of the data source bands as the Y axis, and the dates as the X axis. Click on the band you want to inspect at the spot in the X axis that corresponds with the date you want to investigate. This image shows the Metrics band for June 15 right before it's clicked. A modal opens with the account, data source, and facet selected. You can do a handful of things on this page: Change the account, data source, or facet you want to drill down into. Change the date and time to investigate. Review the results of the query in chart form. The chart displays the top 15 results for the facet query. Open the NRQL query in the Query builder where you'll find additional facets that you can use. Learn more about NRQL queries here. How we break your ingest data down Some of the content in the UI is variable, depending on your account. This information is intended to help you understand how we're working with your ingest data. The chart on the Data ingestion page shows data usage for a little longer time frame than that covered by your retention settings for each data ingest source. If you choose a date outside of your designated retention period for an ingest source, you'll get the message that there's no chart data available. Select a more recent date to fix this problem. If you inspect a data source for an account that has less than a terrabyte of data, we compute the ingest volume over a 24 hour period; otherwise, we compute it for a 1 hour period. The ingest value provided on the main Data ingestion chart will be slightly different from that reflected during inspection. This is because our facet computation is an estimate. Set alerts for data use Query and alert on usage data describes how to set alerts to get notified if you're nearing data ingest limits you don't want to cross. For example, you might set an alert on logs, which can stack up quickly in an active system. Adjust your data ingest Drop data for lower retention costs and data compliance On ingest, we apply data dropping rules so you won't be charged for data that's not useful. Learn how to set additional data dropping rules yourself. Use NerdGraph to drop entire data types or drop data attributes from data types so they’re not written to NRDB. This enables you to focus on the data you want, reduces retention costs, and avoids writing sensitive data to the database. For dropping log data, see Drop data with drop filter rules. Turn off agents and integrations If you don’t need data from specific agents or integrations that you have installed, you can uninstall/delete those tools. For instructions, see the specific documentation for an agent or integration.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 287.63474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> <em>data</em> coming into New Relic",
        "sections": "<em>Manage</em> <em>data</em> coming into New Relic",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": " view and an account view to identify which of your accounts are sending the most <em>data</em>. The page also provides the current month-to-date, and the projected end-of-month total <em>ingest</em> rates. With this information, you can proactively drop <em>data</em> or turn off agents in order to <em>manage</em> <em>ingest</em>"
      },
      "id": "603e978228ccbc8984eba79e"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "4f5724347af7e29f92fa2795c7eaf594e964b450",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-10-08T11:25:05Z",
      "updated_at": "2021-09-27T15:37:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 263.22858,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "The New Relic <em>platform</em> reports four main <em>telemetry</em> <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    },
    {
      "sections": [
        "Manage your data",
        "Important",
        "Where to find the Data management hub",
        "Better cost, performance, and compliance",
        "Cost management",
        "Performance management",
        "Ingest and retention strategies"
      ],
      "title": "Manage your data",
      "type": "docs",
      "tags": [
        "Telemetry Data Platform",
        "Ingest and manage data",
        "Manage data"
      ],
      "external_id": "1938512af1fd477b8cd587cc85a4a1522cd62e9e",
      "image": "https://docs.newrelic.com/static/8a553ce9643c8513be3200af5d924250/c1b63/datamanagement_overview.png",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/manage-data/manage-your-data/",
      "published_at": "2021-10-07T06:31:22Z",
      "updated_at": "2021-09-13T20:40:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "At New Relic, we're super proud of NRDB, the New Relic database where we store your data. It gathers all your telemetry data in one place, gives you a connected view of all your data, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB, including those from third-party sources. We also recognize that some data might not be necessary for your business goals. You shouldn’t have to wade through data you don’t need to get to the data you do. And you definitely shouldn’t have to pay for it. That’s where our data management tools come in: they let you decide what data you send to New Relic and how long it should be stored. Data management hub: from the user profile drop down, select Manage your data. Coupled with user management tools, data management helps you get maximum value from your investment in New Relic, all while safeguarding your data. Important Not yet a New Relic customer? Sign up to create your free account in only a few seconds. Then ingest up to 100GB of data for free each month. Forever. Where to find the Data management hub To locate the data management UI: From one.newrelic.com select the account dropdown, and select Manage your data. If you're on the New Relic One user model, you can also find the Data management hub by selecting Administration > Manage data. Better cost, performance, and compliance Collecting and storing data in New Relic allows you to analyze, visualize, and alert on all your metrics, events, logs, and traces from across all of your sources. However, it’s important to manage that data for cost, performance, and in some cases, compliance reasons. The data management hub provides the tools you need to understand and control where your data is coming from, and adjust what’s stored and for how long. Important If you're on our original product-based pricing plan, you'll see your data ingest, retention, and limits in the Data management hub. The primary difference is that you're not billed on ingest, as with our New Relic One pricing plan. Not sure which plan you're on? See Overview of pricing and user model. Cost management The cost of data storage continually decreases, but storage is still an expense. The amount of data you process and store is closely related to the value you receive from New Relic, because it’s a key component of how you’re charged. Our ingest process helps you hone your data. For example, data might arrive at our processing front door compressed and of varying quality. Through ingest, that data is uncompressed, decorated with queryable attributes, and evaluated. Elements are dropped or trimmed, all before we write it to NRDB. That way, the data you store is only the data you want most. Performance management While NRDB is a phenomenally scalable database, it’s also a reality that queries across huge datasets might not return results in a timely enough fashion for your needs. You get better performance if you limit the data we store, or convert it into a format that keeps it easily queryable. Drop data to improve performance by reducing the amount of data that’s stored. Ingest and retention strategies Depending on your goals, whether to reduce costs, increase specific retention rates, or pare down your data to what’s most essential, we have a strategy for you. Learn about reducing the amount of data that comes into NRDB in Manage data coming into New Relic. Learn about customizing storage so you only store the data you want, for the period you want in Manage data stored in New Relic. Learn about dropping data in Drop data using NerdGraph. And for dropping log data, see Drop data with drop filter rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 247.67493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Manage</em> your <em>data</em>",
        "sections": "<em>Manage</em> your <em>data</em>",
        "tags": "<em>Telemetry</em> <em>Data</em> <em>Platform</em>",
        "body": "At New Relic, we&#x27;re super proud of NRDB, the New Relic database where we store your <em>data</em>. It gathers all your <em>telemetry</em> <em>data</em> in one place, gives you a connected view of all your <em>data</em>, and scales as your business grows. We invite you to send all your metrics, events, logs, and traces to NRDB"
      },
      "id": "603e96ff28ccbcf8bceba796"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.00204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "b6122126a390d40ee68c246abdb66fc2c0211a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-10-08T10:08:39Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.00192,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "af971d2b95ff397b57bf125f6801f57007ea5e77",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-10-08T10:06:26Z",
      "updated_at": "2021-05-15T09:10:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Events reported by synthetic monitoring"
      ],
      "title": "Events reported by synthetic monitoring",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "b6122126a390d40ee68c246abdb66fc2c0211a91",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring/",
      "published_at": "2021-10-08T10:08:39Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Synthetic monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific monitor. These metrics include duration information for the monitor, location of the monitor check, size of the request and response headers, the type of monitor, and a timestamp. Each time a synthetic monitor runs a check, details about the check are captured in theSyntheticCheck event type. SyntheticCheck events contain details specific to the check to provide visibility such as the status, type of monitor, and size of request and response headers. SyntheticRequest SyntheticRequest returns results from individual HTTP requests made during a check. The data gathered include job information, location, type of content for request, duration information, request size, and page load information. With each simple or scripted monitor check, we capture each individual HTTP request made during the check. The HTTP details are captured at a more granular level than the SyntheticCheck event type. SyntheticPrivateLocationStatus Every monitor check running on a private location triggers capacity details for that private location. These details are captured in a SyntheticPrivateLocationStatus event. This provides visibility into the capacity of a private location and whether additional minions are required to support the workload. SyntheticPrivateMinion If you have private locations, such as those inside your firewall, you can view information regarding those locations with the SyntheticPrivateMinion event. Each private minion running sends health details to SyntheticPrivateMinion every 30 seconds. This allows you to understand the health of the private minion running at the location. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Events</em> reported by synthetic monitoring",
        "sections": "<em>Events</em> reported by synthetic monitoring",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "Synthetic monitoring in New Relic reports <em>event</em> <em>data</em> that is displayed in some UI displays and is also available for querying and charting. Select an <em>event</em> name in the following table to see its attributes. <em>Event</em> Description SyntheticCheck SyntheticCheck returns metrics from one run of a specific"
      },
      "id": "609f8faf64441f8e99d2a1d5"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-apm": [
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 301.36575,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "sections": "Default <em>events</em> <em>reported</em> <em>by</em> New Relic products",
        "tags": "Default <em>events</em>",
        "body": "New Relic products <em>report</em> different types of data. One type of data <em>reported</em> is <em>event</em> data. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the <em>events</em> <em>reported</em> by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    },
    {
      "sections": [
        "Manage error data",
        "Error data types: events and trace details",
        "Events",
        "Trace details",
        "Caps on error reporting",
        "Charting error rates and counts",
        "Report custom errors",
        "Ignore errors",
        "Reduce noise with expected errors",
        "Disable error traces",
        "Delete error traces",
        "Caution"
      ],
      "title": "Manage error data",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Error analytics"
      ],
      "external_id": "29a2ebdc7b91029a1fada50791b90e9dc548f17e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/apm-ui-pages/error-analytics/manage-error-data/",
      "published_at": "2021-10-07T16:45:10Z",
      "updated_at": "2021-09-08T19:58:28Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's APM Errors page helps you identify, triage, and fix errors in your services. The Errors page uses data collected by the APM agent to display stack traces, transaction attributes such as HTTP header values, and any other custom attributes, so you can understand the context of the error and fix it. Error data types: events and trace details By default, our APM agents collect two type of error data: Events Trace details Events The error event data type includes default attributes, as well as any custom attributes instrumented in your service. It doesn't include a stack trace. Find your events data in the Errors UI as follows: The Errors column in the Error traces table. The Top 5 errors chart. When you’ve drilled into a grouping of errors, those errors not displaying a stack trace are based on this type of data. You can disable Show only errors with stack trace to show errors that have this type of data collected, but no associated trace details. Events are subject to sampling (see Caps on error reporting and Charting error rates and counts). For more on error event data, see Events reported by APM. Trace details The trace details error data type includes stack traces and attributes, and supplements events with more data. It's expected that more events will be reported than trace details--see Caps on error reporting. Find your trace details data in the Errors UI as follows: The “Stack traces” column of the Error traces table. When you’ve drilled into a grouping of errors, those errors with a stack trace use this type of data: Show only errors with stack trace is enabled by default, to constrain the errors shown to just those that have this type of data collected. This data is governed by specific retention rules for Error details. Caps on error reporting New Relic caps error reporting at: 100 events per minute per agent instance 20 trace details per minute per agent instance These caps prevent error reporting from negatively impacting application performance. Examples: App running across five EC2 instances, one JVM each. New Relic caps error reporting at: 100 events per minute x 5 instances = 500 events per minute 20 trace details per minute x 5 instances = 100 trace details per minute App running on one host with ten instances. New Relic caps error reporting at: 100 events per minute x 10 instances = 1000 events per minute 20 trace details per minute x 10 instances = 200 events per minute Charting error rates and counts The Error rate chart is driven by a query on metric timeslice data, which is an unsampled aggregate data type that is accurate but has very limited dimensionality. This data can't be faceted or filtered as flexibly as error event data. You can reproduce this chart in a dashboard, or explore the metric timeslice data further by clicking the ... menu on the Error rate chart, and then using the View query or Add to dashboard options. To chart faceted error counts using event data, as in the Top 5 errors chart, use an NRQL event query. Click the ... menu on the Top 5 errors chart and choose View query for a starting point in creating your chart. Since event data can be sampled (see Caps on error reporting), you can use the EXTRAPOLATE keyword to get an accurate error count, even if sampling is occurring. Report custom errors You can report errors not collected by default with our agents using our agent APIs. For more, see the documentation on the API. Ignore errors You can prevent certain errors that would normally be reported to New Relic from being collected using our agent APIs or the server-side configuration UI. For more details, see Manage errors in APM. Reduce noise with expected errors Sometimes you want to collect error data, but not have those errors wake you up through alerts. Using the agent API, you can mark such errors as “expected”. They’ll still be visible in the Errors page, but won’t affect your service’s error rate or Apdex metrics. Disable error traces To prevent certain errors from being reported to New Relic, disable them in your agent's configuration file. For most agents, you can ignore certain error codes or disable errors completely. For more information, see your specific agent's configuration documentation: C SDK Go (not applicable; the agent only reports errors when configured to do so) Java .NET Node.js PHP Python Ruby Delete error traces Caution You cannot recover error traces after you delete them. Deleting errors is currently only available in the legacy Errors Classic UI. If you want to... Do this... Delete all error traces for your app If you have permissions to delete all error traces for an app: Go to one.newrelic.com > APM > (select an app) > More views > Errors (classic). Select Delete all errors. Delete all error traces for your account To delete all error traces for your New Relic account, get support at support.newrelic.com. Delete individual error traces To delete individual error traces, use APM's Errors (classic) page. Drill into an error from the table of errors, then click Delete this error. In addition to deleting error traces, you may also want to delete transaction traces or database/slow SQL traces. This will remove potentially sensitive data while retaining your other application data (such as Apdex, deployment information, etc.).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 298.00684,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Error data types: <em>events</em> and trace details",
        "tags": "<em>APM</em>",
        "body": " that have this type of data collected, but no associated trace details. <em>Events</em> are subject to sampling (see Caps on error reporting and Charting error rates and counts). For more on error <em>event</em> data, see <em>Events</em> <em>reported</em> by <em>APM</em>. Trace details The trace details error data type includes stack traces"
      },
      "id": "6044077e28ccbcab752c60d1"
    },
    {
      "sections": [
        "Thread profiler tool",
        "Supported agents",
        "Start the profiler",
        "View profile data",
        "Agent considerations",
        ".NET-specific notes",
        "Python-specific notes",
        "Ruby-specific notes"
      ],
      "title": "Thread profiler tool",
      "type": "docs",
      "tags": [
        "APM",
        "APM UI pages",
        "Events"
      ],
      "external_id": "e2d300aa5dd9bdbf73684a04080773db0d1acd2b",
      "image": "https://docs.newrelic.com/static/1331956275509db052de91a6d8caebda/c1b63/thread-profiler-session.png",
      "url": "https://docs.newrelic.com/docs/apm/apm-ui-pages/events/thread-profiler-tool/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-09-20T19:33:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The thread profiler is a low-impact profiling tool that can be used in production to identify bottlenecks in an application. It works by periodically (100ms) capturing the stack trace of each thread for a specified duration. At the end of the specified duration, the stack traces are aggregated to build a tree. The call count in the tree corresponds to the number of times that function was present in the stack traces under the same context. Although the call tree cannot capture the entire execution, a large enough sample can be a good representation of the application behavior. This provides insights into the \"hot\" functions of the app where most of the time is spent. With this scope, entries sampled less than 0.05% are omitted. Supported agents This feature is available only for specific agents and versions: Java: Agent versions 1.2.004.6 or higher .NET: Framework: Agent versions 2.12.146.0 or higher .NET Core 2.0: Agent versions 8.3.360.0 or higher (Windows only) Linux: .NET Core 3.0 or higher and agent versions 8.23 or higher Python: Agent versions 1.7.0 or higher Ruby: Agent versions 3.5.5 or higher Start the profiler The thread profiler feature is enabled by default. You also may be able to turn it on or off in your agent configuration file: Java: thread_profiler.enabled NET: You cannot disable the thread profiler with .NET apps. Python: thread_profiler.enabled Ruby: thread_profiler.enabled When enabled, you can view the thread profiler from our user interface: Go to one.newrelic.com > APM > (select an app) > Events > Thread profiler. Select the host you want to run the profiler on. Set the duration for the profiling session. Select Start profiler. This triggers the agent to start the thread profiler during the next harvest cycle (every one minute) and capture data for the specified duration. We record thread backtraces whether or not they are in a runnable state at the time the sample is taken. Threads that are sleeping or blocked on IO may appear in the call tree. one.newrelic.com > APM > (select an app) > Events > Thread profiler: Use this page to define the settings for the thread profiler duration and to view the results. View profile data After the profiler finishes running, the agent will report the profile data. The call tree automatically appears on the Thread profiler page. The percentages in the call tree represent the percentage of thread backtrace samples in which each call path appeared during the profiling session. The data collection started at the PROFILE COLLECTED time. The page color-codes the tree results: Red: Percentages greater than 30% Yellow: Percentages greater than 10% Black: Percentages less than 10% If you want to... Do this... Change how the thread profile information appears Select your choices of available options in the Tree settings, and select Refresh tree. Change how much information appears Select the Expand or Collapse options above the call tree, or select the name or arrow on any line in the call tree. View summary information about any line in the call tree Mouse over the line. Email the thread profile results to others Select Share this profile. Start another session or view a different thread profile Select Back to all profiles. Agent considerations Depending on which agent you use, the thread profiling feature has additional considerations. .NET-specific notes When using thread profiling with the .NET Framework agent, be aware of the following. .NET agent Thread profiler notes Supported on Linux Thread profiling on Linux is supported on .NET Core 3.0 or later applications when running .NET agent version 8.23 or later. Managed threads only For .NET agents, the thread profiler only captures stack traces on managed threads. It does not capture stack traces on unmanaged threads. If a call to an unmanaged function occurs on a managed thread, the thread profiler will show Native:Function Call in the call tree. No line numbers A .NET thread profile does not include line numbers in the call tree. The Show line numbers checkbox in the Tree Settings does not have any effect. Bug with 64-bit v4.0 .NET CLR There is a bug in the 64-bit version 4.0 .NET Common Language Runtime (CLR) that interferes with the agent's ability to retrieve managed stack traces. If your app experiences this bug, APM will show empty thread profiles. This bug does not affect 32-bit applications. The bug is fixed in the CLR releases for .NET 4.5. To verify whether your 64-bit application has the fixed version, look at the full version of the mscorlib.dll in the C: \\ Windows \\ Microsoft.NET \\ Framework64 \\ v4.0.30319 directory. The fix is in versions 4.0.30319.17379 or higher. Other category only All threads are put in the Other category. The Web Request and Background categories are not supported. Python-specific notes When using thread profiling with the Python agent, be aware of the following. Python agent Thread profiler notes Co-routine based systems There are limits to capturing details when a co-routine based system is being used, such as gevent or eventlet modes of gunicorn. If creating a new thread, the Python agent will actually create a greenlet instead of a thread profiler background thread. Therefore, the thread profiler will not capture any web request and background transactions on the thread profiler page. Greenlets A greenlet can run only when other greenlets explicitly yield control, such as when they block. For example, if the thread sampler does get to run, it will only sample the stack for other greenlets at a point where they are blocked. It will not sample them when they are executing arbitrary code. It can completely miss execution within a greenlet if it never blocked or otherwise yielded to another greenlet. Time in Python code Time spent in pure Python code that isn't blocking requests will not be picked up, and no information will be recorded or reported. This is because results are misleading when co-routines are used. Ruby-specific notes When using thread profiling with the Ruby agent, be aware of the following. Ruby agent Thread profiler notes Backtraces The thread profiler depends on the ability to capture thread backtraces from within your Ruby application. For this reason, it requires MRI 1.9.2 or higher (for the Thread#backtrace method). Resque The Ruby agent does not currently support thread profiles with Resque background jobs. A thread profiling session initiated against Resque will only capture traces from the parent process, not the job processes. JRuby JRuby support is considered experimental at this time. There are known issues with JRuby's Thread#backtrace implementation that will affect the accuracy of and reliability of backtraces collected under JRuby.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 111.42534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Events</em>",
        "body": " to one.newrelic.com &gt; <em>APM</em> &gt; (select an app) &gt; <em>Events</em> &gt; Thread profiler. Select the host you want to run the profiler on. Set the duration for the profiling session. Select Start profiler. This triggers the agent to start the thread profiler during the next harvest cycle (every one minute) and capture data"
      },
      "id": "603ebd4928ccbccc3ceba78e"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-browser-monitoring": [
    {
      "sections": [
        "Build a custom New Relic One application",
        "Get started",
        "New Relic One: a programmable platform",
        "Tip"
      ],
      "title": "Build a custom New Relic One application ",
      "type": "docs",
      "tags": [
        "New Relic One",
        "Use New Relic One",
        "Build on New Relic One"
      ],
      "external_id": "0fd7afcf4cd3c15157668bf349e84968062140ed",
      "image": "https://docs.newrelic.com/static/2caff7bdf3bb0fb46bee7c214448c921/c1b63/new-relic-one-browser-analyzer-example-application_0.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/build-new-relic-one/build-custom-new-relic-one-application/",
      "published_at": "2021-10-07T07:16:33Z",
      "updated_at": "2021-07-27T13:37:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic gives you a framework to build your own React JavaScript applications that: Reside on the New Relic One platform, alongside your other dashboards and data. Feature visualizations that you've tailored specifically for your organization. Display data from any source you want, whether from a New Relic-monitored entity or data from another service or API. Get started Keep reading to learn more about what you can do with New Relic One apps. If you want to get started building quickly, first read the requirements. New Relic One: a programmable platform We strive to have an automated user experience that provides optimal value for all users. But we also know that some organizations have unique business needs that can’t be met with our standard visualization options. Now, we give you control over the fundamental building blocks of our platform. Using the same tools our engineers use to build New Relic One, you can build custom applications that align with your unique organizational structure and business needs. If you know how to use React, GraphQL, and NRQL (our query language), building an application will take you only a few minutes. Check out these guides for help building custom applications. Solve any data-driven challenge, no matter how complex. You can: Use our APIs to get data into New Relic from any source. Visualize that data in your custom applications. one.newrelic.com: Here’s an example of a custom application built on New Relic One. This application gives a highly detailed analysis of a website, using the PageView events reported from New Relic's browser monitoring. Tip If your visualization needs are relatively simple, consider using custom charts and custom dashboards. Now, visit our developer site and start building!",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 423.771,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " a highly detailed analysis of a website, using the PageView <em>events</em> <em>reported</em> from New Relic&#x27;s <em>browser</em> <em>monitoring</em>. Tip If your visualization needs are relatively simple, consider using custom charts and custom dashboards. Now, visit our developer site and start building!"
      },
      "id": "603eaaa6e7b9d251572a07d0"
    },
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-07T07:56:00Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.92738,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Query your <em>event</em> data",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": ", the current page receives a pageHide <em>event</em> before the previous page is shown. For supporting documentation and <em>browser</em> compatibility for the pageHide <em>event</em>, see the MDN Web Docs site. We also <em>report</em> the cumulative layout shift (CLS) score attribute with pageHide. This attribute is <em>reported</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Page load timing process",
        "Tip",
        "Page load process",
        "Page load time charts in browser monitoring",
        "Web application",
        "Network",
        "Important",
        "DOM processing",
        "Page rendering",
        "Request queuing",
        "App server requests vs. browser transactions",
        "Outliers"
      ],
      "title": "Page load timing process",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "3c1b807e4433968a69a461a95e612812ff0ff8e9",
      "image": "https://docs.newrelic.com/static/ade867510b645a97e56c905e4cf019f9/8c557/browser-page-load-timeline.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/page-load-timing-process/",
      "published_at": "2021-10-07T03:03:32Z",
      "updated_at": "2021-10-07T03:03:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document explains: How a web page loads How browser monitoring measures page load timing, also known as real user monitoring (RUM) Tip This is a description of traditional, synchronous page load timing. Browser can also monitor asynchronous page load timing. Page load process Here are the major steps in the loading of most web pages. The numbers 1-6 in the diagram correspond to the numbered steps below. Page load timeline: The steps involved in a web page load. Browser monitoring charts display the following segments of that process: Network, Web application, DOM processing, and Page rendering. A page load begins when a user selects a hyperlink, submits a form, or types a URL in a browser. This is also referred to as the initial request or the navigation start. The user's action sends a request across the network to the web application server. The request reaches the application for processing. (The request may take some time to start being processed. This could be the result of request queuing or it could be other factors.) The app finishes processing and sends an HTML response back across the network to the user's browser. This is sometimes referred to as response start or first byte. (Time To First Byte) The user's browser begins receiving the HTML response, and starts to process the Document Object Model, or DOM. The DOM finishes loading; this point is known as DOM ready. Using the DOM, the user's browser starts to render the page. The page finishes rendering in the user's browser and the window load event fires. (For pages that use asynchronous loading, some elements may continue to load after the window load event occurs.) Page load time charts in browser monitoring Browser monitoring captures the major page load timing segments in the browser Summary page and the Page views page. If you have SPA monitoring enabled, you will have access to both this chart and SPA-specific charts. The charts show: Network Web application time DOM processing Page rendering Other segments as applicable, such as request queuing The chart colors match the colors in the page load timing diagram. one.newrelic.com > Browser > (select an app) > Summary: The load time chart appears on the Summary and Page views page. The way browser collects these times depends on the browser's capability to use the Navigation Timing Specification API. You can add custom page load timing events with the browser agent API. Here are descriptions of the activity included in the browser load time chart segments: Web application The web application time includes the time spent on the application server. This can only be determined if the browser instrumentation for page load timing was provided by an APM agent. Network The Network layer includes time spent in redirects as well as in requesting and receiving HTML. It does not include time on the server or for static assets. Network time measurement starts from the initial click on a link. Network time includes DNS and may include more than one lookup if you have redirects on your site, TCP (including the firewall, unless you have configured request queue time monitoring), and SSL connect time. If you have configured request queue time monitoring, then the network time does not include any of the request queue time that occurs after the X-Request header. If you have not configured request queue time monitoring, then the network time does include all of the request queue time. The Navigation Timing Specification API provides a detailed breakdown of network time. (For old browsers, the timer starts on the \"before unload event.\") For apps that have been deployed using the copy/paste method, Browser includes web app and queue time in Network time. This is because browser relies on the server-side agent to pass the application values to the browser agent through auto-injection. For more information about how this back-end time breaks down from the browser's point of view, use the Session traces page. The session traces report on all the network related events available, so you can see on a case-by-case basis how the browser is spending time on DNS lookups and other network events. Important Even with request queuing configured, the front-end server's setup can still affect network time. This is because the front-end server does not add the queueing time header until after it actually accepts and processes the request. If the front-end server is configured in some way that causes requests to start backlogging and to queue up in the listener socket that the front-end server uses to accept connections, then you will see network time increase for browser monitoring. The queueing time headers can never account for backlog in this listener socket. DOM processing DOM processing is the time it takes to parse the HTML into a DOM and retrieve or execute synchronous scripts. If the browser starts to download images in this phase, page load timing will capture the image load time. The DOM processing and page rendering layers include network time for static assets (assets that are not explicitly retrieved after page load). However, if a script on the page dynamically inserts image tags and loads images after the server or content delivery system (CDN) finishes, page load timing cannot capture the image load time. Page rendering The Page rendering phase is the time between the DOM being complete and the window load event. This phase measures browser-side processing of the page content, and often includes time for scripts and static assets to load. Request queuing Request queuing will be displayed in the load time chart if your account has both browser and APM linked. In New Relic, request queuing refers to the time between a request entering your production systems and it reaching your application. Depending on the specifics of your production infrastructure, this time may include an actual queue that requests enter, or it may represent other functions that take time (such as load balancing or internal network latency). App server requests vs. browser transactions Often the number of app server transactions (requests per minute or rpm) is larger than the number of browser transactions (pages per minute or ppm) for the same application. For more information, see the troubleshooting procedures. Outliers No matter how well your application performs, there will be some slow browsers, platforms, and networks that make your overall aggregate response times appear slower. To minimize the skew caused by outliers, page load timing clamps and scales the end user response times that are greater than 4.5 times your application's browser Apdex T setting to 4.5 times the Apdex T, or to 13.5 seconds, whichever is greater. (Histogram outliers are cut off at 95%.) For example, if your application's end user Apdex T threshold is 8 seconds, those response times will be clamped at 36 seconds. This minimizes the impact of these response times on your overall application but still provides accounting for \"frustrated\" Apdex scores. For SPA monitoring, outliers are handled differently. When the duration of an initial page load or route change reaches 30 minutes, that event is treated as invalid data and is discarded.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 131.72409,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Page load time charts in <em>browser</em> <em>monitoring</em>",
        "tags": "<em>Browser</em> <em>monitoring</em>",
        "body": "This document explains: How a web page loads How <em>browser</em> <em>monitoring</em> measures page load timing, also known as real user <em>monitoring</em> (RUM) Tip This is a description of traditional, synchronous page load timing. <em>Browser</em> can also <em>monitor</em> asynchronous page load timing. Page load process Here"
      },
      "id": "6043efdf28ccbc21ff2c60a2"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-mobile-monitoring": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-07T20:06:36Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 124.081314,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests UI page that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "PageViewTiming: Async or dynamic page details",
        "Why use PageViewTiming?",
        "Support for Google's Core Web Vitals",
        "Detailed visual, interactivity, and responsiveness metrics",
        "Compatibility and requirements",
        "CumulativeLayoutShift",
        "How is CLS captured in New Relic",
        "Approximating other CLS sources",
        "How CLS is aggregated",
        "Query your event data",
        "Percentile over timeseries",
        "Percentile by transaction and interaction",
        "Histogram of delay timings"
      ],
      "title": "PageViewTiming: Async or dynamic page details",
      "type": "docs",
      "tags": [
        "Browser",
        "Browser monitoring",
        "Page load timing resources"
      ],
      "external_id": "069f311598f5df27ee46006693b077f7f8b8d146",
      "image": "https://docs.newrelic.com/static/e19694ae33f749d66a346968f23bfb5a/c1b63/core-web-vitals_0.png",
      "url": "https://docs.newrelic.com/docs/browser/new-relic-browser/page-load-timing-resources/pageviewtiming-async-or-dynamic-page-details/",
      "published_at": "2021-10-07T07:56:00Z",
      "updated_at": "2021-10-07T07:55:59Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Browser monitoring's PageViewTiming event sends each data point as a separate event as soon as it is available. Because we do not restrict the timing, you can receive first paint or first interaction data regardless of when it fires. This document describes why and how to use PageViewTiming and its attributes to query data about your site, component loading, and user performance metrics, both from visual and responsiveness standpoints. Why use PageViewTiming? If your application uses asynchronous or dynamic pages, you may need additional details about site or component loading. But pages can load content in many different ways, and users control when they interact with that content. This is why some user-centric performance metrics happen outside the standard window onload (page load time) in the browser agent. For example, users may become impatient and begin clicking as soon as content is on the webpage. Or, they may wait to use the page until long after content is loaded. The PageViewTiming event provides a more real-time delivery mechanism that does not have a dependency on any other event. The additional metrics can help you understand how users experience your site, both from visual and responsiveness standpoints. Support for Google's Core Web Vitals As of agent version 1177 for browser monitoring, we have full support for Google's Core Web Vitals for 2020. The metrics that make up Core Web Vitals will evolve over time. The current set for 2020 focuses on three aspects of the user experience: loading, interactivity, and visual stability. This includes the following metrics and their respective thresholds: Core Web Vitals metrics include loading, interactivity, and visual stability. Largest Contentful Paint (LCP): measures loading performance. To provide a good user experience, LCP should occur within 2.5 seconds of when the page first starts loading. First Input Delay (FID): measures interactivity. To provide a good user experience, pages should have a FID of less than 100 milliseconds. Cumulative Layout Shift (CLS): measures visual stability. To provide a good user experience, pages should maintain a CLS of less than 0.1. For each of these metrics, to ensure you're hitting the recommended target for most of your users, a good threshold to measure is the 75th percentile of page loads, segmented across mobile and desktop devices. To learn more, watch our Nerd Days talk on perceived performance. Detailed visual, interactivity, and responsiveness metrics The BrowserInteraction and PageView events end their reporting when they receive the page window load (or window load and AJAX) timing. However, paint and interactivity metrics can happen at any time. PageViewTiming delivers these metrics as a separate event to: Account for the variability in this timing. Avoid setting an arbitrary timeout. Prevent holding BrowserInteraction and PageView events indefinitely. Additional data Comments firstPaint and firstContentfulPaint The firstPaint and firstContentfulPaint attributes already are available with BrowserInteraction and PageView events. However, they are not always reliably captured before the window onload event fires. Using PageViewTiming gives you a way to capture these metrics even if they happen after the original page load time. This gives you a better understanding of the correlation between responsiveness of that load event and the visual rendering of your content. largestContentfulPaint The largestContentfulPaint,metric is available with agent version 1163 or higher. It reports the render time of the largest content element visible in the viewport. Google's research found that looking at when the largest element was rendered was a more accurate way to measure when the main content of a page is loaded and useful. For more information about this metric, including limitations and considerations, see the w3c draft. We also report the cumulative layout shift (CLS) score attribute with LCP. This attribute is reported as cumulativeLayoutShift. Largest Contentful Paint is one of three metrics identified by Google as the Core Web Vitals. LCP values up to 2.5 secs are considered \"Good,\" between 2.5-4.0 secs are considered \"Needs Improvement,\" and above 4.0 secs are considered \"Poor.\" firstInteraction and firstInputDelay With the addition of firstInteraction and firstInputDelay, you can quickly determine the ways that your users are interacting with that visual content. These metrics tell you not only when they interacted, but what type of interaction (mousedown, pointerdown, etc.) and how long it took for them to receive a response from your site. The firstInputDelay metric lies in the middle of FirstContentfulPaint and Time to Interactive (TTI) metrics. It measures the time between when a first input can be made and when the browser's main thread is able to respond to any interactions. We also report the cumulative layout shift (CLS) score attribute at the moment of the user's first interaction. This attribute is reported as cumulativeLayoutShift. First Input Delay is one of three metrics identified by Google as the Core Web Vitals. FID values up to 100 ms are considered \"Good,\" between 100-300 ms are considered \"Needs Improvement,\" and above 300 ms are considered \"Poor.\" For a more detailed explanation, see our browser monitoring release notes. cumulativeLayoutShift Cumulative Layout Shift (CLS) is available with agent v1177 or higher. CLS is an important, user-centric metric for measuring visual stability because it helps quantify how often users experience unexpected layout shifts. A low CLS helps ensure that the page is delightful. This is one of three metrics identified by Google as the Core Web Vitals. Cumulative Layout Shift is one of three metrics identified by Google as the Core Web Vitals. CLS scores up to 0.1 are considered \"Good,\" between 0.1-0.25 are considered \"Needs Improvement,\" and above 0.25 are considered \"Poor.\" timingName You can review different types of activities with the timingName attribute, such as firstPaint, firstContentfulPaint, firstInteraction, largestContentfulPaint, pageHide and windowUnload. For example, a PageViewTiming event may have a timingName of firstPaint and a firstPaint value of .03. The event will also include all default attributes included with the standard BrowserInteraction and PageView events. elementId This is the Id, if specified, of the largestContentfulPaint element. This value will only be reported with the LCP metric. This value can be null. elementSize This is the reported size of the largestContentfulPaint element. This value will only be reported with the LCP metric. pageHide The pageHide event, available with agent v1177 or higher, is sent when the browser hides the current page in the process of presenting a different page from the session's history. For example, when the user clicks the browser's Back button, the current page receives a pageHide event before the previous page is shown. For supporting documentation and browser compatibility for the pageHide event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with pageHide. This attribute is reported as cumulativeLayoutShift. windowLoad The windowLoad event is available with agent v1177 or higher. This is fired when the whole page has loaded, including all dependent resources such as stylesheets and images. For supporting documentation and browser compatibility for the windowLoad event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowLoad. This attribute is reported as cumulativeLayoutShift. windowUnload The windowUnload event is available with agent v1163 or higher. This is fired when a document or child resource is being unloaded. For supporting documentation and browser compatibility for the windowUnload event, see the MDN Web Docs site. We also report the cumulative layout shift (CLS) score attribute with windowUnload. This attribute is reported as cumulativeLayoutShift. Compatibility and requirements Requirements: Meets install requirements. Reporting of this event requires browser agent version 1153 or higher and a Pro or Pro+SPA agent. Follow our Browser agent release notes to find out when new metrics are released. These metrics are supported by the following browser versions. For unsupported browsers, no PageViewTiming events will be recorded. Metrics Supported browser versions cumulativeLayoutShift Chrome 79 Metric is elevated to stable; changes in metric definition will be reported in this log. Chrome 77 Metric exposed via API: Cumulative Layout Shift available via Layout Instability API firstPaint firstContentfulPaint Chrome 60 or higher for desktop and mobile (Android webview and Chrome for Android) Opera 47 or higher for desktop Opera 44 or higher for Android mobile Samsung Internet for mobile largestContentfulPaint Chrome 77 or higher for desktop and mobile firstInteraction firstInputDelay These metrics require the addEventListener browser API. This API is available in all modern browsers, including: Apple Safari Google Chrome Microsoft Internet Explorer (IE) versions 9 or higher Mozilla Firefox pageHide This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowLoad This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. windowUnload This metric is currently supported by all browsers on desktop and mobile. Compatibility matrix via MDN documentation. CumulativeLayoutShift Cumulative Layout Shift (CLS) is a metric measuring the stability of the content on a webpage. For a complete description, see web.dev/cls. How is CLS captured in New Relic Shifts in page layout as reported by the Layout Instability API are aggregated throughout the life of the page and reported as an attribute on all PageViewTiming events, representing the CLS value when that event occurred. Using this model, users can look at their CLS value at different points in the page's life; for example, CLS values up until the first-time users interact with the page or hide the page. Approximating other CLS sources Lighthouse captures CLS value only up to the time when a page is loaded, which is useful in a development or lab environment. You can approximate Lighthouse values by looking at the windowLoad PageViewTiming event. CrUX report uses values captured over the lifespan of the page, which is useful to analyze worst-case shifts in a RUM environment. You can approximate CrUX values by looking at the CLS attribute on the windowUnload PageViewTiming event. These values will not be exactly the same because of different sample sets and a difference in how values from long-lived web pages are included. The New Relic browser monitoring agent captures CLS when the page unloads, while CrUX collects and updates the metric throughout the lifespan of the page. How CLS is aggregated As of July 2021, Google has updated the way CLS values are aggregated. Browser monitoring agent versions v12xx use the method described in Evolving the CLS metric. Browser monitoring agent v12xx or higher: Layout shift values are captured in windows. Layout shifts that occurred within 1 second of each other, but no more than 5 seconds between the first and last shift, are part of the same window. A CLS score represents the sum of layout shift values from the window with the highest sum of layout shift values. Prior to Browser agent v12xx: A CLS score represents the sum of all layout shifts that occurred up until that point in the page's life. Query your event data Here are some sample queries for the event data to help you get started. Percentile over timeseries Show the 95th percentile of first paint and first contentful paint over a time series: SELECT FILTER(percentile(firstPaint, 95), where(timingName = ' firstPaint ')) as 'fp', FILTER(percentile( firstContentfulPaint , 95), where(timingName = 'firstContentfulPaint')) as 'fcp' FROM PageViewTiming TIMESERIES 1 minute SINCE 1 hour ago Copy Percentile by transaction and interaction Show the 95th percentile of first input delay over a time series, faceted by transaction name and interaction type: SELECT percentile( firstInputDelay , 95) as 'fid' FROM PageViewTiming WHERE timingName = 'firstInteraction' TIMESERIES 1 minute FACET browserTransactionName, interactionType SINCE 3 hours ago Copy Histogram of delay timings Show a histogram of first input delay timings faceted by first interaction time ranges: FROM PageViewTiming SELECT histogram( firstInputDelay , 1000, 10) SINCE 3 hours ago WHERE timingName = 'firstInteraction' FACET CASES (WHERE firstInteraction < 1, WHERE firstInteraction >= 1 AND firstInteraction < 5, WHERE firstInteraction >= 5) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.61754,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Query your <em>event</em> data",
        "tags": "Browser <em>monitoring</em>",
        "body": ", the current page receives a pageHide <em>event</em> before the previous page is shown. For supporting documentation and browser compatibility for the pageHide <em>event</em>, see the MDN Web Docs site. We also <em>report</em> the cumulative layout shift (CLS) score attribute with pageHide. This attribute is <em>reported</em>"
      },
      "id": "603ea90a64441f02614e88a4"
    },
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 92.974365,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Data requirements and limits for custom <em>event</em> data",
        "sections": "Data requirements and limits for custom <em>event</em> data",
        "tags": "Custom <em>events</em>",
        "body": " (There are additional requirements when using the <em>Event</em> API.) Browser <em>monitoring</em> agent APIs (There are additional requirements with the custom PageAction <em>event</em>.) <em>Mobile</em> <em>monitoring</em> SDK General requirements When reporting custom <em>events</em> and attributes, follow these general requirements for supported data types, naming"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    }
  ],
  "/docs/telemetry-data-platform/understand-data/event-data/events-reported-synthetic-monitoring": [
    {
      "sections": [
        "Data requirements and limits for custom event data",
        "General requirements",
        "Important",
        "Reserved words",
        "Event type limits"
      ],
      "title": "Data requirements and limits for custom event data",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Custom events"
      ],
      "external_id": "46f2be93b0c4daf40da9b93cfe0fbf5f235eecb7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/custom-data/custom-events/data-requirements-limits-custom-event-data/",
      "published_at": "2021-10-06T23:53:22Z",
      "updated_at": "2021-10-06T23:53:21Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains general requirements and rules for inserting and using custom events and their associated attributes. Additional requirements may apply based on the method you use. You can report custom events to New Relic in several ways, including: APM agent APIs Event API (There are additional requirements when using the Event API.) Browser monitoring agent APIs (There are additional requirements with the custom PageAction event.) Mobile monitoring SDK General requirements When reporting custom events and attributes, follow these general requirements for supported data types, naming syntax, and size: Requirement Description Payload Total maximum size or length: 1MB (10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. The Event API has additional HTTP rate limits. Attribute data types Attribute values can be either a string or a numeric integer or float. If your attribute values contain date information, define it as an unformatted Unix timestamp (in seconds or milliseconds) by using the Insights data formatter. Attribute size Maximum name size: 255 bytes. Maximum attribute value size: Custom attributes sent by the agent: 255 bytes Attributes attached to custom events sent using the Event API: 4096 characters Maximum total attributes per event: 254. Exception: If you use an APM agent API, the max is 64. Maximum total attributes per event type: 48,000. Important Charts may only display the first 255 characters of attribute values. For complete attribute values, use the JSON chart type or Query API. Naming syntax Attribute names can be a combination of alphanumeric characters, colons (:), periods (.), and underscores (_). Event types (using the eventType attribute) can be a combination of alphanumeric characters, colons (:), and underscores (_). If the name begins with anything other than an alphabetical character, enclose the name with backticks in your NRQL query. For example: FROM `0_hello` SELECT count(*) Copy Do not use words reserved for use by NRQL. Null values The database does not store any data with a null value. Reserved words Avoid using the following reserved words as names for events and attributes. Otherwise, unexpected results may occur. Important This is not a complete list. In general, avoid using MySQL-reserved words to avoid collision with future New Relic functionality. Keyword Description accountId This is a reserved attribute name. If it's included, it will be dropped during ingest. appId Value must be an integer. If it is not an integer, the attribute name and value will be dropped during ingest. eventType The event type as stored in New Relic. New Relic agents and scripts normally report this as eventType. Can be a combination of alphanumeric characters, colons (:), and underscores (_). Be sure to review the prohibited eventType values and eventType limits. Prohibited eventType values For your eventType value, avoid using: Metric, MetricRaw, and strings prefixed with Metric[0-9] (such as Metric2 or Metric1Minute). Public_ and strings prefixed with Public_. These event types are reserved for use by New Relic. Events passed in with these eventType values will be dropped. timestamp Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. It must be +/-1 day (24 hours) of the current time on the server. Log forwarding terms The following keys are reserved by the Infrastructure agent's log forwarding feature: entity.guid, log, hostname, plugin.type, fb.input. If used, they are dropped during ingest and a warning is added to the logs. NRQL syntax terms If you need to use NRQL syntax terms as attribute names, including dotted attributes, they must be enclosed in backticks; for example, `LIMIT` or `consumer.offset`. Otherwise, avoid using these reserved words: ago, and, as, auto, begin, begintime, compare, day, days, end, endtime, explain, facet, from, hour, hours, in, is, like, limit, minute, minutes, month, months, not, null, offset, or, raw, second, seconds, select, since, timeseries, until, week, weeks, where, with Event type limits The current limit for total number of eventType values is 250 per child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop data. Event types include: Default events from New Relic agents Custom events from New Relic agents Custom events from Insights custom event inserter",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 256.00153,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "sections": "<em>Data</em> requirements and limits for custom <em>event</em> <em>data</em>",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": " child account in a given 24-hour time period. If a user exceeds this limit, New Relic may filter or drop <em>data</em>. <em>Event</em> types include: <em>Default</em> <em>events</em> from New Relic agents Custom <em>events</em> from New Relic agents Custom <em>events</em> from <em>Insights</em> custom <em>event</em> inserter"
      },
      "id": "609fa5cfe7b9d2bf16c3eb69"
    },
    {
      "sections": [
        "Security for New Relic-reported events and attributes",
        "Default events and attributes",
        "Adjust the data reported"
      ],
      "title": "Security for New Relic-reported events and attributes ",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "af971d2b95ff397b57bf125f6801f57007ea5e77",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/customized-security-settings-insights/",
      "published_at": "2021-10-08T10:06:26Z",
      "updated_at": "2021-05-15T09:10:01Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By default, New Relic products report a variety of data used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. Default events and attributes Our products report a set of default events and attributes. We will never send request parameters or any other attributes that are not in the default set, unless someone has explicitly enabled this via configuration. Adjust the data reported When evaluating security settings for a New Relic product, review the default events and attributes. The default attributes don't contain sensitive data. In general, it's simply the data needed for effective performance monitoring. Our products don't send other data unless you change the default security settings. Depending on your requirements, either or both of these situations may apply: If the default list contains data you're concerned about, you can disable those attributes from being collected. For how to edit that, see the documentation for the product you're using. If you need to send attributes not reported by default, you can enable those attributes to be reported. In that case, do not use high security mode: this will disable the ability to collect custom attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Security for New Relic-reported <em>events</em> and attributes ",
        "sections": "<em>Default</em> <em>events</em> and attributes",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "By <em>default</em>, New Relic products report a variety of <em>data</em> used in our UI charts and that is available for querying. Our products will not transmit sensitive information without being explicitly instrumented to do so. <em>Default</em> <em>events</em> and attributes Our products report a set of <em>default</em> <em>events</em>"
      },
      "id": "60a8ea67e7b9d25ec7aeabfe"
    },
    {
      "sections": [
        "Default events reported by New Relic products"
      ],
      "title": "Default events reported by New Relic products",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Default events"
      ],
      "external_id": "217bc4ed58acefe9175df8be18fdf81baba7cf81",
      "image": "",
      "url": "https://docs.newrelic.com/docs/telemetry-data-platform/understand-data/event-data/default-events-reported-new-relic-products/",
      "published_at": "2021-10-08T11:23:52Z",
      "updated_at": "2021-05-15T09:09:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic products report different types of data. One type of data reported is event data. Events are displayed in UI charts and tables, and also made available for querying. To understand the types of data available, see Data available via NRQL. Learn more about the events reported by New Relic products: APM default events Browser default events Infrastructure default events Mobile default events Synthetics default events NrAuditEvent events for understanding changes to your account",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.62253,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Default</em> <em>events</em> reported by New Relic products",
        "sections": "<em>Default</em> <em>events</em> reported by New Relic products",
        "tags": "<em>Event</em> <em>data</em> <em>sources</em>",
        "body": "New Relic products report different types of <em>data</em>. One type of <em>data</em> reported is <em>event</em> <em>data</em>. <em>Events</em> are displayed in UI charts and tables, and also made available for querying. To understand the types of <em>data</em> available, see <em>Data</em> available via NRQL. Learn more about the <em>events</em> reported by New Relic"
      },
      "id": "609f8faf64441f8af9d2a1f0"
    }
  ]
}