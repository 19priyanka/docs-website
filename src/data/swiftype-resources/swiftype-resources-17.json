{
  "/docs/new-relic-solutions/solve-common-issues/find-help-use-support-portal": [
    {
      "sections": [
        "Glossary of New Relic terms",
        "account dropdown",
        "account switcher",
        "administrator",
        "agent",
        "agent API",
        "aggregated metrics",
        "aggregation delay",
        "aggregation function",
        "aggregation method",
        "aggregation timer",
        "aggregation window",
        "alert",
        "alert condition",
        "alert evaluation",
        "alert policy",
        "apdex",
        "apdex_f",
        "apdex_t",
        "API (application programming interface)",
        "APM",
        "application",
        "application ID",
        "application name",
        "Applied Intelligence (AI)",
        "attribute",
        "availability monitoring",
        "browser",
        "Browser monitoring",
        "background external",
        "child account",
        "cloud-based integration",
        "collector",
        "Command line interface (CLI)",
        "compute unit (CU)",
        "condition_id",
        "CPM (calls per minute)",
        "CPU burn",
        "custom attribute",
        "custom dashboard",
        "custom event",
        "custom instrumentation",
        "custom metric",
        "data collector",
        "data explorer",
        "degradation period",
        "dimensional metric",
        "Docker",
        "downtime",
        "entity",
        "event",
        "expected error",
        "exporter",
        "Flex",
        "framework",
        "harvest cycle",
        "health status indicator",
        "host",
        "host ID",
        "ignored error",
        "incident",
        "Infrastructure monitoring",
        "Insights",
        "instance ID",
        "instrumentation",
        "integration",
        "interaction",
        "interaction trace",
        "inventory data",
        "key transaction",
        "launcher",
        "log",
        "Log monitoring",
        "Logs",
        "Logs in context",
        "master account",
        "metric",
        "metric timeslice",
        "metric grouping issue",
        "minion",
        "Mobile monitoring",
        "monitor",
        "NerdGraph",
        "Nerdlet",
        "Nerdpack",
        "New Relic Edge with Infinite Tracing",
        "New Relic One",
        "New Relic One catalog",
        "NRQL (New Relic query language)",
        "non-web transaction",
        "notification",
        "notification channel",
        "on-host integration",
        "owner",
        "page load timing",
        "parameter",
        "parent account",
        "permalink",
        "pinger",
        "polling interval (AWS)",
        "PPM (pages per minute)",
        "private location",
        "recovery period",
        "response time",
        "restricted user",
        "rollup",
        "root span",
        "RPM",
        "RUM (real user monitoring)",
        "runbook",
        "SAML (Security Assertion Markup Language)",
        "Selenium",
        "service",
        "signal",
        "signal filter",
        "span",
        "SSL certificate",
        "SSO (single sign on)",
        "streaming algorithm",
        "sub-accounts",
        "Synthetic monitoring",
        "target",
        "tag",
        "thresholds",
        "throughput",
        "tier",
        "time picker",
        "time range",
        "timeslice data",
        "trace",
        "traffic light",
        "transaction",
        "transaction trace",
        "UI",
        "user",
        "UTC",
        "value function (metrics)",
        "violation",
        "web external",
        "web transaction",
        "WebDriverJS",
        "workload"
      ],
      "title": "Glossary of New Relic terms",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "8f8fc1ec9f41e6a4d6b4e986e9b0589bc2ca1f86",
      "image": "https://docs.newrelic.com/docs/glossary/glossary/images/account-dropdown.png",
      "url": "https://docs.newrelic.com/docs/glossary/glossary/",
      "published_at": "2021-12-20T01:43:05Z",
      "updated_at": "2021-12-18T01:39:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Whether you're considering New Relic One or you're already using our capabilities, this glossary of common terminology can help. And if you don't already have a New Relic account, don't hesitate to sign up at newrelic.com/signup. It's free, forever! account dropdown In the upper right of the New Relic UI, the account dropdown gives you access to your account settings. If you're trying to switch between accounts, use the account switcher. account switcher If you have access to more than one account in a multi-account organization, you can use the account switcher to switch between accounts. This is located in the top right of most New Relic UI pages. For more on factors that affect access to accounts, see Factors affecting access. To find account settings, use the account dropdown. administrator A type of user role on a New Relic account. For more information, see Users. agent At New Relic, an agent is a piece of monitoring software that provides integrations with various technologies (for example, web frameworks, host operating systems, or database types). The agents send that data to New Relic, usually on a specific cadence. For more information, see: New Relic Instant Observability Install agents agent API Some New Relic agents have agent APIs that allow you to extend the functionality of an agent. You can use the API to control, customize and extend the functionality of the agent. Here are some agent API docs: APM agents: C SDK API Go agent API Java agent API .NET agent API Node.js agent API PHP agent API Ruby agent API Python agent API Browser agent: Browser agent API Mobile agents: iOS SDK API Android SDK API aggregated metrics Aggregated metric data summarizes calls to specific methods in your application, including how many times each one was called and response times. In the New Relic UI, you see the class and method names along with their aggregate numbers. Metric data aggregation depends on the New Relic tool and your subscription level. For more information, see the documentation about data retention. aggregation delay The length of time in seconds to wait for the aggregation window to fill with data. Required when using CADENCE or EVENT_FLOW aggreation_method types. aggregation function You can use NRQL query functions, such as sum(), average(), or latest() to choose how the data points in an aggregation window should be processed into a single data point. The single aggregated data point is what's passed through the alert evaluation process. aggregation method New Relic aggregates data into windows, and needs to determine when the current window ends and the next one begins. The aggregation_method is the logic that tells us when we have all the data for a given aggregation window. Once the window is closed, the data is aggregated into a single point and evaluated against the threshold. This field is optional. One of the following three values can be specified: EVENT_FLOW: (Default) Each aggregation window will wait until it starts to see timestamps arrive that are past its own delay setting. Once this occurs, the data is published. Relies on the timestamps of arriving data, so wall-clock time is no longer relevant. Works best for sources that come in frequently and with low event spread (high througput metrics) CADENCE: Classic New Relic logic where each evaluation window waits exactly as long as the aggregation_delay setting, using the wall-clock time as a timer. aggregation_delay is required when using this option. Data arriving too late will be dropped, which can cause false alerts. EVENT_TIMER: Each aggregation window has a timer on it, set to the aggregation_timer setting. The Timer starts running as soon as the first data point appears for that aggregation window (based on the data point’s timestamp). The aggregation_timer is reset for each new data point that arrives for that window. Once the aggregation_timer reaches 0, the aggregation window is published. Ideal for sparse and batched data, such as cloud integrations and infrequent error logs. aggregation timer The length of time in seconds to wait after each data point received, to ensure the entire batch is processed. Required when using EVENT_TIMER aggregation_method type. aggregation window Streaming alerts gathers data together into specific amounts of time. These windows of time are customizable. Data points are collected together based their timestamps and reported as a batch. The customizable aggregation window provides greater flexibility and fewer false violations when alerting on irregular or less frequent data points. alert An alert communicates an event or incident that designated personnel can track through Alerts. For an explanation of how basic alerts concepts are related, see Concepts and workflow. alert condition An alert condition (or condition), identified by its unique numeric condition_id, contains the criteria for creating a violation. The condition includes the threshold that is set for a metric timeslice or a custom metric over time on a chosen target. For an explanation of how a condition relates to other basic alerts concepts, see Concepts and workflow. alert evaluation Streaming data is assessed on a set of aggregation windows to determine if an alert condition is violating or recovering. The aggregation window time is how long we'll collect data before running the NRQL query condition. The offset evaluation time is how long you want us to wait for late data before assessing it. If a window doesn't have any data points, it's treated as a gap for loss of signal. alert policy A collection of one or more conditions, one or more notification channels, and an Incident preference setting. If a condition contained within the policy opens a violation, an incident may be opened depending on the Incident preference setting. Notifications will then be sent to all channels attached to the policy. For an explanation of how a policy relates to other basic alerts concepts, see Concepts and workflow. apdex Apdex is an industry-standard way to measure users' satisfaction with the response time of an application or service. New Relic rates each response as Satisfied, Tolerated, or Frustrated, and uses these ratings to calculate an overall user satisfaction score. For more information, see Apdex: Measure user satisfaction. apdex_f The response time above which a transaction are rated frustrating. Defaults to four times apdex_t. Requests that complete in less than apdex_t are rated satisfied. Requests that take longer than apdex_t, but less than four times apdex_t (apdex_f), are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. apdex_t The response time above which a transaction is considered tolerable. The default value is 0.5 seconds, but you can change this in your Apdex settings. Requests that complete in less than apdex_t are rated satisfied. Requests that take more than apdex_t, but less than apdex_f, are tolerated. Any requests that take longer than apdex_f are rated frustrating. For more information, see Apdex: Measure user satisfaction. API (application programming interface) New Relic offers a variety of APIs and SDKs. For more information, see the introduction to New Relic's APIs. APM New Relic's APM (application performance monitoring) provides monitoring of your web or non-web application's performance. APM supports apps using several programming languages. application For New Relic purposes, any program instrumented by New Relic. application ID Some New Relic solutions assign a monitored application a unique application ID, often shortened to app ID. When present, this ID is available in the UI. It is also reported as an attribute and can be queried. For how to determine this, see Find app ID. application name The name that New Relic combines with your license key to uniquely identify a particular app. For more information, see Name your application. Applied Intelligence (AI) Applied Intelligence (AI) helps you find, troubleshoot, and resolve problems more quickly. Specifically, it’s a hybrid machine learning engine that reduces alert noise, correlates incidents, and automatically detects anomalies. Applied Intelligence includes Alerts, Incident Intelligence, and Proactive Detection. attribute Attributes are key-value pairs attached to data objects reported to New Relic. Attributes add detail, and they're similar to tags or labels in other SaaS software. You can explore this data by querying or searching via the UI or by using the data dictionary. Examples: APM reports a Transaction event. This includes timing data for the transaction in a duration attribute, which might have a value of .002. Our Infrastructure Monitoring reports a ProcessSample event. This includes a variety of CPU usage attributes, including a cpuSystemPercent attribute, which might have a value of .01. Our Telemetry SDK reports a Metric data type for storing metrics, with attached attributes like metricName and newrelic.source. Some New Relic tools allow you to report custom attributes to enhance your monitoring. For more information about attributes in APM, see Agent attributes. availability monitoring See Types of Synthetics monitors. browser The New Relic UI supports most browsers. For more information, see Supported browsers. For our end-user browser monitoring tool, see Browser Monitoring. Browser monitoring A Real User Monitoring (RUM) solution that measures the speed and performance of your end users as they navigate to your site from different web browsers, devices, operating systems, and networks. background external See web external. child account See parent account. cloud-based integration New Relic offers cloud-based integrations with providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform. collector The component that collects data from New Relic agents running on an app server, mobile device, or end-user browser. While the agent is installed on a user's app server, the collectors are centrally located in New Relic's data center. In order to contact the collector, the agent must be able to reach New Relic's domains and IP addresses. (The exact domain or IP depends on the New Relic monitoring tool.) The collector receives and interprets this data, and stores it in a database. The data is then retrieved and presented in the New Relic UI and by our various REST APIs. Command line interface (CLI) Our command line interface (CLI) is a tool you can use to build a New Relic application. This is the same tool our own engineers use. Go here for quick start instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some New Relic products governed by our original product-based pricing model. For more information, see Compute unit pricing. condition_id See alert condition. CPM (calls per minute) The number of calls your application receives each minute. This usually corresponds to the number of page views or external connections, and is usually the same as RPM (requests per minute). CPU burn The time consumed by code minus the wait time for a transaction. This is the time actually spent processing the transaction. It appears in the New Relic UI at the top of the transaction view for the agents that provide it (Ruby and PHP only). custom attribute A key-value pair added to a transaction or event in order to gain additional information about it. For more information, see custom attributes. custom dashboard A customizable dashboard with charts and tables that includes data from multiple New Relic data sources. For more information, see dashboards. custom event An event, in New Relic terms, is a data object with attached attributes. New Relic reports default event types, like Transaction and TransactionError. You can also create your own events. Events can be queried, and are used in some other features. You can generate custom events with APM agents, the browser monitoring agent, the mobile monitoring agents, and via the Event API. Alternatively, you can add custom attributes to some existing default New Relic events. custom instrumentation Custom instrumentation allows you to extend New Relic's monitoring to instrument code elements New Relic doesn't automatically instrument. Custom instrumentation is useful when your framework is not supported by New Relic, or when New Relic fails to pick up some element of your program. You can also use custom instrumentation to block a transaction from being reported entirely. For more information, see Custom instrumentation. custom metric Metric timeslice data that is manually recorded via an API call. Custom metrics allow you to record arbitrary metrics; for example, timing or computer resource data. All custom metric names must be prefixed with Custom/. For more information, see Custom metrics. Not to be confused with custom instrumentation data. data collector See collector. data explorer Use the data explorer to access, query and customize your data, create visualizations, and make connections between your services in a consistent and curated experience. For more on using the data explorer, see Introduction to the data explorer. degradation period When a data source enters a violating state, a degradation period of time begins. The degradation period is set in the condition's threshold. A violation will open if the source stays in a violating state for the entire degradation period. In addition: If the data source enters a non-violating state before the entire time has elapsed, the degradation period countdown is reset, and a violation does not open. If your alert condition threshold is configured as at least once in, the degradation period always lasts a single minute. dimensional metric A dimensional metric is a metric that has multiple attributes, also known as dimensions. At New Relic, we report dimensional metrics using the Metric data type. For more on other metric data types, see Metric data. Docker An open platform for distributed applications, which allows you to assemble multi-container portable apps. Infrastructure Monitoring includes integrated Docker monitoring. For more information about Docker, see the Docker website. downtime The period of time when customers cannot access your site and your app is not reporting to New Relic. For more information, see Synthetic Monitoring and Types of synthetic monitors. entity In New Relic, an entity is anything we can identify that has data you can monitor. An entity can be something you monitor directly, like applications and microservices, or indirectly, like data centers. You can identify one or more entities to be targets for alert conditions. In the Alerts API, the entity being monitored is identified with an entity_id. For more on this, see What are entities? event The word event is a general term that can have many meanings. At New Relic, event can have several meanings: At New Relic, event data is one of our core data types. Event data represents a record of a single event at a particular moment in time. Events can vary by type (for example, Transaction or Mobile, and will have associated attributes (for example, timestamp or transactionName). For more details, see Event data. For our infrastructure monitoring, the word event can be used to refer to important system and host activity. For example, a configuration change for a monitored host would be registered on Infrastructure's Events UI page. For alerts, the Events UI page displays a list of alerts-related incidents for your monitored entities. Events are reported for a violation opening and for closing. In some contexts, event can refer to any NRQL-queryable data type. For example, when you run a NRQL query, you will see a count of inspected events: this refers to a count of all data types queried. expected error An expected error is a common error that you don't want to affect your Apdex score or error rate. For more information, see Manage errors in APM. exporter At New Relic, an exporter is a type of integration that reports telemetry data to New Relic from a third-party (non-New Relic) telemetry tool. For examples, see Exporters, or search our integration quickstarts in New Relic I/O. Flex New Relic Flex is an application-agnostic, all-in-one infrastructure integration. With it, you can build your own integration that collects metric data from a wide variety of services, and that can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text) to the terminal. It's a recommended way to create a custom integration, because it doesn't require coding skills. framework A framework is a structured collection of pre-defined functions, into which an application builder inserts their own code to build their application. A framework is not the same as a library. While a library is a collection of functions you can call as needed, a framework is a skeleton for your application. The functions in that framework then call your functions. For more about the distinction between a framework and a library, see What is the difference between a framework and a library?. New Relic automatically instruments many common frameworks. For more about the frameworks New Relic supports, see the agent-specific documentation: C SDK supported frameworks Go supported frameworks Java supported frameworks .NET supported frameworks Node.js supported frameworks PHP supported frameworks Python supported frameworks Ruby supported frameworks harvest cycle The period of time between each connection from a New Relic agent to the collector. Between harvest cycles, an agent collects and caches data. At the end of the cycle an agent reports those data to the collector, then begins a new harvest cycle. health status indicator Some New Relic UI pages have a health status indicator appearing next to an index of monitored entities. This is a colored bar (generally green, yellow, red, or gray) indicating the status of your app or other entity monitored by New Relic. It also indicates whether the entity has any alert policies assigned to it and whether there are any policy violations. In general, the colored bar will be green, yellow, red, or gray to indicate the health status. Exceptions: Our REST API (v2) uses orange instead of yellow for the application's health and reporting status. Service maps use different criteria for reporting the health of a connection between an app and an external service not monitored by New Relic (for example, a third party API). host At New Relic, a host means one of the following: A physical machine is a hardware-based device with dedicated physical resources, including memory, processing, and storage. Each machine has its own OS which applications run on. A virtual machine (VM) is the software implementation of a physical machine that executes programs like a physical machine. One or more virtual machines can run on a physical machine. Each virtual machine has its own OS and allocated virtual machine resources such as RAM and CPU. A cloud instance is a type of virtual machine that is run in the public cloud. In this context, virtual machines and cloud instances are different from Java Virtual Machines (JVMs) and containers. host ID Each host identified by APM is assigned a host ID. This ID is used to uniquely identify it, and to retrieve data about that host via the REST API. For more information, see List host ID. ignored error An error that you have told the APM agent not to report to the collector. For more information, see Manage errors in APM. incident An incident is a collection of one or more violations of the conditions defined in an alert policy. An incident record includes all of the open and close time stamps for each violation, as well as chart snapshots of the data being evaluated around the time of each violation. You can view detailed information from the Incidents pages in the user interface. You can also select your preference for how we roll up violations into the incident. For an explanation of how an incident relates to other basic alerts concepts, see Concepts and workflow. Infrastructure monitoring By connecting changes in host performance to changes in your configuration, infrastructure monitoring provides real-time metrics and powerful analytics that reduce your mean-time-to-resolution (MTTR). Infrastructure is specifically designed for complex environments that need flexible, dynamic server monitoring, from a physical datacenter to thousands of Amazon Elastic Compute Cloud (Amazon EC2) instances and other types of integrations. Insights Insights was the name for the New Relic product that previously governed the reporting of custom events, as well as the ability to query and chart your New Relic data. These features are now a fundamental part of the New Relic One platform and are no longer governed by the Insights product or name. To learn more about these features: Event API for reporting custom events Query and chart data For historical reasons, the word \"Insights\" is still used in some places. For example: Some APM agents still have Insights language in their codebase. For example, the Java agent custom_insights_events configuration. For New Relic organizations on our original pricing model, Insights Pro is still the product name governing custom event data ingest and retention. There is an API key called the Insights insert key. instance ID Each instance identified by New Relic is assigned a unique instance ID. Instance IDs are most commonly found for JVMs (Java Virtual Machines), but can exist for each agent. This ID is used to uniquely identify it, and to retrieve data about that instance via the REST API. For more information, see List instance IDs. instrumentation The collection of data from an application or host. When New Relic instruments a framework, it detects the methods and calls used by that framework, and intelligently groups them together. integration At New Relic, an integration refers to a solution that integrates with a specific technology (like a web framework or a type of database). All our integrations can be found as quickstarts in New Relic Instant Observability. interaction In our mobile monitoring, an interaction is a specific code path initiated by a user interaction (usually a button press). An interaction is the mobile equivalent of a transaction, and like a transaction an interaction can be traced and monitored. You can see much of the data included in an interaction in the BrowserInteraction event. interaction trace An interaction trace is a complete picture of a single interaction. With interaction traces, New Relic gives you much deeper visibility into a single slow interaction, which can help you understand a broader problem. Interaction traces are the mobile equivalent of a transaction trace. For more information, see Creating interactions (iOS) and Creating interactions (Android). inventory data Inventory data is information about the status or configuration of a service or host. Examples of inventory data include: Configuration settings Name of the host the service is on Amazon AWS region Port being used For more information, see Understand and use data. key transaction A web transaction that the user has marked as particularly important; for example, key business events (such as signups or purchase confirmations), or transactions with a high performance impact (such as searches). Key transactions have their own pages in the UI and other customized values. For more information, see Key transactions. launcher A launcher is a specific piece of code you can include when you create a New Relic One app. It creates the tile on the homepage that you click to launch the app. For more information, see the documentation about core UI components. log A log is a message about a system used to understand the activity of the system and to diagnose problems. For more information on how we use log data, see Log management. Log monitoring Our log management and monitoring features give you the tools to collect, process, explore, visualize, and alert on your log data using your existing log forwarder. With all of your log data in one place, you'll be able to make better decisions, detect and resolve problems more quickly, and see your logs in context to troubleshoot faster. Logs Our Logs feature is a scalable log management platform that allows you to connect your log data with the rest of your telemetry data. Pre-built plugins with some of the most common open-source logging tools make it simple to send your data from anywhere to New Relic. Logs in context Logs in context makes it easy to link to your log data with related data across the rest of our platform. Bringing all of this data together in a single tool allows you to quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. master account See parent account. metric A metric is a numeric measurement. Metric data is a broad category because there are several ways to make and report measurements. For more about how metrics are reported at New Relic, see New Relic data types. metric timeslice New Relic reports metrics in several ways. One variety of metric data is called metric timeslice data; this is the type of data used to generate many of the charts in APM, mobile monitoring, and browser monitoring (for more details, see metric timeslice data). Over time, metric timeslice data is aggregated into longer timeslice data records for more efficient storage. For more about how we aggregate this type of data, see Data aggregation. For how to query this type of data, see Query metric timeslice data. metric grouping issue A metric grouping issue occurs when an account sends too many differently named metric timeslice data points to New Relic, and those individual web transactions are not properly aggregated. For example, rather than a single /user/controlpanel/ metric name, you might see /user/controlpanel/alice, /user/controlpanel/bob, and /user/controlpanel/carol. For more information, see Metric grouping issues. minion The software that accepts monitor jobs from a private location. A minion is a packaged virtual appliance that runs in your hypervisor. For more information, see Private locations overview and install and configure private minions. Mobile monitoring Mobile monitoring allows you to monitor and manage the performance of your mobile apps on Android, iOS, tvOS, and other systems. Mobile monitoring provides end-to-end details, including crashes, throughput, HTTP requests, error traces, and more. Not to be confused with New Relic's own mobile apps for Android, iPhone, and iPad. monitor For our Synthetic Monitoring, a monitor ensures your website or API endpoint is available. For more information, see Adding and editing monitors. NerdGraph NerdGraph is our GraphQL API, an efficient and flexible query language that lets you request exactly the data you need, without over-fetching or under-fetching. NerdGraph calls get all the data you need in a single request. NerdGraph also makes it easier to evolve APIs over time and enables powerful developer tools. You can use our NerdGraph GraphiQL explorer to explore the schema and find definitions. With valid New Relic API key, you can try it out yourself at api.newrelic.com/graphiql. Nerdlet A Nerdlet is a component of a New Relic One application. It's a specific UI view, represented by a React JavaScript package. For more information, see Nerdpack file structure. Nerdpack A Nerdpack is a component of a New Relic One application. It's the package containing all the files needed by that application. For more information, see Nerdpack file structure. New Relic Edge with Infinite Tracing New Relic Edge with Infinite Tracing is a fully managed, distributed tracing service that observes 100% of your application traces, then provides actionable data so you can solve issues faster. For more information, see /docs/understand-dependencies/distributed-tracing/get-started/how-new-relic-distributed-tracing-works. New Relic One For more information, see Introduction to New Relic One. New Relic One catalog Our catalog is a collection of applications built on the New Relic One platform. The catalog includes custom apps we've built, public open source apps, and any apps that you buid. You can browse the catalog on New Relic One. NRQL (New Relic query language) NRQL is a query language, similar in form to SQL, that allows you to query the data stored in your New Relic account. non-web transaction APM identifies transactions as either web or non-web. When New Relic does not detect a transaction was initiated by a web request, this is called a non-web transaction. For more information, see Background processes and other non-web transactions. notification The message sent when an incident opens, is acknowledged, or closes. The type of notification is defined by the alert policy's notification channel. For an explanation of how notifications relate to other basic alerts concepts, see Concepts and workflow. notification channel Where we send a notification when an incident opens, is acknowledged, or closes. Available channels include email, mobile push notifications, webhooks, and more. on-host integration On-host integrations refer to integrations that reside on your own servers or hosts and that communicate with our infrastructure agent. For more information, see Introduction to on-host integrations. owner For accounts on our original pricing model, this is a type of user role: the user who initially created the account. For more information, see Users. page load timing With page load timing, New Relic monitors the full load time for end-user browsers. New Relic's application agents dynamically inject JavaScript into the page, then capture the following key load points: Navigation start: The user initiates the transaction. First byte: The browser receives the requested page. DOM ready: The browser has finished parsing DOM. Page ready: Page loading is complete. Page load timing is sometimes referred to as RUM, or real user monitoring. Unlike standard RUM, page load timing also captures JavaScript errors and AJAX requests. For more information, see Page load timing process. parameter Deprecated term; see attribute. parent account New Relic organizations can have a parent/child account structure. This structure was much more important for organizations on our original user model, but is still used for some features for organizations on the New Relic One user model. Learn more about account structure. Parent accounts were previously referred to as \"master accounts\", and child accounts were previously referred to as \"sub-accounts\". permalink A unique URL that links to a view of your application at a specific point in time. Permalinks are useful for troubleshooting and for sharing interesting time windows with colleagues. pinger The component of New Relic that connects to your website to verify your website is accessible. New Relic has pingers in Europe, Asia, and the United States. Each pinger attempts to contact your website at least once every two minutes. If enough pingers are unable to reach your website, your application will be considered down. For in-depth scriptable testing, including real browser tests and tests of API endpoints, see Synthetic Monitoring. Synthetic Monitoring includes free ping monitoring, which allows you to monitor your website from locations around the world. For more information, see Types of Synthetic monitors. polling interval (AWS) Our Amazon integrations query your AWS services according to a polling interval, which varies depending on the integration. Each polling interval occurs for every AWS entity. For example, if you have thirteen Elastic Load Balancers (ELB), each one will be polled every five minutes. Depending on the AWS integration, there may be delays in the timing between the API request and the metric data returned. If you notice unusual delays, follow the integration troubleshooting procedures. PPM (pages per minute) The number of pages per minute your application serves. private location A Synthetic monitor feature that allows you to run Synthetic monitors from within your own systems by creating private minions. Private locations allow you to extend your Synthetic coverage to new geographical locations, and to monitor websites behind your firewall such as an intranet site. For more information, see Private locations overview. recovery period A recovery period of time begins when a data source enters a non-violating state after being in a violating state. The recovery period is set in the condition's threshold. A violation will close when a source remains in a non-violating state and the recovery period time has elapsed. If the data source enters a violating state before the time has elapsed, the recovery period clock will reset and the violation won't close. response time The duration of time between a request for service and a response. For more information, see Response time. restricted user A type of user role on a New Relic account. For more information, see Users. rollup Using the same application name for multiple applications. This allows you to combine data in APM, either from multiple applications, or from multiple instances of an application. For more information, see Rolling up app data. root span For distributed tracing, the root span is the first span in a trace. In many cases, the root span duration will represent the duration of the entire trace, or be very close to it. However, for more complex, modern systems that use a lot of asynchronous, non-blocking processes, this will not be true. For those systems, the root span’s duration may be significantly less than the duration of the trace. RPM The term RPM usually refers to the number of requests per minute your application receives from users. This is usually the same as CPM (calls per minute). Historically, some New Relic monitoring solutions, like APM and Browser Monitoring, used to contain RPM in the URL; for example, https://rpm.newrelic.com. This language use originally referred to Rails performance management because the first iteration of our product monitored Ruby on Rails applications. We monitor many more languages and systems than Ruby now. RUM (real user monitoring) See page load timing. runbook A runbook contains standard procedures and operations typically used by system administrators, network operations staff, and other personnel to handle outages, alert incidents, and other situations. If your organization stores runbook instructions as URLs, you can link this information to an alerts policy so your personnel has easy access to this information when an incident violates the defined policy thresholds. SAML (Security Assertion Markup Language) SAML is an XML-based data format for sharing authentication data between two parties. New Relic accounts must obtain a SAML certificate in order to enable Single Sign On for their users. For more information, see SAML service providers. Selenium Selenium is an open-source browser testing suite. Synthetics uses Selenium to test monitored websites with real browsers. For more information, see monitor types. service A service is a cluster of runtime server processes that accomplish a particular task, usually service requests. Unlike an application, a service is not usually invoked by a human. New Relic offers a variety of integrations that allow you to report data from your services. signal The stream of telemetry data that's watched and alerted on. You use NRQL queries to define a signal. signal filter When we receive data and it's routed to the streaming alerts platform, your NRQL WHERE clause will filter the data coming in. The filtered streaming data is what's evaluated for loss of signal violations, for example. span In a distributed trace, a span is a \"named, timed operation representing a contiguous segment of work in that trace\" (from OpenTracing.io definition). For distributed tracing, spans are displayed in the distributed tracing UI, and the data type Span is available to be queried. See also root span. SSL certificate SSL certificates encrypt data that is being transmitted. While New Relic refers to security certificates as SSL because it is a more commonly used term, all certificates adhere to industry standards for secure encryption in transit. SSO (single sign on) SSO (single sign on) allows you to manage user authentication in New Relic using an external SSO provider. For more information, see Setting up SSO. streaming algorithm This is what determines when the data in an aggregation window is processed. The streaming algorithm uses your server's clock time and the aggregation window size to trigger the alert evaluation process. sub-accounts See master account. Synthetic monitoring Synthetic monitoring allows you to monitor your website or API endpoint via automated, scriptable tools. Use free ping monitor to ensure your website is accessible, or expand your monitoring with browser monitors, which test your website with real browsers. Go further with scripting, to script browsers or API monitors for sophisticated testing. target A target is a resource or component monitored by a New Relic monitoring tool that has been identified in an alert condition. When the data source for that target crosses the defined critical threshold, we will open a violation. Depending on your policy's Incident preference setting, Alerts may create an incident record and send notifications through the defined channels. See also entity. tag Tags are key:value metadata added to monitored apps, hosts, dashboards, and other entities to help you organize your data at a high level. For details, see Tags. thresholds Thresholds are alert condition settings that define a violation. Threshold values include the value a data source must pass to trigger a violation and the time-related settings that define a violation; for example: Passing a certain value for at least x minutes Passing a certain value only once in x minutes While the data source passes a certain value, a degradation period starts. Likewise, when that data source stops passing a certain value, a recovery period starts. The durations of these two time periods are defined in the alert condition threshold settings. Thresholds have a required critical (red) threshold and an optional warning (yellow) threshold. In the UI, the entity's health status indicator will change to yellow or red when a threshold has been crossed and a violation will open. For more information, see Define thresholds. For an explanation of how thresholds relate to other basic Alerts concepts, see Concepts and workflow. throughput Throughput is a measurement of user activity for a monitored application. APM throughput and Browser Monitoring throughput are measured in different ways: APM: requests per minute (RPM) Browser: page views per minute (PPM) tier A tier can refer to how New Relic categorizes or visualizes the various agent language ecosystems that we support. For example: In APM, the color-coded categories that appear on your app's main Overview chart show response time spent in various functions, processes, or agents as tiers; for example, request queuing, garbage collection, Middleware, JVMs, etc. In New Relic labels, TIER can be used to define or classify the client-server architecture; for example, front-end and back-end tiers. \"Tier\" may sometimes be used to refer to our pricing editions. time picker By default the New Relic UI shows data for the past 30 minutes, ending now. To change the time window, use the time picker. time range A time range can refer to a length of time selected in the New Relic UI. New Relic displays a time range depending on the range you select using the time picker. timeslice data See metric timeslice data. trace A trace is a description of how a request travels through a system. Trace data helps you understand the performance of your system and diagnose problems. For more information on how we use trace data, see New Relic data types. traffic light See health status. transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. For more information, see documentation about web transactions and non-web transactions. The term transaction is also sometimes used in Browser Monitoring. In that case, it primarily refers to activity beginning with a browser-side web request and ending with a complete page load. transaction trace A transaction trace is a complete picture of a single transaction, down to the database queries and exact invocation patterns. With transaction traces, New Relic gives you much deeper visibility into a single slow transaction, which can help you understand a broader problem. For more information, see Transaction traces. UI The New Relic user interface. For more information, see Standard page functions. user A user can refer to a specific user role in a New Relic account. For more information, see Users. UTC Universal Time Coordinated (UTC), or Coordinated Universal Time, is a standard timestamp for synchronizing time around the world. value function (metrics) The numeric value obtained from metric timeslice data; for example, an average, minimum, maximum, total, sample size, etc. violation A violation occurs when the entity monitored by an alert condition reports a value that crosses the thresholds defined in that condition. For an explanation of how violations relate to other basic alerts concepts, see Concepts and workflow. You can view a summary of the violations for a selected incident's page. You can also view the violations for a specific entity from the product's UI. web external Web external is the term applied to the portion of time spent in transactions to external applications from within the code of the application you are monitoring. That time can be a call to a third party company (a payment provider, for example) or it could be a call to another microservice within your own company. Web external demonstrates how performance is impacted by your code executing outside the application you are measuring. web transaction A transaction is defined as one logical unit of work in an application. This term primarily refers to server-side transactions monitored by APM. Web transactions are initiated with an HTTP request. For most organizations, these represent customer-centric interactions and thus are the most important transactions to monitor. For more information, see Web transactions and Non-web transactions. WebDriverJS WebDriver is a Selenium component, used to control Synthetics scripted browsers. Specifically, Synthetics uses WebDriverJS, a Node.js-based flavor of Selenium. For more information, see Writing scripted browsers and Scripted browser examples. workload A workload represents a group of entities that work together to provide a digital service. For more information, see Workloads.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 292.0818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Glossary of <em>New</em> <em>Relic</em> terms",
        "sections": "Glossary of <em>New</em> <em>Relic</em> terms",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " line interface (CLI) is a tool you can <em>use</em> to build a <em>New</em> <em>Relic</em> application. This is the same tool our own engineers <em>use</em>. Go here for quick <em>start</em> instructions. Go to our Developer site for sample apps and guides. compute unit (CU) A unit of measurement that determines your pricing for some <em>New</em> <em>Relic</em>"
      },
      "id": "61b40189196a672dd0a5aa8c"
    },
    {
      "sections": [
        "Choose your data center (US or EU)",
        "Requirements",
        "Regions and availability",
        "Regions and account hierarchy",
        "Hierarchy example for partnership accounts",
        "Create an EU region account",
        "API endpoints for EU region accounts",
        "Access New Relic One",
        "Billing and pricing",
        "Operational access and processing",
        "Verify your account is based in EU region"
      ],
      "title": "Choose your data center (US or EU)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "58aede83cf1625a8a52aaeed540cebfbaa024d61",
      "image": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/images/Eu_account_hierarchy.png",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/account-setup/choose-your-data-center/",
      "published_at": "2021-12-19T15:40:33Z",
      "updated_at": "2021-12-14T04:22:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's global data hosting structure consists of two regions: the European Union (EU) region and the United States (US) region. Selecting your preferred region during the account setup process allows you to specify the region where your performance monitoring data will be hosted. You can also create accounts in each region. Requirements Access to the New Relic EU region requires the latest agent version. For new customers: Install the most recent agent version. For existing customers: Update to the most recent agent version. Minimum agent version required: C SDK 1.0.0 or higher Go 2.0.0 or higher Java 4.0.0 or higher .NET 8.0.0 or higher Node.js 3.0.0 or higher PHP 8.0.0.204 or higher Python 3.0.0.89 or higher Ruby 5.0.0.342 or higher Regions and availability Your choice of data center is not limited by your geographic location. You can choose to create an account with data hosted in either the EU or US region, regardless of where you or your systems reside. You can also create accounts in each region. New Relic offers almost all the same active products, features, support offerings, and performance levels in the EU region as what is offered in the US region. Exceptions: The following are not supported with an EU region account: Infinite Tracing is not available. APM's weekly performance reports are not available. Errors inbox is not available. Log patterns Deprecated products and features are not available. New Relic's Incident Intelligence service operates solely in the US whether you store your data in New Relic’s US region data center or New Relic’s EU region data center, by using New Relic Incident Intelligence, you consent that New Relic may move and store your data in the US region. New Relic CodeStream operates solely in the US. Whether you have selected New Relic's US or EU region data center during setup of your New Relic account, when using New Relic CodeStream, you consent that your New Relic CodeStream data will get stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted in the US region, you must create a new account to store data in the EU region. You cannot view EU data from a US account, or US data from an EU account. The data collected remains separate. The data cannot be aggregated or migrated between accounts. For organizations that have a parent/child account structure, you can only have one parent account. For more, see Manage apps or users with child accounts. For partnership accounts, no changes to the partnership owner account are required. However, data cannot be shared across regions, so a partnership requires a parent account for each region. Hierarchy example for partnership accounts With partnership accounts, a new parent account must be created for any data to be host in the EU region. This hierarchy illustrates how global accounts are structured with partnership owner accounts. Data is not aggregated beyond the parent account. Example hierarchy for partnership organizations. Because data cannot be shared across regions, a partnership will require a parent account for each region. Create an EU region account To create a New Relic account in the EU region: Go to the New Relic signup page. OR If you have a specific offer from a New Relic partner, follow that link directly. Follow the online steps to create your account. From the Select your region dropdown, select European Union. Agree to the Terms of Service. When you receive an email confirmation message, select the link to confirm your account and sign in to New Relic. Then install or update to the most recent agent version. API endpoints for EU region accounts If you have an EU region account, use the appropriate endpoints to access the following New Relic APIs: API EU endpoint Browser source maps API sourcemaps.service. eu .newrelic.com Copy Infrastructure Alert API infra-api. eu .newrelic.com Copy Dashboard API rpm. eu .newrelic.com/api/explore/dashboards/list Copy Insert API insights-collector. eu01 .nr-data.net Copy Insights Query API insights-api. eu .newrelic.com Copy Mobile apps rpm. eu .newrelic.com/mobile Copy NerdGraph GraphiQL API api. eu .newrelic.com/graphiql Copy Partner API The partner API is a global API with no regional data differences. Use this endpoint for both EU and US accounts: rpm.newrelic.com/api/v2/partners/ Copy REST API api. eu .newrelic.com Copy Synthetics API synthetics. eu .newrelic.com/synthetics/api Copy Trace API trace-api. eu .newrelic.com/trace/v1 Copy Metric API metric-api. eu .newrelic.com/metric/v1 Copy Log API log-api. eu .newrelic.com/log/v1 Copy Access New Relic One If your accounts report data to the EU data center, use the following link to go to New Relic One: one.eu.newrelic.com. Billing and pricing New Relic's account billing process and pricing options are the same for both the EU and US regions. Operational access and processing Customer Data is hosted in the region selected during account creation. Systems Operations Data is stored in the US region. All other information, including account information (such as license subscription information, billing, and internal monitoring) is hosted in the US region and replicated in the EU region. New Relic may access and process Customer Data in the United States and such other jurisdictions where New Relic has affiliates and subsidiaries, including as may be necessary to maintain, secure, or perform the services, to provide technical support, or as necessary to comply with law or a binding order of a government body. Customer Data from existing New Relic accounts cannot be transferred or shared across regions, and new data generated cannot be shared with existing accounts, even in partnership accounts. Verify your account is based in EU region Use either of these options to verify whether your account data is hosted in the EU region's data center: In APM, mouse over the application name to view the URL. If it begins with rpm.eu.newrelic.com/, it is an EU-based account. Check your New Relic license key. If it begins with EU, it is an EU-based account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.8708,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Access <em>New</em> <em>Relic</em> One",
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": " <em>New</em> <em>Relic</em>&#x27;s US or EU region data center during setup of your <em>New</em> <em>Relic</em> account, when <em>using</em> <em>New</em> <em>Relic</em> CodeStream, you consent that your <em>New</em> <em>Relic</em> CodeStream data will <em>get</em> stored in the US. Regions and account hierarchy You can create accounts in each region. If your data is currently being hosted"
      },
      "id": "61b81bf6e7b9d2a96fef4e3a"
    },
    {
      "sections": [
        "View our UI in dark mode",
        "Switch between light and dark mode"
      ],
      "title": "View our UI in dark mode",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Welcome to New Relic",
        "Get started"
      ],
      "external_id": "b36ae1720e821d90136751f9a2f90d3d1f030c16",
      "image": "https://docs.newrelic.com/static/cbbd29dd03ca29a197b3cee88707141b/c1b63/APM_distributed_tracing_dark-Mode.png",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/ui-data/view-our-ui-dark-mode/",
      "published_at": "2021-12-19T17:36:44Z",
      "updated_at": "2021-12-14T03:44:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you're checking on incidents in the middle of the night, or just want to avoid straining your eyes, you can view our UI in dark mode. To switch between light mode and dark mode in New Relic's UI, click the account dropdown. Switch between light and dark mode To view our UI in dark mode: From one.newrelic.com, click the account dropdown. [ NOTE: Currently dark mode is not supported in the Firefox browser.] Click Theme: to switch between the following options: Theme: auto (default): matches the UI with what you already have enabled with your OS. Theme: dark: keeps the UI in dark mode. Theme: light: keeps the UI in light mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 258.70224,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Welcome</em> <em>to</em> <em>New</em> <em>Relic</em>",
        "body": "When you&#x27;re checking on incidents in the middle of the night, or just want to avoid straining your eyes, you can view our UI in dark mode. To switch between light mode and dark mode in <em>New</em> <em>Relic</em>&#x27;s UI, click the account dropdown. Switch between light and dark mode To view our UI in dark mode: From"
      },
      "id": "603e987964441ff7db4e8876"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/find-agent-root-directory": [
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2021-12-19T22:50:13Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2021-12-19T22:49:19Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.5287,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    },
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.1339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "sections": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " values. Ruby <em>Use</em> audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for <em>troubleshooting</em> our infrastructure agent. <em>New</em> <em>Relic</em> account-related logging To audit changes to your <em>New</em> <em>Relic</em> account, run NRQL queries with NrAuditEvent. To customize your query, <em>use</em> any of the available NrAuditEvent attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting": [
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2021-12-19T22:50:13Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3008,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.1339,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "sections": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " values. Ruby <em>Use</em> audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for <em>troubleshooting</em> our infrastructure agent. <em>New</em> <em>Relic</em> account-related logging To audit changes to your <em>New</em> <em>Relic</em> account, run NRQL queries with NrAuditEvent. To customize your query, <em>use</em> any of the available NrAuditEvent attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    },
    {
      "sections": [
        "Metric grouping issues (APM, browser, mobile)",
        "Problem",
        "Solution",
        "Cause",
        "MGI example"
      ],
      "title": "Metric grouping issues (APM, browser, mobile)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "01afbe789d2499767f01e5f171681151a7643a5f",
      "image": "https://docs.newrelic.com/static/cdddc2b190d2c37e636e37cb3a76c79d/c1b63/metric-grouping.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/metric-grouping-issues/",
      "published_at": "2021-12-19T22:50:12Z",
      "updated_at": "2021-12-14T04:17:41Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem For our APM, browser monitoring, and mobile monitoring features, there can be cases when an account or application is sending many individual metrics that could be better managed by grouping them together. We use the term metric grouping issue or MGI to describe this situation. When this occurs, the agent is sending unnecessarily large amounts of data to New Relic, which reduces the effectiveness of New Relic charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. They can also happen with other metrics reported by your application. For example: If your application is crawling the Internet and each external call goes to a different domain If your software dynamically generates temporary database tables every time you receive a request If you are using custom instrumentation that includes UUIDs, article names, or similar unique components Any situation where a potentially infinite list of metrics can be created, rather than metrics being grouped effectively (as with controllers, permanent database tables, or specific external services) can become a metric grouping issue. Solution By understanding what metric grouping is and how issues can arise, you can better understand how New Relic works with your application to group metrics effectively and help prevent metric grouping issues from occurring. Here is a \"before\" and \"after\" example of how metric grouping can help organize transactions, to help you more easily identify patterns with performance problems. To help prevent metric grouping issues from occurring in your app: Check the New Relic release notes to verify you're running the most current version of the New Relic agent. If needed, upgrade your APM/mobile/browser agent to the most current version. Wait a few minutes, then look at new data in the New Relic UI. If the problem persists, follow the procedures for your agent: Agent Preventing MGIs All agents Review the information about what causes metric grouping issues. Browser Add URL groupings. C SDK Avoid using URLs to name your transactions. Instead, follow the procedures to instrument your app with the C SDK. Go Rename your Go transactions. Java See Java metric grouping issues. .NET Rename metrics with SetTransactionName. For more information about using XML to add details, see Name transactions. Node.js Rename transactions with Request API calls. PHP Rename your PHP transactions. Python Rename your Python transactions with set_transaction_name. Ruby Rename your Ruby transactions. Cause Metric grouping issues occur when the granularity of metric names (most often web transaction names) is too fine, resulting in hundreds or thousands of different web transaction names for just a small number of code paths. A few major code paths may generate many different full URL paths to unique documents, articles, or page, etc., and if the unique element of the URL path is included in the transaction name, each of these common paths will have its own unique name. MGI example In this example, you have an application that lets users write articles on any subject and post them for other users to see. Your application has three main functions: add an article, search for an article, and display an article. In order to improve search engine optimization (SEO), the \"view article\" code generates a unique URL to refer to each article. For example, the following URLs each refer to different articles in the example website: http://example.com/article/view/How_to_Install_New_Relic http://example.com/article/view/How_New_Relic_Saved_the_Day http://example.com/article/view/Where_do_I_get_New_Relic Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all use the \"view article\" function. Many web frameworks use this technique. They have a controller or route (in this case named article/view) as part of the URL. New Relic works to automatically identify these patterns and group similar routes together, to prevent metric grouping issues from occurring. Without mechanisms for detecting controllers, the example application would send metrics for each individual URL requested by visitors to your site. If you have a million articles and your site is popular, in each minute there could be several thousand unique URLs visited. This produces a significant amount of additional data to be sent to New Relic for each harvest cycle, and the APM Transactions page would attempt to list thousands of unique URLs, resulting in metric grouping issues. To monitor and improve your application performance, it's much more useful to know the average performance for a function (for example, viewing articles on your site) than how quickly each individual article is displayed. To prevent metric grouping issues, New Relic will normally show a single entry for that function (for example, /article/view/*) on the APM Transactions page. This grouping gives you a much better idea of how much time was spent viewing articles, and allows you to easily spot any performance problems related to viewing articles. If these statistics were spread across hundreds or thousands of transactions, detecting trends, regressions, or performance improvements would be extremely difficult. Each APM agent has distinct ways of detecting controllers and frameworks. Most are automatic, but a few require you to enable or disable options in a config file. You can also follow our recommendations to help prevent metric grouping issues from occurring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.13092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "&#x2F;How_<em>New_Relic</em>_Saved_the_Day http:&#x2F;&#x2F;example.com&#x2F;article&#x2F;view&#x2F;Where_do_I_get_<em>New_Relic</em> Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all <em>use</em> the &quot;view article&quot; <em>function</em>. Many web"
      },
      "id": "61bfb724e7b9d25c426ed2c4"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits": [
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2021-12-19T22:50:13Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.30072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2021-12-19T22:49:19Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.52863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    },
    {
      "sections": [
        "Metric grouping issues (APM, browser, mobile)",
        "Problem",
        "Solution",
        "Cause",
        "MGI example"
      ],
      "title": "Metric grouping issues (APM, browser, mobile)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "01afbe789d2499767f01e5f171681151a7643a5f",
      "image": "https://docs.newrelic.com/static/cdddc2b190d2c37e636e37cb3a76c79d/c1b63/metric-grouping.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/metric-grouping-issues/",
      "published_at": "2021-12-19T22:50:12Z",
      "updated_at": "2021-12-14T04:17:41Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem For our APM, browser monitoring, and mobile monitoring features, there can be cases when an account or application is sending many individual metrics that could be better managed by grouping them together. We use the term metric grouping issue or MGI to describe this situation. When this occurs, the agent is sending unnecessarily large amounts of data to New Relic, which reduces the effectiveness of New Relic charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. They can also happen with other metrics reported by your application. For example: If your application is crawling the Internet and each external call goes to a different domain If your software dynamically generates temporary database tables every time you receive a request If you are using custom instrumentation that includes UUIDs, article names, or similar unique components Any situation where a potentially infinite list of metrics can be created, rather than metrics being grouped effectively (as with controllers, permanent database tables, or specific external services) can become a metric grouping issue. Solution By understanding what metric grouping is and how issues can arise, you can better understand how New Relic works with your application to group metrics effectively and help prevent metric grouping issues from occurring. Here is a \"before\" and \"after\" example of how metric grouping can help organize transactions, to help you more easily identify patterns with performance problems. To help prevent metric grouping issues from occurring in your app: Check the New Relic release notes to verify you're running the most current version of the New Relic agent. If needed, upgrade your APM/mobile/browser agent to the most current version. Wait a few minutes, then look at new data in the New Relic UI. If the problem persists, follow the procedures for your agent: Agent Preventing MGIs All agents Review the information about what causes metric grouping issues. Browser Add URL groupings. C SDK Avoid using URLs to name your transactions. Instead, follow the procedures to instrument your app with the C SDK. Go Rename your Go transactions. Java See Java metric grouping issues. .NET Rename metrics with SetTransactionName. For more information about using XML to add details, see Name transactions. Node.js Rename transactions with Request API calls. PHP Rename your PHP transactions. Python Rename your Python transactions with set_transaction_name. Ruby Rename your Ruby transactions. Cause Metric grouping issues occur when the granularity of metric names (most often web transaction names) is too fine, resulting in hundreds or thousands of different web transaction names for just a small number of code paths. A few major code paths may generate many different full URL paths to unique documents, articles, or page, etc., and if the unique element of the URL path is included in the transaction name, each of these common paths will have its own unique name. MGI example In this example, you have an application that lets users write articles on any subject and post them for other users to see. Your application has three main functions: add an article, search for an article, and display an article. In order to improve search engine optimization (SEO), the \"view article\" code generates a unique URL to refer to each article. For example, the following URLs each refer to different articles in the example website: http://example.com/article/view/How_to_Install_New_Relic http://example.com/article/view/How_New_Relic_Saved_the_Day http://example.com/article/view/Where_do_I_get_New_Relic Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all use the \"view article\" function. Many web frameworks use this technique. They have a controller or route (in this case named article/view) as part of the URL. New Relic works to automatically identify these patterns and group similar routes together, to prevent metric grouping issues from occurring. Without mechanisms for detecting controllers, the example application would send metrics for each individual URL requested by visitors to your site. If you have a million articles and your site is popular, in each minute there could be several thousand unique URLs visited. This produces a significant amount of additional data to be sent to New Relic for each harvest cycle, and the APM Transactions page would attempt to list thousands of unique URLs, resulting in metric grouping issues. To monitor and improve your application performance, it's much more useful to know the average performance for a function (for example, viewing articles on your site) than how quickly each individual article is displayed. To prevent metric grouping issues, New Relic will normally show a single entry for that function (for example, /article/view/*) on the APM Transactions page. This grouping gives you a much better idea of how much time was spent viewing articles, and allows you to easily spot any performance problems related to viewing articles. If these statistics were spread across hundreds or thousands of transactions, detecting trends, regressions, or performance improvements would be extremely difficult. Each APM agent has distinct ways of detecting controllers and frameworks. Most are automatic, but a few require you to enable or disable options in a config file. You can also follow our recommendations to help prevent metric grouping issues from occurring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.13086,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "&#x2F;How_<em>New_Relic</em>_Saved_the_Day http:&#x2F;&#x2F;example.com&#x2F;article&#x2F;view&#x2F;Where_do_I_get_<em>New_Relic</em> Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all <em>use</em> the &quot;view article&quot; <em>function</em>. Many web"
      },
      "id": "61bfb724e7b9d25c426ed2c4"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/metric-grouping-issues": [
    {
      "sections": [
        "Not seeing data",
        "Problem",
        "Solution",
        "APM agents",
        "Deleted or renamed applications in APM",
        "No connection to collector",
        "Browser monitoring",
        "Infrastructure monitoring",
        "Mobile monitoring",
        "Other factors affecting access"
      ],
      "title": "Not seeing data",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "1351bcdb406ddc130d9e2388806e5c2c28e22f75",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data/",
      "published_at": "2021-12-19T22:50:13Z",
      "updated_at": "2021-12-14T04:17:40Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You do not see data in the UI after installing a New Relic agent. Solution You should start seeing data within a few minutes after installing a New Relic agent and generating traffic for your app. If you don't see data, you can use the New Relic Diagnostics utility to automatically identify common issues. For additional troubleshooting tips, see the agent-specific docs.  APM agents Follow the troubleshooting procedures for your APM agent: C SDK Go Java .NET Node.js PHP Python Ruby In addition, you can try these troubleshooting steps that apply to all APM agents: Deleted or renamed applications in APM An app needs to stop reporting data for at least an hour before you can reuse that name. It also needs to reconnect with the New Relic collector (be restarted) before new data will be accepted. The app remains in the collector's cache for an hour before it is flushed. During that time it is marked as \"deleted,\" so no new data is accepted. Also, the data is associated with an executing app that has been deleted until the agent is restarted. For more information, see: Name your application Use multiple names for an app No connection to collector Your app will not be affected if the New Relic agent cannot connect to the collector. Data continues to be collected, and it is uploaded as soon as the connection is restored. While the network is down or the collector unavailable, you may see gaps where data is missing in the APM CPU and memory charts. The agent will continue attempting to reconnect, and when it succeeds, you will again see data appearing in the UI. During the time the agent is unable to communicate with the collector, it is still collecting data. Once it is able to connect again, it will upload the data and fill in the missing segment so there will not be any confusion about whether your application was down or just not reporting data. To save memory, the data will be aggregated and averaged over the period, so you will see flat bars and charts over the period when it was unable to communicate with the collector. Browser monitoring See Troubleshooting browser monitoring installation. Infrastructure monitoring Follow the troubleshooting procedures for your infrastructure agent: Linux Windows AWS integrations On-host integrations Mobile monitoring Follow the troubleshooting procedures for your mobile app: iOS Android Other factors affecting access For more on factors that can affect your ability to access New Relic features, see Factors affecting access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.30072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Problem You do not see data in the UI after installing a <em>New</em> <em>Relic</em> agent. Solution You should start seeing data within a few minutes after installing a <em>New</em> <em>Relic</em> agent and generating traffic for your app. If you don&#x27;t see data, you can <em>use</em> the <em>New</em> <em>Relic</em> Diagnostics utility to automatically identify"
      },
      "id": "603e8f2928ccbccc87eba750"
    },
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2021-12-19T22:49:19Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.52863,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    },
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.13385,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "sections": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " values. Ruby <em>Use</em> audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for <em>troubleshooting</em> our infrastructure agent. <em>New</em> <em>Relic</em> account-related logging To audit changes to your <em>New</em> <em>Relic</em> account, run NRQL queries with NrAuditEvent. To customize your query, <em>use</em> any of the available NrAuditEvent attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    }
  ],
  "/docs/new-relic-solutions/solve-common-issues/troubleshooting/not-seeing-data": [
    {
      "sections": [
        "Generate New Relic agent logs for troubleshooting",
        "APM agent logging",
        "Infrastructure agent logging",
        "Mobile agent logging",
        "Logging for other New Relic tools"
      ],
      "title": "Generate New Relic agent logs for troubleshooting",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "cc4e412038d0e125474a7ead0440a3cad51554dc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/generate-new-relic-agent-logs-troubleshooting/",
      "published_at": "2021-12-19T22:49:19Z",
      "updated_at": "2021-12-14T04:16:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Some New Relic solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for troubleshooting, auditing, and diagnostics. Related docs: For general agent troubleshooting, see Not seeing data. Learn about New Relic Diagnostics: a utility that automatically detects common problems. APM agent logging C SDK logs Go agent logs Java logs .NET logs Node.js logs PHP logs Python logs Ruby logs Infrastructure agent logging See Infrastructure agent logs. Mobile agent logging Android log settings iOS log settings Logging for other New Relic tools For log generation and troubleshooting instructions for tools not listed here, see the docs for a specific solution in New Relic Instant Observability.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 281.52853,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "sections": "Generate <em>New</em> <em>Relic</em> agent logs for <em>troubleshooting</em>",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "Some <em>New</em> <em>Relic</em> solutions require manual installation of an agent. Most agents include built-in tools to generate detailed logs for <em>troubleshooting</em>, auditing, and diagnostics. Related docs: For general agent <em>troubleshooting</em>, see Not seeing data. Learn about <em>New</em> <em>Relic</em> Diagnostics: a utility"
      },
      "id": "61bfb6ef196a67b63eef0936"
    },
    {
      "sections": [
        "Log (audit) all data your New Relic agent transmits",
        "Caution",
        "APM agent audit logging",
        "Infrastructure agent logging",
        "New Relic account-related logging"
      ],
      "title": "Log (audit) all data your New Relic agent transmits",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "66cd6ec040e070623d345e5319b1246d2ba4c3b8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/log-audit-all-data-your-new-relic-agent-transmits/",
      "published_at": "2021-12-19T20:56:53Z",
      "updated_at": "2021-12-14T04:18:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Every New Relic agent includes strong safeguards to ensure data security. For example, New Relic automatically encrypts sensitive information before it is transmitted. For more information about New Relic's security measures, see our security and privacy documentation, or visit the New Relic security website. If you need to record and view information about all data your app transmits to New Relic, you can enable audit logging for short periods of time. This is useful, for example, with debugging or auditing, when you need detailed information about what exactly is being transmitted. Caution Be sure to disable audit logging as soon as you are finished using it. This feature causes additional overhead, which may overload the audit log file if left turned on for extended periods of time. APM agent audit logging For details about the audit logging options for your APM agent's configuration file, see the agent-specific documentation: Agent Configuration file C SDK When starting the C SDK daemon, add -auditlog <file> to the daemon configuration file. For example: ./newrelic-daemon -f -logfile stdout -loglevel debug -auditlog audit.log Copy Go Logging is optional with the Go agent. If you are using newrelic.NewLogger(w) and want more detailed output, change newrelic.NewLogger(w) to newrelic.NewDebugLogger(w). For more information, see the New Relic Go logging documentation on GitHub. Java Set audit_mode to true. .NET Set auditLog to true. Node.js New Relic's Node.js agent does not use separate audit logs because the payload is already available in the configuration logs. To view increasing levels of detail, use your config file's logging level variables. PHP Use PHP newrelic.daemon.auditlog (for newrelic.ini) or auditlog (for newrelic.cfg). Python Use Python audit_log_file values. Ruby Use audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for troubleshooting our infrastructure agent. New Relic account-related logging To audit changes to your New Relic account, run NRQL queries with NrAuditEvent. To customize your query, use any of the available NrAuditEvent attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.1338,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "sections": "Log (audit) all data your <em>New</em> <em>Relic</em> agent transmits",
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": " values. Ruby <em>Use</em> audit_log values. For more information, see Ruby agent audit log. Infrastructure agent logging You can generate infrastructure monitoring logs for <em>troubleshooting</em> our infrastructure agent. <em>New</em> <em>Relic</em> account-related logging To audit changes to your <em>New</em> <em>Relic</em> account, run NRQL queries with NrAuditEvent. To customize your query, <em>use</em> any of the available NrAuditEvent attributes."
      },
      "id": "61bf9c95196a67c384eee313"
    },
    {
      "sections": [
        "Metric grouping issues (APM, browser, mobile)",
        "Problem",
        "Solution",
        "Cause",
        "MGI example"
      ],
      "title": "Metric grouping issues (APM, browser, mobile)",
      "type": "docs",
      "tags": [
        "Using New Relic",
        "Cross-product functions",
        "Troubleshooting"
      ],
      "external_id": "01afbe789d2499767f01e5f171681151a7643a5f",
      "image": "https://docs.newrelic.com/static/cdddc2b190d2c37e636e37cb3a76c79d/c1b63/metric-grouping.png",
      "url": "https://docs.newrelic.com/docs/new-relic-solutions/solve-common-issues/troubleshooting/metric-grouping-issues/",
      "published_at": "2021-12-19T22:50:12Z",
      "updated_at": "2021-12-14T04:17:41Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem For our APM, browser monitoring, and mobile monitoring features, there can be cases when an account or application is sending many individual metrics that could be better managed by grouping them together. We use the term metric grouping issue or MGI to describe this situation. When this occurs, the agent is sending unnecessarily large amounts of data to New Relic, which reduces the effectiveness of New Relic charts, tables, and reports. Metric grouping issues occur most commonly with web transactions, especially if the name is based on URLs. They can also happen with other metrics reported by your application. For example: If your application is crawling the Internet and each external call goes to a different domain If your software dynamically generates temporary database tables every time you receive a request If you are using custom instrumentation that includes UUIDs, article names, or similar unique components Any situation where a potentially infinite list of metrics can be created, rather than metrics being grouped effectively (as with controllers, permanent database tables, or specific external services) can become a metric grouping issue. Solution By understanding what metric grouping is and how issues can arise, you can better understand how New Relic works with your application to group metrics effectively and help prevent metric grouping issues from occurring. Here is a \"before\" and \"after\" example of how metric grouping can help organize transactions, to help you more easily identify patterns with performance problems. To help prevent metric grouping issues from occurring in your app: Check the New Relic release notes to verify you're running the most current version of the New Relic agent. If needed, upgrade your APM/mobile/browser agent to the most current version. Wait a few minutes, then look at new data in the New Relic UI. If the problem persists, follow the procedures for your agent: Agent Preventing MGIs All agents Review the information about what causes metric grouping issues. Browser Add URL groupings. C SDK Avoid using URLs to name your transactions. Instead, follow the procedures to instrument your app with the C SDK. Go Rename your Go transactions. Java See Java metric grouping issues. .NET Rename metrics with SetTransactionName. For more information about using XML to add details, see Name transactions. Node.js Rename transactions with Request API calls. PHP Rename your PHP transactions. Python Rename your Python transactions with set_transaction_name. Ruby Rename your Ruby transactions. Cause Metric grouping issues occur when the granularity of metric names (most often web transaction names) is too fine, resulting in hundreds or thousands of different web transaction names for just a small number of code paths. A few major code paths may generate many different full URL paths to unique documents, articles, or page, etc., and if the unique element of the URL path is included in the transaction name, each of these common paths will have its own unique name. MGI example In this example, you have an application that lets users write articles on any subject and post them for other users to see. Your application has three main functions: add an article, search for an article, and display an article. In order to improve search engine optimization (SEO), the \"view article\" code generates a unique URL to refer to each article. For example, the following URLs each refer to different articles in the example website: http://example.com/article/view/How_to_Install_New_Relic http://example.com/article/view/How_New_Relic_Saved_the_Day http://example.com/article/view/Where_do_I_get_New_Relic Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all use the \"view article\" function. Many web frameworks use this technique. They have a controller or route (in this case named article/view) as part of the URL. New Relic works to automatically identify these patterns and group similar routes together, to prevent metric grouping issues from occurring. Without mechanisms for detecting controllers, the example application would send metrics for each individual URL requested by visitors to your site. If you have a million articles and your site is popular, in each minute there could be several thousand unique URLs visited. This produces a significant amount of additional data to be sent to New Relic for each harvest cycle, and the APM Transactions page would attempt to list thousands of unique URLs, resulting in metric grouping issues. To monitor and improve your application performance, it's much more useful to know the average performance for a function (for example, viewing articles on your site) than how quickly each individual article is displayed. To prevent metric grouping issues, New Relic will normally show a single entry for that function (for example, /article/view/*) on the APM Transactions page. This grouping gives you a much better idea of how much time was spent viewing articles, and allows you to easily spot any performance problems related to viewing articles. If these statistics were spread across hundreds or thousands of transactions, detecting trends, regressions, or performance improvements would be extremely difficult. Each APM agent has distinct ways of detecting controllers and frameworks. Most are automatic, but a few require you to enable or disable options in a config file. You can also follow our recommendations to help prevent metric grouping issues from occurring.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 264.1308,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Cross</em>-<em>product</em> <em>functions</em>",
        "body": "&#x2F;How_<em>New_Relic</em>_Saved_the_Day http:&#x2F;&#x2F;example.com&#x2F;article&#x2F;view&#x2F;Where_do_I_get_<em>New_Relic</em> Copy All three articles are different; they contain different content and their URLs are different. However, the code path that generates each article is the same: they all <em>use</em> the &quot;view article&quot; <em>function</em>. Many web"
      },
      "id": "61bfb724e7b9d25c426ed2c4"
    }
  ],
  "/docs/query-your-data/explore-query-data/browse-data/introduction-data-explorer": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 273.53717,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let&#x27;s say you want to <em>query</em> some <em>data</em> and put the responses"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 231.70833,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.64857,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see <em>Explore</em> the Public API Performance dashboard."
      },
      "id": "60445920196a673eee960f25"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.7355,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.83394,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance <em>dashboard</em>. This <em>dashboard</em> provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance <em>dashboard</em> quickly and easliy. To start using this <em>dashboard</em>, see <em>Explore</em> the Public API Performance <em>dashboard</em>."
      },
      "id": "60445920196a673eee960f25"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.05856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/dashboards-api": [
    {
      "sections": [
        "Dashboard API migration: from Insights API to NerdGraph",
        "Why a new dashboards API?",
        "Get started with NerdGraph",
        "Operations mapping table",
        "Dashboard properties mapping table",
        "Widget properties mapping table",
        "Tip",
        "Visualizations mapping table",
        "Examples: from REST endpoints to GraphQL queries/mutations",
        "List (GET) -> entitySearch query",
        "List all dashboard entities you have access to",
        "List all dashboards by name",
        "List all dashboards by creator’s email",
        "List all dashboards by creator’s user id",
        "Show (GET) -> entity query",
        "Get dashboard info given its entity guid",
        "Create (POST) -> dashboardCreate mutation",
        "Create dashboard with two pages and two widgets per page",
        "Update (PUT) -> dashboardUpdate mutation",
        "Update previously created dashboard to 1 page and 1 widget per page",
        "Delete (DELETE) -> dashboardDelete mutation",
        "Delete previously created dashboard"
      ],
      "title": "Dashboard API migration: from Insights API to NerdGraph",
      "type": "docs",
      "tags": [
        "NerdGraph",
        "Dashboards",
        "Dashboards API"
      ],
      "external_id": "7a1a086f45b7aefccb5d2cd5f42b3a0f0dd526c2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/new-relic-one/use-new-relic-one/core-concepts/dashboards-api-migration-insights-api-nerdgraph/",
      "published_at": "2021-12-20T09:43:36Z",
      "updated_at": "2021-10-13T02:05:11Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Insights Dashboard API is deprecated, but you can use NerdGraph (our GraphQL API) to create and configure dashboards. If you're not migrating from the old Insights API, you can skip this doc and go to the new Dashboards API. Why a new dashboards API? Our Insights product, which was a way to query data and create charts and dashboards, has been deprecated and its set of features moved over to be a core part of the New Relic One platform. To learn more about this transition and new features, see the Insights to New Relic One migration guide. The Insights Dashboard API will be deprecated in July of 2021. Until then, if you're using the Insights Dashboard API, you should attempt to switch over to using NerdGraph. (The Insights query API will not be deprecated but NerdGraph is preferred.) Keep reading to learn how to get started with NerdGraph and learn about equivalent operations. Get started with NerdGraph NerdGraph is the preferred API for making NRQL queries of your New Relic data. Every user who uses NerdGraph needs their own user key. When using NerdGraph, it helps to understand that our dashboards are entities that report data from other entities, such as monitored apps, hosts and services. If you're new to NerdGraph and GraphQL, you may want to first read our Introduction to NerdGraph and some of Create dashboards with NerdGraph. The NerdGraph API explorer is located at api.newrelic.com/graphiql. Operations mapping table The table below maps every Insights API operation to the new dashboards API. Insights API operation NerdGraph API query/mutation Notes List (GET) entitySearch() View a paginated list of dashboards that match the filter. Show (GET) entity() View an existing dashboard given its entity guid. Create (POST) dashboardCreate() Create a new dashboard. Update (PUT) dashboardUpdate() Update an existing dashboard given its entity guid. Delete (DELETE) dashboardDelete() Delete an existing dashboard given its entity guid. Dashboard properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps dashboard properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id guid ID of the New Relic entity the dashboard now represents createdAt createdAt updatedAt updatedAt title name editable permissions editable and visibility merged in the same concept visibility permissions editable and visibility merged in the same concept description description metadata - No need of versioning in GraphQL APIs icon - Not translated to New Relic One grid_column_count - 12 column dashboards by default in New Relic One filter - Not translated to New Relic One yet Widget properties mapping table For more information about all the fields in the new dashboards GraphQL schema, have a look at NerdGraph's GraphiQL explorer. The table below maps widget properties from the Insights API to the new dashboards API. Insights API dashboard property NerdGraph API dashboard property Notes id id account_id - Translated into widget configuration for those that require one visualization visualization presentation.title title presentation.drilldown_dashboard_id linkedEntities Used to link a widget to a dashboard for the facet linking feature presentation.notes - Not translated to New Relic One yet layout layout data configuration + rawConfiguration Tip To learn how to build every type of widget, see Create dashboard widgets. Visualizations mapping table We have simplified our widget visualizations by grouping the ones that were in fact the same but obtained through different types of queries. For instance, a line widget is plotted the same way regardless of the type of query: old line_chart vs. comparison_line_chart in Insights. Insights API visualization NerdGraph API visualization uniques_list viz.table single_event viz.table facet_table viz.table event_table viz.table faceted_area_chart viz.area predefined_metric_chart.application_breakdown viz.area predefined_metric_chart.scope_breakdown viz.area predefined_metric_chart.browser_breakdown viz.area predefined_metric_chart.background_breakdown viz.area predefined_metric_chart.solr_breakdown viz.area predefined_metric_chart.gc_runs_breakdown viz.area facet_bar_chart viz.bar billboard viz.billboard attribute_sheet viz.billboard billboard_comparison viz.billboard gauge viz.bullet event_feed viz.event-feed funnel viz.funnel heatmap viz.heatmap histogram viz.histogram inventory infra.inventory raw_json viz.json line_chart viz.line comparison_line_chart viz.line faceted_line_chart viz.line metric_line_chart viz.line markdown viz.markdown facet_pie_chart viz.pie Examples: from REST endpoints to GraphQL queries/mutations One of the main benefits of NerdGraph being a GraphQL-format API is that it provides a complete and understandable description of the APIs' data. By using the NerdGraph API explorer, you can discover GraphQL types and fields, along with a brief explanation. We want to facilitate your migration from the Insights API to the new New Relic One dashboards API. Find below some examples that illustrate how the old REST endpoints map to the new GraphQL queries or mutations. List (GET) -> entitySearch query Dashboards in New Relic One embrace the concept of entity. They are now another entity in New Relic’s entity ecosystem. Try it out using the NerdGraph GraphiQL explorer. List all dashboard entities you have access to { actor { entitySearch(queryBuilder: {type: DASHBOARD}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by name { actor { entitySearch(queryBuilder: {name: \"My dashboard\"}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s email { actor { entitySearch(queryBuilder: {type: DASHBOARD, tags: {key: \"createdBy\", value: \"email@domain.com\"}}) { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy List all dashboards by creator’s user id { actor { entitySearch(query: \"type ='DASHBOARD' and ownerId = '2357322'\") { results { entities { ... on DashboardEntityOutline { guid name accountId } } } } } } Copy Show (GET) -> entity query In order to get information on a dashboard, all you need is to provide its unique entity identifier or entity guid. Then you can access all the dashboard properties that you are interested in by adding them in the GraphQL query. Try it out using the NerdGraph GraphiQL explorer. Get dashboard info given its entity guid { actor { entity(guid: \"MY_DASHBOARD_GUID\") { ... on DashboardEntity { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } } Copy Create (POST) -> dashboardCreate mutation Operations that mutate the state of the system are mutations in GraphQL APIs. You can create a dashboard by providing the required input for the dashboardCreate mutation. Although GraphQL APIs aim to be self-explanatory, Nerdgraph docs can help you with some information about the fields, like the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Create dashboard with two pages and two widgets per page mutation { dashboardCreate(accountId: 1, dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.markdown\" }, title: \"My markdown widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { text: \"#My markdown\" } }, { visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.billboard\" }, title: \"My billboard widget with thresholds\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction\" }], thresholds: [{ alertSeverity: WARNING, value: 650 }, { alertSeverity: CRITICAL, value: 1500 }] } }, { visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 5, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Update (PUT) -> dashboardUpdate mutation The dashboardUpdate mutation allows you to update an existing dashboard by providing the existing dashboard guid and the new configuration. Similarly to creating a dashboard, the mutation tries to be self-explanatory, but you can look up the doc about how to build dashboard widgets. Try it out using the NerdGraph GraphiQL explorer. Update previously created dashboard to 1 page and 1 widget per page mutation { dashboardUpdate(guid: \"MY_DASHBOARD_GUID\" dashboard: { name: \"My awesome dashboard\", permissions: PUBLIC_READ_WRITE, pages: [{ name: \"My first page\", widgets: [{ visualization: { id: \"viz.line\" }, title: \"My line widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ accountId: 1, query: \"SELECT count(*) FROM Transaction FACET appName TIMESERIES\" }] } }] }, { name: \"My second page\", widgets: [{ visualization: { id: \"viz.table\" }, title: \"My table widget\", layout: { row: 1, column: 1, width: 4, height: 3 }, rawConfiguration: { nrqlQueries: [{ query: \"SELECT * FROM Transaction\", accountId: 1 }] } }] }] }) { errors { description type } entityResult { guid accountId name createdAt updatedAt permissions description owner { email userId } pages { guid name createdAt updatedAt description owner { email userId } widgets { id visualization { id } title layout { row column height width } rawConfiguration linkedEntities { guid } } } } } } Copy Delete (DELETE) -> dashboardDelete mutation The dashboardDelete mutation allows you to delete an existing dashboard by providing its entity guid. Try it out using the NerdGraph GraphiQL explorer. Delete previously created dashboard mutation { dashboardDelete(guid:\"MY_DASHBOARD_GUID\") { status errors { type description } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.98096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Dashboard</em> <em>API</em> migration: from Insights <em>API</em> to NerdGraph",
        "sections": "<em>Dashboard</em> <em>API</em> migration: from Insights <em>API</em> to NerdGraph",
        "tags": "<em>Dashboards</em> <em>API</em>",
        "body": "The Insights <em>Dashboard</em> <em>API</em> is deprecated, but you can use NerdGraph (our GraphQL <em>API</em>) to create and configure <em>dashboards</em>. If you&#x27;re not migrating from the old Insights <em>API</em>, you can skip this doc and go to the new <em>Dashboards</em> <em>API</em>. Why a new <em>dashboards</em> <em>API</em>? Our Insights product, which was a way"
      },
      "id": "60441442e7b9d2020b5799b9"
    },
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 56.603577,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Dashboards</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter your <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, your <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Insights Dashboard API",
        "End of life notice",
        "Requirements",
        "Overview",
        "Example use cases",
        "Account and data security",
        "Use the API Explorer",
        "View Dashboard API video",
        "Use API endpoints",
        "Dashboard API schema",
        "Important",
        "Caution",
        "Example dashboard schema",
        "Dashboard data definitions",
        "Widget data definitions",
        "Supported visualizations"
      ],
      "title": "Insights Dashboard API",
      "type": "docs",
      "tags": [
        "Insights",
        "Event data sources",
        "Insights API"
      ],
      "external_id": "71a0104d88a3a8859513802e853850d8b0456606",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/insights-apis/insights-dashboard-api/",
      "published_at": "2021-12-19T15:42:49Z",
      "updated_at": "2021-08-02T03:52:39Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do not use the Insights Dashboards API. Instead, use the New Relic One Dashboards API with NerdGraph, our GraphQL API. End of life notice The Insights Dashboard API reaches end of life in 2021. As of July 28, 2021, the CREATE and UPDATE endpoints are not available. As of August 30, 2021, the GET and DELETE endpoints are not available. To make the transition from the Insights Dashboard API to the New Relic One Dashboards API, see our migration guide. For more information, see the NerdGraph dashboards tutorial and Explorers Hub post. Requirements If your account hosts data in the EU data center, ensure you're using the proper API endpoints for EU region accounts. Overview The Insights Dashboard API allows you to list, create, read, update, and delete new or existing dashboards. New Relic's API Explorer includes the cURL request format, available parameters, response status codes, and JSON response structure for available API calls. Example use cases The Insights Dashboard API is a flexible solution for many different use cases. Here are a few examples of how you can leverage the Dashboard API to solve problems: Automatically create dashboards for new teams or services pre-populated with standard organization metrics and charts. Use the API to view dashboard schemas, and save them in a central repository for source control and backups. Create widget and dashboard templates to allow teams to self-service. Account and data security The Dashboard API includes safeguards to help ensure account and data security. Requirements Comments User key and permissions Required: This API requires a user key. You cannot use your account-level REST API key to manage dashboards. Cross-account widgets You can view cross-account widgets on a dashboard by using the Insights or New Relic One dashboards UI. However, the ability to view cross-account widgets when using the Dashboard API has these restrictions: To view the list of widgets on a specific dashboard with the Dashboard API, you must use the SHOW endpoint. To view a widget in the API payload, the widget's account ID must be the same as the account ID for the payload. If the account ID is not the same, the widget's details will not be listed. Instead, the widget's payload will show: \"visualization\": \"inaccessible\" Copy Use the API Explorer To view the Dashboard API options in the API Explorer: Log in to your New Relic account. Go to rpm.newrelic.com/api/explore. From the API Explorer's Select an account and key dropdown, select a user key. Select Dashboards, then select the API function. To use API functions with existing dashboards, include the dashboard id. To find the dashboard id, select the LIST endpoint, and apply filtering options. View Dashboard API video Follow along with this step-by-step tutorial to learn how to find your API keys, create new dashboards, view and update existing dashboards via the REST API. For a step-by-step guide to using the New Relic API Explorer to manage Insights dashboards, watch this video (approximately 6 minutes). Or, go directly to the full online course about New Relic APIs. Use API endpoints The API supports the following functions for Insights dashboards only. The API does not support these functions for data apps (collections of linked dashboards). API endpoints Comments CREATE POST /v2/dashboards Create a new dashboard. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to POST more than 300 widgets will produce an error. To add more widgets to the dashboard, use the Insights UI. UPDATE PUT /v2/dashboards/:id: Update an existing dashboard for the dashboard id. The API permits a maximum of 300 widgets when creating or updating a dashboard. Attempting to PUT more than 300 widgets will produce an error. To add more or edit existing widgets on the dashboard, use the Insights UI. SHOW GET /v2/dashboards/:id: View an existing dashboard and all accessible widgets for the dashboard id. To help ensure data security, the SHOW function returns only the dashboard widgets that the user has permission to view. If a dashboard includes widgets that the user is not authorized to view, the API will provide a placeholder with the visualization field set to inaccessible. LIST GET /v2/dashboards?page=:page:&per_page=:count: View a paginated list of dashboards. The list shows filterable dashboard metadata only; no widgets will appear in the list. Search options include: filter[title] as substring search filter[category] (all / favorites / mine} filter[created_after] as ISO date filter[created_before] as ISO date filter[updated_after] as ISO date filter[updated_before] as ISO date Sort options include: name recently_viewed last_edited If no sort option is provided, results will be ordered by id. Pagination options include the page and per_page fields. The per_page field controls the number of results per page with a default and maximum of 100 results. The response will include a pagination Link header, which provides next page and last page links. DELETE DELETE /v2/dashboards/:id: Delete an existing dashboard indicated by the dashboard id. Dashboard API schema JSON is the only supported format. When using API functions, be sure to add .json to the end of the request URL, as shown in the API Explorer. Important Widgets have a size limit of 3x3 (height and width may not exceed 3). Caution The Dashboard API 3-column restriction also applies to the dashboards you upload to New Relic One dashboards. If you update a dashboard with a different layout using the API, the uploaded dashboard will revert to the 3-column configuration. Example dashboard schema { \"dashboard\": { \"metadata\": { \"version\": 1 }, \"title\": \"API Widget Sample\", \"icon\":\"none|archive|bar-chart|line-chart|bullseye|user|usd|money|thumbs-up|thumbs-down|cloud|bell|bullhorn|comments-o|envelope|globe|shopping-cart|sitemap|clock-o|crosshairs|rocket|users|mobile|tablet|adjust|dashboard|flag|flask|road|bolt|cog|leaf|magic|puzzle-piece|bug|fire|legal|trophy|pie-chart|sliders|paper-plane|life-ring|heart\", \"grid_column_count\": 3|12, \"visibility\": \"owner|all\", \"editable\": \"read_only|editable_by_owner|editable_by_all\", \"filter\": { \"event_types\": [ \"Transaction\" ], \"attributes\": [ \"appName\" ] }, \"widgets\": [ { \"visualization\": \"billboard|gauge|billboard_comparison\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Threshold Event Chart\", \"notes\": null, \"threshold\": { \"red\": 18000000, \"yellow\": 8000000 } }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 1 } }, { \"visualization\": \"facet_bar_chart|faceted_line_chart|facet_pie_chart|facet_table|faceted_area_chart|heatmap\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT count(*) from Transaction since 5 minutes ago facet appName\" } ], \"presentation\": { \"title\": \"Facet Chart\", \"notes\": null, \"drilldown_dashboard_id\": 64 }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 2 } }, { \"visualization\": \"attribute_sheet|single_event|histogram|funnel|raw_json|event_feed|event_table|uniques_list|line_chart|comparison_line_chart\", \"account_id\": 12345, \"data\": [ { \"nrql\": \"SELECT latest(appName), latest(duration) from Transaction since 5 minutes ago\" } ], \"presentation\": { \"title\": \"Simple Event Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 1, \"column\": 3 } }, { \"visualization\": \"markdown\", \"account_id\": 12345, \"data\": [ { \"source\": \"# Dashboard Note\\n\\n[link goes here](https://www.newrelic.com)\" } ], \"presentation\": { \"title\": \"\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 1 } }, { \"visualization\": \"metric_line_chart\", \"account_id\": 12345, \"data\": [ { \"duration\": 1800000, \"end_time\": null, \"entity_ids\": [ 238575 ], \"metrics\": [ { \"name\": \"Apdex\", \"units\": null, \"scope\": \"\", \"values\": [ \"score\" ] } ], \"order_by\": \"score\", \"limit\": 10 } ], \"presentation\": { \"title\": \"Metric Line Chart\", \"notes\": null }, \"layout\": { \"width\": 1, \"height\": 1, \"row\": 2, \"column\": 2 } }, ] } } Copy Dashboard data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Dashboard data element Description metadata Object Specifies the version of the dashboard schema. The version must be 1. icon String Name of an icon from the Insights icon library. grid_column_count Integer Specifies the number of columns in the grid layout. title String User-supplied title of the dashboard. filter Object Specifies configuration of the smart filter on the dashboard. visibility String Specifies who can view the dashboard in the Insights UI and the API. editable String Specifies who can edit the dashboard in the Insights UI and the API. widgets Array Array of widget data element objects. Widget data definitions For examples of these data elements being used in a JSON call, see the Dashboard API schema. Widget data element Description visualization String What sort of visualization to place in the widget; for example, billboard, line_chart, area chart, etc. data Array Array of objects with chart-specific information needed to query necessary data. Currently only one data object is supported. account_id Long Source account to fetch data from, if not the current account. presentation Object Object with chart title and notes, plus chart-specific customization. layout Object Object with column, row, width, and height to determine chart layout in the dashboard. Supported visualizations The Dashboard API supports: event_table line_chart facet_table facet_bar_chart facet_pie_chart billboard faceted_area_chart faceted_line_chart event_table comparison_line_chart heatmap histogram billboard_comparison attribute_sheet funnel gauge json list Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 49.358414,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Insights <em>Dashboard</em> <em>API</em>",
        "sections": "Insights <em>Dashboard</em> <em>API</em>",
        "tags": "Insights <em>API</em>",
        "body": "Do not use the Insights <em>Dashboards</em> <em>API</em>. Instead, use the New Relic One <em>Dashboards</em> <em>API</em> with NerdGraph, our GraphQL <em>API</em>. End of life notice The Insights <em>Dashboard</em> <em>API</em> reaches end of life in 2021. As of July 28, 2021, the CREATE and UPDATE endpoints are not available. As of August 30, 2021, the GET"
      },
      "id": "609f9c8664441fc63fd2a1f9"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/dashboards-charts-import-export-data": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 330.62735,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing <em>dashboard</em>. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One <em>dashboards</em>. Will not work on a standalone <em>chart</em> in the <em>query</em> builder. NRQL <em>query</em> must contain a FACET clause. Available only for bar <em>charts</em>, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81795,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 243.66698,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Manage <em>your</em> <em>charts</em> <em>and</em> markdown content",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> <em>charts</em> directly from the <em>chart</em> menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> <em>charts</em>, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/explore-public-api-performance-dashboard": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.73538,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.83392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance <em>dashboard</em>. This <em>dashboard</em> provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance <em>dashboard</em> quickly and easliy. To start using this <em>dashboard</em>, see <em>Explore</em> the Public API Performance <em>dashboard</em>."
      },
      "id": "60445920196a673eee960f25"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets": [
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81793,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.83392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance <em>dashboard</em>. This <em>dashboard</em> provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance <em>dashboard</em> quickly and easliy. To start using this <em>dashboard</em>, see <em>Explore</em> the Public API Performance <em>dashboard</em>."
      },
      "id": "60445920196a673eee960f25"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.05856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.73532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.83392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance <em>dashboard</em>. This <em>dashboard</em> provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance <em>dashboard</em> quickly and easliy. To start using this <em>dashboard</em>, see <em>Explore</em> the Public API Performance <em>dashboard</em>."
      },
      "id": "60445920196a673eee960f25"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.73532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "New Relic Global Performance data sets",
        "Important",
        "Access valuable data and try out New Relic",
        "Get started with the Public API Performance dashboard"
      ],
      "title": "New Relic Global Performance data sets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "ed1b2c2cdfb59dae247d2690bd470a93b585c9e8",
      "image": "https://docs.newrelic.com/static/2c9a2621107e0114a2c345fcbb22356f/8c557/Public-API-Performance-Dash-for-GPD.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets/",
      "published_at": "2021-12-19T22:51:50Z",
      "updated_at": "2021-10-24T20:04:26Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic’s Global Performance data sets offer immediate access to meaningful, large-scale, aggregated telemetry data. Global Performance data sets data are useful for: Existing New Relic customers who want to gain general monitoring and troubleshooting insights from a curated collection of aggregated, real-world data. Newcomers who want to get a feel for New Relic’s dashboards and data tools and view real data visualizations in order to make informed decisions about how to add their own data to New Relic. This resource provides information about the Global Performance data sets, how they work, what they do, and current options for accessing Global Performance data. Public API Performance dashboard Important Please note: Global Performance data sets are presented as-is. Global Performance data sets represent an aggregate of samples across a range of sources, and New Relic makes no effort to attempt to confirm the correctness, completeness, or veracity of the data. This data should not be relied on as the sole source of information for any purpose you may use it, and New Relic is not responsible for decisions made in reliance on this data. Global Performance data sets should not be viewed as either an endorsement or a recommendation by New Relic of the technologies represented in the data sets. Access valuable data and try out New Relic Our first Global Performance data set, Public API Performance, offers a large body of real-world, real-time data about the performance of public APIs including AWS, Google, and more as experienced by New Relic customers (as authorized). Because this data is already flowing through New Relic, you can access it within seconds of activating your account, and test drive New Relic dashboarding and querying capabilities in the process. There’s no need to connect your own data sources to New Relic first, although we recommend you do so because adding your own data is easy, free, and the best way to understand how New Relic can serve your business needs. Get started with the Public API Performance dashboard To help you get started using Public API Performance data, we've created a Public API Performance dashboard. This dashboard provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to your own data. Both new and existing customers should be able to view Global Performance data in the Public API Performance dashboard quickly and easliy. To start using this dashboard, see Explore the Public API Performance dashboard.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 220.83392,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Global Performance <em>data</em> sets",
        "sections": "Access valuable <em>data</em> <em>and</em> try out New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " Public API Performance <em>data</em>, we&#x27;ve created a Public API Performance <em>dashboard</em>. This <em>dashboard</em> provides both actionable general insights and analytics and also an example of how you might apply dashboarding capabilities to <em>your</em> own <em>data</em>. Both new and existing customers should be able to view Global Performance <em>data</em> in the Public API Performance <em>dashboard</em> quickly and easliy. To start using this <em>dashboard</em>, see <em>Explore</em> the Public API Performance <em>dashboard</em>."
      },
      "id": "60445920196a673eee960f25"
    }
  ],
  "/docs/query-your-data/explore-query-data/dashboards/new-relic-global-performance-data-sets": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.73532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Filter New Relic One <em>dashboards</em> by facets",
        "sections": "Filter New Relic One <em>dashboards</em> by facets",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " attributes to filter the current <em>dashboard</em> or a related, linked <em>dashboard</em>. By letting you quickly filter <em>your</em> <em>dashboards</em>, and link to pre-filtered <em>dashboards</em>, <em>your</em> <em>dashboards</em> are more interactive and easy to use. This feature is available when adding a new chart to a <em>dashboard</em> or when editing a chart"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 248.81792,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "sections": "Add custom visualizations to <em>your</em> <em>dashboards</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a <em>dashboard</em>. This gives you great flexibility around what you display on <em>dashboards</em>, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.05856,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> <em>dashboard</em>",
        "sections": "Organize <em>your</em> <em>dashboards</em> with pages",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One <em>dashboards</em> to create or manage <em>your</em> charts directly from the chart menu, customize <em>your</em> <em>dashboard</em>&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> <em>dashboard</em> and built <em>your</em> charts, use our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/get-started/introduction-querying-new-relic-data": [
    {
      "sections": [
        "New Relic data types",
        "Get started",
        "Tip",
        "Metrics",
        "Metrics in the monitoring industry",
        "Metrics at New Relic",
        "Dimensional metrics (used by Metric API and many integrations)",
        "Metric timeslice data (used by APM, browser, mobile)",
        "Metric timeslice examples",
        "Metrics attached to events (used by Infrastructure, other products)",
        "Metrics as a computation of events (used in some charts and queries)",
        "Event data",
        "Events in the monitoring industry",
        "Events at New Relic",
        "Log data",
        "Logs in the monitoring industry",
        "Logs at New Relic",
        "Trace data",
        "Tracing in the monitoring industry",
        "Tracing at New Relic",
        "Query and send data",
        "Learn more"
      ],
      "title": "New Relic data types",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "8e4ab82bb58db47bc412f57231d4956c6068262b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/new-relic-data-types/",
      "published_at": "2021-12-19T15:32:43Z",
      "updated_at": "2021-12-04T21:48:30Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform is built around the four fundamental telemetry data types we believe are necessary for complete and effective system monitoring: metrics, events, logs, and traces. After you sign up for a free New Relic account and install any of our monitoring services, you can start working with your data. Get started This doc will give you a fairly technical explanation of our core data types, their structure, and how they're used in our features. You can use most of our features without needing to understand the underlying data structure. But having a better understanding of this can help you get data into New Relic, understand the data you see in our UI, and query your data. For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types. Another good way to understand your data is to just start querying it. Tip Access your data easily on one.newrelic.com: Click the Browse data dropdown menu and select the data type (metrics, events, logs, and traces) you want to explore. Metrics First, we’ll explain the definition of metrics from a monitoring industry perspective, and then we’ll explain how New Relic handles metrics. For a list of the metrics we collect, see our documentation on metrics. Metrics in the monitoring industry In the software monitoring industry, a metric means a numeric measurement of an application or system. Metrics are typically reported on a regular schedule. Two major types of metrics are: Aggregated data. For example: a count of events over one minute’s time, or the rate of some event per minute. A numeric status at a moment in time. For example: a CPU temperature reading, or a “CPU% used” status. Metrics are relatively easy to report and store because a single record can represent a range of time. They can also be aggregated more and more over time. For example, per-minute data may be “rolled up” to per-hour aggregations after some amount of time, and eventually may be rolled up to a per-day aggregation. This approach is efficient for long-term data storage. Metrics are a strong solution for storing data long-term, and understanding trends over time. One potential downside is that it can be difficult to do detailed analysis of older data that has been aggregated over time; when high detail is required about specific important actions, event data can be used. Metrics at New Relic Conceptually, \"metrics\" is a broad, general category. There are various ways New Relic measures and reports metrics but, in practice, when using the New Relic UI, you usually won't have to understand how exactly this happens. In our documentation, we typically will just refer to \"metrics,\" regardless of how that data is reported, unless there's a reason you need to know more (like understanding how to query your data). Here are some of the ways metrics are reported and stored across the New Relic platform: Dimensional metrics (used by Metric API and many integrations) In the monitoring industry, \"dimensional\" metrics refer to metric data that has a variety of attributes (dimensions) attached, such as duration-related attributes (start time, end time), entity ID, region, host, etc. This amount of detail allows for in-depth analysis and querying. At New Relic, this metric data is attached to the Metric data type and is sent from several sources: Some open-source integrations, such as the Prometheus exporter. Our Telemetry SDKs Infrastructure services The Metric API (the underlying API used by the above tools) The events-to-metrics service To query this data and see its attributes (\"dimensions\"), you could use a NRQL query like: Select * from Metric Copy As time passes, these metrics are increasingly aggregated into larger time buckets. This is done to optimize your ability to query data over a long period of time. For more details about the metric data type, see our docs. To learn how this data is ingested and stored, see the Metric API documentation. For tips on querying, see Metric query examples. Metric timeslice data (used by APM, browser, mobile) New Relic's APM, browser, and mobile report and display metrics in a simple data format that we refer to as metric timeslice data. A metric timeslice consists of three parts: a metric name, the segment of time the metric represents (the \"timeslice\"), and a numeric value (the measurement). For example: an APM metric timeslice for time spent in a particular transaction is named WebTransaction/URI/foo, and might have a response time of 0.793 for a one-minute time slice from 10:20am to 10:21am. These metrics usually follow a pattern like <category>/<class>/<method>. Our agents (APM, browser, and mobile) can collect thousands of metric timeslices per minute for a variety of performance metrics. For example: error rate, bandwidth usage, and garbage collection time. You also have the ability to create custom metrics. Metric timeslice data is a lightweight data type and lacks the detail that dimensional metrics have. Ways to explore and query metric timeslice data: For APM: metric timeslice data is converted to dimensional metrics and can be queried via NRQL Use the REST API If you want to learn more about the structure of metric timeslice data and see some examples, expand the collapser below. Metric timeslice examples Here are some common metric timeslice data examples, with a focus on common ones used by Ruby applications. ActiveMerchant New Relic tracks a variety of metrics on ActiveMerchant transactions which can be used for business analytics as well as performance monitoring. The metrics are summarized by operation as well as by gateway. regex sample metric legend name ActiveMerchant/. * ActiveMerchant/PayJunctionGateway ActiveMerchant/gateway/. * ActiveMerchant/gateway/PayJunctionGateway/purchase PayJunctionGateway ActiveMerchant/operation/. * ActiveMerchant/operation/purchase purchase For more information, see the ActiveMerchant website. ActiveRecord ActiveRecord is the Object-Relational Mapping API used by Ruby on Rails applications. The metrics shown here measure the performance of ActiveRecord's find and save methods. regex sample metric legend name ActiveRecord/. * /find ActiveRecord/User/find User#find ActiveRecord/. * /save ActiveRecord/Product/save Product#save For more information, see the API documentation for ActiveRecord. Apdex Apdex is a measure of user satisfaction with page load times. Controller In Ruby on Rails applications, HTTP requests are handled by Controller actions. A Rails application has many controllers, each of which has one or more actions. When your rails application receives an http request, that request is routed to the appropriate controller and action, based on the URL of that request. That action then does whatever processing is neccesary to generate an http response, which is most often a web page, but could also be a page fragment, an xml document, or any other kind of data that is requested by the client. The following metrics track the performance of controller actions, regardless of routing, and without taking into account any network or web server effects. regex sample metric legend name Controller/. * Controller/Users/show /Users/show Controller/. * /(?! \\ (other \\ )). * Controller/Users/show /Users/show Controller$ Controller All Controller Actions ControllerCPU/ ControllerCPU/Users/Show /Users/show For more information, see the API documentation for ActionController. Errors This metric tracks the number of errors or exceptions raised while processing requests. regex sample metric legend name Errors/all Errors/all External services External service instrumentation captures calls to out-of-process services such as web services, resources in the cloud and any other network calls. It does not include other first class back-end components such as MemCache and the database. In Ruby applications we instrument the Net::Http library to capture all HTTP services. regex sample metric legend name External/ [ ^/]+/all$ External/service.example.com/all All service.example.com calls External/ External/host.aws.com/Net::Http : :POST Net::Http : :POST [ host.aws.com] External/all$ External/all External Services External/ [ ^/]+/(?!all)/ External/service.example.com/all All service.example.com calls HTTP dispatcher This metric represents a summary of the throughput and response time of all web requests. regex sample metric legend name ^HttpDispatcher$ HttpDispatcher HttpDispatcher MemCache MemCache is a popular technology that enables applications to access shared memory provided by any number of physical machines as a global cache. Applications that heavily use the database often use MemCache for performance and scalability benefits. These metrics measure the frequency and response time of calls to MemCache to read and write data from the cache. Response times should be low (less than 5 ms) for a well performing MemCache deployment. regex sample metric legend name MemCache/. * MemCache/read MemCache read operations MemCache/read MemCache/read MemCache read operations MemCache/write MemCache/write MemCache write operations Mongrel This metric measures the length of the mongrel queue, which holds pending http requests to be processed by mongrel. The HTTP Activity graph overlays the maximimum queue length for a given period. The value is zero if mongrel is processing a request but has no other requests waiting in its queue. When looking at this value across an aggregate cluster of mongrels, the queue lengths of all mongrels is added together, showing the sum of all queue lengths. A mongrel queue length should be at or near zero; if it is consistently at a higher level, then it indicates that your rails application is having trouble keeping up with its load requirements. regex sample metric legend name Mongrel/Queue Length Mongrel/Queue Length Queue Length View ActionView is a package in Rails that is used to render the output that is the response to an http request, such as an html page or an xml document. The View is rendered by the controller that is handling the request. If View metrics represent a large portion of your controller's response time, it could mean you are doing a lot of database operations inside the view template itself. regex sample metric legend name View/. * View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Partial View/Users/ _ child.html.erb/Partial Users/ _ child.html.erb View/. * /Rendering View/Users/show.html.erb/Rendering Users/show.html.erb For more information, see the API documentation for ActionView. Metrics attached to events (used by Infrastructure, other products) Because event-type data can have any type of key-value pair data attached to it, one way metrics can be reported is as attributes attached to an event. A couple examples of this at New Relic: Our infrastructure monitoring reports many metrics that are attached to events. For example, we report a ProcessSample event, which has various sample-based metrics attached to it, like CPU percentage. To learn more about infrastructure monitoring data, see Infrastructure data. In APM, the Transaction event has several metrics attached to it, including databaseDuration. To learn more about this data and how to query it, see Events. Metrics as a computation of events (used in some charts and queries) Metrics can be formed by counting New Relic events, or doing some other mathematical calculation on those events. For example, if you wanted to measure the total number of Transaction events over the last half hour, you might run this NRQL query: Select count(*) from Transaction since 30 minutes ago Copy Another example: if you wanted to compute the average response time for your service, you might run a query like: FROM Transaction SELECT average(duration) SINCE 30 minutes ago Copy Some New Relic charts are generated with these kinds of queries. The downside of this approach is that there are limits on how many events a monitoring system (including ours) can report. This means that sometimes, for high-throughput systems, the count may not accurately represent the total activity on that system. To learn more about how this can be addressed, see Event limits and sampling. Want to report custom metrics? See Get data into New Relic. Event data First, we’ll explain the definition of events from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles event data. Events in the monitoring industry In the software industry, events can be thought of as simply “things that occur in a system.” For example, a server setting being changed would be an event. Another example: a website user clicking a mouse. Some events will generate a stored record, and that record is typically also called an event. Event data represents discrete occurrences and typically will have a high level of detail, so event data is suited for detailed analysis and querying. The downside to the use of event data is that there are typically so many events reported that it can become difficult to query that large dataset over longer time ranges. Events at New Relic At New Relic, we report events to data objects also called events. These events have multiple attributes (key-value pairs) attached. Event data is used in some UI charts and tables, and you can also query it. How long event data remains available is determined by data retention rules. One example of an event: APM reports an event type named Transaction, which represents a logical unit of work in an application. To see the attributes attached to this event, you could use a NRQL query like: Select * from Transaction Copy For examples of querying event data, see Introduction to NRQL. Other details about New Relic event data: Events can have any type of attributes attached. Some events have attributes that report metric data. You can report custom events. To increase the availability of your event data for querying/charting, you can turn events into metrics. Some systems generate a large number of events that exceeds collection limits and results in incomplete query results. For more on this, see Event sampling. Because event is a general term, in some New Relic contexts it will refer to any data type that can be queried via NRQL. For example, when you run a NRQL query, it returns a count of inspected events: this is a count of all data types queried. Log data First, we’ll explain the definition of logs from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles log reporting. Logs in the monitoring industry A log is a message about a system used to understand the activity of the system and to diagnose problems. Logs at New Relic New Relic's Logs gives you a centralized log management platform that connects your log data with other New Relic-monitored data. For example, you can see logs alongside your APM data. In New Relic, log data is reported with multiple attributes (key-value data) attached. To query your log data, you could use a NRQL query like: Select * from Log Copy To report custom log data, see the Log API. Trace data First, we’ll explain the definition of traces from a monitoring industry perspective, and then we’ll explain some specifics about how New Relic handles tracing. Tracing in the monitoring industry In the application/infrastructure-monitoring world, tracing is a general term used to refer to various ways to report information about how a program or system is operating. For example, a stack trace provides in-depth information about a program’s subroutines. For large modern systems, which are often distributed across many services and micro-services, “tracing” often refers to distributed tracing, which is a way to monitor requests as they propagate through a complex, distributed environment. Tracing at New Relic New Relic offers a distributed tracing feature that tracks requests across a distributed system, and provides a dedicated UI for understanding and analyzing your traces. In New Relic, trace data is reported as Span objects, with multiple attributes (key-value pairs) attached. To query your tracing data, you could use a NRQL query like: Select * from Span Copy To learn more about how distributed tracing works, see Understand distributed tracing. To report custom distributed tracing data, see the Trace API. Query and send data Understanding New Relic data types can help you: Query data in New Relic Send data to New Relic Learn more For a simpler explanation of these data types using real-world examples, see Introduction to essential telemetry data types.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.94624,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic <em>data</em> types",
        "sections": "Query <em>and</em> send <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": " with your <em>data</em>. Get started This doc will give you a fairly technical explanation of our core <em>data</em> types, their structure, and how they&#x27;re used in our features. You can use most of our features without needing to <em>understand</em> the underlying <em>data</em> structure. But having a better understanding"
      },
      "id": "6045280de7b9d266e1579a0f"
    },
    {
      "sections": [
        "Telemetry SDKs: Report custom telemetry data",
        "Requirements and compatibility",
        "Tip",
        "Available libraries",
        "Write your own Telemetry SDK or contribute to an existing one"
      ],
      "title": "Telemetry SDKs: Report custom telemetry data",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Ingest APIs"
      ],
      "external_id": "d883a07b7ede4c3beaba4077c507b95f9a228435",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/telemetry-sdks-report-custom-telemetry-data/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T14:27:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our Telemetry SDKs are an open source set of API client libraries that send data to the New Relic platform. Under the hood, these SDKs rely on our primary data ingest APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don't meet your needs, our Telemetry SDKs are one way to create a custom telemetry solution (see other solutions for reporting custom data). Requirements and compatibility The Telemetry SDKs use our Metric API, Event API, Log API, and Trace API, which all require a license key, so you'll need a license key for the account you wish to send data to. Tip New Relic has contributed the Telemetry SDK to the open source community under an Apache 2.0 license. Available libraries The Telemetry SDKs are open source software on GitHub. Use the language-specific GitHub links below to get library details, coding examples, and procedures for how to use the SDKs. We currently support the following libraries, with more to be created in the future: Language Library Supported New Relic data types Java Java library on GitHub Metrics Events Logs Traces Node/TypeScript NodeJS library on GitHub Metrics Traces Python Python library on GitHub Metrics Events Logs Traces Go Go library on Github Metrics Traces .NET .NET library on GitHub .NET package in NuGet Metrics Traces C C library on Github Traces Rust Rust library on Github Traces Ruby Ruby library on Github Gem on Rubygems Traces For more on the supported data types, see: An overview of New Relic data types Metrics: see the Metric API Logs: see the Log API Traces: see the Trace API Events: see the Event API Write your own Telemetry SDK or contribute to an existing one If you need a Telemetry SDK in a language that does not currently exist or want to contribute to an existing library, please see the Telemetry SDK specifications.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.06357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "sections": "Telemetry SDKs: Report custom telemetry <em>data</em>",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "Our Telemetry SDKs are an open source set of API client libraries that send <em>data</em> to the New Relic platform. Under the hood, these SDKs rely on our primary <em>data</em> <em>ingest</em> APIs: the Metric API, Trace API, Log API, and Event API. If our pre-built solutions don&#x27;t meet your needs, our Telemetry SDKs"
      },
      "id": "603ea196196a670192a83d83"
    },
    {
      "sections": [
        "Metric data structure",
        "Metric types"
      ],
      "title": "Metric data structure",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Understand data"
      ],
      "external_id": "179e9cbddd7ef1025e4803d79842140acd3a674b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/metric-data/metric-data-type/",
      "published_at": "2021-12-20T10:05:52Z",
      "updated_at": "2021-10-23T17:24:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic platform reports four main telemetry data types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric data, aka the Metric data type. To learn about how to query this type of data, see Query metrics. Metric types The metric type determines how the data is aggregated over longer time windows. It also determines which functions you can use to query the data. Metric types Description Available query functions count Measures the number of occurrences of an event. The count should be reset to 0 every time the metric is reported. Examples include cache hits per reporting interval and the number of threads created per reporting interval. You must specify a value for interval.ms when reporting the count metric type using the Metric API. The value must be a positive double. Generally, you want to take the rate of the sum: From Metric select rate(sum(myMetric), 1 minute) . . . sum distribution Tracks the statistical distribution on a numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type: Supports statistical functions like percentile and histogram, and all functions supported by the summary type. Uses the same algorithm as the percentile function. percentile histogram min max sum count average gauge Represents a value that can increase or decrease with time. Examples of gauges include the temperature, CPU usage, and memory. For example, there is always a temperature, but you are periodically taking the temperature and reporting it. The value must fit into the range of a Java double. latest min max sum count average summary Used to report pre-aggregated data, or information on aggregated discrete events. A summary includes a count, sum value, min value, and max value. The count value must be positive. Examples include transaction count/durations and queue count/ durations. You must specify a value for interval.ms when reporting the summary metric type using the Metric API. min max sum count average uniqueCount Tracks the number of unique values on a string or numeric attribute. This metric is re-aggregatable. For example, 1-minute data points from 60 minutes can be aggregated into a 1-hour data point, without degradation on accuracy. This type is generated only via the event-to-metrics service. uniqueCount",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.77039,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Metric <em>data</em> structure",
        "sections": "Metric <em>data</em> structure",
        "tags": "<em>Ingest</em> <em>and</em> <em>manage</em> <em>data</em>",
        "body": "The New Relic platform reports four main telemetry <em>data</em> types: metrics, events, logs, and traces. This document describes the structure of our dimensional metric <em>data</em>, aka the Metric <em>data</em> type. To learn about how to query this type of <em>data</em>, see Query metrics. Metric types The metric type determines"
      },
      "id": "609f9cbfe7b9d205f0c3eb54"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/introduction-query-builder": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.6268,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. NRQL <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use the NRQL console to query data anywhere in New Relic",
        "Important",
        "Tip",
        "Use the NRQL console"
      ],
      "title": "Use the NRQL console to query data anywhere in New Relic",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder",
        "NRQL console"
      ],
      "external_id": "3dea46fed19250290e96d7abac4d60382cc307e9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/nrql-console/",
      "published_at": "2021-12-19T20:58:20Z",
      "updated_at": "2021-09-13T10:27:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The NRQL console is only available through an Early Access Program. The NRQL console is a quick way to query your data anywhere in New Relic One while keeping context of what you're doing. Whether you're monitoring your services, troubleshooting an issue, or just browsing your platform, with the NRQL console you can explore your data to understand more about what you are seeing in just a click, without leaving your current view. Be faster at querying your data! Tip New to NRQL, New Relic's query languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin, elegant bar available everywhere for data exploration. Using it is very simple: Find the NRQL console at the bottom of the UI anywhere in New Relic One. It's omnipresent! You can also use the NRQL console to see queries clicking View query at the ... chart action menu in any widget from your dashboards. Type in your query: The console comes with autocomplete and syntax highlighting. Run the query, you'll see a visualization of it. All the queries you perform in the NRQL console will be displayed in the Recent queries tab in the query builder. Save the results to your dashboards. For advanced customizations, open your query in the query builder. You'll be able to complete the query, change the visualization type, configure the y-axis, format data, etc. Once you are done with your query you can minimize the console to keep the query on it in case you need it later, or you can clear it by pressing x. Tip The NRQL console is always available and visible by default, but you can turn it off (and back on!) in your user preferences clicking the avatar at the top right corner of the UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.70776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "sections": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": ", with the NRQL console you can <em>explore</em> <em>your</em> <em>data</em> to understand more about what you are seeing in just a click, without leaving <em>your</em> current view. Be faster at querying <em>your</em> <em>data</em>! Tip New to NRQL, New Relic&#x27;s <em>query</em> languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin"
      },
      "id": "613f2776e7b9d20b39b6f233"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.9526,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/nrql-console": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.62674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. <em>NRQL</em> <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 235.47862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    },
    {
      "sections": [
        "Query builder: Basic mode",
        "Important",
        "Data type",
        "Example of using basic mode",
        "Step 1: Select the source of the data for a chart",
        "Step 2: Filter the data",
        "Step 3: Adjust time range and limits",
        "Step 4: Customize the chart"
      ],
      "title": "Query builder: Basic mode",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder"
      ],
      "external_id": "7f076b3909c9462829453bc59f0dae0f5d5501fd",
      "image": "https://docs.newrelic.com/static/6be4a8d2af5e02259c01e180d7f43326/58213/crop-basic-example-chart_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode/",
      "published_at": "2021-12-19T20:58:21Z",
      "updated_at": "2021-08-27T08:13:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the New Relic One query builder in basic mode to create a chart without having to use NRQL, our querying language. The basic mode helps guides you through a query-creation process. You can choose the source of the raw data, apply filters, and use other techniques to narrow the scope of the data in the chart. Important As of September 1, 2021, we are discontinuing support of the query builder's basic mode. Instead, you can use our data explorer's user-friendly and intuitive functionality in New Relic One. For more details, including how you can easily prepare for this transition, see our Explorers Hub post. Data type The query builder basic mode has a Data type selector with two options: Events: In this context, this refers to all our non-Metric-type data, including events, logs, and trace data. Metrics: This refers to our dimensional Metric data type. You can also use this to query some types of metric timeslice data. For more on other types of metrics, see Data types. Example of using basic mode This example shows how to create a chart in basic mode. Step 1: Select the source of the data for a chart Begin by specifying what data you want to view in your chart. Click in the View a chart with box to select the event type, an attribute, and a function to perform on the attribute. You can use the event data dictionary to view information about an event type and its attributes on a single page. To see a tooltip with information about an event or attribute, hover over any term that has a dotted line underneath it. Here are the results of using the event data dictionary to specify the data: Event type. The Transaction event type measures a variety of data that describes what happens while a user is on a website, such as that user clicking on a button on a page. Attribute. The name attribute stores information on all transactions. Function. Select the unique_count function to get a count of all the transactions that occurred during the time frame. Basic mode now shows the selection: one.newrelic.com > Query builder > Basic > (event and attribute specified) As you specify data, the chart updates to show you the results from the data you specified. Based on the information specified so far, you can see a chart that shows the total number of transactions during the default time frame of 30 minutes. This total includes all transactions, whether the transaction was completed successfully or had errors. one.newrelic.com > Query builder > Basic > (event and attribute specified) Step 2: Filter the data Your next step is to determine which of those transactions got a 404 page not found error. If you look in the data dictionary for the Transaction event, you'll find this event also includes an attribute called httpResponseCode. Narrow the results to show only those transactions where a page not found error occurred. Use the Narrow results to box to create this filter: httpResponseCode = 404 . Because you want to be able to see the names of the apps that are resulting in the 404 errors, you use the Facet by box to see the results by appName (which is also an attribute for the Transaction event type). Faceting by appName updates the chart to break down the total number of 404 errors by the application names. This lets you know which apps are experiencing 404 errors. Your chart now shows the line chart with a line for each app, each with its own color. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) Step 3: Adjust time range and limits You decide to focus on the five apps with the most page not found errors. The default value for the Limit field is 10, meaning that your chart will show the ten most relevant returns. You change that value to 5. Customer support told you that they had been getting calls about these errors for a little over two hours. You decide to change the time range from the last 30 minutes to the last three hours so that you can view the errors during the time when the customers were calling support. Now that you have the data set so that you are seeing exactly what you need, you can turn your attention to the appearance of the chart. Step 4: Customize the chart Because you are more interested in the total number of errors than a timeline view, you change the chart type to a bar chart. one.newrelic.com > Query builder > Basic > (event and attribute specified) > (filters and facets applied) > (time range and limit customized) > (chart type customized) When you're finished with your chart, you can add it to a dashboard or share it. This table contains notes about using basic mode. Item Description Prompts You can start typing directly in an empty box; a list of items that match the information you type will display. You can also click on an empty box to view a list of all of the items that are appropriate for the field, based on your earlier choices. Saving a basic mode data specification Every time you run a query, that query is saved in the My recent queries dropdown in advanced (NRQL) mode. Events Basic mode only supports data for one event and attribute. If you want to use more than one event and/or attribute, use the SELECT statement in advanced (NRQL) mode. Shortcuts Basic mode contains shortcuts that can display more complex events and attributes that aren't generally supported, as in this example (which shows the tooltip for the shortcut). Example of the Response time histogram shortcut, showing a tooltip. Tooltips Any time you see a dotted line under a term, you can hover over that term to see a tooltip with an explanation of the term. Narrow by You can use more than one Narrow by definition in basic mode filter; the conditions will be joined by AND. The WHERE clause in advanced (NRQL) allows OR in addition to AND. Important If your query was started using basic mode and if you make changes to that query using advanced (NRQL) mode, you cannot return to basic mode to edit that query. Any additional changes may only be made in advanced (NRQL) mode.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 213.96875,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> <em>builder</em>: Basic mode",
        "sections": "<em>Query</em> <em>builder</em>: Basic mode",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Use the New Relic One <em>query</em> <em>builder</em> in basic mode to create a chart without having to use <em>NRQL</em>, our querying language. The basic mode helps guides you through a <em>query</em>-creation process. You can choose the source of the raw <em>data</em>, apply filters, and use other techniques to narrow the scope of the <em>data</em>"
      },
      "id": "603ec319e7b9d2008c2a07e0"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/query-builder-basic-mode": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.62674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. NRQL <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use the NRQL console to query data anywhere in New Relic",
        "Important",
        "Tip",
        "Use the NRQL console"
      ],
      "title": "Use the NRQL console to query data anywhere in New Relic",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder",
        "NRQL console"
      ],
      "external_id": "3dea46fed19250290e96d7abac4d60382cc307e9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/nrql-console/",
      "published_at": "2021-12-19T20:58:20Z",
      "updated_at": "2021-09-13T10:27:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The NRQL console is only available through an Early Access Program. The NRQL console is a quick way to query your data anywhere in New Relic One while keeping context of what you're doing. Whether you're monitoring your services, troubleshooting an issue, or just browsing your platform, with the NRQL console you can explore your data to understand more about what you are seeing in just a click, without leaving your current view. Be faster at querying your data! Tip New to NRQL, New Relic's query languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin, elegant bar available everywhere for data exploration. Using it is very simple: Find the NRQL console at the bottom of the UI anywhere in New Relic One. It's omnipresent! You can also use the NRQL console to see queries clicking View query at the ... chart action menu in any widget from your dashboards. Type in your query: The console comes with autocomplete and syntax highlighting. Run the query, you'll see a visualization of it. All the queries you perform in the NRQL console will be displayed in the Recent queries tab in the query builder. Save the results to your dashboards. For advanced customizations, open your query in the query builder. You'll be able to complete the query, change the visualization type, configure the y-axis, format data, etc. Once you are done with your query you can minimize the console to keep the query on it in case you need it later, or you can clear it by pressing x. Tip The NRQL console is always available and visible by default, but you can turn it off (and back on!) in your user preferences clicking the avatar at the top right corner of the UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.70776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "sections": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": ", with the NRQL console you can <em>explore</em> <em>your</em> <em>data</em> to understand more about what you are seeing in just a click, without leaving <em>your</em> current view. Be faster at querying <em>your</em> <em>data</em>! Tip New to NRQL, New Relic&#x27;s <em>query</em> languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin"
      },
      "id": "613f2776e7b9d20b39b6f233"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.95259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-nrql-mode-query-data": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.62674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. NRQL <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use the NRQL console to query data anywhere in New Relic",
        "Important",
        "Tip",
        "Use the NRQL console"
      ],
      "title": "Use the NRQL console to query data anywhere in New Relic",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder",
        "NRQL console"
      ],
      "external_id": "3dea46fed19250290e96d7abac4d60382cc307e9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/nrql-console/",
      "published_at": "2021-12-19T20:58:20Z",
      "updated_at": "2021-09-13T10:27:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The NRQL console is only available through an Early Access Program. The NRQL console is a quick way to query your data anywhere in New Relic One while keeping context of what you're doing. Whether you're monitoring your services, troubleshooting an issue, or just browsing your platform, with the NRQL console you can explore your data to understand more about what you are seeing in just a click, without leaving your current view. Be faster at querying your data! Tip New to NRQL, New Relic's query languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin, elegant bar available everywhere for data exploration. Using it is very simple: Find the NRQL console at the bottom of the UI anywhere in New Relic One. It's omnipresent! You can also use the NRQL console to see queries clicking View query at the ... chart action menu in any widget from your dashboards. Type in your query: The console comes with autocomplete and syntax highlighting. Run the query, you'll see a visualization of it. All the queries you perform in the NRQL console will be displayed in the Recent queries tab in the query builder. Save the results to your dashboards. For advanced customizations, open your query in the query builder. You'll be able to complete the query, change the visualization type, configure the y-axis, format data, etc. Once you are done with your query you can minimize the console to keep the query on it in case you need it later, or you can clear it by pressing x. Tip The NRQL console is always available and visible by default, but you can turn it off (and back on!) in your user preferences clicking the avatar at the top right corner of the UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.70776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "sections": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": ", with the NRQL console you can <em>explore</em> <em>your</em> <em>data</em> to understand more about what you are seeing in just a click, without leaving <em>your</em> current view. Be faster at querying <em>your</em> <em>data</em>! Tip New to NRQL, New Relic&#x27;s <em>query</em> languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin"
      },
      "id": "613f2776e7b9d20b39b6f233"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.95259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/query-builder/use-advanced-promql-style-mode-query-data": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 289.62668,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the <em>query</em> <em>builder</em>. NRQL <em>query</em> must contain a FACET clause. Available only for bar charts, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Use the NRQL console to query data anywhere in New Relic",
        "Important",
        "Tip",
        "Use the NRQL console"
      ],
      "title": "Use the NRQL console to query data anywhere in New Relic",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Query builder",
        "NRQL console"
      ],
      "external_id": "3dea46fed19250290e96d7abac4d60382cc307e9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/query-builder/nrql-console/",
      "published_at": "2021-12-19T20:58:20Z",
      "updated_at": "2021-09-13T10:27:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The NRQL console is only available through an Early Access Program. The NRQL console is a quick way to query your data anywhere in New Relic One while keeping context of what you're doing. Whether you're monitoring your services, troubleshooting an issue, or just browsing your platform, with the NRQL console you can explore your data to understand more about what you are seeing in just a click, without leaving your current view. Be faster at querying your data! Tip New to NRQL, New Relic's query languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin, elegant bar available everywhere for data exploration. Using it is very simple: Find the NRQL console at the bottom of the UI anywhere in New Relic One. It's omnipresent! You can also use the NRQL console to see queries clicking View query at the ... chart action menu in any widget from your dashboards. Type in your query: The console comes with autocomplete and syntax highlighting. Run the query, you'll see a visualization of it. All the queries you perform in the NRQL console will be displayed in the Recent queries tab in the query builder. Save the results to your dashboards. For advanced customizations, open your query in the query builder. You'll be able to complete the query, change the visualization type, configure the y-axis, format data, etc. Once you are done with your query you can minimize the console to keep the query on it in case you need it later, or you can clear it by pressing x. Tip The NRQL console is always available and visible by default, but you can turn it off (and back on!) in your user preferences clicking the avatar at the top right corner of the UI.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 216.70776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "sections": "Use the NRQL console to <em>query</em> <em>data</em> anywhere in New Relic",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": ", with the NRQL console you can <em>explore</em> <em>your</em> <em>data</em> to understand more about what you are seeing in just a click, without leaving <em>your</em> current view. Be faster at querying <em>your</em> <em>data</em>! Tip New to NRQL, New Relic&#x27;s <em>query</em> languange? Learn more in our docs! Use the NRQL console The NRQL console is a thin"
      },
      "id": "613f2776e7b9d20b39b6f233"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 215.95259,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Export <em>and</em> share <em>your</em> <em>data</em>",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " can use the search feature at any time to search <em>data</em> across New Relic One. Add new content to <em>your</em> dashboard There are multiple ways to add new content to <em>your</em> dashboard: From the <em>data</em> explorer and <em>query</em> <em>builder</em> features. Use the + Add to <em>your</em> dashboard button (accessible from the main dashboard"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/chart-refresh-rates": [
    {
      "sections": [
        "Real time streaming",
        "Why it matters",
        "Agent version to automatically enable",
        "Caution",
        "Query real time streaming data",
        "Create real time streaming charts"
      ],
      "title": "Real time streaming",
      "type": "docs",
      "tags": [
        "Agents",
        "Manage APM agents",
        "Agent data"
      ],
      "external_id": "47ea348bf8d620acfae2fbf48452147553d329ba",
      "image": "https://docs.newrelic.com/static/bfccf48174daa734a2359d7c15354222/c1b63/RTS-small.png",
      "url": "https://docs.newrelic.com/docs/apm/agents/manage-apm-agents/agent-data/real-time-streaming/",
      "published_at": "2021-12-20T01:09:08Z",
      "updated_at": "2021-10-23T19:43:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "With real time streaming, your APM event data is sent to New Relic every five seconds. You can query and visualize your data for transactions, errors, and custom events in near real time. The smaller payloads result in faster chart refreshes and faster queries of data that is the most important to you. No configuration is needed to take advantage of real time streaming. All you need to do is ensure your APM agent version is up to date. Why it matters Real time streaming doesn't result in more events being sent. The combination of more frequent posts, with a smaller number of events per post, results in approximately the same number of events per minute as there would be without real time streaming. The following image shows a comparison between data sent to New Relic with and without real time streaming. Note that 10,000 is an example number of events; some agents have lower default limits. The overall limits on how many events can be sent per minute haven't changed. Also, non-event data (spans, traces, and metrics) are unaffected; they're still sent every minute. Use real time streaming to quickly understand the impact when something has changed, such as deploying a new app version. Examine key performance indicators (throughput, error rates, charting, etc.) in near real time. Respond quickly to failure conditions and anomalies. Get the most out of New Relic One dashboards. Reduce mean time to detection with APM events reporting every five seconds. Agent version to automatically enable To enable real time streaming, update to the latest APM agent. You don't need to configure anything to enable real time streaming; it will automatically report faster! Real time streaming is supported by all APM agents. Here are the minimum agent versions: C SDK: v1.3.0 or higher Go: v2.8.0 or higher Java: v5.5.0 or higher .NET: v8.23.107.0 or higher Node.js: v5.13.0 or higher PHP: v9.5.0.252 or higher Python: v5.2.0.127 or higher Ruby: v6.7.0.359 or higher Caution If Transaction event reporting is disabled, this can affect some UI elements throughout New Relic. You may see some empty charts on some UI pages that rely on this data. Query real time streaming data When building charts, include the following in your NRQL query: NRQL clause Comments SINCE 5 minutes ago Be sure to add a SINCE 5 minutes ago clause to your NRQL query in order to take advantage of the 5 second chart refresh interval. This is because the chart's refresh interval is based on the time window. TIMESERIES bucket To set the refresh interval for time series charts, you can also specify the bucket size as an optional argument to the TIMESERIES clause. For example, SINCE 30 minutes ago TIMESERIES 5 seconds will display a 30 minute window at a 5 second resolution. You can have a maximum of 366 buckets. Create real time streaming charts You can visualize the results of your NRQL query in New Relic One: Go to one.newrelic.com, and at the top of the page, select Query your data. Use the data explorer to start building a chart. Select the advanced (NRQL) mode to refine your query. In your NRQL query, adjust the SINCE and TIMESERIES clauses to take advantage of the 5 second refresh intervals.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 108.10349,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Create real time streaming <em>charts</em>",
        "body": " <em>refresh</em> interval. This is because the <em>chart</em>&#x27;s <em>refresh</em> interval is based on the time window. TIMESERIES bucket To set the <em>refresh</em> interval for time series charts, you can also specify the bucket size as an optional argument to the TIMESERIES clause. For example, SINCE 30 minutes ago TIMESERIES 5"
      },
      "id": "617e63f228ccbc68a6800a0a"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "27d8e170b877432a396667cc541e0d3f95d82831",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-12-19T15:52:42Z",
      "updated_at": "2021-12-14T03:44:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 8.0 (Oreo) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 70.33069,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview <em>chart</em> to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/components/icon/",
      "sections": [
        "Icon",
        "Usage",
        "Examples",
        "Props"
      ],
      "published_at": "2021-12-19T13:51:51Z",
      "title": "Icon",
      "updated_at": "2021-12-18T01:40:46Z",
      "type": "developer",
      "external_id": "c6efdde9954d4b3df76ecab1c3326e5fd5bfe083",
      "document_type": "page",
      "popularity": 1,
      "body": "Usage import { Icon } from 'nr1' Copy Examples Props classNamestring Appends class names to the component. Should be used only for positioning and spacing purposes. colorstring Color of the icon. By default it gets the current value of the css color property of the element. spacingTypeenum[] Spacing property. Spacing is defined as a tuple of zero to four values, which follow the same conventions as CSS properties like margin or padding. To omit a value, use SPACING_TYPE.OMIT. <Array of <One of Icon.SPACING_TYPE.EXTRA_LARGE , Icon.SPACING_TYPE.LARGE , Icon.SPACING_TYPE.MEDIUM , Icon.SPACING_TYPE.NONE , Icon.SPACING_TYPE.OMIT , Icon.SPACING_TYPE.SMALL , > > styleobject Inline style for custom styling. Should be used only for positioning and spacing purposes. testIdstring Adds a data-test-id attribute. Use it to target the component in unit and E2E tests. For a test id to be valid, prefix it with your nerdpack id, followed up by a dot. For example, my-nerdpack.some-element. Note: You might not see data-test-id attributes as they are removed from the DOM, to debug them pass a e2e-test query parameter to the URL. typerequiredenum Name of the icon to display. <One of Icon.TYPE.DATAVIZ__DATAVIZ__AREA_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__BAR_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__BILLBOARD_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__BULLET_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__CHART , Icon.TYPE.DATAVIZ__DATAVIZ__CHART__A_ADD , Icon.TYPE.DATAVIZ__DATAVIZ__CHART__A_EDIT , Icon.TYPE.DATAVIZ__DATAVIZ__CHART__A_REMOVE , Icon.TYPE.DATAVIZ__DATAVIZ__DASHBOARD , Icon.TYPE.DATAVIZ__DATAVIZ__DASHBOARD__A_ADD , Icon.TYPE.DATAVIZ__DATAVIZ__DASHBOARD__A_EDIT , Icon.TYPE.DATAVIZ__DATAVIZ__DASHBOARD__A_FILTER , Icon.TYPE.DATAVIZ__DATAVIZ__DASHBOARD__A_REMOVE , Icon.TYPE.DATAVIZ__DATAVIZ__EVENT_FEED_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__HEATMAP_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__LINE_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__MARKDOWN , Icon.TYPE.DATAVIZ__DATAVIZ__PIE_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__SCATTER_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__SERVICE_MAP_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__STACKED_BAR_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__STACKED_HORIZONTAL_BAR_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__TABLE_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__TRAFFIC_LIGHTS_CHART , Icon.TYPE.DATAVIZ__DATAVIZ__VERTICAL_BAR_CHART , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__DATE , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__DATE__A_ADD , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__DATE__A_REMOVE , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__TIME , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__TIME__A_ADD , Icon.TYPE.DATE_AND_TIME__DATE_AND_TIME__TIME__A_REMOVE , Icon.TYPE.DOCUMENTS__DOCUMENTS__ATTACHMENT , Icon.TYPE.DOCUMENTS__DOCUMENTS__DOCUMENTATION , Icon.TYPE.DOCUMENTS__DOCUMENTS__EMAIL , Icon.TYPE.DOCUMENTS__DOCUMENTS__EMAIL__V_ALTERNATE , Icon.TYPE.DOCUMENTS__DOCUMENTS__FILE , Icon.TYPE.DOCUMENTS__DOCUMENTS__FILE__A_ADD , Icon.TYPE.DOCUMENTS__DOCUMENTS__FILE__A_REMOVE , Icon.TYPE.DOCUMENTS__DOCUMENTS__FOLDER , Icon.TYPE.DOCUMENTS__DOCUMENTS__FOLDER__A_ADD , Icon.TYPE.DOCUMENTS__DOCUMENTS__FOLDER__A_REMOVE , Icon.TYPE.DOCUMENTS__DOCUMENTS__NOTES , Icon.TYPE.DOCUMENTS__DOCUMENTS__NOTES__A_ADD , Icon.TYPE.DOCUMENTS__DOCUMENTS__NOTES__A_EDIT , Icon.TYPE.DOCUMENTS__DOCUMENTS__NOTES__A_REMOVE , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__ANOMALIES , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER__A_INSPECT , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CLUSTER__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__CPU , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__DESKTOP , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__DESKTOP__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__DESKTOP__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__DESKTOP__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__DESKTOP__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MEMORY , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__MOBILE__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK__A_INSPECT , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__NETWORK__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_ADD , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_CONFIGURE , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_EDIT , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_INSPECT , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_PAUSE , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__A_REMOVE , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__SERVER__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__HARDWARE__STORAGE , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_CLUSTER , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_CONTAINER , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_DEPLOYMENT , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_MASTER_NODE , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_NAMESPACE , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_NODE , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_POD , Icon.TYPE.HARDWARE_AND_SOFTWARE__KUBERNETES__K8S_SERVICE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__ALL_ENTITIES , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__APPLICATION__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__BROWSER__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CLOUD , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CODE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CONTAINER , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CONTROL_CENTER , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CORRELATION , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__CORRELATION_REASONING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DATABASE__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DECISIONS , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DESTINATIONS , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DOWNSTREAM_CONNECTION , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__DOWNSTREAM_DEPLOYMENT , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__EVENT , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__FEED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__LIVE_VIEW , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__LOGS , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MOBILE_APPLICATION__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__MONITORING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__NODE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__OVERVIEW , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PATHWAY , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__PLUGIN__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__QUERY , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE__A_CHECKED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE__S_DISABLED , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE__S_ERROR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE__S_OK , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SERVICE__S_WARNING , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SOURCES , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__STACK_TRACE , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SYNTHESIZED_ENTITY , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SYNTHETICS_MONITOR , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__SYSTEM , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__TRACES , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__TRAFFIC , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__UPSTREAM_CONNECTION , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__UPSTREAM_DEPLOYMENT , Icon.TYPE.HARDWARE_AND_SOFTWARE__SOFTWARE__WORKLOADS , Icon.TYPE.INTERFACE__ARROW__ARROW_BOTTOM , Icon.TYPE.INTERFACE__ARROW__ARROW_BOTTOM__V_ALTERNATE , Icon.TYPE.INTERFACE__ARROW__ARROW_BOTTOM__V_ALTERNATE__WEIGHT_BOLD , Icon.TYPE.INTERFACE__ARROW__ARROW_DIAGONAL_BOTTOM_LEFT , Icon.TYPE.INTERFACE__ARROW__ARROW_DIAGONAL_BOTTOM_RIGHT , Icon.TYPE.INTERFACE__ARROW__ARROW_DIAGONAL_TOP_LEFT , Icon.TYPE.INTERFACE__ARROW__ARROW_DIAGONAL_TOP_RIGHT , Icon.TYPE.INTERFACE__ARROW__ARROW_HORIZONTAL , Icon.TYPE.INTERFACE__ARROW__ARROW_LEFT , Icon.TYPE.INTERFACE__ARROW__ARROW_LEFT__V_ALTERNATE , Icon.TYPE.INTERFACE__ARROW__ARROW_LEFT__V_ALTERNATE__WEIGHT_BOLD , Icon.TYPE.INTERFACE__ARROW__ARROW_RIGHT , Icon.TYPE.INTERFACE__ARROW__ARROW_RIGHT__V_ALTERNATE , Icon.TYPE.INTERFACE__ARROW__ARROW_RIGHT__V_ALTERNATE__WEIGHT_BOLD , Icon.TYPE.INTERFACE__ARROW__ARROW_TOP , Icon.TYPE.INTERFACE__ARROW__ARROW_TOP__V_ALTERNATE , Icon.TYPE.INTERFACE__ARROW__ARROW_TOP__V_ALTERNATE__WEIGHT_BOLD , Icon.TYPE.INTERFACE__ARROW__ARROW_VERTICAL , Icon.TYPE.INTERFACE__ARROW__EXPAND , Icon.TYPE.INTERFACE__ARROW__GO_TO , Icon.TYPE.INTERFACE__ARROW__MOVE , Icon.TYPE.INTERFACE__ARROW__RESIZE , Icon.TYPE.INTERFACE__ARROW__RETURN_LEFT , Icon.TYPE.INTERFACE__ARROW__RETURN_RIGHT , Icon.TYPE.INTERFACE__ARROW__SHRINK , Icon.TYPE.INTERFACE__ARROW__SORT , Icon.TYPE.INTERFACE__CARET__CARET_BOTTOM , Icon.TYPE.INTERFACE__CARET__CARET_BOTTOM__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_BOTTOM__V_ALTERNATE , Icon.TYPE.INTERFACE__CARET__CARET_BOTTOM__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CARET__CARET_BOTTOM__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_LEFT , Icon.TYPE.INTERFACE__CARET__CARET_LEFT__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_LEFT__V_ALTERNATE , Icon.TYPE.INTERFACE__CARET__CARET_LEFT__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CARET__CARET_LEFT__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_RIGHT , Icon.TYPE.INTERFACE__CARET__CARET_RIGHT__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_RIGHT__V_ALTERNATE , Icon.TYPE.INTERFACE__CARET__CARET_RIGHT__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CARET__CARET_RIGHT__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_TOP , Icon.TYPE.INTERFACE__CARET__CARET_TOP__SIZE_8 , Icon.TYPE.INTERFACE__CARET__CARET_TOP__V_ALTERNATE , Icon.TYPE.INTERFACE__CARET__CARET_TOP__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CARET__CARET_TOP__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_BOTTOM , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_BOTTOM__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_BOTTOM__V_ALTERNATE , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_BOTTOM__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_BOTTOM__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_LEFT , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_LEFT__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_LEFT__V_ALTERNATE , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_LEFT__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_LEFT__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_RIGHT , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_RIGHT__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_RIGHT__V_ALTERNATE , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_RIGHT__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_RIGHT__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_TOP , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_TOP__SIZE_8 , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_TOP__V_ALTERNATE , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_TOP__WEIGHT_BOLD , Icon.TYPE.INTERFACE__CHEVRON__CHEVRON_TOP__WEIGHT_BOLD__SIZE_8 , Icon.TYPE.INTERFACE__INFO__ANNOUNCEMENT , Icon.TYPE.INTERFACE__INFO__HELP , Icon.TYPE.INTERFACE__INFO__INFO , Icon.TYPE.INTERFACE__INFO__INFO__WEIGHT_BOLD , Icon.TYPE.INTERFACE__OPERATIONS__ADJUST , Icon.TYPE.INTERFACE__OPERATIONS__ALERT , Icon.TYPE.INTERFACE__OPERATIONS__ALERT__A_REMOVE , Icon.TYPE.INTERFACE__OPERATIONS__ALERT__S_OFF , Icon.TYPE.INTERFACE__OPERATIONS__ALERT__S_ON , Icon.TYPE.INTERFACE__OPERATIONS__ARCHIVE , Icon.TYPE.INTERFACE__OPERATIONS__CENTER , Icon.TYPE.INTERFACE__OPERATIONS__CLOSE , Icon.TYPE.INTERFACE__OPERATIONS__CLOSE__SIZE_8 , Icon.TYPE.INTERFACE__OPERATIONS__CLOSE__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__CONFIGURE , Icon.TYPE.INTERFACE__OPERATIONS__COPY_TO , Icon.TYPE.INTERFACE__OPERATIONS__COPY_TO_CLIPBOARD , Icon.TYPE.INTERFACE__OPERATIONS__DOWNLOAD , Icon.TYPE.INTERFACE__OPERATIONS__DRAG , Icon.TYPE.INTERFACE__OPERATIONS__EDIT , Icon.TYPE.INTERFACE__OPERATIONS__EXPORT , Icon.TYPE.INTERFACE__OPERATIONS__EXTERNAL_LINK , Icon.TYPE.INTERFACE__OPERATIONS__FILTER , Icon.TYPE.INTERFACE__OPERATIONS__FILTER__A_ADD , Icon.TYPE.INTERFACE__OPERATIONS__FILTER__A_REMOVE , Icon.TYPE.INTERFACE__OPERATIONS__FILTER__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__FOLLOW , Icon.TYPE.INTERFACE__OPERATIONS__GROUP , Icon.TYPE.INTERFACE__OPERATIONS__GROUP__A_REMOVE , Icon.TYPE.INTERFACE__OPERATIONS__GROUP__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__HIDE , Icon.TYPE.INTERFACE__OPERATIONS__HIDE_OTHERS , Icon.TYPE.INTERFACE__OPERATIONS__HIGHLIGHT , Icon.TYPE.INTERFACE__OPERATIONS__IMPORT , Icon.TYPE.INTERFACE__OPERATIONS__MORE , Icon.TYPE.INTERFACE__OPERATIONS__PAUSE , Icon.TYPE.INTERFACE__OPERATIONS__PAUSE_ALTERNATE__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__PIN , Icon.TYPE.INTERFACE__OPERATIONS__PLAY , Icon.TYPE.INTERFACE__OPERATIONS__PLAY_ALTERNATE__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__REARRANGE , Icon.TYPE.INTERFACE__OPERATIONS__REDO , Icon.TYPE.INTERFACE__OPERATIONS__REFRESH , Icon.TYPE.INTERFACE__OPERATIONS__REMOVE__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__REPLY__A_REPLY , Icon.TYPE.INTERFACE__OPERATIONS__SEARCH , Icon.TYPE.INTERFACE__OPERATIONS__SEARCH__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__SELECTION , Icon.TYPE.INTERFACE__OPERATIONS__SELECTION__V_ALTERNATE , Icon.TYPE.INTERFACE__OPERATIONS__SHARE , Icon.TYPE.INTERFACE__OPERATIONS__SHARE_LINK , Icon.TYPE.INTERFACE__OPERATIONS__SHOW , Icon.TYPE.INTERFACE__OPERATIONS__SKIP_BACK , Icon.TYPE.INTERFACE__OPERATIONS__SKIP_FORWARD , Icon.TYPE.INTERFACE__OPERATIONS__TAG , Icon.TYPE.INTERFACE__OPERATIONS__TRASH , Icon.TYPE.INTERFACE__OPERATIONS__TV_MODE , Icon.TYPE.INTERFACE__OPERATIONS__TV_MODE__A_TV_MODE , Icon.TYPE.INTERFACE__OPERATIONS__UNDO , Icon.TYPE.INTERFACE__OPERATIONS__UNPIN , Icon.TYPE.INTERFACE__OPERATIONS__UPLOAD , Icon.TYPE.INTERFACE__PLACEHOLDERS__CUSTOM_PLACEHOLDER , Icon.TYPE.INTERFACE__PLACEHOLDERS__ICON_PLACEHOLDER , Icon.TYPE.INTERFACE__SIGN__ASTERISK , Icon.TYPE.INTERFACE__SIGN__CHECKMARK , Icon.TYPE.INTERFACE__SIGN__CHECKMARK__V_ALTERNATE , Icon.TYPE.INTERFACE__SIGN__CHECKMARK__V_ALTERNATE__WEIGHT_BOLD , Icon.TYPE.INTERFACE__SIGN__CLOSE , Icon.TYPE.INTERFACE__SIGN__DOLLAR_SIGN , Icon.TYPE.INTERFACE__SIGN__EXCLAMATION , Icon.TYPE.INTERFACE__SIGN__EXCLAMATION__V_ALTERNATE , Icon.TYPE.INTERFACE__SIGN__MINUS , Icon.TYPE.INTERFACE__SIGN__MINUS__V_ALTERNATE , Icon.TYPE.INTERFACE__SIGN__NUMBER , Icon.TYPE.INTERFACE__SIGN__PLUS , Icon.TYPE.INTERFACE__SIGN__PLUS__V_ALTERNATE , Icon.TYPE.INTERFACE__SIGN__TIMES , Icon.TYPE.INTERFACE__SIGN__TIMES__SIZE_8 , Icon.TYPE.INTERFACE__SIGN__TIMES__V_ALTERNATE , Icon.TYPE.INTERFACE__STATE__CLOSED , Icon.TYPE.INTERFACE__STATE__CRITICAL , Icon.TYPE.INTERFACE__STATE__CRITICAL__WEIGHT_BOLD , Icon.TYPE.INTERFACE__STATE__DISABLED , Icon.TYPE.INTERFACE__STATE__ENABLED , Icon.TYPE.INTERFACE__STATE__HEALTHY , Icon.TYPE.INTERFACE__STATE__LOADING , Icon.TYPE.INTERFACE__STATE__LOCK , Icon.TYPE.INTERFACE__STATE__OPEN , Icon.TYPE.INTERFACE__STATE__PRIVATE , Icon.TYPE.INTERFACE__STATE__PUBLIC , Icon.TYPE.INTERFACE__STATE__UNAVAILABLE , Icon.TYPE.INTERFACE__STATE__UNLOCK , Icon.TYPE.INTERFACE__STATE__WARNING , Icon.TYPE.INTERFACE__STATE__WARNING__WEIGHT_BOLD , Icon.TYPE.INTERFACE__VIEW__ENTER_FULL_SCREEN , Icon.TYPE.INTERFACE__VIEW__EXIT_FULL_SCREEN , Icon.TYPE.INTERFACE__VIEW__GRID_VIEW , Icon.TYPE.INTERFACE__VIEW__HIGH_DENSITY_VIEW , Icon.TYPE.INTERFACE__VIEW__LAYER_LIST , Icon.TYPE.INTERFACE__VIEW__LIST_VIEW , Icon.TYPE.INTERFACE__VIEW__SIXTH_SENSE , Icon.TYPE.INTERFACE__VIEW__THEME_TOGGLE , Icon.TYPE.INTERFACE__VIEW__THEME_TOGGLE__S_DARK , Icon.TYPE.INTERFACE__VIEW__THEME_TOGGLE__S_LIGHT , Icon.TYPE.LOCATION__LOCATION__HOME , Icon.TYPE.LOCATION__LOCATION__MAP , Icon.TYPE.LOCATION__LOCATION__PIN , Icon.TYPE.LOCATION__LOCATION__WORLD , Icon.TYPE.PROFILES__EVENTS__COMMENT , Icon.TYPE.PROFILES__EVENTS__COMMENT__A_EDIT , Icon.TYPE.PROFILES__EVENTS__FAVORITE , Icon.TYPE.PROFILES__EVENTS__FAVORITE__WEIGHT_BOLD , Icon.TYPE.PROFILES__EVENTS__LIKE , Icon.TYPE.PROFILES__USERS__ORGANIZATION , Icon.TYPE.PROFILES__USERS__ORGANIZATION__A_ADD , Icon.TYPE.PROFILES__USERS__ORGANIZATION__A_EDIT , Icon.TYPE.PROFILES__USERS__ORGANIZATION__A_REMOVE , Icon.TYPE.PROFILES__USERS__TEAM , Icon.TYPE.PROFILES__USERS__TEAM__A_ADD , Icon.TYPE.PROFILES__USERS__TEAM__A_EDIT , Icon.TYPE.PROFILES__USERS__TEAM__A_REMOVE , Icon.TYPE.PROFILES__USERS__USER , Icon.TYPE.PROFILES__USERS__USER__A_ADD , Icon.TYPE.PROFILES__USERS__USER__A_EDIT , Icon.TYPE.PROFILES__USERS__USER__A_REMOVE , >",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 68.45814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " of Icon.TYPE.DATAVIZ__DATAVIZ__AREA_<em>CHART</em> , Icon.TYPE.DATAVIZ__DATAVIZ__BAR_<em>CHART</em> , Icon.TYPE.DATAVIZ__DATAVIZ__BILLBOARD_<em>CHART</em> , Icon.TYPE.DATAVIZ__DATAVIZ__BULLET_<em>CHART</em> , Icon.TYPE.DATAVIZ__DATAVIZ__<em>CHART</em> , Icon.TYPE.DATAVIZ__DATAVIZ__<em>CHART</em>__A_ADD , Icon.TYPE.DATAVIZ__DATAVIZ__<em>CHART</em>"
      },
      "id": "6091f874196a678161d52a63"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/chart-types": [
    {
      "sections": [
        "Customize your visualization with configuration options",
        "Course",
        "Tip",
        "Add a new configuration option",
        "Replace your SegmentedControl with the configurable property",
        "Summary"
      ],
      "title": "Customize your visualization with configuration options",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "visualizations"
      ],
      "external_id": "9028e58f383ea362d2c9d3a7ecd6404dbfeac87c",
      "image": "https://developer.newrelic.com/static/429297e04a38e93e7c2bd5bfcada5021/0086b/nav-to-apps.png",
      "url": "https://developer.newrelic.com/build-apps/customize-visualizations-with-configuration/",
      "published_at": "2021-12-22T01:40:07Z",
      "updated_at": "2021-09-30T01:41:15Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization using configuration",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Each lesson in the course builds upon the last, so make sure you've completed the last lesson, Custom visualizations and the New Relic One SDK, before starting this one. In the previous lesson, you built a custom visualization that shows queried data in one of two chart types: RadarChart Treemap You used a SegmentedControl to switch between the two chart types in the visualization UI. This implementation takes up space in the visualization, but it offers your users the choice to switch between two chart types even after you've created an instance of your chart. But what if you only need to be able to select an option once, when initializing the visualization? In this lesson you'll learn how to add a configuration option to your visualization which replaces the SegmentedControl. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Add a new configuration option Step 1 of 8 In your visualization's nr1.json file, add an enum configuration object for selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }); 80 }; 81 82 render() { 83 const { nrqlQueries, stroke, fill } = this.props; 84 const { selectedChart } = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({ width, height }) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({ data, loading, error }) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl onChange={this.updateSelectedChart}> 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 {selectedChart === CHART_TYPES.Radar ? ( 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 ) : ( 144 <Treemap 145 width={width} 146 height={height} 147 data={transformedData} 148 dataKey=\"value\" 149 ratio={4 / 3} 150 stroke={stroke || '#000000'} 151 fill={fill || '#51C9B7'} 152 /> 153 )} 154 </React.Fragment> 155 ); 156 }} 157 </NrqlQuery> 158 )} 159 </AutoSizer> 160 ); 161 } 162 } 163 164 const EmptyState = () => ( 165 <Card className=\"EmptyState\"> 166 <CardBody className=\"EmptyState-cardBody\"> 167 <HeadingText 168 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 169 type={HeadingText.TYPE.HEADING_3} 170 > 171 Please provide at least one NRQL query & account ID pair 172 </HeadingText> 173 <HeadingText 174 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 175 type={HeadingText.TYPE.HEADING_4} 176 > 177 An example NRQL query you can try is: 178 </HeadingText> 179 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 180 </CardBody> 181 </Card> 182 ); 183 184 const ErrorState = () => ( 185 <Card className=\"ErrorState\"> 186 <CardBody className=\"ErrorState-cardBody\"> 187 <HeadingText 188 className=\"ErrorState-headingText\" 189 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 190 type={HeadingText.TYPE.HEADING_3} 191 > 192 Oops! Something went wrong. 193 </HeadingText> 194 </CardBody> 195 </Card> 196 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 2 of 8 Navigate to the root of your Nerdpack at alternate-viz. Step 3 of 8 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve If you're still serving your Nerdpack from the last lesson, you need to stop it with CTRL-X and serve it again to reflect changes to nr1.json. Step 4 of 8 Go to https://one.newrelic.com/?nerdpacks=local. The nerdpacks=local query string directs the UI to load your visualization from the local server. Step 5 of 8 Open the Apps page: Step 6 of 8 Go to Custom Visualizations, which is favorited by default: Step 7 of 8 In Custom Visualizations, find and click your visualization: Step 8 of 8 Notice the new Select chart configuration option: Selecting a chart type doesn't effect your visualization. This is because you first need to introduce the selectedChart property to the visualization component. Then, you use selectedChart to determine the chart type to render. Replace your SegmentedControl with the configurable property Step 1 of 5 Open your visualization's index.js file. You'll be working here for the rest of the guide. Step 2 of 5 In render(), include selectedChart as a constant you get from destructuring props, and remove your component's state: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({ width, height }) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({ data, loading, error }) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now that you're using selectedChart from the configuration options instead of component state, you can select a chart in the configuration panel and watch the visualization change. Unfortunately, there's a bug. The default chart option is Radar, but the initial render shows a Treemap. Step 3 of 5 Update your ternary expression to account for the case where there is no selectedChart: index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 Radar: 'radar', 24 Treemap: 'treemap', 25 }; 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 /** 55 * Restructure the data for a non-time-series, facet-based NRQL query into a 56 * form accepted by the Recharts library's RadarChart. 57 * (https://recharts.org/api/RadarChart). 58 */ 59 transformData = (rawData) => { 60 return rawData.map((entry) => ({ 61 name: entry.metadata.name, 62 // Only grabbing the first data value because this is not time-series data. 63 value: entry.data[0].y, 64 })); 65 }; 66 67 /** 68 * Format the given axis tick's numeric value into a string for display. 69 */ 70 formatTick = (value) => { 71 return value.toLocaleString(); 72 }; 73 74 render() { 75 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 76 77 const nrqlQueryPropsAvailable = 78 nrqlQueries && 79 nrqlQueries[0] && 80 nrqlQueries[0].accountId && 81 nrqlQueries[0].query; 82 83 if (!nrqlQueryPropsAvailable) { 84 return <EmptyState />; 85 } 86 87 return ( 88 <AutoSizer> 89 {({ width, height }) => ( 90 <NrqlQuery 91 query={nrqlQueries[0].query} 92 accountId={parseInt(nrqlQueries[0].accountId)} 93 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 94 > 95 {({ data, loading, error }) => { 96 if (loading) { 97 return <Spinner />; 98 } 99 100 if (error) { 101 return <ErrorState />; 102 } 103 104 const transformedData = this.transformData(data); 105 106 return ( 107 <React.Fragment> 108 <SegmentedControl> 109 <SegmentedControlItem 110 value={CHART_TYPES.Radar} 111 label=\"Radar chart\" 112 /> 113 <SegmentedControlItem 114 value={CHART_TYPES.Treemap} 115 label=\"Treemap chart\" 116 /> 117 </SegmentedControl> 118 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 119 <RadarChart 120 width={width} 121 height={height} 122 data={transformedData} 123 > 124 <PolarGrid /> 125 <PolarAngleAxis dataKey=\"name\" /> 126 <PolarRadiusAxis tickFormatter={this.formatTick} /> 127 <Radar 128 dataKey=\"value\" 129 stroke={stroke || '#51C9B7'} 130 fill={fill || '#51C9B7'} 131 fillOpacity={0.6} 132 /> 133 </RadarChart> 134 ) : ( 135 <Treemap 136 width={width} 137 height={height} 138 data={transformedData} 139 dataKey=\"value\" 140 ratio={4 / 3} 141 stroke={stroke || '#000000'} 142 fill={fill || '#51C9B7'} 143 /> 144 )} 145 </React.Fragment> 146 ); 147 }} 148 </NrqlQuery> 149 )} 150 </AutoSizer> 151 ); 152 } 153 } 154 155 const EmptyState = () => ( 156 <Card className=\"EmptyState\"> 157 <CardBody className=\"EmptyState-cardBody\"> 158 <HeadingText 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Please provide at least one NRQL query & account ID pair 163 </HeadingText> 164 <HeadingText 165 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 166 type={HeadingText.TYPE.HEADING_4} 167 > 168 An example NRQL query you can try is: 169 </HeadingText> 170 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 171 </CardBody> 172 </Card> 173 ); 174 175 const ErrorState = () => ( 176 <Card className=\"ErrorState\"> 177 <CardBody className=\"ErrorState-cardBody\"> 178 <HeadingText 179 className=\"ErrorState-headingText\" 180 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 181 type={HeadingText.TYPE.HEADING_3} 182 > 183 Oops! Something went wrong. 184 </HeadingText> 185 </CardBody> 186 </Card> 187 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Now, your data is rendered in a RadarChart if you haven't yet configured the option. Step 4 of 5 Remove SegmentedControl from render(): index.js nr1.json 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 Spinner, 18 } from 'nr1'; 19 20 const CHART_TYPES = { 21 Radar: 'radar', 22 Treemap: 'treemap', 23 }; 24 25 export default class RadarOrTreemapVisualization extends React.Component { 26 // Custom props you wish to be configurable in the UI must also be defined in 27 // the nr1.json file for the visualization. See docs for more details. 28 static propTypes = { 29 /** 30 * A fill color to override the default fill color. This is an example of 31 * a custom chart configuration. 32 */ 33 fill: PropTypes.string, 34 35 /** 36 * A stroke color to override the default stroke color. This is an example of 37 * a custom chart configuration. 38 */ 39 stroke: PropTypes.string, 40 /** 41 * An array of objects consisting of a nrql `query` and `accountId`. 42 * This should be a standard prop for any NRQL based visualizations. 43 */ 44 nrqlQueries: PropTypes.arrayOf( 45 PropTypes.shape({ 46 accountId: PropTypes.number, 47 query: PropTypes.string, 48 }) 49 ), 50 }; 51 52 /** 53 * Restructure the data for a non-time-series, facet-based NRQL query into a 54 * form accepted by the Recharts library's RadarChart. 55 * (https://recharts.org/api/RadarChart). 56 */ 57 transformData = (rawData) => { 58 return rawData.map((entry) => ({ 59 name: entry.metadata.name, 60 // Only grabbing the first data value because this is not time-series data. 61 value: entry.data[0].y, 62 })); 63 }; 64 65 /** 66 * Format the given axis tick's numeric value into a string for display. 67 */ 68 formatTick = (value) => { 69 return value.toLocaleString(); 70 }; 71 72 render() { 73 const { nrqlQueries, stroke, fill, selectedChart } = this.props; 74 75 const nrqlQueryPropsAvailable = 76 nrqlQueries && 77 nrqlQueries[0] && 78 nrqlQueries[0].accountId && 79 nrqlQueries[0].query; 80 81 if (!nrqlQueryPropsAvailable) { 82 return <EmptyState />; 83 } 84 85 return ( 86 <AutoSizer> 87 {({ width, height }) => ( 88 <NrqlQuery 89 query={nrqlQueries[0].query} 90 accountId={parseInt(nrqlQueries[0].accountId)} 91 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 92 > 93 {({ data, loading, error }) => { 94 if (loading) { 95 return <Spinner />; 96 } 97 98 if (error) { 99 return <ErrorState />; 100 } 101 102 const transformedData = this.transformData(data); 103 104 return ( 105 <React.Fragment> 106 {!selectedChart || selectedChart === CHART_TYPES.Radar ? ( 107 <RadarChart 108 width={width} 109 height={height} 110 data={transformedData} 111 > 112 <PolarGrid /> 113 <PolarAngleAxis dataKey=\"name\" /> 114 <PolarRadiusAxis tickFormatter={this.formatTick} /> 115 <Radar 116 dataKey=\"value\" 117 stroke={stroke || '#51C9B7'} 118 fill={fill || '#51C9B7'} 119 fillOpacity={0.6} 120 /> 121 </RadarChart> 122 ) : ( 123 <Treemap 124 width={width} 125 height={height} 126 data={transformedData} 127 dataKey=\"value\" 128 ratio={4 / 3} 129 stroke={stroke || '#000000'} 130 fill={fill || '#51C9B7'} 131 /> 132 )} 133 </React.Fragment> 134 ); 135 }} 136 </NrqlQuery> 137 )} 138 </AutoSizer> 139 ); 140 } 141 } 142 143 const EmptyState = () => ( 144 <Card className=\"EmptyState\"> 145 <CardBody className=\"EmptyState-cardBody\"> 146 <HeadingText 147 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 148 type={HeadingText.TYPE.HEADING_3} 149 > 150 Please provide at least one NRQL query & account ID pair 151 </HeadingText> 152 <HeadingText 153 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 154 type={HeadingText.TYPE.HEADING_4} 155 > 156 An example NRQL query you can try is: 157 </HeadingText> 158 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 159 </CardBody> 160 </Card> 161 ); 162 163 const ErrorState = () => ( 164 <Card className=\"ErrorState\"> 165 <CardBody className=\"ErrorState-cardBody\"> 166 <HeadingText 167 className=\"ErrorState-headingText\" 168 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 169 type={HeadingText.TYPE.HEADING_3} 170 > 171 Oops! Something went wrong. 172 </HeadingText> 173 </CardBody> 174 </Card> 175 ); visualizations/radar-or-treemap/index.js Copy 1 { 2 \"schemaType\": \"VISUALIZATION\", 3 \"id\": \"radar-or-treemap\", 4 \"displayName\": \"RadarOrTreemap\", 5 \"description\": \"\", 6 \"configuration\": [ 7 { 8 \"name\": \"selectedChart\", 9 \"title\": \"Select chart\", 10 \"description\": \"Select which chart to display\", 11 \"type\": \"enum\", 12 \"items\": [ 13 { 14 \"title\": \"Radar\", 15 \"value\": \"radar\" 16 }, 17 { 18 \"title\": \"Treemap\", 19 \"value\": \"treemap\" 20 } 21 ] 22 }, 23 { 24 \"name\": \"nrqlQueries\", 25 \"title\": \"NRQL Queries\", 26 \"type\": \"collection\", 27 \"items\": [ 28 { 29 \"name\": \"accountId\", 30 \"title\": \"Account ID\", 31 \"description\": \"Account ID to be associated with the query\", 32 \"type\": \"account-id\" 33 }, 34 { 35 \"name\": \"query\", 36 \"title\": \"Query\", 37 \"description\": \"NRQL query for visualization\", 38 \"type\": \"nrql\" 39 } 40 ] 41 }, 42 { 43 \"name\": \"fill\", 44 \"title\": \"Fill color\", 45 \"description\": \"A fill color to override the default fill color\", 46 \"type\": \"string\" 47 }, 48 { 49 \"name\": \"stroke\", 50 \"title\": \"Stroke color\", 51 \"description\": \"A stroke color to override the default stroke color\", 52 \"type\": \"string\" 53 } 54 ] 55 } visualizations/radar-or-treemap/nr1.json Copy Step 5 of 5 Serve your Nerdpack locally, and view it in the Custom Visualizations app in New Relic. Select a chart type from the dropdown in the configuration sidebar, and see your visualization update to show the matching chart type: Summary Congratulations on completing this lesson! You've learned how to customize your visualization using nr1.json configuration. Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Add custom visualizations to your dashboards.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 415.4946,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": ". In the previous lesson, you built a custom visualization that shows queried data in one of two <em>chart</em> <em>types</em>: Radar<em>Chart</em> Treemap You used a SegmentedControl to switch between the two <em>chart</em> <em>types</em> in the visualization UI. This implementation takes up space in the visualization, but it offers your users"
      },
      "id": "6091fa3ae7b9d2df595068c1"
    },
    {
      "sections": [
        "Use your charts",
        "Change the appearance of your chart",
        "Customize your charts",
        "Tip",
        "Format date and time",
        "Customize the Y axis",
        "Enable or disable the legend",
        "Remove the other groups facet",
        "More chart-specific features",
        "Chart share and view options"
      ],
      "title": "Use  your charts ",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Use charts"
      ],
      "external_id": "947a92d0243924f412fedb47bcb95dc40ec953fb",
      "image": "https://docs.newrelic.com/static/9bd74f30a31df0cb0ab112a325296b92/59415/crop-cb-chart-menu-tooltip_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/use-charts/use-your-charts/",
      "published_at": "2021-12-19T20:24:14Z",
      "updated_at": "2021-07-21T13:02:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Once you've created a chart, you can customize the appearance of it to best present the data. You can share a chart in different formats and add a chart to a new or existing dashboard. Change the appearance of your chart When you run your query in advanced (NRQL) mode or view your chart while using the data explorer to specify data, the query builder analyzes your data and applies a chart type that fits your data. For some queries, you'll have several options of chart types to choose from. To change chart type, use the Chart type menu to the right of the current chart. Each type in the list has a tooltip with information about using that type. Example of the chart type menu, showing a tooltip. Customize your charts While we try our best to optimize how we display your data, sometimes you may have other needs. To this end, you can customize charts to display information at your convenience. Tip Customizations are available depending on the chart type. Format date and time Tip For table and billboard charts. Customize the date and time format for tables and billboards: for each type of data, you can select if you want to leave it as it is, or modify the format as Numeric or Date. If data is a timestamp, you can choose how to represent the date and time: For numbers, select if you want us to auto-format them, or chose the number of decimals you want to see. Customize the Y axis Tip For line and area charts. On line charts and area charts you can adjust the Y axis to display the data within certain values by setting a minimum and maximum value for the axis. If no customization option is selected, dashboards automatically displays the full Y axis from 0 to the top value plus a margin. Enable or disable the legend Tip For line and area charts, and histograms. For line charts, area charts, and histograms, you can disable or enable the legend. Remove the other groups facet Tip For bar and pie charts, and tables. When faceting on bar charts, pie charts, or tables, and if the number of faceting on queries is larger than 2,000, the Other groups facet aggregates the rest of facets. With this customization you can select whether to see Other groups, or remove it. More chart-specific features For more chart type-specific features, see Chart types. Chart share and view options Most charts have various options, including a chart-embed option, getting a chart as an image, and adding a chart to a dashboard. To read about general chart options, see Basic UI features.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 387.66205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use  your <em>charts</em> ",
        "sections": "Use your <em>charts</em>",
        "tags": "Use <em>charts</em>",
        "body": " the data explorer to specify data, the query builder analyzes your data and applies a <em>chart</em> <em>type</em> that fits your data. For some queries, you&#x27;ll have several options of <em>chart</em> <em>types</em> to choose from. To change <em>chart</em> <em>type</em>, use the <em>Chart</em> <em>type</em> menu to the right of the current <em>chart</em>. Each <em>type</em> in the list"
      },
      "id": "603ec29a196a67ef5da83d82"
    },
    {
      "sections": [
        "Customize your visualization with SDK components",
        "Course",
        "Tip",
        "Before you begin",
        "Create your visualization",
        "Set up your component state",
        "Add SegmentedControl components",
        "Connect your component's state to the SegmentedControl",
        "Implement a Treemap option",
        "Technical detail",
        "Switch between charts with your component's state",
        "Summary"
      ],
      "title": "Customize your visualization with SDK components",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "NR One Catalog",
        "Subscribe visualizations"
      ],
      "external_id": "8317cf0361e92ab36c922dd87720e01a69530f9b",
      "image": "https://developer.newrelic.com/static/ae9d817689607337734a3d66e12d1dc4/ba3ac/radar-chart-with-segmented-control.png",
      "url": "https://developer.newrelic.com/build-apps/custom-visualizations-and-the-new-relic-one-sdk/",
      "published_at": "2021-12-22T01:39:16Z",
      "updated_at": "2021-05-13T01:45:29Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Customize your visualization",
      "body": "Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. Use New Relic One custom visualizations to display your data, whether it's from New Relic's database or an external source, in unique ways that are distinct from the charts offered by the New Relic platform. In this lesson, you build a visualization that displays your data in one of two chart types: RadarChart or Treemap. You then implement a SegmentedControl component from the New Relic One SDK, which allows you to alternate between the two chart types. Ultimately, this gives you freedom to view your data in a dynamic way that isn't possible with New Relic's base offerings. Tip If you get lost in the code project and would like to see what the files should look like when you're done with each lesson, check out the course project on Github. Before you begin Explore our custom visualization guides and build your first visualization. After you're done, you'll have a better foundation for building more complex visualizations, such as the one you'll build in this course. Finally, if you haven't already: Sign up for a New Relic account Install Node.js Complete the steps in the nr1 quick start to install and configure the CLI Create your visualization Step 1 of 2 Ensure you're working with the latest version of the New Relic One CLI: bash Copy $ nr1 update Step 2 of 2 Create a visualization, called radar-or-treemap, in a Nerdpack, called alternate-viz: bash Copy $ nr1 create --type visualization --name radar-or-treemap ✔ You’re trying to create a visualization outside of a Nerdpack. We’ll create a Nerdpack for you—what do you want to name it? … alternate-viz ✔ nerdpack created successfully! nerdpack alternate-viz is available at \"./alternate-viz\" ✔ visualization created successfully! visualization radar-or-treemap is available at \"./alternate-viz/visualizations/radar-or-treemap\" Tip If you receive a RequestError for a self-signed certificate when you run nr1 create, you may need to add a certificate to Node's certificate chain. Read more about this and other advanced configurations in Enable advanced configurations for your Nerdpack. As a result, you have a new visualizations/radar-or-treemap directory under alternate-viz: bash Copy $ cd alternate-viz $ ls visualizations/radar-or-treemap index.js nr1.json styles.scss Set up your component state Add component state to the default visualization template that nr1 created for you. Step 1 of 3 Navigate to alternate-viz/visualizations/radar-or-treemap/index.js. You'll work in here for the rest of this lesson. Step 2 of 3 Add a constant called CHART_TYPES: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 /** 45 * Restructure the data for a non-time-series, facet-based NRQL query into a 46 * form accepted by the Recharts library's RadarChart. 47 * (https://recharts.org/api/RadarChart). 48 */ 49 transformData = (rawData) => { 50 return rawData.map((entry) => ({ 51 name: entry.metadata.name, 52 // Only grabbing the first data value because this is not time-series data. 53 value: entry.data[0].y, 54 })); 55 }; 56 57 /** 58 * Format the given axis tick's numeric value into a string for display. 59 */ 60 formatTick = (value) => { 61 return value.toLocaleString(); 62 }; 63 64 render() { 65 const {nrqlQueries, stroke, fill} = this.props; 66 67 const nrqlQueryPropsAvailable = 68 nrqlQueries && 69 nrqlQueries[0] && 70 nrqlQueries[0].accountId && 71 nrqlQueries[0].query; 72 73 if (!nrqlQueryPropsAvailable) { 74 return <EmptyState />; 75 } 76 77 return ( 78 <AutoSizer> 79 {({width, height}) => ( 80 <NrqlQuery 81 query={nrqlQueries[0].query} 82 accountId={parseInt(nrqlQueries[0].accountId)} 83 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 84 > 85 {({data, loading, error}) => { 86 if (loading) { 87 return <Spinner />; 88 } 89 90 if (error) { 91 return <ErrorState />; 92 } 93 94 const transformedData = this.transformData(data); 95 96 return ( 97 <RadarChart 98 width={width} 99 height={height} 100 data={transformedData} 101 > 102 <PolarGrid /> 103 <PolarAngleAxis dataKey=\"name\" /> 104 <PolarRadiusAxis tickFormatter={this.formatTick} /> 105 <Radar 106 dataKey=\"value\" 107 stroke={stroke || '#51C9B7'} 108 fill={fill || '#51C9B7'} 109 fillOpacity={0.6} 110 /> 111 </RadarChart> 112 ); 113 }} 114 </NrqlQuery> 115 )} 116 </AutoSizer> 117 ); 118 } 119 } 120 121 const EmptyState = () => ( 122 <Card className=\"EmptyState\"> 123 <CardBody className=\"EmptyState-cardBody\"> 124 <HeadingText 125 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 126 type={HeadingText.TYPE.HEADING_3} 127 > 128 Please provide at least one NRQL query & account ID pair 129 </HeadingText> 130 <HeadingText 131 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 132 type={HeadingText.TYPE.HEADING_4} 133 > 134 An example NRQL query you can try is: 135 </HeadingText> 136 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 137 </CardBody> 138 </Card> 139 ); 140 141 const ErrorState = () => ( 142 <Card className=\"ErrorState\"> 143 <CardBody className=\"ErrorState-cardBody\"> 144 <HeadingText 145 className=\"ErrorState-headingText\" 146 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 147 type={HeadingText.TYPE.HEADING_3} 148 > 149 Oops! Something went wrong. 150 </HeadingText> 151 </CardBody> 152 </Card> 153 ); visualizations/radar-or-treemap/index.js Copy CHART_TYPES enumerates the two chart types you'll alternate between in your visualization. Step 3 of 3 Initialize selectedChart in your component's state: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import {Card, CardBody, HeadingText, NrqlQuery, Spinner, AutoSizer} from 'nr1'; 11 12 const CHART_TYPES = { 13 'Radar': 'radar', 14 'Treemap': 'treemap' 15 } 16 17 export default class RadarOrTreemapVisualization extends React.Component { 18 // Custom props you wish to be configurable in the UI must also be defined in 19 // the nr1.json file for the visualization. See docs for more details. 20 static propTypes = { 21 /** 22 * A fill color to override the default fill color. This is an example of 23 * a custom chart configuration. 24 */ 25 fill: PropTypes.string, 26 27 /** 28 * A stroke color to override the default stroke color. This is an example of 29 * a custom chart configuration. 30 */ 31 stroke: PropTypes.string, 32 /** 33 * An array of objects consisting of a nrql `query` and `accountId`. 34 * This should be a standard prop for any NRQL based visualizations. 35 */ 36 nrqlQueries: PropTypes.arrayOf( 37 PropTypes.shape({ 38 accountId: PropTypes.number, 39 query: PropTypes.string, 40 }) 41 ), 42 }; 43 44 state = { 45 selectedChart: CHART_TYPES.Radar, 46 }; 47 48 /** 49 * Restructure the data for a non-time-series, facet-based NRQL query into a 50 * form accepted by the Recharts library's RadarChart. 51 * (https://recharts.org/api/RadarChart). 52 */ 53 transformData = (rawData) => { 54 return rawData.map((entry) => ({ 55 name: entry.metadata.name, 56 // Only grabbing the first data value because this is not time-series data. 57 value: entry.data[0].y, 58 })); 59 }; 60 61 /** 62 * Format the given axis tick's numeric value into a string for display. 63 */ 64 formatTick = (value) => { 65 return value.toLocaleString(); 66 }; 67 68 render() { 69 const {nrqlQueries, stroke, fill} = this.props; 70 71 const nrqlQueryPropsAvailable = 72 nrqlQueries && 73 nrqlQueries[0] && 74 nrqlQueries[0].accountId && 75 nrqlQueries[0].query; 76 77 if (!nrqlQueryPropsAvailable) { 78 return <EmptyState />; 79 } 80 81 return ( 82 <AutoSizer> 83 {({width, height}) => ( 84 <NrqlQuery 85 query={nrqlQueries[0].query} 86 accountId={parseInt(nrqlQueries[0].accountId)} 87 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 88 > 89 {({data, loading, error}) => { 90 if (loading) { 91 return <Spinner />; 92 } 93 94 if (error) { 95 return <ErrorState />; 96 } 97 98 const transformedData = this.transformData(data); 99 100 return ( 101 <RadarChart 102 width={width} 103 height={height} 104 data={transformedData} 105 > 106 <PolarGrid /> 107 <PolarAngleAxis dataKey=\"name\" /> 108 <PolarRadiusAxis tickFormatter={this.formatTick} /> 109 <Radar 110 dataKey=\"value\" 111 stroke={stroke || '#51C9B7'} 112 fill={fill || '#51C9B7'} 113 fillOpacity={0.6} 114 /> 115 </RadarChart> 116 ); 117 }} 118 </NrqlQuery> 119 )} 120 </AutoSizer> 121 ); 122 } 123 } 124 125 const EmptyState = () => ( 126 <Card className=\"EmptyState\"> 127 <CardBody className=\"EmptyState-cardBody\"> 128 <HeadingText 129 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 130 type={HeadingText.TYPE.HEADING_3} 131 > 132 Please provide at least one NRQL query & account ID pair 133 </HeadingText> 134 <HeadingText 135 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 136 type={HeadingText.TYPE.HEADING_4} 137 > 138 An example NRQL query you can try is: 139 </HeadingText> 140 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 141 </CardBody> 142 </Card> 143 ); 144 145 const ErrorState = () => ( 146 <Card className=\"ErrorState\"> 147 <CardBody className=\"ErrorState-cardBody\"> 148 <HeadingText 149 className=\"ErrorState-headingText\" 150 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 151 type={HeadingText.TYPE.HEADING_3} 152 > 153 Oops! Something went wrong. 154 </HeadingText> 155 </CardBody> 156 </Card> 157 ); visualizations/radar-or-treemap/index.js Copy This state value stores the chart type in which you want to show your data. Now that you've created an object which enumerates the chart type options for your visualization, and you've initialized state.selectedChart, you're ready to implement a control UI for switching between the two chart types. Add SegmentedControl components state.selectedChart isn't useful unless your visualization's users can actually select a chart type. Use SegmentedControl and SegmentedControlItem to switch between the two chart types. Tip To learn more about the components available in the New Relic One SDK, go to our Intro to New Relic One SDK. Step 1 of 7 Import SegmentedControl and SegmentedControlItem from nr1: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <RadarChart 111 width={width} 112 height={height} 113 data={transformedData} 114 > 115 <PolarGrid /> 116 <PolarAngleAxis dataKey=\"name\" /> 117 <PolarRadiusAxis tickFormatter={this.formatTick} /> 118 <Radar 119 dataKey=\"value\" 120 stroke={stroke || '#51C9B7'} 121 fill={fill || '#51C9B7'} 122 fillOpacity={0.6} 123 /> 124 </RadarChart> 125 ); 126 }} 127 </NrqlQuery> 128 )} 129 </AutoSizer> 130 ); 131 } 132 } 133 134 const EmptyState = () => ( 135 <Card className=\"EmptyState\"> 136 <CardBody className=\"EmptyState-cardBody\"> 137 <HeadingText 138 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 139 type={HeadingText.TYPE.HEADING_3} 140 > 141 Please provide at least one NRQL query & account ID pair 142 </HeadingText> 143 <HeadingText 144 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 145 type={HeadingText.TYPE.HEADING_4} 146 > 147 An example NRQL query you can try is: 148 </HeadingText> 149 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 150 </CardBody> 151 </Card> 152 ); 153 154 const ErrorState = () => ( 155 <Card className=\"ErrorState\"> 156 <CardBody className=\"ErrorState-cardBody\"> 157 <HeadingText 158 className=\"ErrorState-headingText\" 159 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 160 type={HeadingText.TYPE.HEADING_3} 161 > 162 Oops! Something went wrong. 163 </HeadingText> 164 </CardBody> 165 </Card> 166 ); visualizations/radar-or-treemap/index.js Copy Step 2 of 7 In render(), wrap RadarChart in a React.Fragment: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <RadarChart 112 width={width} 113 height={height} 114 data={transformedData} 115 > 116 <PolarGrid /> 117 <PolarAngleAxis dataKey=\"name\" /> 118 <PolarRadiusAxis tickFormatter={this.formatTick} /> 119 <Radar 120 dataKey=\"value\" 121 stroke={stroke || '#51C9B7'} 122 fill={fill || '#51C9B7'} 123 fillOpacity={0.6} 124 /> 125 </RadarChart> 126 </React.Fragment> 127 ); 128 }} 129 </NrqlQuery> 130 )} 131 </AutoSizer> 132 ); 133 } 134 } 135 136 const EmptyState = () => ( 137 <Card className=\"EmptyState\"> 138 <CardBody className=\"EmptyState-cardBody\"> 139 <HeadingText 140 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 141 type={HeadingText.TYPE.HEADING_3} 142 > 143 Please provide at least one NRQL query & account ID pair 144 </HeadingText> 145 <HeadingText 146 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 147 type={HeadingText.TYPE.HEADING_4} 148 > 149 An example NRQL query you can try is: 150 </HeadingText> 151 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 152 </CardBody> 153 </Card> 154 ); 155 156 const ErrorState = () => ( 157 <Card className=\"ErrorState\"> 158 <CardBody className=\"ErrorState-cardBody\"> 159 <HeadingText 160 className=\"ErrorState-headingText\" 161 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 162 type={HeadingText.TYPE.HEADING_3} 163 > 164 Oops! Something went wrong. 165 </HeadingText> 166 </CardBody> 167 </Card> 168 ); visualizations/radar-or-treemap/index.js Copy This allows you to return multiple components from the same render(). Step 3 of 7 Add a SegmentedControl and two SegmentedControlItem components, each with a value and a label: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 render() { 78 const {nrqlQueries, stroke, fill} = this.props; 79 80 const nrqlQueryPropsAvailable = 81 nrqlQueries && 82 nrqlQueries[0] && 83 nrqlQueries[0].accountId && 84 nrqlQueries[0].query; 85 86 if (!nrqlQueryPropsAvailable) { 87 return <EmptyState />; 88 } 89 90 return ( 91 <AutoSizer> 92 {({width, height}) => ( 93 <NrqlQuery 94 query={nrqlQueries[0].query} 95 accountId={parseInt(nrqlQueries[0].accountId)} 96 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 97 > 98 {({data, loading, error}) => { 99 if (loading) { 100 return <Spinner />; 101 } 102 103 if (error) { 104 return <ErrorState />; 105 } 106 107 const transformedData = this.transformData(data); 108 109 return ( 110 <React.Fragment> 111 <SegmentedControl 112 onChange={(event, value) => console.log(value)} 113 > 114 <SegmentedControlItem 115 value={CHART_TYPES.Radar} 116 label=\"Radar chart\" 117 /> 118 <SegmentedControlItem 119 value={CHART_TYPES.Treemap} 120 label=\"Treemap chart\" 121 /> 122 </SegmentedControl> 123 <RadarChart 124 width={width} 125 height={height} 126 data={transformedData} 127 > 128 <PolarGrid /> 129 <PolarAngleAxis dataKey=\"name\" /> 130 <PolarRadiusAxis tickFormatter={this.formatTick} /> 131 <Radar 132 dataKey=\"value\" 133 stroke={stroke || '#51C9B7'} 134 fill={fill || '#51C9B7'} 135 fillOpacity={0.6} 136 /> 137 </RadarChart> 138 </React.Fragment> 139 ); 140 }} 141 </NrqlQuery> 142 )} 143 </AutoSizer> 144 ); 145 } 146 } 147 148 const EmptyState = () => ( 149 <Card className=\"EmptyState\"> 150 <CardBody className=\"EmptyState-cardBody\"> 151 <HeadingText 152 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 153 type={HeadingText.TYPE.HEADING_3} 154 > 155 Please provide at least one NRQL query & account ID pair 156 </HeadingText> 157 <HeadingText 158 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 159 type={HeadingText.TYPE.HEADING_4} 160 > 161 An example NRQL query you can try is: 162 </HeadingText> 163 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 164 </CardBody> 165 </Card> 166 ); 167 168 const ErrorState = () => ( 169 <Card className=\"ErrorState\"> 170 <CardBody className=\"ErrorState-cardBody\"> 171 <HeadingText 172 className=\"ErrorState-headingText\" 173 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 174 type={HeadingText.TYPE.HEADING_3} 175 > 176 Oops! Something went wrong. 177 </HeadingText> 178 </CardBody> 179 </Card> 180 ); visualizations/radar-or-treemap/index.js Copy Here, your SegmentedControl logs the SegmentedControlItem.value to the console when you change your selection. The values you've defined for your SegmentedControlItem components correspond to the two CHART_TYPES you created in a previous step. Step 4 of 7 Navigate to the root of your Nerdpack at alternate-viz. Step 5 of 7 Serve your Nerdpack locally: bash Copy $ nr1 nerdpack:serve Step 6 of 7 Open the link to your visualization that's shown in the terminal when the Node server starts: bash Copy Visualizations: ⁎ radar-or-treemap https://one.nr/012ab3cd4Ef Step 7 of 7 Configure your visualization with an account ID and a query: With some required data for your chart to process, you now see a RadarChart with the SegmentedControl at the top of the view. Look at your browser's console to see your SegmentedControl logs: Connect your component's state to the SegmentedControl Add a method to update state and connect that method with the SegmentedControl you added in the last section. Step 1 of 2 Add a component method, called updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={(event, value) => console.log(value)} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy This new method takes a value argument and sets state.selectedChart to that value. Step 2 of 2 Set SegmentedControl.onChange to updateSelectedChart(): index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 } from 'recharts'; 10 import { 11 AutoSizer, 12 Card, 13 CardBody, 14 HeadingText, 15 NrqlQuery, 16 SegmentedControl, 17 SegmentedControlItem, 18 Spinner, 19 } from 'nr1'; 20 21 const CHART_TYPES = { 22 'Radar': 'radar', 23 'Treemap': 'treemap' 24 } 25 26 export default class RadarOrTreemapVisualization extends React.Component { 27 // Custom props you wish to be configurable in the UI must also be defined in 28 // the nr1.json file for the visualization. See docs for more details. 29 static propTypes = { 30 /** 31 * A fill color to override the default fill color. This is an example of 32 * a custom chart configuration. 33 */ 34 fill: PropTypes.string, 35 36 /** 37 * A stroke color to override the default stroke color. This is an example of 38 * a custom chart configuration. 39 */ 40 stroke: PropTypes.string, 41 /** 42 * An array of objects consisting of a nrql `query` and `accountId`. 43 * This should be a standard prop for any NRQL based visualizations. 44 */ 45 nrqlQueries: PropTypes.arrayOf( 46 PropTypes.shape({ 47 accountId: PropTypes.number, 48 query: PropTypes.string, 49 }) 50 ), 51 }; 52 53 state = { 54 selectedChart: CHART_TYPES.Radar, 55 }; 56 57 /** 58 * Restructure the data for a non-time-series, facet-based NRQL query into a 59 * form accepted by the Recharts library's RadarChart. 60 * (https://recharts.org/api/RadarChart). 61 */ 62 transformData = (rawData) => { 63 return rawData.map((entry) => ({ 64 name: entry.metadata.name, 65 // Only grabbing the first data value because this is not time-series data. 66 value: entry.data[0].y, 67 })); 68 }; 69 70 /** 71 * Format the given axis tick's numeric value into a string for display. 72 */ 73 formatTick = (value) => { 74 return value.toLocaleString(); 75 }; 76 77 updateSelectedChart = (evt, value) => { 78 this.setState({ selectedChart: value }) 79 }; 80 81 render() { 82 const {nrqlQueries, stroke, fill} = this.props; 83 84 const nrqlQueryPropsAvailable = 85 nrqlQueries && 86 nrqlQueries[0] && 87 nrqlQueries[0].accountId && 88 nrqlQueries[0].query; 89 90 if (!nrqlQueryPropsAvailable) { 91 return <EmptyState />; 92 } 93 94 return ( 95 <AutoSizer> 96 {({width, height}) => ( 97 <NrqlQuery 98 query={nrqlQueries[0].query} 99 accountId={parseInt(nrqlQueries[0].accountId)} 100 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 101 > 102 {({data, loading, error}) => { 103 if (loading) { 104 return <Spinner />; 105 } 106 107 if (error) { 108 return <ErrorState />; 109 } 110 111 const transformedData = this.transformData(data); 112 113 return ( 114 <React.Fragment> 115 <SegmentedControl 116 onChange={this.updateSelectedChart} 117 > 118 <SegmentedControlItem 119 value={CHART_TYPES.Radar} 120 label=\"Radar chart\" 121 /> 122 <SegmentedControlItem 123 value={CHART_TYPES.Treemap} 124 label=\"Treemap chart\" 125 /> 126 </SegmentedControl> 127 <RadarChart 128 width={width} 129 height={height} 130 data={transformedData} 131 > 132 <PolarGrid /> 133 <PolarAngleAxis dataKey=\"name\" /> 134 <PolarRadiusAxis tickFormatter={this.formatTick} /> 135 <Radar 136 dataKey=\"value\" 137 stroke={stroke || '#51C9B7'} 138 fill={fill || '#51C9B7'} 139 fillOpacity={0.6} 140 /> 141 </RadarChart> 142 </React.Fragment> 143 ); 144 }} 145 </NrqlQuery> 146 )} 147 </AutoSizer> 148 ); 149 } 150 } 151 152 const EmptyState = () => ( 153 <Card className=\"EmptyState\"> 154 <CardBody className=\"EmptyState-cardBody\"> 155 <HeadingText 156 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 157 type={HeadingText.TYPE.HEADING_3} 158 > 159 Please provide at least one NRQL query & account ID pair 160 </HeadingText> 161 <HeadingText 162 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 163 type={HeadingText.TYPE.HEADING_4} 164 > 165 An example NRQL query you can try is: 166 </HeadingText> 167 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 168 </CardBody> 169 </Card> 170 ); 171 172 const ErrorState = () => ( 173 <Card className=\"ErrorState\"> 174 <CardBody className=\"ErrorState-cardBody\"> 175 <HeadingText 176 className=\"ErrorState-headingText\" 177 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 178 type={HeadingText.TYPE.HEADING_3} 179 > 180 Oops! Something went wrong. 181 </HeadingText> 182 </CardBody> 183 </Card> 184 ); visualizations/radar-or-treemap/index.js Copy Now, when you change your selection in the SegmentedControl, your selection will be set in state. Implement a Treemap option Add a Treemap to your visualization. This map will be an alternative to the existing RadarChart. Technical detail This guide uses Recharts components for third-party charts, but you can use any other JavaScript charting libraries that are compatible with the current React version when you build New Relic One visualizations and apps. Step 1 of 3 Import Treemap from recharts: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 </React.Fragment> 144 ); 145 }} 146 </NrqlQuery> 147 )} 148 </AutoSizer> 149 ); 150 } 151 } 152 153 const EmptyState = () => ( 154 <Card className=\"EmptyState\"> 155 <CardBody className=\"EmptyState-cardBody\"> 156 <HeadingText 157 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 158 type={HeadingText.TYPE.HEADING_3} 159 > 160 Please provide at least one NRQL query & account ID pair 161 </HeadingText> 162 <HeadingText 163 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 164 type={HeadingText.TYPE.HEADING_4} 165 > 166 An example NRQL query you can try is: 167 </HeadingText> 168 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 169 </CardBody> 170 </Card> 171 ); 172 173 const ErrorState = () => ( 174 <Card className=\"ErrorState\"> 175 <CardBody className=\"ErrorState-cardBody\"> 176 <HeadingText 177 className=\"ErrorState-headingText\" 178 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 179 type={HeadingText.TYPE.HEADING_3} 180 > 181 Oops! Something went wrong. 182 </HeadingText> 183 </CardBody> 184 </Card> 185 ); visualizations/radar-or-treemap/index.js Copy Now, you can use Treemap in your visualization component. Step 2 of 3 In render(), add a Treemap component: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 85 const nrqlQueryPropsAvailable = 86 nrqlQueries && 87 nrqlQueries[0] && 88 nrqlQueries[0].accountId && 89 nrqlQueries[0].query; 90 91 if (!nrqlQueryPropsAvailable) { 92 return <EmptyState />; 93 } 94 95 return ( 96 <AutoSizer> 97 {({width, height}) => ( 98 <NrqlQuery 99 query={nrqlQueries[0].query} 100 accountId={parseInt(nrqlQueries[0].accountId)} 101 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 102 > 103 {({data, loading, error}) => { 104 if (loading) { 105 return <Spinner />; 106 } 107 108 if (error) { 109 return <ErrorState />; 110 } 111 112 const transformedData = this.transformData(data); 113 114 return ( 115 <React.Fragment> 116 <SegmentedControl 117 onChange={this.updateSelectedChart} 118 > 119 <SegmentedControlItem 120 value={CHART_TYPES.Radar} 121 label=\"Radar chart\" 122 /> 123 <SegmentedControlItem 124 value={CHART_TYPES.Treemap} 125 label=\"Treemap chart\" 126 /> 127 </SegmentedControl> 128 <RadarChart 129 width={width} 130 height={height} 131 data={transformedData} 132 > 133 <PolarGrid /> 134 <PolarAngleAxis dataKey=\"name\" /> 135 <PolarRadiusAxis tickFormatter={this.formatTick} /> 136 <Radar 137 dataKey=\"value\" 138 stroke={stroke || '#51C9B7'} 139 fill={fill || '#51C9B7'} 140 fillOpacity={0.6} 141 /> 142 </RadarChart> 143 <Treemap 144 width={width} 145 height={height} 146 data={transformedData} 147 dataKey=\"value\" 148 ratio={4 / 3} 149 stroke={stroke || '#000000'} 150 fill={fill || '#51C9B7'} 151 /> 152 </React.Fragment> 153 ); 154 }} 155 </NrqlQuery> 156 )} 157 </AutoSizer> 158 ); 159 } 160 } 161 162 const EmptyState = () => ( 163 <Card className=\"EmptyState\"> 164 <CardBody className=\"EmptyState-cardBody\"> 165 <HeadingText 166 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 167 type={HeadingText.TYPE.HEADING_3} 168 > 169 Please provide at least one NRQL query & account ID pair 170 </HeadingText> 171 <HeadingText 172 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 173 type={HeadingText.TYPE.HEADING_4} 174 > 175 An example NRQL query you can try is: 176 </HeadingText> 177 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 178 </CardBody> 179 </Card> 180 ); 181 182 const ErrorState = () => ( 183 <Card className=\"ErrorState\"> 184 <CardBody className=\"ErrorState-cardBody\"> 185 <HeadingText 186 className=\"ErrorState-headingText\" 187 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 188 type={HeadingText.TYPE.HEADING_3} 189 > 190 Oops! Something went wrong. 191 </HeadingText> 192 </CardBody> 193 </Card> 194 ); visualizations/radar-or-treemap/index.js Copy Here, you've defined a new Treemap component with some props, including height, width, fill, and stroke. Step 3 of 3 With your Nerdpack served locally, view your visualization. The SegmentedControl and RadarChart are at the top of the view, but if you scroll down, you'll see your new Treemap: Switch between charts with your component's state Use state.selectedChart to determine which chart to show: the RadarChart or the Treemap. Step 1 of 1 Destructure this.state to access selectedChart as a separate constant. Then, compare selectedChart to CHART_TYPES.Radar. If they are the same, render a RadarChart. Otherwise, render a Treemap: index.js 1 import React from 'react'; 2 import PropTypes from 'prop-types'; 3 import { 4 Radar, 5 RadarChart, 6 PolarGrid, 7 PolarAngleAxis, 8 PolarRadiusAxis, 9 Treemap, 10 } from 'recharts'; 11 import { 12 AutoSizer, 13 Card, 14 CardBody, 15 HeadingText, 16 NrqlQuery, 17 SegmentedControl, 18 SegmentedControlItem, 19 Spinner, 20 } from 'nr1'; 21 22 const CHART_TYPES = { 23 'Radar': 'radar', 24 'Treemap': 'treemap' 25 } 26 27 export default class RadarOrTreemapVisualization extends React.Component { 28 // Custom props you wish to be configurable in the UI must also be defined in 29 // the nr1.json file for the visualization. See docs for more details. 30 static propTypes = { 31 /** 32 * A fill color to override the default fill color. This is an example of 33 * a custom chart configuration. 34 */ 35 fill: PropTypes.string, 36 37 /** 38 * A stroke color to override the default stroke color. This is an example of 39 * a custom chart configuration. 40 */ 41 stroke: PropTypes.string, 42 /** 43 * An array of objects consisting of a nrql `query` and `accountId`. 44 * This should be a standard prop for any NRQL based visualizations. 45 */ 46 nrqlQueries: PropTypes.arrayOf( 47 PropTypes.shape({ 48 accountId: PropTypes.number, 49 query: PropTypes.string, 50 }) 51 ), 52 }; 53 54 state = { 55 selectedChart: CHART_TYPES.Radar, 56 }; 57 58 /** 59 * Restructure the data for a non-time-series, facet-based NRQL query into a 60 * form accepted by the Recharts library's RadarChart. 61 * (https://recharts.org/api/RadarChart). 62 */ 63 transformData = (rawData) => { 64 return rawData.map((entry) => ({ 65 name: entry.metadata.name, 66 // Only grabbing the first data value because this is not time-series data. 67 value: entry.data[0].y, 68 })); 69 }; 70 71 /** 72 * Format the given axis tick's numeric value into a string for display. 73 */ 74 formatTick = (value) => { 75 return value.toLocaleString(); 76 }; 77 78 updateSelectedChart = (evt, value) => { 79 this.setState({ selectedChart: value }) 80 }; 81 82 render() { 83 const {nrqlQueries, stroke, fill} = this.props; 84 const {selectedChart} = this.state; 85 86 const nrqlQueryPropsAvailable = 87 nrqlQueries && 88 nrqlQueries[0] && 89 nrqlQueries[0].accountId && 90 nrqlQueries[0].query; 91 92 if (!nrqlQueryPropsAvailable) { 93 return <EmptyState />; 94 } 95 96 return ( 97 <AutoSizer> 98 {({width, height}) => ( 99 <NrqlQuery 100 query={nrqlQueries[0].query} 101 accountId={parseInt(nrqlQueries[0].accountId)} 102 pollInterval={NrqlQuery.AUTO_POLL_INTERVAL} 103 > 104 {({data, loading, error}) => { 105 if (loading) { 106 return <Spinner />; 107 } 108 109 if (error) { 110 return <ErrorState />; 111 } 112 113 const transformedData = this.transformData(data); 114 115 return ( 116 <React.Fragment> 117 <SegmentedControl 118 onChange={this.updateSelectedChart} 119 > 120 <SegmentedControlItem 121 value={CHART_TYPES.Radar} 122 label=\"Radar chart\" 123 /> 124 <SegmentedControlItem 125 value={CHART_TYPES.Treemap} 126 label=\"Treemap chart\" 127 /> 128 </SegmentedControl> 129 {selectedChart === CHART_TYPES.Radar ? ( 130 <RadarChart 131 width={width} 132 height={height} 133 data={transformedData} 134 > 135 <PolarGrid /> 136 <PolarAngleAxis dataKey=\"name\" /> 137 <PolarRadiusAxis tickFormatter={this.formatTick} /> 138 <Radar 139 dataKey=\"value\" 140 stroke={stroke || '#51C9B7'} 141 fill={fill || '#51C9B7'} 142 fillOpacity={0.6} 143 /> 144 </RadarChart> 145 ) : ( 146 <Treemap 147 width={width} 148 height={height} 149 data={transformedData} 150 dataKey=\"value\" 151 ratio={4 / 3} 152 stroke={stroke || '#000000'} 153 fill={fill || '#51C9B7'} 154 /> 155 )} 156 </React.Fragment> 157 ); 158 }} 159 </NrqlQuery> 160 )} 161 </AutoSizer> 162 ); 163 } 164 } 165 166 const EmptyState = () => ( 167 <Card className=\"EmptyState\"> 168 <CardBody className=\"EmptyState-cardBody\"> 169 <HeadingText 170 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 171 type={HeadingText.TYPE.HEADING_3} 172 > 173 Please provide at least one NRQL query & account ID pair 174 </HeadingText> 175 <HeadingText 176 spacingType={[HeadingText.SPACING_TYPE.MEDIUM]} 177 type={HeadingText.TYPE.HEADING_4} 178 > 179 An example NRQL query you can try is: 180 </HeadingText> 181 <code>FROM NrUsage SELECT sum(usage) FACET metric SINCE 1 week ago</code> 182 </CardBody> 183 </Card> 184 ); 185 186 const ErrorState = () => ( 187 <Card className=\"ErrorState\"> 188 <CardBody className=\"ErrorState-cardBody\"> 189 <HeadingText 190 className=\"ErrorState-headingText\" 191 spacingType={[HeadingText.SPACING_TYPE.LARGE]} 192 type={HeadingText.TYPE.HEADING_3} 193 > 194 Oops! Something went wrong. 195 </HeadingText> 196 </CardBody> 197 </Card> 198 ); visualizations/radar-or-treemap/index.js Copy Here, you used a ternary expression to render a RadarChart or a Treemap. The rendered chart is determined by the value of selectedChart. With your Nerdpack served locally, view your visualization. Select Radar chart from the SegmentedControl: Select Treemap chart from the SegmentedControl: Summary Congratulations! In this lesson, you learned how to: Customize your visualization using New Relic One SDK components Add a new chart type to your visualization Create a user interaction in your visualization Course This lesson is part of a course that teaches you how to build a custom visualization in the New Relic One platform. When you're ready, continue on to the next lesson: Customize visualizations with configuration.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 376.53275,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Switch between <em>charts</em> with your component&#x27;s state",
        "body": " spacing<em>Type</em>={[HeadingText.SPACING_<em>TYPE</em>.LARGE]} 147 <em>type</em>={HeadingText.<em>TYPE</em>.HEADING_3} 148 &gt; 149 Oops! Something went wrong. 150 &lt;&#x2F;HeadingText&gt; 151 &lt;&#x2F;CardBody&gt; 152 &lt;&#x2F;Card&gt; 153 ); visualizations&#x2F;radar-or-treemap&#x2F;index.js Copy <em>CHART_TYPES</em> enumerates the two <em>chart</em> <em>types</em> you&#x27;ll alternate between in your"
      },
      "id": "6091fa3b196a679beed52a6b"
    }
  ],
  "/docs/query-your-data/explore-query-data/use-charts/use-your-charts": [
    {
      "sections": [
        "Filter New Relic One dashboards by facets",
        "Why use facet filtering?",
        "Requirements",
        "Example use of facet filtering",
        "Facet linking with the FACET CASES clause"
      ],
      "title": "Filter New Relic One dashboards by facets",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "107c9537e64d2568fcba3ec6a717b84684c24a41",
      "image": "https://docs.newrelic.com/static/8190f8c9ef92e92ca0996c32b91b53a5/c1b63/facetfiltering01bis.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/filter-new-relic-one-dashboards-facets/",
      "published_at": "2021-12-19T22:50:55Z",
      "updated_at": "2021-12-10T08:27:46Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can filter your New Relic One dashboards by faceted attributes, making your dashboards more interactive and easy to use. Why use facet filtering? In New Relic One dashboards, for NRQL queries containing a FACET clause and meeting other chart-type requirements, you can set up the faceted attributes to filter the current dashboard or a related, linked dashboard. By letting you quickly filter your dashboards, and link to pre-filtered dashboards, your dashboards are more interactive and easy to use. This feature is available when adding a new chart to a dashboard or when editing a chart on an existing dashboard. To see this feature in action, see the example use case. Requirements Requirements to use this feature: Must be in New Relic One dashboards. Will not work on a standalone chart in the query builder. NRQL query must contain a FACET clause. Available only for bar charts, heat maps, pie charts, and tables. Example use of facet filtering Let's say you create the following facet-containing NRQL query for an existing dashboard in New Relic One: one.newrelic.com > Dashboards: For queries containing a FACET clause and meeting chart-type requirements, you can set those attributes to be used as an easy dashboard filter. You can set the attribute to filter the current dashboard you're on, or filter a related dashboard that you select. If you select Filter the current dashboard, that chart will be used to filter the current dashboard by the available userAgentName attributes. Here's a view of selecting one of those attributes to filter that dashboard. Notice that the chosen attribute appears as a filter in the search bar at the top. one.newrelic.com > Dashboards: When you select an attribute you've set up for facet filtering, it filters the current dashboard. For more about this feature, see the Explorers Hub post on facet filtering. Facet linking with the FACET CASES clause FACET CASES is a NRQL function that allows to group facets based on conditions. We support multiple cases in the same facet. Let's say you want to query some data and put the responses into mnemonic categories for a dashboard or report. This syntax will allow you to query based on transaction duration and put the results into two categories: ACCEPTABLE and UNACCEPTABLE. This can be really useful for making dashboards more human readable and actionable. SELECT filter(count(*), WHERE duration > 1) as 'UNACCEPTABLE', filter(count(*), WHERE duration <=1) as 'ACCEPTABLE' FROM Transaction FACET appName LIMIT 5 since 5 minutes ago Copy By using FACET CASES, we can more efficiently use multiple complex conditions to generate a set of custom facets. Building on the previous example, let's say we want to include a compound condition which excludes errors from our duration data and adds them into a third category: SELECT count(*) FROM Transaction FACET CASES (where duration > 1 and error is NULL as 'UNACCEPTABLE', where duration <= 1 and error is NULL as 'ACCEPTABLE', where error is not NULL as 'ERROR') since 5 minutes ago Copy Then, using facet linking, you can filter your dashboards by those facets.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 237.204,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Why <em>use</em> facet filtering?",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": " on an existing dashboard. To see this feature in action, see the example <em>use</em> case. Requirements Requirements to <em>use</em> this feature: Must be in New Relic One dashboards. Will not work on a standalone <em>chart</em> in the <em>query</em> builder. NRQL <em>query</em> must contain a FACET clause. Available only for bar <em>charts</em>, heat maps"
      },
      "id": "60445d1e28ccbc23082c60af"
    },
    {
      "sections": [
        "Add custom visualizations to your dashboards",
        "Add a visualization to a dashboard",
        "Manage your dashboard visualizations"
      ],
      "title": "Add custom visualizations to your dashboards",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "d6c9973ef2c2547a99539d1da027b54db23af42c",
      "image": "https://docs.newrelic.com/static/5f7bd9c6a2a163d1f19c5c8b0d844d2f/c1b63/dashboard_viz.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/add-custom-visualizations-your-dashboards/",
      "published_at": "2021-12-19T20:57:38Z",
      "updated_at": "2021-11-25T05:12:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can build your own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any data source. This visualization shows the number of people in each city who are viewing New Relic within an organization. The visualization was created using the New Relic One CLI and Treemap from the Recharts library. If you have full platform user permissions, which include the Nerdpack manager role, you can add a visualization to a dashboard as described in the following section. The process for creating a visualization is covered in the guide, Build a custom visualization for dashboards. Add a visualization to a dashboard You can add a visualization to a new or existing dashboard. From New Relic, in the top right, click the Apps button, and then on the Apps page, click Custom Visualizations. Hint: if you don't see the Custom Visualizations tile, use the search to locate it. In Custom Visualizations, select the visualization you want to add to a dashboard and then enable it. If there are configuration options, fill those in. The visualization will update with your changes. Click Add to dashboard and then select a dashboard from the list of available dashboards, or select New dashboard. If you decide to create a new dashboard, select the account where you want to run the dashboard, and give the dashboard a name. Click Add to dashboard, then click the link to your dashboard to see the custom visualization. Manage your dashboard visualizations Deleting: To remove a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Delete. Editing: To edit a visualization from a dashboard, click the ellipses button in the right-hand corner of the visualization and click Edit.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 200.93134,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom visualizations to <em>your</em> dashboards",
        "sections": "Add custom visualizations to <em>your</em> dashboards",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "You can build <em>your</em> own visualizations and add them to a dashboard. This gives you great flexibility around what you display on dashboards, from a company logo to custom queries from any <em>data</em> source. This visualization shows the number of people in each city who are viewing New Relic within"
      },
      "id": "603ec4e628ccbc9409eba7ab"
    },
    {
      "sections": [
        "Manage your dashboard",
        "Customize your dashboard",
        "Tip",
        "Edit your dashboard",
        "Settings menu",
        "TV mode",
        "Dark mode",
        "Copy your dashboard as JSON",
        "Export your dashboard",
        "Duplicate your dashboard",
        "Add new content to your dashboard",
        "Add custom content using the markdown editor",
        "Organize your dashboards with pages",
        "Add and edit pages to a dashboard",
        "Manage your charts and markdown content",
        "Important",
        "Filter and refine your charts",
        "Filter using the chart legend",
        "Filter dashboards using facets",
        "Use the time picker to adjust time settings",
        "Export and share your data"
      ],
      "title": "Manage your dashboard",
      "type": "docs",
      "tags": [
        "Query your data",
        "Explore and query data",
        "Dashboards"
      ],
      "external_id": "dce15c906d7868f83813516908f3490e5e3be78f",
      "image": "https://docs.newrelic.com/static/c0ad91accb3281bf160b50ef505530de/c1b63/dashboards_menu_20210623.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/manage-your-dashboard/",
      "published_at": "2021-12-19T20:57:39Z",
      "updated_at": "2021-09-14T18:19:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Access any of your New Relic One dashboards to create or manage your charts directly from the chart menu, customize your dashboard's layout, adjust display modes, or export your data. Once you have customized your dashboard and built your charts, use our advanced visualization features and tools for data exploration to correlate and analyze your data. Customize your dashboard Dashboards are highly flexible: you can tailor your dashboard layout and arrange chart sizes to optimize how you see your data. Tip Click the icon to access the See metadata and manage tags modal. There you can see the dashboard's GUID, account ID, and App ID, and manage all the tags that have been added to the dashboard. Dashboards features include: Edit your dashboard Use the edit button to: Copy the dashboard's permalink. Rename your dashboard. Names are searchable, so we recommend giving it a meaningful name. Create new content by clicking the Add widget button. Add a new chart using the query builder, or add text, images, or links using our markdown editor. Resize and rearrange charts. You can move any chart and put it anywhere in the dashboard so the layout you set fits your preferences: place your more relevant charts on top, or drop less used charts in a corner. You can set up to 12 columns of charts. Settings menu Use the settings menu on the upper right corner: To change the name of the dashboard. Names are searchable, so we recommend giving it a meaningful name that will help you locate your dashboard easily. To modify the dashboard's permissions. At the settings menu you can also see when the dashboard was created and the account it belongs to. These values cannot be modified. TV mode You can enable a full-screen TV mode that optimizes the dashboard for display on a television screen. There are two ways to turn on TV mode: When viewing a dashboard in New Relic One, select the icon at the top right. Add this parameter to a dashboard page URL: &platform[tvMode]=true To configure TV mode, from a dashboard, select the icon. Options include: Dashboard name display. Turning off the dashboard name gives the dashboard charts more space on the screen. Page cycle. For dashboards with multiple pages, this automatically cycles from page to page. Dark mode High-contrast mode is available in dashboards. Select the icon from the upper right menu bar. Copy your dashboard as JSON You can copy your dashboard as JSON and add it to the clipboard by clicking on the < / > icon on the right corner. Export your dashboard You can export your dashboard as a pdf file clicking the icon. Duplicate your dashboard You can duplicate your dashboard clicking the duplicate icon regardless of your permission levels. The dashboard is automatically copied and the duplicate is added to the index. The duplicate has Public - Read and write permissions. Access the new, duplicated dashboard by clicking on the message that pops up on your screen. The duplicated dashboard is named like the original dashboard followed by the word “copy”. For example, if you duplicate a dashboard named This is my dashboard, the duplicate is called This is my dashboard copy. You can change the name when you duplicate it. You can edit the name and other properties of the dashboard, such as permissions, any time. Tip You can use the search feature at any time to search data across New Relic One. Add new content to your dashboard There are multiple ways to add new content to your dashboard: From the data explorer and query builder features. Use the + Add to your dashboard button (accessible from the main dashboard page or in the edit mode) to access the query builder, or to add content (such as text, links, or images) using our Markdown editor. Copy an existing chart from any dashboard. If you experience issues adding new content, check our error messages. Add custom content using the markdown editor The Markdown editor contains a Markdown pane, where you enter your content, as well as a Preview pane, where you can view it. For more information about Markdown syntax options, see the Commonmark website. You can also edit existing content by clicking the ellipses icon on any markdown widget and selecting Edit. Organize your dashboards with pages You can use multiple pages to organize your dashboard data in different views. When you add more pages to that dashboard, you can access these pages using the tabs at the top of the dashboard UI. one.newrelic.com > Dashboards: This is an example of a dashboard in New Relic One with multiple pages, represented by the tabs at the top of the dashboard. You can add pages to dashboards, copy existing pages, and drag and drop the page tabs to new positions. You can use this feature to group together related dashboard views. This is valuable when you're aggregating a lot of data and charts related to a specific project, team, or subject. For example, a mobile app team might build a dashboard focused on app performance by country. The first dashboard page might be an overview of performance across all countries, with other pages focused on specific countries. We offer other features to connect dashboards: Create widgets containing markdown text to add direct links to specific UI pages or dashboards. Use facet filtering to create links that automatically link to and filter other dashboards. Use the dashboard search to find similarly named dashboards. To take advantage of this, you can add team- or project-specific words/phrases to dashboard names. In New Relic Insights, this feature was called data apps. For more about switching from Insights to New Relic One, see our transition guide. Add and edit pages to a dashboard To add or edit a page in a dashboard: From a new or existing dashboard, enter edit mode by selecting the icon. Add a new page: Select Add a page to add a blank page. Clone an existing page by clicking the dropdown next to a dashboard name, and selecting Duplicate. While in edit mode, you can add widgets to the new page, drag and drop page tabs to new locations, and do other dashboard editing tasks. When finished, select Done editing. Manage your charts and markdown content From any markdown element, access the menu on the upper right corner to edit or delete it. From any chart, access the chart action menu on the upper right corner to: Expand your chart to full screen. Share your chart as an image or with a link. Copy the chart to any dashboard. For table charts only, export as a .csv file. You can import this file into other apps like Microsoft Excel or Google Sheets to do further analysis. Create an alert condition. Open the NRQL console to see or edit the query associated to the chart. Duplicate the chart. Delete the chart. Important You cannot edit the query of a chart if you have Read only permissions to the dashboard. Learn more about how to use your charts. Filter and refine your charts You can narrow down the information on display using the filtering function, which is a visual representation of query conditions: Use the filter bar to select the values or attributes you want to see, and remove the rest of the elements from the charts. Open the advanced filter bar to access the boolean operators (such as =, !=, CONTAINS, EXCLUDES, etc.) and add compound and complex conditions for filtering data. After applying the filter, your dashboard will only show the data associated to the elements you selected. A small counter indicates how many filters are being applied at a time. To return to the default view, click on the small cross by the filter to remove it. Filter using the chart legend Click on a legend in any chart with legends to see that series only and remove the rest of them from the chart. This helps you isolate the data you want to analyze. Use CMD (in a Mac) or CTRL (in Windows) for the opposite behavior: removing the selected series and keeping the rest. Filter dashboards using facets If a chart's NRQL query contains a FACET clause, you can use the faceted attributes to filter the current dashboard or another related dashboard. For details, see Filter by facets. Use the time picker to adjust time settings By default, each chart in the dashboard will show data for the time period specified when they were created in the query builder. However, you can use the time picker to change the time range of the data on display and set the same range for all charts. This is particularly useful while troubleshooting incidents, if you need to narrow down your data to observe what happened in a specific time period. The refresh rate depends on the duration of the time window you are viewing. For more information and examples, see Chart refresh intervals. To change the time range: Select one of the available options from the dropdown menu (ranging from Last 30 minutes to Last 7 days). Customize the time range with specific start and end timestamps using the custom menu. Important In dashboards, unlike Insights, the time zone is independent from your laptop's time. You can set the time zone you want to use in your user preferences, easily accessible from the custom menu in the time picker. Export and share your data It is very easy to export dashboard and chart data and share it within your company and beyond: You can export any dashboard as a PDF file, using the Export dashboard as PDF button located in the upper right menu bar. You can also share your charts either as a PNG image or as a link. Go to the chart menu and select either the Get as image or Get chart link options.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 182.09174,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Manage <em>your</em> dashboard",
        "sections": "Manage <em>your</em> <em>charts</em> <em>and</em> markdown content",
        "tags": "<em>Explore</em> <em>and</em> <em>query</em> <em>data</em>",
        "body": "Access any of <em>your</em> New Relic One dashboards to create or manage <em>your</em> <em>charts</em> directly from the <em>chart</em> menu, customize <em>your</em> dashboard&#x27;s layout, adjust display modes, or export <em>your</em> <em>data</em>. Once you have customized <em>your</em> dashboard and built <em>your</em> <em>charts</em>, <em>use</em> our advanced visualization features and tools"
      },
      "id": "603ec235196a67206fa83dde"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 394.13843,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use basic math operators with SELECT",
        "Use advanced math operators with SELECT",
        "abs",
        "clamp_max, clamp_min",
        "exp",
        "Logarithmic functions: ln, log, log2, log10",
        "pow",
        "pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n)",
        "Rounding functions: round, floor, ceil",
        "sqrt",
        "Results with STRING or FLOAT",
        "Tip"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/8bfef938a82b9feb0fc18864699f176a/c1b63/clamp.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-12-19T20:24:55Z",
      "updated_at": "2021-11-13T23:43:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL supports the use of basic and advanced mathematical operators within a SELECT clause. You can apply mathematical calculations on both individual attributes and also the results of aggregator functions. Use basic math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Use advanced math operators with SELECT NRQL also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process data to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). Logarithmic functions: ln, log, log2, log10 These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting no value back from your query. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2 and abs(-4) = 4. Rounding functions: round, floor, ceil These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) (short for \"ceiling\") returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: pow(n, m) computes n raised to the power m. (for example, n * n * ... * n, with m copies of n) Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.78351,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": " operators with SELECT <em>NRQL</em> also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process <em>data</em> to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-12-19T20:59:14Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.92842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 394.13818,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> metric <em>data</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.10193,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": ", clauses, and functions. Ready to <em>get</em> <em>started</em>? If you haven&#x27;t already, be sure to sign up for a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-12-19T20:59:14Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.92842,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions": [
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 242.12907,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": ", clauses, and functions. Ready to <em>get</em> <em>started</em>? If you haven&#x27;t already, be sure to sign up for a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. What is <em>NRQL</em>? <em>NRQL</em> is <em>New</em> <em>Relic</em>&#x27;s SQL-like <em>query</em> <em>language</em>. You can use <em>NRQL</em> to retrieve detailed <em>New</em> <em>Relic</em> <em>data</em> and <em>get</em> insight into <em>your</em> applications, hosts"
      },
      "id": "60445a0e196a67cb09960f6e"
    },
    {
      "sections": [
        "NRQL math using SELECT",
        "Use basic math operators with SELECT",
        "Use advanced math operators with SELECT",
        "abs",
        "clamp_max, clamp_min",
        "exp",
        "Logarithmic functions: ln, log, log2, log10",
        "pow",
        "pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n)",
        "Rounding functions: round, floor, ceil",
        "sqrt",
        "Results with STRING or FLOAT",
        "Tip"
      ],
      "title": "NRQL math using SELECT",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "99bfd8fb7663a1c589160ea026ff585acf9d4023",
      "image": "https://docs.newrelic.com/static/8bfef938a82b9feb0fc18864699f176a/c1b63/clamp.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-math-using-select/",
      "published_at": "2021-12-19T20:24:55Z",
      "updated_at": "2021-11-13T23:43:31Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL supports the use of basic and advanced mathematical operators within a SELECT clause. You can apply mathematical calculations on both individual attributes and also the results of aggregator functions. Use basic math operators with SELECT To use basic math functions in NRQL, include operators within the SELECT clause: Addition: + Subtraction: - Multiplication: * Division: / Here are some examples: SELECT duration-databaseDuration FROM Transaction Copy SELECT count(*)/uniqueCount(session) FROM PageView Copy SELECT average(duration-databaseDuration) FROM Transaction Copy Use advanced math operators with SELECT NRQL also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process data to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2, and abs(-4) = 4. clamp_max, clamp_min The clamping functions impose an upper or lower bound on values. For example, clamp_max(duration, 10) returns the duration, unless it exceeds 10, in which case 10 is returned. Similarly clamp_min(duration, 1) will not return any value lower than 1. The following chart shows the result of clamping both min and max to keep the value in the range 70-90. Sample graph showing raw data with clamp function applied. exp Computes the natural exponential function of the argument: exp(n) = pow(e, n). Logarithmic functions: ln, log, log2, log10 These functions compute the logarithm of the argument for various bases. ln(n) computes the natural logarithm: the logarithm base e. log2(n) computes the logarithm base 2. log10(n) computes the logarithm base 10. log(n, b) allows logarithms to be computed with an arbitrary base b. All logarithms satisfy the identity: log(pow(b, n), b) = n. Note that log(0) is undefined, for all bases. Be aware that if you take the logarithm of something that might be zero, you may end up getting no value back from your query. pow pow(n, m) computes n raised to the power m. (I.e. n * n * ... * n, with m copies of n) abs(n) returns the absolute value of n. For non-negative n it returns n, and for negative n it returns the positive number -n. For example abs(2) = 2 and abs(-4) = 4. Rounding functions: round, floor, ceil These three functions force decimal numbers to one of the neighboring integers. floor(n) returns the closest integer less than or equal to n. ceil(n) (short for \"ceiling\") returns the closest integer greater than or equal to n. round(n) returns the closest integer to n in either direction. Sample graph showing raw data, with floor, round, and ceiling functions applied. sqrt sqrt(n) returns the square root of n, that is, the number such that sqrt(n) * sqrt(n) = n. Results with STRING or FLOAT Here is how NRQL handles strings present in math calculations: pow(n, m) computes n raised to the power m. (for example, n * n * ... * n, with m copies of n) Examples: sum(1+STRING) = 0 sum(1+MIXED) = skips records where MIXED is a string average(1+STRING) = 0 average(1+MIXED) = skips records where MIXED is a string NULL and zero both appear as 0 in the dashboard. To override NULL values with another numeric value, use the syntax: SELECT average(purchasePrice OR 0) Copy This will replace NULL values with 0 or any number specified. Tip This can also be used to test whether something returns NULL or zero. (zero) OR 1 returns 0. (NULL) OR 1 returns 1.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 229.80925,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> math using SELECT",
        "sections": "<em>NRQL</em> math using SELECT",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": " operators with SELECT <em>NRQL</em> also includes some advanced mathematical capabilities that can be used for complex calculations. This is helpful if you want to process <em>data</em> to display it more effectively in the UI, or make statistical or psychometric calculations on queried results in a single step. abs"
      },
      "id": "603ec31864441f942b4e884c"
    },
    {
      "sections": [
        "Query infrastructure dimensional metrics with NRQL",
        "BETA FEATURE",
        "Why it matters",
        "Get started",
        "Where and how to query dimensional metrics",
        "Naming conventions for metrics and attributes",
        "Examples",
        "AWS EBS query example",
        "Azure Service bus query example",
        "Azure functions query example",
        "Azure VMs query example",
        "NGINX query example",
        "MySQL query example",
        "Known limitations"
      ],
      "title": "Query infrastructure dimensional metrics with NRQL",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "a131af1f3655ef8b78acfccf8be619c43cb2c51e",
      "image": "https://docs.newrelic.com/static/916ce526afc3e8c7d9ea1325f1fdb980/1b853/naming-convention.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql/",
      "published_at": "2021-12-19T20:59:14Z",
      "updated_at": "2021-09-14T20:46:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric data. All infrastructure metrics are stored as event data in New Relic, but you can also query them through dimensional metrics. In this page you can learn: The benefits of dimensional metrics. A few examples on how and where to use them. Known issues. Why it matters At New Relic we report metrics in several ways, including dimensional metrics, which are used by our metric API, Telemetry SDK, some open-source integrations, and our infrastructure services. This type of metric enables you to: Enjoy an improved query experience for Infrastructure data. Discover all your metrics in one place. Tap into more metric sources, such as Prometheus. For example, the query to get the maximum duration of your Lambda functions is simplified: Query with samples FROM ServerlessSample SELECT max(provider.duration.Maximum) WHERE provider = 'LambdaFunction' Copy Query with metrics FROM Metric SELECT max(aws.lambda.function.duration) Copy Get started No agent or integration updates are required to use these metrics. NRQL alerting based on dimensional metrics is also supported, except for data coming from cloud integrations (that is metrics from AWS polling integrations, GCP, and Azure). AWS CloudWatch Metric Streams metrics are ingested as dimensional metrics and NRQL alerts are recommended. Where and how to query dimensional metrics All current NRQL query features are supported. Queries can use WHERE, FACET, and time selection functions such as SINCE, UNTIL, and COMPARE WITH. The query builder in New Relic One supports metrics in both simple and advanced (NRQL) mode. Naming conventions for metrics and attributes All metric names and attributes for dimensional metrics follow the same naming convention in order to make them easy to find and use. Metric and attribute names are namespaced with dots: for example, the host. prefix is used for host metrics, the k8s. prefix is used for Kubernetes metrics, and aws. is used for AWS metrics. The graphic below shows how a ProcessSample that contains three metrics (cpuPercent, ioTotalReadBytes, and ioTotalWriteBytes) is split into three separate metrics. Note the updated naming of the metrics and the attributes. Dimensional metrics naming convention Examples Here are some examples of NQRL queries with and without dimensional metrics: AWS EBS query example Get the total write time by EBS Volume. Query with samples FROM BlockDeviceSample SELECT sum('provider.volumeTotalWriteTime.Sum') WHERE provider = 'EbsVolume' FACET entityName Copy Query with metrics FROM Metric SELECT sum(aws.ebs.volume.TotalWriteTime) FACET entity.name Copy Azure Service bus query example Maximum number of messages in an Azure Service Bus topic by resource group. Query with samples FROM AzureServiceBusTopicSample SELECT max(activeMessages.Maximum) FACET resourceGroupName Copy Query with metrics FROM Metric SELECT max(azure.servicebus.topic.activeMessages) FACET azure.resourceGroup Copy Azure functions query example Number of function executions Azure Functions over the past 6 hours by region over time. Query with samples FROM AzureFunctionsAppSample SELECT sum(functionExecutionCount.Total) FACET regionName TIMESERIES SINCE 6 hours ago Copy Query with metrics FROM Metric SELECT sum(azure.functions.app.functionExecutionCount) FACET azure.region TIMESERIES SINCE 6 hours ago Copy Azure VMs query example Compare the number of Azure VMs over the past thirty minutes with the same time a week ago. Query with samples FROM AzureVirtualMachineScaleSetSample SELECT uniqueCount(vMName) FACET name SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy Query with metrics FROM Metric SELECT uniqueCount(azure.vms.vmName) FACET azure.resourceName WHERE azure.resourceType='Microsoft.Compute/virtualMachineScaleSets' SINCE 30 MINUTES AGO COMPARE WITH 1 WEEK AGO Copy NGINX query example The average number of NGINX requests per second over time. Query with samples FROM NginxSample SELECT average(net.requestsPerSecond) TIMESERIES Copy Query with metrics FROM Metric SELECT average(nginx.server.net.requestsPerSecond) TIMESERIES Copy MySQL query example The maximum number of used MySQL connections. Query with samples FROM MysqlSample SELECT max(net.maxUsedConnections) Copy Query with metrics FROM Metric SELECT max(mysql.node.net.maxUsedConnections) Copy Known limitations Metric queries with * do not return Infrastructure sample data (for example, SELECT * FROM Metric). In order to select attributes starting with tags. a metric name has to be provided. For example, SELECT uniques(tags.environment) FROM Metric WHERE metricName='aws.lambda.function.duration' does not work without the WHERE clause. Results may not be complete if the selection criteria matches too many samples. For example, SELECT uniqueCount(entity.guid) FROM Metric maps to all Infrastructure samples, and may return incomplete results. Initially there is no support for the newly introduced metric wildcarding feature (for example, SELECT average(host.swap%Bytes) FROM Metric).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 145.77425,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Query</em> infrastructure dimensional metrics with <em>NRQL</em>",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "BETA FEATURE This feature is currently in beta. Dimensional metrics are an industry standard for storing and querying metric <em>data</em>. All infrastructure metrics are stored as event <em>data</em> in <em>New</em> <em>Relic</em>, but you can also <em>query</em> them through dimensional metrics. In this page you can learn: The benefits"
      },
      "id": "603e95e8e7b9d286642a07fa"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/get-started/rate-limits-nrql-queries": [
    {
      "sections": [
        "NerdGraph tutorial: Query your data using NRQL",
        "Basic NRQL queries with NerdGraph",
        "Create embeddable charts",
        "Suggested facets",
        "Rules governing suggested facets",
        "Example of returning suggested attributes"
      ],
      "title": "NerdGraph tutorial: Query your data using NRQL",
      "type": "docs",
      "tags": [
        "APIs",
        "NerdGraph",
        "Examples"
      ],
      "external_id": "b56b0e93848c3830a3d0767278e844700c958531",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/nerdgraph/examples/nerdgraph-nrql-tutorial/",
      "published_at": "2021-12-19T15:41:51Z",
      "updated_at": "2021-11-06T05:45:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can use the New Relic NerdGraph GraphiQL explorer to make New Relic Query Language (NRQL) queries. To learn how to construct these queries and see responses, go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. This document explains some of the available functions for NRQL queries. NRQL queries made through NerdGraph are subject to NRQL Query Rate Limits. Basic NRQL queries with NerdGraph To make NRQL queries using NerdGraph: Go to the NerdGraph GraphiQL explorer at api.newrelic.com/graphiql. Pass the NRQL query as a string argument to the NRQL object, and include the results field in your NerdGraph query. For example, to get a count of all transaction events in the last hour, use the following query: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) FROM Transaction SINCE 1 HOUR AGO\") { results } } } } Copy This NerdGraph query example returns the following results: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \"results\": [ { \"count\": 1000 } ] } } } } } Copy The actual value of the count varies depending on your transaction data. Use the NerdGraph GraphiQL explorer to experiment with queries. Create embeddable charts In addition to returning raw data, you can fetch embeddable chart links for the data to use in an application. For example, instead of a single count of transaction, you can create a chart that illustrates a timeseries of bucketed counts over time. Add TIMESERIES to your query with embeddedChartUrl: { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) from Transaction TIMESERIES\") { embeddedChartUrl } } } } Copy This NerdGraph query example returns the URL for the chart in the following response: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \" embeddedChartUrl \": \"https://chart-embed.service.newrelic.com/charts/EMBEDDABLE-CHART-ID\" } } } } } Copy If you view the embedded chart URL using any standard HTTP client, it returns an image showing a visualization of the response to the query you submitted. These charts follow the same embedded chart rules as embedded charts that are created elsewhere. To change the style of the data visualization, pass a chartType argument to embeddedChartUrl. Suggested facets When using NerdGraph to explore your data, you can use the suggestedFacets field to return suggested attributes for use in faceted NRQL queries. Rules governing suggested facets Here are some of the rules that govern what attributes are suggested: Built-in suggestions. Each event type comes with its own set of recommended attributes. These are attributes chosen by New Relic for their importance and popularity. Usage-based suggestions. Some attribute suggestions are based on the queries that have been frequently used by your account. These suggestions can include custom attributes. Role restriction. Restricted users do not have access to account-related facet suggestions. To disable the use of account data for determining suggested queries, contact Support. Example of returning suggested attributes Here's an example of returning suggested attributes for faceting transaction counts. The response suggests the host attribute. Faceting by host can reveal that one host is servicing more requests than other hosts. { actor { account(id: YOUR_ACCOUNT_ID) { nrql(query: \"SELECT count(*) from Transaction TIMESERIES\") { suggestedFacets { attributes } } } } } Copy This NerdGraph query example returns a response similar to this: { \"data\": { \"actor\": { \"account\": { \"nrql\": { \" suggestedFacets \": [ \"attributes\": [\"host\"] ] } } } } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1314.958,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NerdGraph tutorial: <em>Query</em> your data using <em>NRQL</em>",
        "sections": "Basic <em>NRQL</em> <em>queries</em> with NerdGraph",
        "body": " <em>queries</em>. <em>NRQL</em> <em>queries</em> made through NerdGraph are subject to <em>NRQL</em> Query <em>Rate</em> <em>Limits</em>. Basic <em>NRQL</em> <em>queries</em> with NerdGraph To make <em>NRQL</em> <em>queries</em> using NerdGraph: Go to the NerdGraph GraphiQL explorer at api.newrelic.com&#x2F;graphiql. Pass the <em>NRQL</em> query as a string argument to the <em>NRQL</em> object, and include"
      },
      "id": "6044058c196a67976b960f3d"
    },
    {
      "sections": [
        "Translate PromQL queries to NRQL",
        "Tip",
        "Prometheus and New Relic metric types",
        "Mapping between NRQL and our PromQL-style queries",
        "PromQL-style query example",
        "NRQL query example",
        "Filter examples",
        "PromQL-style to NRQL query examples"
      ],
      "title": "Translate PromQL queries to NRQL",
      "type": "docs",
      "tags": [
        "Integrations",
        "Prometheus integrations",
        "View and query data"
      ],
      "external_id": "a6d9e2f685b835d6d540d1b4a1bc30a99ab3bd92",
      "image": "https://docs.newrelic.com/static/PROMQL-query-2-4f5bf0fc14fc06c4e85f7bf7c4937401.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/view-query-data/translate-promql-queries-nrql/",
      "published_at": "2021-12-20T04:23:56Z",
      "updated_at": "2021-12-20T04:23:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Do you have a PromQL query you’d like to convert to NRQL? This document provides examples that show you how to convert some common PromQL queries to NRQL queries. You can use our PromQL-style query language to explore your Prometheus OpenMetrics integration data along with other data sent to New Relic. Tip To run PromQL-style queries in New Relic One, go to the query builder advanced PromQL-style mode. Prometheus and New Relic metric types The different metric types supported by Prometheus and New Relic are related to each other: New Relic Prometheus Description Count Counter The Prometheus counter is a cumulative sum while the New Relic count is a delta sum. For example, if you see 2 requests in the first reporting period and 3 requests in the second reporting period. The Prometheus counter will report 2 and then 5, while the New Relic count will report 2 and then 3. Gauge Gauge A Prometheus gauge is similar to a New Relic gauge. Multiple counts Histogram Prometheus automatically maps a histogram to a set of counters. In New Relic, these counters should be changed to deltas and reported as counts. Gauges and counts Summary Prometheus represents a Summary with a given basename as the following time series: a basename_sum a basename_count and 0 or more of basename{quantile=\".xx\"...} metrics New Relic maps the _sum as a Summary, the _count as a Counter, and each quantile metric as a Gauge. Summary (No equivalent in Prometheus) New Relic has a distinct metric type called a summary that is different than the Prometheus summary. It is designed for reporting aggregated discrete events so that you can query the count, sum, min, max, and average values. Mapping between NRQL and our PromQL-style queries Tip To see how New Relic translates PromQL-style queries to NRQL, write a query in the query builder PromQL-style tab, then switch to the NRQL tab. This table shows the mapping between NRQL and our PromQL-style queries when exploring data. For more contextual information, see the examples. Description Mapping between NRQL and PromQL-style queries Search for attributes: Explore the attributes on the container_memory_usage_bytes metric. PromQL: container_memory_usage_bytes Copy NRQL: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy Find attribute's value: Explore the current value of the container_memory_usage_bytes metric for unique id attributes. PromQL: sum(container_memory_usage_bytes) by (id) Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy Visualize the attribute's value: Chart the value of the container_memory_usage_bytes metric with the given id attribute value. PromQL: container_memory_usage_bytes{id=\"/\"} Copy NRQL: FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = '/' TIMESERIES Copy PromQL-style query example 1. Start your query. When exploring your data for a particular metric in PromQL, such as memory by container usage in bytes, you can start with a query such as: container_memory_usage_bytes Copy This will chart all the unique metric timeseries for the input metric. 2. Filter the query results. Looking at the data, you can add more query parameters to filter down the number of metric timeseries. For example, if you only want timeseries where the id is /, the PromQL-style query will be: container_memory_usage_bytes{id=\"/\"} Copy PromQL-style example: To filter the data, run this PromQL-style query: container_memory_usage_bytes { id=\"/\". NRQL query example 1. Query available metrics. To explore your data, start by looking at all the available metrics. Use the following NRQL query: FROM Metric SELECT uniques(metricName) Copy 2. Find unique attributes. Once you have found the metric you want to review, such as container_memory_usage_bytes, you can find the unique attributes with the following query: FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes' Copy The results will show each available attribute key and the value type (string, boolean, or number). 3. Aggregate and chart the metrics. To chart metrics using NRQL, you first need an aggregation function. For example, you can use latest for gauges, sum for counts, and average for summaries. As the following chart shows, all the unique timeseries are aggregated into one unique timeseries by default: one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT keyset() WHERE metricName = 'container_memory_usage_bytes'. 4. View metrics by ID. To view the unique metric timeseries with various id values, run the following query: FROM Metric SELECT latest(container_memory_usage_bytes) FACET id Copy one.newrelic.com > Query your data: This example shows the data you see after running FROM Metric SELECT latest(container_memory_usage_bytes) FACET id. 5. Add the selected ID to the query. Next you can select an id value and put it in the NRQL where clause. FROM Metric SELECT latest(container_memory_usage_bytes) WHERE id = \"/\" timeseries Copy one.newrelic.com > Query your data: This example shows the data displayed after running From Metric select latest(container_memory_usage_bytes) where id = \"/\" timeseries. Filter examples Both our PromQL-style query language and NRQL provide syntax to filter down the number of unique metric timeseries. PromQL-style uses brackets to filter. NRQL uses a WHERE clause. Here are some example queries: Description PromQL-style and NRQL queries Select data with specific values. PromQL: go_memstats_heap_alloc_bytes{job=\"apiserver\", instance=\"1234\"}) Copy NRQL: To only select data with specific values in NRQL, use the WHERE clause with =. In this example, all data must have the selected value for job and handler. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE job = 'apiserver' AND instance = '1234' TIMESERIES Copy Select data with multiple values. PromQL: go_memstats_heap_alloc_bytes{environment=~\"staging|testing|development\",method!=\"GET\"} Copy NRQL: In NRQL use the in clause to select multiple values for an attribute and the != sign to select all values but the one listed. In this example, the environment can be staging, testing, or development, and the method cannot be GET. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHERE environment IN ('staging', 'testing', 'development') AND method != 'GET' TIMESERIES Copy Select data using partial string values. PromQL: go_memstats_heap_alloc_bytes{job=~\"api.*\"} Copy NRQL: In NRQL use the LIKE clause to match part of a string value. In this example, all data will be returned where the job attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE 'api%' TIMESERIES Copy PromQL-style to NRQL query examples You can simulate the following PromQL-style queries with NRQL queries: Description PromQL-style and NRQL queries Measure the per second rate over the last minute of the http_request_total metric. PromQL: sum(rate(http_requests_total[1m])) Copy NRQL: FROM Metric SELECT rate(sum(http_request_total), 1 second) TIMESERIES 1 minute Copy Chart the difference of the two metrics, then divide by 1024. PromQL: (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 Copy NRQL: FROM Metric SELECT (latest(instance_memory_limit_bytes) - latest(instance_memory_usage_bytes)) / 1024 TIMESERIES Copy Provide the summed rate per 30-second interval by each handler. PromQL: sum(rate(http_requests_total[30s])) by (handler) Copy NRQL: FROM Metric SELECT rate(sum(http_requests_total), 30 seconds) FACET handler TIMESERIES Copy Chart the difference in the two metrics where the instance is named foo and the fstype is either ext4 or xfs. PromQL: (node_filesystem_free_bytes{instance='foo',fstype=~\"ext4|xfs\"} / node_filesystem_size_bytes{instance='foo',fstype=~\"ext4|xfs\"}) Copy NRQL: FROM Metric SELECT latest(node_filesystem_free_bytes) / latest(node_filesystem_size_bytes) WHERE instance = 'foo' AND fstype IN ('ext4', 'xfs') Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 152.54916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Translate PromQL <em>queries</em> to <em>NRQL</em>",
        "sections": "Translate PromQL <em>queries</em> to <em>NRQL</em>",
        "tags": "View and <em>query</em> data",
        "body": " attributes start with api. FROM Metric SELECT latest(go_memstats_heap_alloc_bytes) WHEREe job LIKE &#x27;api%&#x27; TIMESERIES Copy PromQL-style to <em>NRQL</em> query examples You can simulate the following PromQL-style <em>queries</em> with <em>NRQL</em> <em>queries</em>: Description PromQL-style and <em>NRQL</em> <em>queries</em> Measure the per second <em>rate</em> over"
      },
      "id": "617daa50e7b9d2dab7c060c2"
    },
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 142.72623,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> using <em>LIMIT</em>",
        "tags": "<em>NRQL</em>: New Relic <em>Query</em> Language",
        "body": " that EXTRAPOLATE is most useful for homogenous data (like throughput or error <em>rate</em>). It&#x27;s not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with <em>NRQL</em> <em>queries</em> that use one of the following aggregator functions: apdex average count"
      },
      "id": "604456c1196a678db8960f41"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/app-data-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9557,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13455,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/browserspa-nrql-query-examples": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9555,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13454,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/funnels-evaluate-data-series-related-events": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9553,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88304,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13452,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/improvements-nrql-percentile": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.95508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.1345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nested-aggregation-make-ordered-computations-single-query": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.95508,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.1345,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-group-results-across-time": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-query-examples-mobile-monitoring": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.9549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13449,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/nrql-segment-your-data-buckets": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.95465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.95465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>NRQL</em> syntax, clauses, and functions",
        "sections": "<em>Query</em> one <em>data</em> type",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": "<em>NRQL</em> is a <em>query</em> <em>language</em> you can use to <em>query</em> the <em>New</em> <em>Relic</em> database. This document explains <em>NRQL</em> syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a <em>NRQL</em> <em>query</em>. Other resources for understanding <em>NRQL</em>: Intro to <em>NRQL</em>: explains what"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Understand and query high cardinality metrics",
        "What is cardinality and why does it matter?",
        "Tip",
        "Cardinality limits and enforcement",
        "Cardinality and dimensional metrics",
        "Cardinality influences",
        "Examples and sample workflows",
        "Find cardinality contributors: metrics",
        "Finding cardinality contributors: dimensions"
      ],
      "title": "Understand and query high cardinality metrics",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "NRQL query tutorials"
      ],
      "external_id": "323ed8d1ff44dfb94f876392908786cf30647a63",
      "image": "https://docs.newrelic.com/static/e2982d4f7d99b4cd27d8600a1692c661/c1b63/high-cardinality-metrics-1.png",
      "url": "https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/NRQL-high-cardinality-metrics/",
      "published_at": "2021-12-20T10:03:04Z",
      "updated_at": "2021-10-23T17:27:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Understanding how high cardinality works is important, because it can impact how quickly you reach your data limits. What is cardinality and why does it matter? Cardinality is generally defined as the number of elements in a set. For dimensional metrics, the set in question is the collection of unique maps of attributes observed for a given metric in a one-day period. You can query the cardinality of a metric in New Relic with the following NRQL format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to query the cardinality of the metric memory.heap and find out how many unique key-value pairs exist for this metric, run the following query: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy Tip We recommend including the RAW clause in cardinality queries that use FROM Metric. This is because in the event your cardinality has been limited, queries like SINCE today will query rollups that are no longer reporting and so need to look at the raw data points to perform the necessary analysis. Note that because querying the raw data points over long time ranges can be slow, RAW queries spanning more than 2 days worth of data are not allowed. While the basics of what cardinality means can be simple to state, learning how to address and manage high cardinality can be a little more complicated. Cardinality limits and enforcement New Relic enforces limits on your metric cardinality both at the per-metric level and at the account level. Cardinality is evaluated over the course of a UTC day, starting at 00:00:00 UTC and ending at 23:59:59 UTC. For more information on data limits and related policies, see New Relic data usage limits and policies Cardinality and dimensional metrics The cardinality of a metric is the size of the set of unique maps of attributes observed for the given metric in a one-day period. If keys or values in that map change over time, they will add new cardinality for that metric. Let's see an example. Imagine a network of 4 hosts, each with 2 containers running on them, and each container periodically reports the gauge metric memory.heap, with the host name and container id added as attributes. When submitted to the Metric API, one of these metrics might look something like this: \"metrics\":[ { \"name\":\"memory.heap\", \"type\":\"gauge\", \"value\":5514, \"timestamp\":1234567890, \"attributes\":{ \"host\":\"W\", \"container\":\"1\" } } ] Copy This metric would then have a cardinality of 8, as that's how many unique mappings of host and container are possible. If a new measurement for this metric is taken with identical attributes as one that had previously reported, no new cardinality would be counted. Cardinality influences As shown above, any changes to the keys or values will represent new cardinality, but predicting how those changes will impact your total cardinality can get a little tricky. It's tempting to assume that the cardinality of a metric is then the product of the number of all possible values for each possible key, but this is rarely the case in practice, as the values a given key often depend on or determine the values of other keys. Using the previous example, once we had a container value of 1, the value of host was fixed to W, assuming those container IDs are globally unique. So while there are 8 containers across 4 hosts, the cardinality is still 8, not 4 * 8 = 32, since most combinations counted by the simple multiplication method are not possible and therefore don't contribute to that metric's cardinality. We will never see the combination of host = 'X', container = 1, for instance. This also means that adding more keys to an attributes map does not necessarily imply an increase to total cardinality. If the value of the new key is uniquely determined by the values of existing keys, it will not add new cardinality in the long term. For instance if you add something like region to your map in the example, it's likely the case that the container value is also fixed to a particular region value, and therefore keeps your cardinality at 8. An important caveat here is that while adding region won't increase the cardinality going forward, it will introduce new cardinality when it is first added. This is because adding keys will make those attribute maps distinct from any that came before them, temporarily increasing the total cardinality for that day. Examples and sample workflows If you hit one of your cardinality limits, there are a couple of options you can use to remedy the situation. One easy answer is increasing your limits, but if you would prefer not to do that, a good alternative is to explore which dimensions are contributing the most to your cardinality and think about removing them if they do not provide value. This can save storage and bandwidth costs and potentially prevent you needing to raise your limits. Find cardinality contributors: metrics Recall how to get the cardinality of a particular metric: FROM Metric SELECT cardinality(memory.heap) SINCE today RAW Copy For the total account cardinality, you can use the same basic query structure and simply omit the metric name: FROM Metric SELECT cardinality() SINCE today RAW Copy The account's cardinality is essentially the sum of each metric's cardinality, so adding in a simple FACET query can help find the highest cardinality metrics: FROM Metric SELECT cardinality() SINCE today RAW FACET metricName Copy Finally, if you believe you have hit one of your cardinality limits, you can confirm this by checking for a related NrIntegrationError: FROM NrIntegrationError SELECT count(*) where name = 'CardinalityViolationException' and newRelicFeature = 'Metrics' facet cardinalityLimitType, metricName, message since today Copy Finding cardinality contributors: dimensions Once you've determined a metric you want to explore, the next step is to determine which dimensions in a given metric contribute the most to its cardinality. If you are unfamiliar with the values of your dimensions, you can look at them like so: FROM Metric SELECT dimensions() WHERE metricName = 'memory.heap' SINCE today RAW Copy The JSON results view will likely be advisable here. Looking through these could reveal some dimensions containing a unique ID or other highly variable value that might be worth removing. If you are already familiar with what values your attributes can take on, the keySet() results may be easier to scan: FROM Metric SELECT keySet() WHERE metricName = 'memory.heap' SINCE today RAW Copy Understanding the dimensions that have the most influence on your total cardinality comes down to understanding how each key's values correlate with one another. You can experiment with what your cardinality would be without a dimension simply by adding it to the exclude list: FROM Metric SELECT cardinality(memory.heap, exclude: {'container.id'}) SINCE today RAW Copy Likewise, there is an include list if that is more convenient to the query context: FROM Metric SELECT cardinality(memory.heap, include: {'host.name', 'region'}) SINCE today RAW Copy Managing cardinality can be tricky to conceptualize, but the above methods will help you get answers to questions like \"What metric is contributing the most cardinality?\" and \"What impact does a given attribute(s) have to that total cardinality?\". It's often the case that cardinality tracks with the most unique value, as that value may pin down the possible values other attributes can take on. However, there are plenty of cases where the explosion of possible combinations of a handful of attributes drives the total cardinality. Things that look like unique identifiers are generally a good place to start, but sometimes it's no single key but the combination of two or more keys. The more familiar you are with your data and the systems that generate it, the easier it will be to know which attributes to include or exclude. Tip If you'd like to learn more about limits and troubleshooting the Metric API, here are two good resources: Metric API limits and restricted attributes Troubleshoot Metric API with NRIntegrationError events are both great resources to explore.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 214.88303,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Understand and <em>query</em> high cardinality metrics",
        "sections": "Understand and <em>query</em> high cardinality metrics",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em>",
        "body": " of unique maps of attributes observed for a given metric in a one-day period. You can <em>query</em> the cardinality of a metric in <em>New</em> <em>Relic</em> with the following <em>NRQL</em> format: FROM Metric SELECT cardinality(metric.name) SINCE today RAW Copy For example, to <em>query</em> the cardinality of the metric memory.heap and find out"
      },
      "id": "61663e6ae7b9d2958c477f3e"
    },
    {
      "sections": [
        "Introduction to NRQL, New Relic's query language",
        "What is NRQL?",
        "Where can you use NRQL?",
        "What data can you query with NRQL?",
        "Tip",
        "Start using NRQL",
        "Important",
        "NRQL query examples",
        "Basic NRQL query of browser data",
        "Attribute name with a space in it",
        "Querying multiple data sources",
        "Query returning multiple columns",
        "NRQL syntax"
      ],
      "title": "Introduction to NRQL, New Relic's query language",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic query language",
        "Get started"
      ],
      "external_id": "51e361ee5ec2a2379486d6686677e0383eb49163",
      "image": "https://docs.newrelic.com/static/04052353f8dbe132cd384d7472778b3f/c1b63/new-relic-view-chart-nrql-query_0.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/",
      "published_at": "2021-12-20T01:38:19Z",
      "updated_at": "2021-11-24T02:51:08Z",
      "document_type": "page",
      "popularity": 1,
      "body": "One way to query your New Relic data is with the New Relic Query Language (NRQL). This resource explains what NRQL is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see NRQL syntax, clauses, and functions. Ready to get started? If you haven't already, be sure to sign up for a New Relic account. It's free, forever. What is NRQL? NRQL is New Relic's SQL-like query language. You can use NRQL to retrieve detailed New Relic data and get insight into your applications, hosts, and business-important activity. Reasons to use NRQL include: To answer a question for the purpose of troubleshooting or business analysis To create a new chart To make API queries of New Relic data (for example, using our NerdGraph API) NRQL is used behind the scenes to generate some New Relic charts: Some New Relic charts are built using NRQL. One way to start using NRQL is to view a chart's query and then edit it to make your own custom chart. Where can you use NRQL? You can use NRQL in these places: New Relic One query builder NerdGraph: our GraphQL-format API, which includes options for making NRQL queries one.newrelic.com > Query your data: You can run a NRQL query in New Relic One. This NRQL query shows a count of distributed tracing spans faceted by their entity names. NRQL is one of several ways to query New Relic data. For more on all query options, see Query your data. What data can you query with NRQL? NRQL allows you to query these New Relic data types: Event data from all New Relic products, including: APM events, like Transaction Browser monitoring events, like PageView Mobile monitoring events, like Mobile Infrastructure events, like ProcessSample Synthetics events, like SyntheticCheck Custom events, like those reported by the Event API Metric timeslice data (metrics reported by APM, browser, and mobile) The Metric data type (metrics reported by the Metric API and data sources that use that API) The Span data type (distributed tracing data) The Log data type (data from New Relic Logs) Tip Some data, like relationships between monitored entities, is not available via NRQL but is available using our NerdGraph API. Start using NRQL One way to start using NRQL and to understand what data you have available is to go to a NRQL interface (for example, the New Relic One query builder), type FROM, and press space. The interface will suggest available types of data: To see the attributes available for a specific data type, type FROM DATA_TYPE SELECT and press space. The interface will suggest available attributes. For example: To see the complete JSON associated with a data type, including all of its attributes, use the keyset() attribute. For example: FROM Transaction SELECT keyset() Copy NRQL is used behind the scenes to build some New Relic charts and dashboards. One way to learn NRQL is to find one of these NRQL-generated charts and start playing with the NRQL to create new, customized queries and charts: Charts built with NRQL will have View query as an option. You can then edit and customize that query to see how your changes affect the resulting visualization. Important To explore your data without having to use NRQL, use the data explorer. Learn more about querying data in New Relic. NRQL query examples Here's an example NRQL query of Transaction data, which is reported by APM. FROM Transaction SELECT average(duration) FACET appName TIMESERIES auto Copy This would generate a chart that looks like: Here are some more query examples: Basic NRQL query of browser data Here's a NRQL query of PageView data from browser monitoring. SELECT uniqueCount(user) FROM PageView WHERE userAgentOS = 'Mac' FACET countryCode SINCE 1 day ago LIMIT 20 Copy Attribute name with a space in it If a custom attribute name has a space in it, use backticks around the attribute name: SELECT count(*) FROM Transaction FACET `Logged-in user` Copy Querying multiple data sources To return data from two data sources, separate their data types with a comma. For example, this query returns a count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Query returning multiple columns To return multiple columns from a dataset, separate the aggregator arguments with a comma: SELECT function(attribute), function(attribute) ... FROM ... Copy This query returns the minimum, average, and maximum duration for browser monitoring PageView events over the last week: SELECT min(duration), max(duration), average(duration) FROM PageView SINCE 1 week ago Copy See more NRQL query examples. NRQL syntax The syntax of a NRQL query is similar to standard SQL queries. Here is a breakdown of the structure of a NRQL query: SELECT function(attribute) [AS 'label'][, ...] FROM data type [WHERE attribute [comparison] [AND|OR ...]][AS 'label'][, ...] [FACET attribute | function(attribute)] [LIMIT number] [SINCE time] [UNTIL time] [WITH TIMEZONE timezone] [COMPARE WITH time] [TIMESERIES time] Copy Basic rules include: NRQL condition Details Required values The SELECT statement and FROM clause are required. All other clauses are optional. You can start your query with either SELECT or FROM. Query string size The query string must be less than 4 KB. Case sensitivity The data type names and attribute names are case sensitive. NRQL clauses and functions are not case sensitive. Syntax for strings NRQL uses single quotes to designate strings. For example: ... where traceId = '030a573f0df02c57' Copy Attribute names with spaces Use backticks `` to quote a custom attribute name that has a space in it. For example: ... FACET `Logged-in user` Copy Data type coercion Insights does not support data type \"coercion.\" For more information, see Data type conversion. Use of math functions Basic and advanced math functions are supported in the SELECT statement. JOIN functions NRQL does not have the equivalent of the SQL JOIN function, but you can simulate a JOIN with custom attributes. Read more about NRQL syntax and functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.13448,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "sections": "Introduction to <em>NRQL</em>, <em>New</em> <em>Relic&#x27;s</em> <em>query</em> <em>language</em>",
        "tags": "<em>NRQL</em>: <em>New</em> <em>Relic</em> <em>query</em> <em>language</em>",
        "body": "One way to <em>query</em> <em>your</em> <em>New</em> <em>Relic</em> <em>data</em> is with the <em>New</em> <em>Relic</em> <em>Query</em> <em>Language</em> (<em>NRQL</em>). This resource explains what <em>NRQL</em> is, when and how you can use it, and basic syntax rules. For more detailed information on querying, including a listing of clauses and functions and example queries, see <em>NRQL</em> syntax"
      },
      "id": "60445a0e196a67cb09960f6e"
    }
  ],
  "/docs/security/index": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 89.70042,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em>",
        "body": "This document contains important information regarding <em>security</em> vulnerabilities that could affect some versions of New Relic products and service. <em>Security</em> bulletins are a way for us to let you know about <em>security</em> vulnerabilities, remediation strategies, and applicable updates for affected software"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 85.88516,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 84.679535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em>",
        "body": " this <em>Security</em> Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/covid-19": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47247,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.091,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39215,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/notification-apolloio-security-incident": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47226,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47226,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09082,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39203,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47205,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09064,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39188,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr17-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4718,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39172,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47162,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.09027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3916,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47137,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0901,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39145,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-06": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-07": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4712,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0899,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3913,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-08": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47095,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-09": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47095,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39114,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-10": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-11": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47073,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08954,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.391,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr18-12": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.47052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08936,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-04": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4703,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08917,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39072,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr19-05": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4701,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.4701,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39056,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr20-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.46985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-01": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.46985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-02": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.46985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.0888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.3904,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 545.4641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> bulletins for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache <em>log4j</em> logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 537.32733,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Apache <em>Log4j</em> Critical Vulnerability CVE-2021-<em>44228</em> - CPM",
        "sections": "Apache <em>Log4j</em> Critical Vulnerability CVE-2021-<em>44228</em> - CPM",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using <em>log4j</em> directly in their applications should carefully review the Apache <em>Log4j</em> <em>Security</em> Vulnerabilities page for remediation"
      },
      "id": "61b9dbce64441ffabdd716f2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/java-release-notes/java-agent-652/",
      "sections": [
        "Java agent v6.5.2",
        "Fixes",
        "Mitigation for Java 7",
        "Support statement:"
      ],
      "published_at": "2021-12-19T22:23:14Z",
      "title": "Java agent v6.5.2",
      "updated_at": "2021-12-19T04:32:25Z",
      "type": "docs",
      "external_id": "93c3ee24b7cad972c222331f50f54e71234c9291",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Fixes Changed log4j version to 2.12.2 to mitigate the security vulnerability CVE-2021-45046. 605 Mitigation for Java 7 This release is compatible with Java 7. Support statement: New Relic recommends that you upgrade the agent regularly to ensure that you're getting the latest features and performance benefits. Additionally, older releases will no longer be supported when they reach end-of-life.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.51776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em> agent v6.5.2",
        "sections": "<em>Java</em> agent v6.5.2",
        "body": "Fixes Changed <em>log4j</em> version to 2.12.2 to mitigate the <em>security</em> vulnerability CVE-2021-45046. 605 Mitigation for Java 7 This release is compatible with Java 7. Support statement: New Relic recommends that you upgrade the agent regularly to ensure that you&#x27;re getting the latest features and performance benefits. Additionally, older releases will no longer be supported when they reach end-of-life."
      },
      "id": "61beb5d9196a6722a4eeefa3"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04": [
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 562.8021,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Apache <em>Log4j</em> Critical Vulnerability CVE-2021-<em>44228</em> - <em>Java</em>",
        "sections": "Apache <em>Log4j</em> Critical Vulnerability CVE-2021-<em>44228</em> - <em>Java</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " 9.0 Apache <em>log4j</em> <em>Security</em> Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this <em>bulletin</em>. How do I find out which versions of the agent we"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 545.4641,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> bulletins for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache <em>log4j</em> logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/java-release-notes/java-agent-652/",
      "sections": [
        "Java agent v6.5.2",
        "Fixes",
        "Mitigation for Java 7",
        "Support statement:"
      ],
      "published_at": "2021-12-19T22:23:14Z",
      "title": "Java agent v6.5.2",
      "updated_at": "2021-12-19T04:32:25Z",
      "type": "docs",
      "external_id": "93c3ee24b7cad972c222331f50f54e71234c9291",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "Fixes Changed log4j version to 2.12.2 to mitigate the security vulnerability CVE-2021-45046. 605 Mitigation for Java 7 This release is compatible with Java 7. Support statement: New Relic recommends that you upgrade the agent regularly to ensure that you're getting the latest features and performance benefits. Additionally, older releases will no longer be supported when they reach end-of-life.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 285.51776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Java</em> agent v6.5.2",
        "sections": "<em>Java</em> agent v6.5.2",
        "body": "Fixes Changed <em>log4j</em> version to 2.12.2 to mitigate the <em>security</em> vulnerability CVE-2021-45046. 605 Mitigation for Java 7 This release is compatible with Java 7. Support statement: New Relic recommends that you upgrade the agent regularly to ensure that you&#x27;re getting the latest features and performance benefits. Additionally, older releases will no longer be supported when they reach end-of-life."
      },
      "id": "61beb5d9196a6722a4eeefa3"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/security-heartbleed-vulnerability": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.46942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/new-relic-security/security-bulletins/solarwinds-orion": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 369.46942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> <em>bulletins</em>",
        "sections": "<em>Security</em> <em>bulletins</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " feed. APM <em>Security</em> <em>bulletins</em> for our APM agents include a vulnerability rating. <em>Security</em> <em>bulletin</em> Summary and related release notes Rating NR21-03, original date 12&#x2F;10&#x2F;2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. <em>Bulletin</em>"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 299.08844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity"
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
        "Summary",
        "Affected software",
        "Action items",
        "Important",
        "Vulnerability information",
        "Frequently asked questions",
        "I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - CPM",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "d715f552d46851d0f526d65d2a05331eb685af70",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-04/",
      "published_at": "2021-12-20T02:36:11Z",
      "updated_at": "2021-12-19T05:10:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic released Containerized Private Minion (CPM) version 3.0.57 on 2021-12-14 to address critical vulnerabilities CVE 2021-44228 and CVE-2021-45046 in the open source Apache Log4j framework. A malicious actor may be able to execute arbitrary code using log messages or log message parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-04 Priority: Critical Affected software Versions affected: All supported containerized private minion (CPM) versions prior to 3.0.57 Fixed version: 3.0.57, also available through Helm Charts version 1.0.45 New Relic CPM version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 3.0.57 yes yes If you use Helm Charts to update your CPM configurations, you will want to implement New Relic Helm Charts version 1.0.45. This will update your CPM to version 3.0.57. Action items To remediate CVE-2021-44228 in the New Relic Containerized Private Minion, we recommend customers upgrade to version 3.0.57 as soon as possible. This version has been updated to use the remediated 2.16.0 version of the Apache Log4j framework. You may update your CPM through Helm Charts version 1.0.45. Important If you have already upgraded to Containerized Private Minion (CPM) version 3.0.55, Apache Foundation's current technical guidance is that your CPM has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We strongly recommend updating to CPM version 3.0.57 at this time. This step will remediate your New Relic Containerized Private Minion (CPM) only. You may also need to update your New Relic Java agent. Please refer to NR21-03 for more information. Customers using log4j directly in their applications should carefully review the Apache Log4j Security Vulnerabilities page for remediation details that should be considered. Vulnerability information A high level vulnerability was publicly disclosed for the log4j framework on 2021-12-09. An attacker is able to execute arbitrary code using log messages or log message parameters. CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions I've updated to CPM 3.0.55 already. Do I need to update to 3.0.57? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j v2.15.0 is not sufficient protection against exploitation. CPM 3.0.57 and later versions are the only CPM versions available with log4j 2.16.0. Publication history December 17, 2021: NR21-04 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-04 Major Revision: Change in guidance regarding sufficiency of CPM 3.0.55 containing log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Addition of Helm Charts version 1.0.45 that contains the CPM 3.0.57 update. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-04 Major Revision: New fix version 3.0.57 released to address both CVE-2021-44228 and CVE-2021-45046. Updated to provide better clarity between New Relic CPM updates and the best practices customers should take to secure their applications. Added FAQ section. December 13, 2021: NR21-04 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 282.39014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " parameters. New Relic also released Helm Charts version 1.0.45 on 2021-12-14 to address CVE-2021-44228 and CVE-2021-45046. Helm Charts version 1.0.45 contains the CPM version 3.0.57. New Relic will update this <em>Security</em> <em>Bulletin</em> and our customer guidance as new information becomes available. Vulnerability"
      },
      "id": "61b9dbce64441ffabdd716f2"
    }
  ],
  "/docs/security/security-privacy/compliance/certificates-standards-regulations/fedramp-moderate": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa": [
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    },
    {
      "sections": [
        "SOC 2",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "SOC 2",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "df4a1eb2441fc8484cd0fe625f4bb81c6908556c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/soc2/",
      "published_at": "2021-12-20T12:44:22Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The American Institute of Certified Public Accountants (AICPA) Service Organization Controls (SOC) reports give assurance over control environments as they relate to the retrieval, storage, processing, and transfer of data. The reports cover IT General controls and controls around availability, confidentiality and security of customer data. The SOC 2 reports cover controls around security, availability, and confidentiality of customer data. Additional information can be found at the AICPA's Report. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services SOC 2 Type 2 2021-AUG-20 AWS & First Party New Relic One Platform SOC 2 Type 1 2020-NOV-12 GCP Pixie: Community Cloud for Pixie has completed a SOC 2 Type 1 audit Services not in scope The following services are not SOC 2 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A AWS CodeStream N/A AWS Network Performance Monitoring N/A GCP Pixie: Auto-telemetry with Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", confidentiality and <em>security</em> of customer data. The SOC 2 reports cover controls around <em>security</em>, availability, and confidentiality of customer data. Additional information can be found at the AICPA&#x27;s Report. Applicable document by service Caution Not all New Relic One services are in <em>compliance</em>"
      },
      "id": "61865487196a6765fbf4209d"
    }
  ],
  "/docs/security/security-privacy/compliance/certificates-standards-regulations/iso": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.089,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    },
    {
      "sections": [
        "SOC 2",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "SOC 2",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "df4a1eb2441fc8484cd0fe625f4bb81c6908556c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/soc2/",
      "published_at": "2021-12-20T12:44:22Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The American Institute of Certified Public Accountants (AICPA) Service Organization Controls (SOC) reports give assurance over control environments as they relate to the retrieval, storage, processing, and transfer of data. The reports cover IT General controls and controls around availability, confidentiality and security of customer data. The SOC 2 reports cover controls around security, availability, and confidentiality of customer data. Additional information can be found at the AICPA's Report. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services SOC 2 Type 2 2021-AUG-20 AWS & First Party New Relic One Platform SOC 2 Type 1 2020-NOV-12 GCP Pixie: Community Cloud for Pixie has completed a SOC 2 Type 1 audit Services not in scope The following services are not SOC 2 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A AWS CodeStream N/A AWS Network Performance Monitoring N/A GCP Pixie: Auto-telemetry with Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56659,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", confidentiality and <em>security</em> of customer data. The SOC 2 reports cover controls around <em>security</em>, availability, and confidentiality of customer data. Additional information can be found at the AICPA&#x27;s Report. Applicable document by service Caution Not all New Relic One services are in <em>compliance</em>"
      },
      "id": "61865487196a6765fbf4209d"
    }
  ],
  "/docs/security/security-privacy/compliance/certificates-standards-regulations/soc2": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.0888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.5665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.0888,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92096,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "SOC 2",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "SOC 2",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "df4a1eb2441fc8484cd0fe625f4bb81c6908556c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/soc2/",
      "published_at": "2021-12-20T12:44:22Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The American Institute of Certified Public Accountants (AICPA) Service Organization Controls (SOC) reports give assurance over control environments as they relate to the retrieval, storage, processing, and transfer of data. The reports cover IT General controls and controls around availability, confidentiality and security of customer data. The SOC 2 reports cover controls around security, availability, and confidentiality of customer data. Additional information can be found at the AICPA's Report. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services SOC 2 Type 2 2021-AUG-20 AWS & First Party New Relic One Platform SOC 2 Type 1 2020-NOV-12 GCP Pixie: Community Cloud for Pixie has completed a SOC 2 Type 1 audit Services not in scope The following services are not SOC 2 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A AWS CodeStream N/A AWS Network Performance Monitoring N/A GCP Pixie: Auto-telemetry with Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.5665,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", confidentiality and <em>security</em> of customer data. The SOC 2 reports cover controls around <em>security</em>, availability, and confidentiality of customer data. Additional information can be found at the AICPA&#x27;s Report. Applicable document by service Caution Not all New Relic One services are in <em>compliance</em>"
      },
      "id": "61865487196a6765fbf4209d"
    }
  ],
  "/docs/security/security-privacy/compliance/data-encryption": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.08862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/fedramp-compliant-endpoints": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.08862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.92087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56644,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/hipaa-readiness-new-relic": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 438.34814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>HIPAA</em>",
        "sections": "<em>HIPAA</em>",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The <em>HIPAA</em> <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find <em>HIPAA</em> account enablement information at the <em>HIPAA</em> readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.4986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.14474,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/key-management-encryption-rest": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.08844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.9208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/compliance/regulatory-audits-new-relic-services": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 312.08844,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in <em>compliance</em>"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.9208,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 249.56635,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard information <em>security</em> assessment (ISA) catalog based on key aspects of information <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    }
  ],
  "/docs/security/security-privacy/data-privacy/data-privacy-new-relic": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.14374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.7084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, <em>data</em> <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.84727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", 2021: NR21-03 published Report <em>security</em> vulnerabilities to New Relic New Relic is committed to the <em>security</em> of our customers and your <em>data</em>. If you believe you have found a <em>security</em> vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic&#x27;s coordinated disclosure program. For more information, see our documentation about reporting <em>security</em> vulnerabilities."
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    }
  ],
  "/docs/security/security-privacy/data-privacy/new-relic-personal-data-requests": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.14374,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.7084,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, <em>data</em> <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.84727,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", 2021: NR21-03 published Report <em>security</em> vulnerabilities to New Relic New Relic is committed to the <em>security</em> of our customers and your <em>data</em>. If you believe you have found a <em>security</em> vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic&#x27;s coordinated disclosure program. For more information, see our documentation about reporting <em>security</em> vulnerabilities."
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    }
  ],
  "/docs/security/security-privacy/data-privacy/security-controls-privacy": [
    {
      "sections": [
        "HIPAA",
        "Important",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "HIPAA",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "64dba706af7dcc63120f03305649fdbe35a14335",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/hipaa/",
      "published_at": "2021-12-20T12:29:25Z",
      "updated_at": "2021-12-20T12:29:24Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The HIPAA Privacy Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance with US HIPAA contact your account representative regarding a Business Associate Addendum (BAA). Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services HIPAA BAA FAQ 2021-JUL-01 AWS & First Party New Relic One Platform Services not in scope The following services are not covered under the BAA: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS & Customer Programmability: New Relic One apps N/A AWS Codestream N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.14359,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The HIPAA <em>Privacy</em> Rule provides federal protections for personal health information held by covered entities, and gives patients an array of rights with respect to that information. Find HIPAA account enablement information at the HIPAA readiness page. Important To use New Relic in compliance"
      },
      "id": "61865458e7b9d26cb9c2be73"
    },
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.70828,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more information, see our documentation about <em>security</em>, <em>data</em> <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
        "Summary",
        "Versions affected",
        "Action items",
        "Important",
        "How to disable the Java agent logging",
        "Containerized private minions",
        "Technical vulnerability information",
        "Frequently asked questions",
        "What are our options if we are not able to upgrade our Java agent or version of Java?",
        "How do I find out which versions of the agent we are running?",
        "Why isn't there a patch for agent v5 and below?",
        "I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2?",
        "Publication history",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Apache Log4j Critical Vulnerability CVE-2021-44228 - Java",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Security bulletin",
        "Log4j"
      ],
      "external_id": "61b969349bcf206d80577b327e58740a1d4d5474",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/new-relic-security/security-bulletins/security-bulletin-nr21-03/",
      "published_at": "2021-12-20T09:33:07Z",
      "updated_at": "2021-12-20T09:33:07Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Summary New Relic has released Java agents 6.5.2 and 7.4.2 to address critical vulnerabilities CVE-2021-44228 and CVE-2021-45046 in the log4j framework. A malicious actor may be able to exfiltrate data or execute arbitrary code using log messages or log message parameters. New Relic will update this Security Bulletin and our customer guidance as new information becomes available. Vulnerability identifier: NR21-03 Versions affected All agent versions between (a) 4.12.0 and 6.5.1; and (b) 7.0.0 and 7.4.1 Fix versions: 6.5.2, 7.4.2 New Relic Java agent version Remediates CVE-2021-44228 Severity: Critical CVSS 10.0 Remediates CVE-2021-45046 Severity: Critical CVSS 9.0 6.5.2 yes yes 7.4.2 yes yes Action items To remediate both CVE-2021-44228 and CVE-2021-45046 in the New Relic Java agent, we recommend customers upgrade to agent release 6.5.2 (requires Java 7 or higher) or 7.4.2 (requires Java 8 or higher) as soon as possible. If you have already upgraded to agent versions 6.5.1 or 7.4.1, these agent versions are using log4j2 version 2.15.0. However Apache Foundation's current technical guidance is that log4j2 v2.15.0 has incomplete protection against CVE 2021-44228 and remains susceptible to remote code execution. We recommend updating or implementing the additional workaround below at this time. Important If you are on an earlier or affected version of the agent, or cannot upgrade your agent version, we strongly recommend you disable the Java agent logging. How to disable the Java agent logging You can set your Java agent logging level to OFF to temporarily remediate CVE-2021-44228. To do this, use any of the following options: Modify your local agent configuration file (search for the log_level parameter). Define the newrelic.config.log_level=OFF system property. Set the NEW_RELIC_LOG_LEVEL=OFF environment variable. Then restart your application. After restart, you can verify that agent logging has been disabled by checking the agent log file. You should not see any new messages being written. Note: This workaround is recommended only as a temporary solution until you can update your agent version. We will share more information, and additional steps for remediation, if the situation changes. If you use log4j directly in your applications, be sure to carefully review the Apache Log4j Security Vulnerabilities. This page provides remediation details for you to consider. Containerized private minions The above step will remediate your New Relic Java agent only. You may also need to update your New Relic Containerized Private Minion. Please refer to NR21-04 for more information. Technical vulnerability information CVE-2021-44228 CVSS 10.0 CVE-2021-45046 CVSS 9.0 Apache log4j Security Vulnerabilities New Relic Explorers Hub Frequently asked questions What are our options if we are not able to upgrade our Java agent or version of Java? Please implement the recommended workaround in this bulletin. How do I find out which versions of the agent we are running? To see agent version information, go to your Environment page in New Relic One. See our environment documentation for more information. Why isn't there a patch for agent v5 and below? Most of our customers are using agent versions 6.x or 7.x, and we encourage customers to use newer versions of our agent to ensure they have the best experience. If you are not able to upgrade your agent version, please implement the recommended workarounds in this bulletin. I've updated to 6.5.1 or 7.4.1 already. Do I need to update to 6.5.2 or 7.4.2? Apache Foundation and NIST have revised their technical assessment of CVE-2021-44228 and advise that log4j 2.15.0 is not sufficient protection against exploitation. Java agents 6.5.2 and 7.4.2 are the only Java agent versions currently available with log4j 2.16.0. Publication history December 17, 2021: NR21-03 Revision: Change in severity and technical description of CVE-2021-45046 December 16, 2021: NR21-03 Major Revision: New fix version 6.5.2 available to address both CVE-2021-44228 and CVE-2021-45046. Change in guidance regarding sufficiency of log4j version 2.15.0 to protect against exploitation of CVE-2021-44228. Change in recommended workaround. Update of NIST technical description of CVE-2021-44228. December 14, 2021: NR21-03 Major Revision: New fix version 7.4.2 available to address both CVE-2021-44228 and CVE-2021-45046. Updated to include an additional workaround option. Updated to provide clarity between New Relic Java agent updates and the best practices customers should take to secure their applications. Added technical vulnerability descriptions and CVSS scores from the National Institute of Standards and Technology (NIST). December 13, 2021: NR21-03 updated to include more explicit workaround guidance and FAQs December 10, 2021: NR21-03 published Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic's coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.84717,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Report <em>security</em> vulnerabilities to New Relic",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ", 2021: NR21-03 published Report <em>security</em> vulnerabilities to New Relic New Relic is committed to the <em>security</em> of our customers and your <em>data</em>. If you believe you have found a <em>security</em> vulnerability in one of our products or websites, we welcome and greatly appreciate you reporting it to New Relic&#x27;s coordinated disclosure program. For more information, see our documentation about reporting <em>security</em> vulnerabilities."
      },
      "id": "61b814c9e7b9d2f4a5ef36ec"
    }
  ],
  "/docs/security/security-privacy/information-security/report-security-vulnerabilities-hackerone": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.86105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.18294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard <em>information</em> <em>security</em> assessment (ISA) catalog based on key aspects of <em>information</em> <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.45789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an <em>information</em> <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    }
  ],
  "/docs/security/security-privacy/information-security/security-bulletins": [
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.18294,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard <em>information</em> <em>security</em> assessment (ISA) catalog based on key aspects of <em>information</em> <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.45789,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an <em>information</em> <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    },
    {
      "sections": [
        "FedRAMP Moderate",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "FedRAMP Moderate",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "d321748f3edb0e29c3db0734405faa40f93de13f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/fedramp-moderate/",
      "published_at": "2021-12-20T12:57:25Z",
      "updated_at": "2021-12-14T20:36:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Federal Risk and Authorization Management Program (FedRAMP) is a U.S. Federal government program that provides a standardized approach to security assessment, authorization, and continuous monitoring for cloud products and services. The FedRAMP program has helped to accelerate the adoption of secure cloud solutions through the reuse of assessments and authorizations across government agencies. FedRAMP leverages a standardized set of requirements, established in accordance with the Federal Information Security Management Act (FISMA), to improve consistency and confidence in the security of cloud solutions. Cloud Service Providers (CSP) that support U.S. government customers or operate on U.S. government information are responsible for complying with the requirements established by the FedRAMP program. For more information, see our public sector solutions, or download the New Relic FedRAMP Customer Responsibility Matrix (CRM) Worksheet as a PDF|87K. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services FedRAMP Moderate 2021-OCT-08 AWS & First Party New Relic One Platform Services not in scope The following services are not FedRAMP-authorized: Last Updated Infrastructure Services N/A AWS Amazon CloudWatch Metric Streams Integration N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A N/A Cloud integrations (AWS, Azure, and GCP) N/A AWS CodeStream N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and Customer Programmability: New Relic One apps N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.21622,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": " of secure cloud solutions through the reuse of assessments and authorizations across government agencies. FedRAMP leverages a standardized set of requirements, established in accordance with the Federal <em>Information</em> <em>Security</em> Management Act (FISMA), to improve consistency and confidence in the <em>security</em>"
      },
      "id": "61865459e7b9d24a35c2bacd"
    }
  ],
  "/docs/security/security-privacy/information-security/software-development-lifecycle": [
    {
      "sections": [
        "Security bulletins",
        "Get security notifications",
        "APM",
        "Infrastructure monitoring",
        "Browser monitoring",
        "Synthetic monitoring",
        "Security vulnerability ratings",
        "Report security vulnerabilities to New Relic"
      ],
      "title": "Security bulletins",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Information security"
      ],
      "external_id": "9fdc7f00a2f5dee1ec57904fd2b6fecfcf37d9bc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/information-security/security-bulletins/",
      "published_at": "2021-12-22T01:43:19Z",
      "updated_at": "2021-12-20T02:43:56Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document contains important information regarding security vulnerabilities that could affect some versions of New Relic products and service. Security bulletins are a way for us to let you know about security vulnerabilities, remediation strategies, and applicable updates for affected software. For more information, see our documentation about security, data privacy, and compliance, or visit the New Relic security website. Get security notifications Select the Watching option in our Explorers Hub's Security notifications community channel to receive email alerts. Or subscribe to the RSS feed. APM Security bulletins for our APM agents include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-03, original date 12/10/2021 The Java agent use of the Apache log4j logging framework and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR21-02, 4/26/2021 The Java agent implements a YAML parser that may lead to limited code execution when parsing a crafted YAML payload. Low NR20-02, 8/20/2020 The agent does not remove the URI from transaction traces when request.uri has been disabled in attribute configuration. See the Node.js agent release notes. Medium NR20-01, 1/16/2020 The agent may capture full SQL queries when an exception occurs. See the .NET agent release notes. Medium NR19-05, 8/26/2019 Incorrect metric names created with non-parameterized queries may contain sensitive information. See the .NET agent release notes. Medium NR19-03, 4/22/2019 Query obfuscation may fail in Microsoft SQL server. See the .NET agent release notes. Medium NR19-02, 4/1/2019 Segment attributes may include request parameters in high security mode or when using configurable security policies. See the Node.js agent release notes. Medium NR19-01, 1/9/2019 OpenRasta instrumentation may capture query strings. See the .NET agent release notes. Medium NR18-09, 5/2/2018 The agent may capture sensitive data when record_sql is set to off. See the Java agent release notes. Low NR18-08, 4/12/2018 The agent uses a vulnerable https-proxy-agent Node module. See the Node.js agent release notes. Low NR18-07, 3/7/2018 The agents may report DB query results to New Relic or reissue an SQL statement. See the release notes for the Python, Java, and .NET agents. High NR18-06, 3/5/2018 The agent may capture all transaction attributes. See the Node.js agent release notes. High NR18-04, 1/22/2018 Error messages are not removed in high security mode. See the .NET agent release notes. Medium NR18-02, 1/9/2018 The agent may not obfuscate SQL params with SQLite. See the Python agent release notes. Medium NR18-01, 1/9/2018 The agent may capture custom API parameters in high security mode. See the Python agent release notes. Medium NR17-06, 12/18/2017 The agent captures external HTTP request parameters during a transaction trace. See the .NET agent release notes. Medium NR17-05, 5/30/2017 The agent may capture full SQL queries when an exception occurs. See the Java agent release notes. High NR17-04, 5/5/2017 The agent captures WCF service request parameters during a TransactionError. See the .NET agent release notes. Medium NR17-03, 2/9/2017 MongoDB aggregate queries not obfuscated. See the Ruby agent release notes. Low NR17-02, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the .NET agent release notes. Medium NR17-01, 1/12/2017 Query parameters are not removed from the referer attribute in error trace. See the Node.js agent release notes. Medium Infrastructure monitoring Security bulletins for infrastructure monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR18-12, 11/28/18 Windows agent may follow unprivileged hard links or junction folders. See the agent release notes for infrastructuring monitoring Low NR18-11, 10/8/18 Windows agent may execute privileged binaries in the system path. See the agent release notes for infrastructuring monitoring. Medium NR18-10, 6/18/18 Hard-coded file path allows for user-controlled configuration. See the agent release notes for infrastructuring monitoring. High NR18-05, 2/8/2018 Command line options may be captured. See the agent release notes for infrastructuring monitoring. High Browser monitoring Security bulletins for browser monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-01, 3/9/2021 The agent does not properly sanitize local file URIs when an instrumented HTML page is opened directly from the operating systems's filesystem. Medium Synthetic monitoring Security bulletins for synthetic monitoring include a vulnerability rating. Security bulletin Summary and related release notes Rating NR21-04, original date 12/13/2021 Containerized private minion (CPM) and procedures to address CVE-2021-44228 and CVE-2021-45046. Bulletin includes action items and links to related release notes. Critical NR19-04, 7/22/2019 Sensitive data may appear in logs. See the release notes for containerized private minions. Medium NR18-03, 1/12/2018 Update private minions for Meltdown (CVE-2017-5754). See the release notes for containerized private minions. High Security vulnerability ratings At New Relic, we use four levels to rate security vulnerability. Rating Description Critical A vulnerability in a New Relic product or service that could be exploited to compromise the confidentiality or integrity of your data. High Atypical or unintended information is likely to be received by New Relic, potentially compromising the confidentiality or integrity of your data. Medium Atypical or unintended information could be received by New Relic, but the risk of compromise is mitigated by default configuration or standard security practices. Low Atypical or unintended information may be received by New Relic, but the vulnerability would be difficult to exploit, or it would have minimal impact. Report security vulnerabilities to New Relic New Relic is committed to the security of our customers and your data. If you believe you have found a security vulnerability in one of our products, services, or websites, we welcome and greatly appreciate you reporting it to our coordinated disclosure program. For more information, see our documentation about reporting security vulnerabilities via HackerOne.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 331.86087,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Security</em> bulletins",
        "sections": "<em>Security</em> bulletins",
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": ". For more <em>information</em>, see our documentation about <em>security</em>, data <em>privacy</em>, and compliance, or visit the New Relic <em>security</em> website. Get <em>security</em> notifications Select the Watching option in our Explorers Hub&#x27;s <em>Security</em> notifications community channel to receive email alerts. Or subscribe to the RSS"
      },
      "id": "6045248b196a67f158960f1b"
    },
    {
      "sections": [
        "TISAX",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "TISAX",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "97d039cd7b1d5ae9f050b0831a9ad6e45415578b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/tisax/",
      "published_at": "2021-12-20T12:30:24Z",
      "updated_at": "2021-12-14T20:36:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "TISAX is a European automotive industry-standard information security assessment (ISA) catalog based on key aspects of information security such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope of certifications covers the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services TISAX 2021-NOV-3 AWS, IBM & First Party New Relic One Platform Services not in scope The following services are not TISAX certified. Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.18286,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "TISAX is a European automotive industry-standard <em>information</em> <em>security</em> assessment (ISA) catalog based on key aspects of <em>information</em> <em>security</em> such as data protection and connection to third parties. For a copy of New Relic’s shared assessment, you must be a member of ENX Association. The scope"
      },
      "id": "618e8f5e196a679d34e73cb9"
    },
    {
      "sections": [
        "ISO 27001 standard",
        "Applicable document by service",
        "Caution",
        "Services not in scope"
      ],
      "title": "ISO 27001 standard",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "67548497b437b8626d15451066e7c232a202e818",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/certificates-standards-regulations/iso/",
      "published_at": "2021-12-20T12:57:26Z",
      "updated_at": "2021-12-14T21:52:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an information security standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch point audits (surveillance audits). The scope of certification covered the Company’s locations in Portland, Oregon; San Francisco, California; Barcelona, Spain; Dublin, Ireland; Atlanta, Georgia; and London, United Kingdom. Applicable document by service Caution Not all New Relic One services are in compliance with this program. For non-compliant services, please see the section of services not in scope. The following applies to the New Relic One platform: Document Last Updated Infrastructure Services ISO 27001:2013 Certificate 2021-OCT-04 AWS & First Party New Relic One Platform Services not in scope The following services are not ISO 27001 certified: Last Updated Infrastructure Services N/A GCP AI Ops - Incident Intelligence N/A GCP Log Patterns N/A GCP Pixie: Auto-telemetry with Pixie N/A GCP Pixie: Community Cloud for Pixie N/A AWS and GCP ML Ops",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 228.45782,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Security</em> <em>and</em> <em>Privacy</em>",
        "body": "The International Organization for Standardization 27001 Standard (ISO 27001) is an <em>information</em> <em>security</em> standard that ensures office sites, development centers, support centers and data centers are securely managed. These certifications run for 3 years (with renewal audits), and have annual touch"
      },
      "id": "61865486196a67aa8ff428b8"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/account-linking": [
    {
      "sections": [
        "NRQL syntax, clauses, and functions",
        "Syntax",
        "Query components",
        "Required clauses",
        "Required: SELECT statement",
        "Avg response time since last week",
        "Required: FROM clause",
        "Query one data type",
        "Query multiple data types",
        "Optional clauses",
        "AS clause",
        "Query using math function and AS",
        "Query using funnel and AS",
        "COMPARE WITH clause",
        "EXTRAPOLATE clause",
        "Important",
        "Example of extrapolating throughput",
        "Example of extrapolating throughput as a time series",
        "FACET clause",
        "Faceted query using count()",
        "Faceted query using uniqueCount()",
        "Grouping results across time",
        "FACET ... AS clause",
        "FACET CASES clause",
        "Basic usage with WHERE",
        "Group based on multiple attributes",
        "Label groups with AS",
        "Facet non-matching data with OR",
        "FACET ... ORDER BY clause",
        "Tip",
        "LIMIT clause",
        "Query using LIMIT",
        "OFFSET clause",
        "ORDER BY clause",
        "SHOW EVENT TYPES clause",
        "Data types in the last day",
        "SINCE clause",
        "SLIDE BY clause",
        "Use SLIDE BY with MAX or AUTO interval",
        "TIMESERIES clause",
        "Use a set interval",
        "Use an automatically set interval",
        "Use MAX interval",
        "UNTIL clause",
        "WHERE clause",
        "Example query with three conditions",
        "WITH METRIC_FORMAT clause",
        "WITH TIMEZONE clause",
        "Query metric data",
        "Functions",
        "Aggregator functions",
        "aggregationendtime()",
        "apdex(attribute, t: )",
        "Get Apdex for specific customers",
        "Get Apdex for specific transaction",
        "Get overall Apdex for your app",
        "average(attribute)",
        "buckets(attribute, ceiling [,number of buckets])",
        "bucketPercentile(attribute)",
        "cardinality(attribute)",
        "count(*)",
        "derivative(attribute [,time interval])",
        "dimensions(include: {attributes}, exclude: {attributes})",
        "latestrate(attribute, time interval)",
        "Get the most recent rate of change of PageView Duration",
        "max(attribute)",
        "median(attribute)",
        "Median query",
        "min(attribute)",
        "minuteOf(attribute)",
        "mod(attribute, divisor)",
        "mod() within a WHERE clause condition",
        "mod() within a FACET clause",
        "percentage(function(attribute), WHERE condition)",
        "percentile(attribute [, percentile [, ...]])",
        "Basic percentile query",
        "predictLinear(attribute, [,time interval])",
        "rate(function(attribute) [,time interval])",
        "Basic rate query",
        "round(attribute)",
        "stddev(attribute)",
        "stdvar(attribute)",
        "sum(attribute)",
        "uniqueCount(attribute)",
        "uniques(attribute [,limit])",
        "Using tuple",
        "capture(attribute, regular expression)",
        "capture() within a SELECT clause condition",
        "capture() within a FACET clause condition",
        "capture() within a WHERE clause condition",
        "capture() with a numeric cast",
        "Non-aggregator functions",
        "earliest(attribute)",
        "Get earliest country per user agent from PageView",
        "eventType()",
        "Use eventType() in filter() function",
        "Use eventType() with FACET",
        "filter(function(attribute), WHERE condition)",
        "Analyze purchases that used offer codes",
        "funnel(attribute, steps)",
        "getField(attribute, field)",
        "histogram(attribute, ceiling [,number of buckets])",
        "Histogram of response times from PageView events",
        "Prometheus histogram buckets",
        "New Relic distribution metric",
        "Histogram with a FACET clause",
        "keyset()",
        "See all attributes for a data type",
        "latest(attribute)",
        "Get most recent country per user agent from PageView",
        "Type conversion"
      ],
      "title": "NRQL syntax, clauses, and functions",
      "type": "docs",
      "tags": [
        "Query your data",
        "NRQL: New Relic Query Language",
        "Get started"
      ],
      "external_id": "97c38ce7950d354d9f1d9efa5f432326f9bb4b00",
      "image": "https://docs.newrelic.com/static/507a44dd5750a7c536bee652e105179f/8c557/screen-apdex-function.png",
      "url": "https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/",
      "published_at": "2021-12-22T01:44:07Z",
      "updated_at": "2021-12-20T12:58:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "NRQL is a query language you can use to query the New Relic database. This document explains NRQL syntax, clauses, components, and functions. Syntax This document is a reference for the functions and clauses used in a NRQL query. Other resources for understanding NRQL: Intro to NRQL: explains what NRQL is used for, what data you can query with it, and basic NRQL syntax Examine NRQL queries used to build New Relic charts Learn how to query the Metric data type Use funnels to evaluate a series of related data Format NRQL for querying with the Event API Query components Every NRQL query will begin with a SELECT statement or a FROM clause. All other clauses are optional. The clause definitions below also contain example NRQL queries. Required clauses Required: SELECT statement SELECT attribute ... Copy SELECT function(attribute) ... Copy The SELECT specifies what portion of a data type you want to query by specifying an attribute or a function. It's followed by one or more arguments separated by commas. In each argument you can: Get the values of all available attributes by using * as a wildcard. For example: SELECT * from Transaction. Get values associated with a specified attribute or multiple attributes specified in a comma separated list. Get aggregated values from specified attributes by selecting an aggregator function. Label the results returned in each argument with the AS clause. You can also use SELECT with basic math functions. Avg response time since last week This query returns the average response time since last week. SELECT average(duration) FROM PageView SINCE 1 week ago Copy Required: FROM clause SELECT ... FROM data type ... Copy Use the FROM clause to specify the data type you wish to query. You can start your query with FROM or with SELECT. You can merge values for the same attributes across multiple data types in a comma separated list. Query one data type This query returns the count of all APM transactions over the last three days: SELECT count(*) FROM Transaction SINCE 3 days ago Copy Query multiple data types This query returns the count of all APM transactions and browser events over the last three days: SELECT count(*) FROM Transaction, PageView SINCE 3 days ago Copy Optional clauses AS clause SELECT ... AS 'label' ... Copy Use the AS clause to label an attribute, aggregator, step in a funnel, or the result of a math function with a string delimited by single quotes. The label is used in the resulting chart. Query using math function and AS This query returns the number of page views per session: SELECT count(*)/uniqueCount(session) AS 'Pageviews per Session' FROM PageView Copy Query using funnel and AS This query returns a count of people who have visited both the main page and the careers page of a site over the past week: SELECT funnel(SESSION, WHERE name='Controller/about/main' AS 'Step 1', WHERE name = 'Controller/about/careers' AS 'Step 2') FROM PageView SINCE 1 week ago Copy COMPARE WITH clause SELECT ... (SINCE or UNTIL) (integer units) AGO COMPARE WITH (integer units) AGO ... Copy Use the COMPARE WITH clause to compare the values for two different time ranges. COMPARE WITH requires a SINCE or UNTIL statement. The time specified by COMPARE WITH is relative to the time specified by SINCE or UNTIL. For example, SINCE 1 day ago COMPARE WITH 1 day ago compares yesterday with the day before. The time range for theCOMPARE WITH value is always the same as that specified by SINCE or UNTIL. For example, SINCE 2 hours ago COMPARE WITH 4 hours ago might compare 3:00pm through 5:00pm against 11:00am through 1:00pm. COMPARE WITH can be formatted as either a line chart or a billboard: With TIMESERIES, COMPARE WITH creates a line chart with the comparison mapped over time. Without TIMESERIES, COMPARE WITH generates a billboard with the current value and the percent change from the COMPARE WITH value. Example: This query returns data as a line chart showing the 95th percentile for the past hour compared to the same range one week ago. First as a single value, then as a line chart. SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO SELECT percentile(duration) FROM PageView SINCE 1 week ago COMPARE WITH 1 week AGO TIMESERIES AUTO Copy EXTRAPOLATE clause You can use this clause with these data types: Transaction TransactionError Custom events reported via APM agent APIs The purpose of EXTRAPOLATE is to mathematically compensate for the effects of APM agent sampling of event data so that query results more closely represent the total activity in your system. This clause will be useful when a APM agent reports so many events that it often passes its harvest cycle reporting limits. When that occurs, the agent begins to sample events. When EXTRAPOLATE is used in a NRQL query that supports its use, the ratio between the reported events and the total events is used to extrapolate a close approximation of the total unsampled data. When it is used in a NRQL query that doesn’t support its use or that hasn’t used sampled data, it has no effect. Important Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions: apdex average count histogram sum percentage (if function it takes as an argument supports EXTRAPOLATE) rate (if function it takes as an argument supports EXTRAPOLATE) stddev Example of extrapolating throughput A query that will show the extrapolated throughput of a service named interestingApplication. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago EXTRAPOLATE Copy Example of extrapolating throughput as a time series A query that will show the extrapolated throughput of a service named interestingApplication by transaction name, displayed as a time series. SELECT count(*) FROM Transaction WHERE appName='interestingApplication' SINCE 60 minutes ago FACET name TIMESERIES 1 minute EXTRAPOLATE Copy FACET clause SELECT ... FACET attribute ... Copy Use FACET to separate and group your results by attribute values. For example, you could FACET your PageView data by deviceType to figure out what percentage of your traffic comes from mobile, tablet, and desktop devices. Use the LIMIT clause to specify how many facets appear (default is 10). For more complex grouping, use FACET CASES. FACET clauses support up to five attributes, separated by commas. The facets are sorted in descending order by the first field you provide in the SELECT clause. If you are faceting on attributes with more than 2,000 unique values, a subset of facet values is selected and sorted according to the query type. When selecting min(), max(), percentile(), average() or count(), FACET uses those functions to determine how facets are picked and sorted. When selecting any other function, FACET uses the frequency of the attribute you are faceting on to determine how facets are picked and sorted. Faceted query using count() This query shows cities with the highest pageview counts. This query uses the total number of pageviews per city to determine how facets are picked and ordered. SELECT count(*) FROM PageView FACET city Copy Faceted query using uniqueCount() This query shows the cities that access the highest number of unique URLs. This query uses the total number of times a particular city appears in the results to determine how facets are picked and ordered. SELECT uniqueCount(pageUrl) FROM PageView FACET city Copy Grouping results across time Advanced segmentation and cohort analysis allow you to facet on bucket functions to more effectively break out your data. Cohort analysis is a way to group results together based on timestamps. You can separate them into buckets that cover a specified range of dates and times. FACET ... AS clause Use FACET ... AS to name facets using the AS keyword in queries. This clause is helpful for adding clearer or simplified names for facets in your results. It can also be used to rename facets in nested aggregation queries. FACET ... AS queries will change the facet names in results (when they appear as headers in tables, for example), but not the actual facet names themselves. FROM Transaction SELECT count(*) FACET response.headers.contentType AS 'content type' Copy FACET CASES clause SELECT ... FACET CASES ( WHERE attribute operator value, WHERE attribute operator value, ... ) ... Copy Use FACET CASES to break out your data by more complex conditions than possible with FACET. Separate multiple conditions with a comma ,. For example, you could query your PageView data and FACET CASES into categories like less than 1 second, from 1 to 10 seconds, and greater than 10 seconds. You can combine multiple attributes within your cases, and label the cases with the AS selector. Data points will be added to at most one facet case, the first facet case that they match. You may also use a time function with your attribute, and you can use the OR operator to facet results that don't match any of your specified cases. Basic usage with WHERE SELECT count(*) FROM PageView FACET CASES (WHERE duration < 1, WHERE duration > 1 and duration < 10, WHERE duration > 10) Copy Group based on multiple attributes This example groups results into one bucket where the transaction name contains login, and another where the URL contains login and a custom attribute indicates that the user was a paid user: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') Copy Label groups with AS This example uses the AS selector to give your results a human-readable name: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%' AS 'Total Logins', WHERE name LIKE '%feature%' AND customer_type='Paid' AS 'Feature Visits from Paid Users') Copy Facet non-matching data with OR This example uses the OR operator to facet results that didn't match any of your cases: SELECT count(*) FROM Transaction FACET CASES (WHERE name LIKE '%login%', WHERE name LIKE '%feature%' AND customer_type='Paid') OR name Copy FACET ... ORDER BY clause In NRQL, the default is for the first aggregation in the SELECT clause to guide the selection of facets in a query. FACET ... ORDER BY allows you to override this default behavior by adding an aggregate function with the ORDER BY modifier to specify how facets are selected. Specifically, the clause will override the priority by which facets are chosen to be in the final result before being limited by the LIMIT clause. This clause can be used in querying but not for alerts or streaming. This example shows how to use FACET ... ORDER BY to find the average durations of app transactions, showing the top 10 (default limit) highest durations by apps which have the highest response size. In this case, if FACET ... ORDER BY is not used, the query results will instead show the top 10 by highest durations, with response size being irrelevant to the app selection. FROM Transaction SELECT average(duration) TIMESERIES FACET appName ORDER BY max(responseSize) Copy Tip Because the operations are performed before the LIMIT clause is applied, FACET ... ORDER BY does not impact the sort of the final query results, which will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute1 ORDER BY attribute2, New Relic will read these as FACET ... ORDER BY queries, but only if ORDER BY appears immediately after FACET. Otherwise ORDER BY will be interpreted by New Relic as a clause. LIMIT clause SELECT ... LIMIT count ... Copy Use the LIMIT clause to control the maximum number of facet values returned by FACET queries or the maximum number of items returned by SELECT * queries. This clause takes a single integer value as an argument. If the LIMIT clause is not specified, or no value is provided, the limit defaults to 10 for FACET queries and 100 in the case of SELECT * queries. The maximum allowed value for the LIMIT clause is 2,000. Query using LIMIT This query shows the top 20 countries by session count and provides 95th percentile of response time for each country for Windows users only. SELECT uniqueCount(session), percentile(duration, 95) FROM PageView WHERE userAgentOS = 'Windows' FACET countryCode LIMIT 20 SINCE YESTERDAY Copy OFFSET clause SELECT ... LIMIT count OFFSET count ... Copy Use the OFFSET clause with LIMIT to control the portion of rows returned by SELECT * or SELECT column queries. Like the LIMIT clause, OFFSET takes a single integer value as an argument. OFFSET sets the number of rows to be skipped before the selected rows of your query are returned. This is constrained by LIMIT. OFFSET rows are skipped starting from the most recent record. For example, the query SELECT interestingValue FROM Minute_Report LIMIT 5 OFFSET 1 returns the last 5 values from Minute_Report except for the most recent one. ORDER BY clause The ORDER BY clause allows you to specify how you want to sort your query results in queries that select event attributes by row. This query orders transactions by duration. FROM Transaction SELECT appName, duration ORDER BY duration Copy The default sort order is ascending, but this can be changed by adding the ASC or DESC modifiers. SHOW EVENT TYPES clause SHOW EVENT TYPES... Copy SHOW EVENT TYPES will return a list of all the data types present in your account for a specific time range. It is used as the first clause in a query instead of SELECT. Important In this context, \"event types\" refers to the data types you can access with a NRQL query. Data types in the last day This query will return all the data types present over the past day: SHOW EVENT TYPES SINCE 1 day ago Copy SINCE clause SELECT ... SINCE [numerical units AGO | phrase] ... Copy The default value is 1 hour ago. Use the SINCE clause to define the beginning of a time range for the returned data. When using NRQL, you can set a UTC timestamp or relative time range. You can specify a timezone for the query but not for the results. NRQL results are based on your system time. SLIDE BY clause The SLIDE BY clause supports a feature known as sliding windows. With sliding windows,SLIDE BY data is gathered into \"windows\" of time that overlap with each other. These windows can help to smooth out line graphs with a lot of variation in cases where the rolling aggregate (such as a rolling mean) is more important than aggregates from narrow windows of time. To use SLIDE BY, place it in a query after the TIMESERIES clause. For example, this query pulls data in 5-minute windows with a 1-minute SLIDE BY interval, meaning that each window lasts 5 minutes, but window 1 starts at 0 minutes, window 2 starts at 1 minute, window 3 starts at 2 minutes, and so on. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY 1 minute Copy To learn more about how and when you can use SLIDE BY, see Create smoother charts with sliding windows. Use SLIDE BY with MAX or AUTO interval You can use sliding windows in combination with MAX or AUTO. However, MAX or AUTO may not be placed between TIMESERIES and SLIDE BY. This query will automatically decide a SLIDE BY window interval. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY AUTO Copy This query will set the SLIDE BY window to the maximum interval granularity. SELECT average(duration) FROM Transaction TIMESERIES 5 minutes SLIDE BY MAX Copy Important The SLIDE BY value as determined by AUTO or MAX can produce a step interval greater than the window size, which can cause gaps and unexpected results. TIMESERIES clause SELECT ... TIMESERIES integer units ... Copy Use the TIMESERIES clause to return data as a time series broken out by a specified period of time. Since TIMESERIES is used to trigger certain charts, there is no default value. To indicate the time range, use integer units. For example: TIMESERIES 1 minute TIMESERIES 30 minutes TIMESERIES 1 hour TIMESERIES 30 seconds TIMESERIES can be combined with arguments such as MAX, AUTO, and SLIDE BY to further tailor query results, as shown in the examples below. Important For functions such as average( ) or percentile( ), a large aggregation window can have a significant smoothing effect on outliers. This is true whether or not the query makes use of sliding windows. Use a set interval The value provided indicates the units used to break out the graph. For example, to present a one-day graph showing 30 minute increments: SELECT ... SINCE 1 day AGO TIMESERIES 30 minutes Copy Use an automatically set interval TIMESERIES can also be set to AUTO, which will divide your graph into a reasonable number of divisions. For example, a daily chart will be divided into 30 minute intervals and a weekly chart will be divided into 6 hour intervals. This query returns data as a line chart showing the 50th and 90th percentile of client-side transaction time for one week with a data point every 6 hours. SELECT average(duration), percentile(duration, 50, 90) FROM PageView SINCE 1 week AGO TIMESERIES AUTO Copy Use MAX interval You can set TIMESERIES to MAX, which will automatically adjust your time window to the maximum number of intervals allowed for a given time period. This allows you to update your time windows without having to manually update your TIMESERIES buckets and ensures your time window is being split into the peak number of intervals allowed. The maximum number of TIMESERIES buckets that will be returned is 366. For example, the following query creates 4-minute intervals, which is the ceiling for a daily chart. SELECT average(duration) FROM Transaction since 1 day ago TIMESERIES MAX Copy UNTIL clause SELECT ... UNTIL integer units AGO ... Copy The default value is NOW. Only use UNTIL to specify an end point other than the default. Use the UNTIL clause to define the end of a time range across which to return data. Once a time range has been specified, the data will be preserved and can be reviewed after the time range has ended. See Use the time picker to adjust time settings for detailed information and examples. WHERE clause Use the WHERE clause to filter results. NRQL returns the results that fulfill the condition(s) you specify in the clause. SELECT function(attribute) ... WHERE attribute [operator 'value' | IN ('value' [, 'value]) | IS [NOT] NULL ] [AND|OR ...] ... Copy If you specify more than one condition, separate the conditions by the operators AND or OR. If you want to simulate a SQL join, use custom attributes in a WHERE or FACET clause. Operators that the WHERE clause accepts Description =, !=, <, <=, >, >= NRQL accepts standard comparison operators. Example: state = 'WA' AND Used to define an intersection of two conditions. OR Used to define a union of two conditions. IS NULL Determines if an attribute has a null value. IS NOT NULL Determines if an attribute does not have a null value. IN Determines if the string value of an attribute is in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Example: animalType IN ('cat', 'dog', 'fish') NOT IN Determines if the string value of an attribute is not in a specified set. Using this method yields better performance than stringing together multiple WHERE clauses. Values must be in parentheses, separated by commas. For example: SELECT * FROM PageView WHERE countryCode NOT IN ('CA', 'WA') Copy LIKE Determines if an attribute contains a specified sub-string. The string argument for the LIKE operator accepts the percent sign (%) as a wildcard anywhere in the string. If the substring does not begin or end the string you are matching against, the wildcard must begin or end the string. Examples: userAgentName LIKE 'IE%' IE IE Mobile userAgentName LIKE 'o%a%' Opera Opera Mini userAgentName LIKE 'o%a' Opera userAgentName LIKE '%o%a%' Opera Opera Mini Mozilla Gecko NOT LIKE Determines if an attribute does not contain a specified sub-string. RLIKE Determines if an attribute contains a specified Regex sub-string. Uses RE2 syntax. Examples: appName RLIKE r'z.*|q.*'' hostname RLIKE r'ip-10-351-[0-2]?[0-9]-.*' z-app q-app ip-10-351-19-237 ip-10-351-2-41 ip-10-351-24-238 ip-10-351-14-15 Important Regex defaults to full-string matching, therefore ^ and $ are implicit and you do not need to add them. NOT RLIKE Determines if an attribute does not contain a specified Regex sub-string. Uses RE2 syntax. Example query with three conditions This query returns the browser response time for pages with checkout in the URL for Safari users in the United States and Canada over the past 24 hours. SELECT histogram(duration, 50, 20) FROM PageView WHERE countryCode IN ('CA', 'US') AND userAgentName='Safari' AND pageUrl LIKE '%checkout%' SINCE 1 day ago Copy WITH METRIC_FORMAT clause For information on querying metric data, see Query metrics. WITH TIMEZONE clause SELECT ... WITH TIMEZONE (selected zone) ... Copy By default, query results are displayed in the timezone of the browser you're using. Use the WITH TIMEZONE clause to select a time zone for a date or time in the query that hasn't already had a time zone specified for it. For example, the query clause SINCE Monday UNTIL Tuesday WITH TIMEZONE 'America/New_York' will return data recorded from Monday at midnight, Eastern Standard Time, until midnight Tuesday, Eastern Standard Time. Available Time Zone Selections Africa/Abidjan Africa/Addis_Ababa Africa/Algiers Africa/Blantyre Africa/Cairo Africa/Windhoek America/Adak America/Anchorage America/Araguaina America/Argentina/Buenos_Aires America/Belize America/Bogota America/Campo_Grande America/Cancun America/Caracas America/Chicago America/Chihuahua America/Dawson_Creek America/Denver America/Ensenada America/Glace_Bay America/Godthab America/Goose_Bay America/Havana America/La_Paz America/Los_Angeles America/Miquelon America/Montevideo America/New_York America/Noronha America/Santiago America/Sao_Paulo America/St_Johns Asia/Anadyr Asia/Bangkok Asia/Beirut Asia/Damascus Asia/Dhaka Asia/Dubai Asia/Gaza Asia/Hong_Kong Asia/Irkutsk Asia/Jerusalem Asia/Kabul Asia/Katmandu Asia/Kolkata Asia/Krasnoyarsk Asia/Magadan Asia/Novosibirsk Asia/Rangoon Asia/Seoul Asia/Tashkent Asia/Tehran Asia/Tokyo Asia/Vladivostok Asia/Yakutsk Asia/Yekaterinburg Asia/Yerevan Atlantic/Azores Atlantic/Cape_Verde Atlantic/Stanley Australia/Adelaide Australia/Brisbane Australia/Darwin Australia/Eucla Australia/Hobart Australia/Lord_Howe Australia/Perth Chile/EasterIsland Etc/GMT+10 Etc/GMT+8 Etc/GMT-11 Etc/GMT-12 Europe/Amsterdam Europe/Belfast Europe/Belgrade Europe/Brussels Europe/Dublin Europe/Lisbon Europe/London Europe/Minsk Europe/Moscow Pacific/Auckland Pacific/Chatham Pacific/Gambier Pacific/Kiritimati Pacific/Marquesas Pacific/Midway Pacific/Norfolk Pacific/Tongatapu UTC See Set time range on dashboards and charts for detailed information and examples. Query metric data Metric data is more complex than other types of data. There are specific tips for querying it well. We have two types of metric data, each with their own query guidelines: Query dimensional metrics, which are reported by our Metric API and by some of our solutions that use that API (for example, our Dropwizard integration or Micrometer integration). Query metric timeslice data, which is our original metric data type reported by our APM, mobile monitoring, and browser monitoring. For more details about how we report metric data, see Metric data types. Functions In this section we explain NRQL functions, both aggregator functions and non-aggregator functions. Aggregator functions You can use aggregator functions to filter and aggregate data. Some tips for using these: See New Relic University tutorials for Filter queries, Apdex queries, and Percentile queries. Or, go to the full online course Writing NRQL queries. If you're using an aggregator function multiple times in the same query (for example, SELECT median(one_metric), median(another_metric)), it can cause problems in displaying results. To solve this, use the AS function. For example: `SELECT median(one_metric) as 'med-a', median(another_metric) as 'med-b'` Copy Data type \"coercion\" is not supported. Read about available type conversion functions. For how to display results over time, see Group results over time. Examples: SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy aggregationendtime() Use the aggregationendtime() function to return the time of the relevant aggregation. More specifically, for a given aggregate, the aggregationendtime() function provides the timestamp of the end of the time period of that aggregation. For example, in a timeseries query, for a data point that encompasses an hour’s worth of data, the function would return the timestamp of the end of that hour period. apdex(attribute, t: ) Use the apdex function to return an Apdex score for a single transaction or for all your transactions. The attribute can be any attribute based on response time, such as duration or backendDuration. The t: argument defines an Apdex T threshold in the same unit of time as the chosen attribute. For instance, if the attribute is measured in seconds, t will be a threshold in seconds. The Apdex score returned by the apdex( ) function is based only on execution time. It does not account for APM errors. If a transaction includes an error but completes in Apdex T or less, that transaction will be rated satisfying by the apdex ( ) function. Get Apdex for specific customers If you have defined custom attributes, you can filter based on those attributes. For example, you could monitor the Apdex for a particularly important customer: SELECT apdex(duration, t: 0.4) FROM Transaction WHERE customerName='ReallyImportantCustomer' SINCE 1 day ago Copy Get Apdex for specific transaction Use the name attribute to return a score for a specific transaction, or return an overall Apdex by omitting name. This query returns an Apdex score for the Controller/notes/index transaction over the last hour: The apdex function returns an Apdex score that measures user satisfaction with your site. Arguments are a response time attribute and an Apdex T threshold in seconds. SELECT apdex(duration, t: 0.5) from Transaction WHERE name='Controller/notes/index' SINCE 1 hour ago Copy Get overall Apdex for your app This example query returns an overall Apdex for the application over the last three weeks: SELECT apdex(duration, t: 0.08) FROM Transaction SINCE 3 week ago Copy average(attribute) Use the average( ) function to return the average value for an attribute. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. buckets(attribute, ceiling [,number of buckets]) Use the buckets() function to aggregate data split up by a FACET clause into buckets based on ranges. You can bucket by any attribute that is stored as a numerical value in the New Relic database. It takes three arguments: Attribute name Maximum value of the sample range. Any outliers will appear in the final bucket. Total number of buckets For more information and examples, see Split your data into buckets. bucketPercentile(attribute) The bucketPercentile( ) function is the NRQL equivalent of the histogram_quantile function in Prometheus. It is intended to be used with dimensional metric data. Instead of the quantile, New Relic returns the percentile, which is the quantile * 100. Use the bucketPercentile( ) function to calculate the quantile from the histogram data in a Prometheus format. It takes the bucket name as an argument and reports percentiles along the bucket's boundaries: SELECT bucketPercentile(duration_bucket) FROM Metric SINCE 1 day ago Copy Optionally, you can add percentile specifications as an argument: SELECT bucketPercentile(duration_bucket, 50, 75, 90) FROM Metric SINCE 1 day ago Copy Because multiple metrics are used to make up Prometheus histogram data, you must query for specific Prometheus metrics in terms of the associated <basename>. For example, to compute percentiles from a Prometheus histogram, with the <basename> prometheus_http_request_duration_seconds using NRQL, use bucketPercentile(prometheus_http_request_duration_seconds_bucket, 50). Note how _ bucket is added to the end of the <basename> as a suffix. See the Prometheus.io documentation for more information. cardinality(attribute) Use the cardinality( ) function to obtain the number of combinations of all the dimensions (attributes) on a metric. It takes three arguments, all optional: Metric name: if present, cardinality( ) only computes the metric specified. Include: if present, the include list restricts the cardinality computation to those attributes. Exclude: if present, the exclude list causes those attributes to be ignored in the cardinality computation. SELECT cardinality(metric_name, include:{attribute_list}, exclude:{attribute_list}) Copy count(*) Use the count( ) function to return a count of available records. It takes a single argument; either *, an attribute, or a constant value. Currently, it follows typical SQL behavior and counts all records that have values for its argument. Since count(*) does not name a specific attribute, the results will be formatted in the default \"humanize\" format. derivative(attribute [,time interval]) derivative() finds the rate of change for a given dataset. The rate of change is calculated using a linear least-squares regression to approximate the derivative. Since this calculation requires comparing more than one datapoint, if only one datapoint is included in the evaluation range, the calculation is indeterminate and won't work, resulting in a null value. The time interval is the period for which the rate of change is calculated. For example, derivative(attributeName, 1 minute) will return the rate of change per minute. dimensions(include: {attributes}, exclude: {attributes}) Use the dimensions( ) function to return all the dimensional values on a data type. You can explicitly include or exclude specific attributes using the optional arguments: Include: if present, the include list limits dimensions( ) to those attributes. Exclude: if present, the dimensions( ) calculation ignores those attributes. FROM Metric SELECT count(node_filesystem_size) TIMESERIES FACET dimensions() Copy When used with a FACET clause, dimensions( ) produces a unique timeseries for all facets available on the event type, similar to how Prometheus behaves with non-aggregated queries. latestrate(attribute, time interval) Use the latestrate( ) function to return the rate of change of a value based on the last 2 data points. It takes the attribute in question as the first argument and the unit of time for the resulting rate as the second argument. The function returns a result in units of change in attribute/time interval. This function can be useful to provide the most recent rate of change for an attribute in order to see leading-edge trends. Get the most recent rate of change of PageView Duration This query returns the rate of change of duration based on the last 2 data points. It will be returned in units of duration/second because of the 1 SECOND argument. SELECT latestrate(duration, 1 SECOND) FROM PageView Copy max(attribute) Use the max( ) function to return the maximum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. median(attribute) Use the median( ) function to return an attribute's median, or 50th percentile. For more information about percentile queries, see percentile(). Tip The median( ) query is only available when using the query builder. Median query This query will generate a line chart for the median value. SELECT median(duration) FROM PageView TIMESERIES AUTO Copy min(attribute) Use the min( ) function to return the minimum recorded value of a numeric attribute over the time range specified. It takes a single attribute name as an argument. If a value of the attribute is not numeric, it will be ignored when aggregating. If data matching the query's conditions is not found, or there are no numeric values returned by the query, it will return a value of null. minuteOf(attribute) Use the minuteOf() function to extract only the minute portion (that is, seconds 0 to 59) of an attribute holding a valid timestamp value. mod(attribute, divisor) Use the mod( ) function to return the floor modulus after dividing the value of the provided numeric attribute (the first argument, or dividend) by a numeric value (the second argument, or divisor). This modulo operation can be used within a WHERE clause condition to filter to an arbitrary subset of results or within a FACET clause as a way to subdivide the result set. mod() within a WHERE clause condition FROM Transaction SELECT * WHERE mod(port, 2) = 1 Copy mod() within a FACET clause FROM NrDailyUsage SELECT uniques(hostId, 10000) SINCE 1 day AGO FACET mod(hostId, 10) Copy percentage(function(attribute), WHERE condition) Use the percentage( ) function to return the percentage of a target data set that matches some condition. The first argument requires an aggregator function against the desired attribute. Use exactly two arguments (arguments after the first two will be ignored). If the attribute is not numeric, this function returns a value of 100%. percentile(attribute [, percentile [, ...]]) Use the percentile( ) function to return an attribute's approximate value at a given percentile. It requires an attribute and can take any number of arguments representing percentile points. The percentile() function enables percentiles to displays with up to three digits after the decimal point, providing greater precision. Percentile thresholds may be specified as decimal values, but be aware that for most data sets, percentiles closer than 0.1 from each other will not be resolved. Percentile display examples Use TIMESERIES to generate a line chart with percentiles mapped over time. Omit TIMESERIES to generate a billboard and attribute sheet showing aggregate values for the percentiles. If no percentiles are listed, the default is the 95th percentile. To return only the 50th percentile value, the median, you can also use median(). Basic percentile query This query will generate a line chart with lines for the 5th, 50th, and 95th percentile. SELECT percentile(duration, 5, 50, 95) FROM PageView TIMESERIES AUTO Copy predictLinear(attribute, [,time interval]) predictLinear() is an extension of the derivative() function. It uses a similar method of least-squares linear regression to predict the future values for a dataset. The time interval is how far the query will look into the future. For example, predictLinear(attributeName, 1 hour) is a linear prediction 1 hour into the future of the query time window. Generally, predictLinear() is helpful for continuously growing values like disk space, or predictions on large trends. Since predictLinear() is a linear regression, familiarity with the dataset being queried helps to ensure accurate long-term predictions. Any dataset which grows exponentially, logarithmically, or by other nonlinear means will likely only be successful in very short-term predictions. New Relic recommends against using predictLinear in TIMESERIES queries. This is because each bucket will be making an individual prediction based on its relative timeframe within the query, meaning that such queries will not show predictions from the end of the timeseries forward. rate(function(attribute) [,time interval]) Use the rate( ) function to visualize the frequency or rate of a given query per time interval. For example, you might want to know the number of pageviews per minute over an hour-long period or the count of unique sessions on your site per hour over a day-long period. Use TIMESERIES to generate a line chart with rates mapped over time. Omit TIMESERIES to generate a billboard showing a single rate value averaged over time. Basic rate query This query will generate a line chart showing the rate of throughput for APM transactions per 10 minutes over the past 6 hours. SELECT rate(count(*), 10 minute) FROM Transaction SINCE 6 hours ago TIMESERIES Copy round(attribute) Use the round( ) function to return the rounded value of an attribute. Optionally round( ) can take a second argument, to_nearest, to round the first argument to the closest multiple of the second one. to_nearest can be fractional. SELECT round(n [, to_nearest]) Copy stddev(attribute) Use the stddev( ) function to return one standard deviation for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. stdvar(attribute) Use the stdvar( ) function to return the standard variance for a numeric attribute over the time range specified. It takes a single argument. If the attribute is not numeric, it will return a value of zero. sum(attribute) Use the sum( ) function to return the sum recorded values of a numeric attribute over the time range specified. It takes a single argument. Arguments after the first will be ignored. If the attribute is not numeric, it will return a value of zero. uniqueCount(attribute) Use the uniqueCount( ) function to return the number of unique values recorded for an attribute over the time range specified. Tip To optimize query performance, this function returns approximate results for queries that inspect more than 256 unique values. uniques(attribute [,limit]) Use the uniques( ) function to return a list of unique values recorded for an attribute over the time range specified. When used along with the facet clause, a list of unique attribute values will be returned per each facet value. The limit parameter is optional. When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000. The uniques( ) function will return the first set of unique attribute values discovered, until the limit is reached. Therefore, if you have 5,000 unique attribute values in your data set, and the limit is set to 1,000, the operator will return the first 1,000 unique values that it discovers, regardless of their frequency. The maximum number of values that can be returned in a query result is the product of the uniques( ) limit times the facet limit. In the following query, the theoretical maximum number of values that can be returned is 5 million (5,000 x 1,000). Depending on the data set being queried, and the complexity of the query, memory protection limits may prevent a very large query from being executed. From Transaction SELECT uniques(host,5000) FACET appName LIMIT 1000 Copy Using tuple If you'd like to know the unique combinations of a handful of attributes, you can structure a query in the format SELECT uniques(tuple(x, y, ... z)) ...` to get all the unique tuples of values, to maintain their relationship. In the following query, tuple is used on index and cellName together to find uniques where those two values occur in combination. FROM NodeStatus SELECT uniques(tuple(index, cellName), 5) Copy capture(attribute, regular expression) Use the capture() to extract values from an attribute using a regular expression. Uses RE2 syntax. It takes two arguments: Attribute name Regular expression with capture syntax. Regex expressions in NRQL use Python-like syntax, r'...'. When capturing, use the RE2 named-capture syntax ...(?P<name> pattern )... to capture the contained pattern, given the specified name. Currently, only 1 capture group is supported. Please see the examples below. capture() within a SELECT clause condition The following will select the domain name of the website, removing https:// and any paths following the .com SELECT capture(pageUrl, r'https://(?P<baseUrl>.*.com)/.+') FROM PageView SINCE 1 day ago Copy The following will capture only the first word of the error message. SELECT capture(errorMessage, r'(?P<firstWord>\\S+)\\s.+') FROM Transaction SINCE 1 hour ago where errorMessage is not null Copy capture() within a FACET clause condition The following will facet by the captured HTTP method. SELECT count(*) FROM Log WHERE message like '%HTTP%' FACET capture(message, r'.* \"(?P<httpMethod>[A-Z]+) .*') Copy capture() within a WHERE clause condition The following will filter the results based on Log events with message attribute that matches the regular expression where the captured job name is ExampleJob. SELECT message FROM Log WHERE capture(message, r'.*Job Failed: (?P<jobName>[A-Za-z]+),.*') = 'ExampleJob' SINCE 10 minutes ago Copy capture() with a numeric cast The following will capture sum of CPU Time from log lines. You must explicitly cast to numeric to do mathematical operations. SELECT sum(numeric(capture(message, r'.*CpuTime:\\s(?P<cpuTime>\\d+)'))) FROM Log WHERE message like '%CpuTime:%' SINCE 1 hour ago Copy Non-aggregator functions Use non-aggregator functions for non-numerical data in NRQL queries. earliest(attribute) Use the earliest( ) function to return the earliest value for an attribute over the specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get earliest country per user agent from PageView This query returns the earliest country code per each user agent from the PageView event. SELECT earliest(countryCode) FROM PageView FACET userAgentName Copy eventType() ...WHERE eventType() = 'EventNameHere'... ...FACET eventType()... Copy Use the eventType() function in a FACET clause to break out results by the selected data type or in a WHERE clause to filter results to a specific data type. This is particularly useful for targeting specific data types with the filter() and percentage() functions. Important In this context, \"event type\" refers to the types of data you can access with a NRQL query. Use eventType() in filter() function This query returns the percentage of total TransactionError results out of the total Transaction results. You can use the eventType() function to target specific types of data with the filter() function. SELECT 100 * filter(count(*), where eventType() = 'TransactionError') / filter(count(*), where eventType() = 'Transaction') FROM Transaction, TransactionError WHERE appName = 'App.Prod' TIMESERIES 2 Minutes SINCE 6 hours ago Copy Use eventType() with FACET This query displays a count of how many records each data type (Transaction and TransactionError) returns. SELECT count(*) FROM Transaction, TransactionError FACET eventType() TIMESERIES Copy filter(function(attribute), WHERE condition) Use the filter() function to limit the results for one of the aggregator functions in your SELECT statement. You can use filter() in conjunction with FACET or TIMESERIES. Filter is only useful when selecting multiple different aggregations such as SELECT filter(sum(x), WHERE attribute='a') AS 'A', filter(sum(x), WHERE attribute='b') AS 'B' .... Otherwise, it's better to just use the standard WHERE clause. Analyze purchases that used offer codes You could use filter() to compare the items bought in a set of transactions for those using an offer code versus those who aren't: Use the filter( ) function to limit the results for one of the aggregator functions in your SELECT statement. funnel(attribute, steps) Use the funnel() function to generate a funnel chart. It takes an attribute as its first argument. You then specify steps as WHERE clauses (with optional AS clauses for labels) separated by commas. For details and examples, see the funnels documentation. getField(attribute, field) Use the getField() function to extract a field from compound data types, such as metric data. It takes the following arguments: Metric type Supported fields summary count, total, max, min, type gauge count, total, max, min, latest, type distribution count, total, max, min, type counter count, type timeslice count, total, totalExclusive, min, and max Examples: SELECT max(getField(mySummary, count)) from Metric Copy SELECT sum(mySummary) from Metric where getField(mySummary, count) > 10 Copy histogram(attribute, ceiling [,number of buckets]) Use the histogram( ) function to generate histograms. It takes three arguments: Attribute name Maximum value of the sample range Total number of buckets (between 1 and 500, inclusive) Histogram of response times from PageView events This query results in a histogram of response times ranging up to 10 seconds over 20 buckets. SELECT histogram(duration, 10, 20) FROM PageView SINCE 1 week ago Copy Prometheus histogram buckets histogram( ) accepts Prometheus histogram buckets: SELECT histogram(duration_bucket, 10, 20) FROM Metric SINCE 1 week ago Copy New Relic distribution metric histogram( ) accepts Distribution metric as an input: SELECT histogram(myDistributionMetric, 10, 20) FROM Metric SINCE 1 week ago Copy Histogram with a FACET clause Use histogram( ) with a FACET clause to generate a heatmap chart: SELECT histogram(duration) FROM PageView FACET appName SINCE 1 week ago Copy keyset() Using keyset() will allow you to see all of the attributes for a given data type over a given time range. It takes no arguments. It returns a JSON structure containing groups of string-typed keys, numeric-typed keys, boolean-typed keys, and all keys. See all attributes for a data type This query returns the attributes found for PageView events from the last day: SELECT keyset() FROM PageView SINCE 1 day ago Copy latest(attribute) Use the latest( ) function to return the most recent value for an attribute over a specified time range. It takes a single argument. Arguments after the first will be ignored. If used in conjunction with a FACET it will return the most recent value for an attribute for each of the resulting facets. Get most recent country per user agent from PageView This query returns the most recent country code per each user agent from the PageView event. SELECT latest(countryCode) FROM PageView FACET userAgentName Copy Type conversion NRQL does not support \"coercion.\" This means that a float stored as a string is treated as a string and cannot be operated on by functions expecting float values. You can convert a string with a numeric value or a boolean with a string value to their numeric and boolean types with these functions: Use the numeric() function to convert a number with a string format to a numeric function. The function can be built into a query that uses math functions on query results or NRQL aggregator functions, such as average(). Use the boolean() function to convert a string value of \"true\" or \"false\" to the corresponding boolean value.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 121.41605,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "NRQL syntax, clauses, <em>and</em> functions",
        "sections": "<em>New</em> <em>Relic</em> distribution metric",
        "tags": "NRQL: <em>New</em> <em>Relic</em> Query Language",
        "body": " will be particularly noticeable in the results for non-timeseries queries. Important The ORDER BY modifier in this case works differently than the ORDER BY clause. When parsing queries that follow the format FACET attribute<em>1</em> ORDER BY attribute2, <em>New</em> <em>Relic</em> will read these as FACET ... ORDER BY queries"
      },
      "id": "604456c1196a678db8960f41"
    },
    {
      "sections": [
        "Query and alert on billing/usage data",
        "Available data types",
        "Query examples",
        "Data usage queries",
        "Daily data usage",
        "Daily usage by source",
        "Metrics ingest by source",
        "Month-to-date data usage",
        "Month-to-date estimated data cost",
        "User count queries",
        "Month-to-date full platform users",
        "Projected monthly full platform user count",
        "Count full platform users and basic users",
        "Set usage alerts",
        "Caution",
        "Ingested gigabytes exceed a fixed value",
        "Usage exceeds fixed threshold for GBs",
        "Usage exceeds fixed threshold for users",
        "Usage exceeds fixed threshold for estimated cost",
        "Available attributes"
      ],
      "title": "Query and alert on billing/usage data",
      "type": "docs",
      "tags": [
        "Accounts",
        "Accounts and billing",
        "New Relic One pricing and billing"
      ],
      "external_id": "e22ae9e26686d11726a82ad4036ff58520b4a439",
      "image": "",
      "url": "https://docs.newrelic.com/docs/accounts/accounts-billing/new-relic-one-pricing-billing/usage-queries-alerts/",
      "published_at": "2021-12-19T15:22:20Z",
      "updated_at": "2021-12-04T21:08:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "For accounts on our New Relic One pricing model, we provide a View your usage UI for understanding billing-related usage and a Manage your data UI for managing billing-related data. Additionally, you can: Query your usage data to get more detail than is available in the UI. Set up NRQL alert conditions to get notifications about changes in your usage. Note that account hierarchy may affect queried data. See Account structure. Available data types Usage data is attached to these events: NrConsumption records usage every hour, and is the equivalent of \"real-time\" usage. Use this event to observe usage trends over time. NrMTDConsumption generates aggregate values from the NrConsumption event. Use this event to see usage or estimated cost for a billing period. NrUsage records usage every hour and is used to see usage reported per product. To see changes made to your account (for example, user management changes), you can query NrAuditEvent. Query examples The View your usage UI displays your data usage and billable user count. If you need more detail than that UI provides, you can use these NRQL queries. For definitions of some of the attributes used in these queries, see Attributes. Data usage queries Here are some data usage query examples: Daily data usage This query totals your billable ingested data, and displays a daily value for the past three months: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago TIMESERIES 1 day Copy Daily usage by source This query totals your billable ingested data, and displays a daily value for the past three months faceted by the source: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE 3 months ago FACET usageMetric TIMESERIES 1 day Copy Metrics ingest by source This query breaks down Metric data by the top ten metric names. You could also facet by appName or host to adjust the analysis. FROM Metric SELECT bytecountestimate()/10e8 as 'GB Estimate' SINCE '2021-04-01' UNTIL '2021-04-08' FACET metricName LIMIT 10 TIMESERIES 1 day Copy Month-to-date data usage This query shows the current full platform user count. In other words, it shows how much you'd be billed for your data for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' SINCE this month Copy Month-to-date estimated data cost This query shows the estimated cost of your ingested data: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' SINCE this month Copy User count queries Here are some user-related query examples. For details on how users are counted, see User count calculations. Month-to-date full platform users This query shows the billable full platform users for the month. In other words, it shows how much you'd be billed for your users for that month if you were billed right now. FROM NrMTDConsumption SELECT latest(usersBillable) SINCE this month Copy This query shows how many full platform users were counted by hour. This is useful for seeing how the full platform user count changed over time. from NrConsumption SELECT max(FullUsers) SINCE 10 days ago TIMESERIES 1 hour Copy Projected monthly full platform user count This query shows a projected count of monthly users. This query would not be good for using in a dashboard; it requires values based on a) the days remaining in the month, b) the start of the month. Here's an example querying the projected end-of-month count with 10 days left in that month: FROM NrMTDConsumption SELECT predictLinear(FullUsers, 10 days) SINCE '2020-09-01' Copy Count full platform users and basic users The usage UI shows the count of full platform users and basic users. The query used is: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric Copy To see the count of full and basic users over time: FROM NrUsage SELECT max(usage) SINCE 10 days ago WHERE productLine='FullStackObservability' WHERE metric in ('FullUsers', 'BasicUsers') FACET metric TIMESERIES 1 hour Copy Set usage alerts To help manage your billable data, you can set alerts to notify you of unexpected increases in usage. Learn how to create alerts with NRQL queries here. Caution When creating alert conditions, you should use the Event Timer method, which works very well with infrequent data. Here are some NRQL alert condition examples. For attribute definitions, see Attributes. Ingested gigabytes exceed a fixed value This query will create an alert when your hourly usage exceeds a fixed value: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy If you have multiple child accounts, you may want to set threshold alerts for a specific subaccount: FROM NrConsumption SELECT sum(GigabytesIngested) WHERE productLine = 'DataPlatform' AND consumingAccountId = YOUR_CHILD-ACCOUNT_ID Copy Usage exceeds fixed threshold for GBs This query will create an alert when your usage exceeds fixed monthly threshold for GBs: FROM NrMTDConsumption SELECT latest(GigabytesIngested) WHERE productLine = 'DataPlatform' Copy Usage exceeds fixed threshold for users This query will create an alert when your usage exceeds fixed monthly threshold for billable users: FROM NrMTDConsumption SELECT latest(usersBillable) Copy Usage exceeds fixed threshold for estimated cost This query will create an alert when your usage exceeds fixed threshold for estimated cost: FROM NrMTDConsumption SELECT latest(estimatedCost) WHERE productLine = 'DataPlatform' Copy Available attributes Below are some of the important attributes attached to usage events. Attribute Description productLine The category of usage. There are three options: DataPlatform, FullStackObservability, and ProactiveDetection. (Starting November 1, 2021, IncidentIntelligence is no longer a billing factor). For more details about these categories, see New Relic platform. metric Consolidates multiple categories of usage into a single metric. Helpful when faceting by productLine. consumingAccountId ID of the New Relic account that is directly responsible for the stored events, as determined from the license key used. estimatedCost Calculates a cost estimate based on usage and metric cost. This is an estimate of costs to date, not your monthly invoice. For more attributes, see the data dictionary.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 114.46939,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Query <em>and</em> alert on billing&#x2F;usage data",
        "sections": "Query <em>and</em> alert on billing&#x2F;usage data",
        "tags": "<em>Accounts</em> <em>and</em> billing",
        "body": "For <em>accounts</em> on our <em>New</em> <em>Relic</em> One pricing model, we provide a View <em>your</em> usage UI for understanding billing-related usage and a Manage <em>your</em> data UI for managing billing-related data. Additionally, you can: Query <em>your</em> usage data to get more detail than is available in the UI. Set up NRQL alert"
      },
      "id": "6175f12b64441f53a35fc21c"
    },
    {
      "sections": [
        "Create a \"Hello, World!\" application",
        "Before you begin",
        "Tip",
        "Update and serve your application locally",
        "Publish your application",
        "Describe your project with catalog details",
        "Subscribe accounts to your application",
        "Summary"
      ],
      "title": "Create a \"Hello, World!\" application",
      "type": "developer",
      "tags": [
        "nr1 cli",
        "Nerdpack file structure",
        "NR One Catalog",
        "Subscribe applications"
      ],
      "external_id": "aa427030169067481fb69a3560798265b6b52b7c",
      "image": "https://developer.newrelic.com/static/6817b94358dddb2a9bef51e734df5bc4/0086b/hello-world-output-local.png",
      "url": "https://developer.newrelic.com/build-apps/build-hello-world-app/",
      "published_at": "2021-12-22T01:37:28Z",
      "updated_at": "2021-12-18T01:37:38Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Build a \"Hello, World!\" app and publish it to New Relic One",
      "body": "Here's how you build a \"Hello, world!\" application in New Relic One. In this guide, you: Create a local version of the New Relic One site where you prototype your application Share your application with your teammates by publishing it to Instant Observability Before you begin Developing applications requires a New Relic account and the New Relic One CLI (nr1). If you haven't already: Sign up for a New Relic account. You need publish and subscribe permissions to complete this guide. Install Node.js Complete the CLI quick start Now, you have a Nerdpack, called my-awesome-nerdpack. This Nerdpack has a Nerdlet and a launcher that you named (though, this guide uses the default launcher name, \"launcher\", and Nerdlet name, \"home\"). You use this Nerdpack throughout this guide. Finally, make sure your nr1 is up-to-date: bash Copy $ nr1 update For additional details about setting up your environment, see Set up your development environment and Enable advanced configurations for your Nerdpack. Tip If you use VSCode, we have an extension and an extension pack you can use to build your app. Update and serve your application locally With nr1, you can serve a local build of your Nerdpack to New Relic One. This helps you develop your application in a production-like environment before you publish it. Before you change any code, familiarize yourself with the Nerdpack's directory structure: my-awesome-nerdpack/ ├───README.md ├───launchers/ │ └───launcher/ │ └───nr1.json ├───nerdlets/ │ └───home │ ├───index.js │ ├───nr1.json │ └───styles.scss ├───node_modules/ ├───nr1.json ├───package-lock.json └───package.json Copy The launchers and nerdlets directories contain the logic of your application. It's in these directories that you update most of your code. The nr1.json files throughout the Nerdpack hold metadata about your Nerdpack, Nerdlets, and launchers. Tip Read our documentation to learn more about the Nerdpack file structure. Step 1 of 6 In my-awesome-nerdpack/nerdlets/home/index.js, change the default return message to \"Hello, world!\": import React from 'react'; // https://docs.newrelic.com/docs/new-relic-programmable-platform-introduction export default class HomeNerdlet extends React.Component { render() { return <h1>Hello, world!</h1>; } } Copy Step 2 of 6 As an optional step, you can add a custom launcher icon using any image named icon.png. In launchers/launcher, add an image called icon.png: my-awesome-nerdpack/ ├───README.md ├───launchers/ │ └───launcher/ │ ├───icon.png │ └───nr1.json ├───nerdlets/ │ └───home │ ├───index.js │ ├───nr1.json │ └───styles.scss ├───node_modules/ ├───nr1.json ├───package-lock.json └───package.json Copy This creates an icon for your launcher. In the root directory, add the same image: my-awesome-nerdpack/ ├───README.md ├───icon.png ├───launchers/ │ └───launcher/ │ ├───icon.png │ └───nr1.json ├───nerdlets/ │ └───home │ ├───index.js │ ├───nr1.json │ └───styles.scss ├───node_modules/ ├───nr1.json ├───package-lock.json └───package.json Copy This sets the icon for the app details page. Step 3 of 6 Next, change the name of the launcher to something more meaningful. In my-awesome-nerdpack/launchers/launcher/nr1.json, change the displayName to \"Hello world\": { \"schemaType\": \"LAUNCHER\", \"id\": \"my-awesome-nerdpack-launcher\", \"description\": \"Describe me\", \"displayName\": \"Hello world\", \"rootNerdletId\": \"my-awesome-nerdpack-nerdlet\" } Copy Step 4 of 6 To see your new changes locally, start a local Node server from within the Nerdpack: bash Copy $ nr1 nerdpack:serve Found and loaded 2 nr1.json files on MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g1hi2) Nerdpack. Nerdpack: ✔ MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g1hi2) nr1.json Launchers: ✔ launcher launchers/launcher/nr1.json Nerdlets: ✔ home nerdlets/home/nr1.json There is no certificate created yet. ✔ New certificate created. Webpack bundle analyzer is enabled (you need to wait for the first build to finish) └ You can head to http://127.0.0.1:27888 NOTE: To verify how your assets will look in production, you need to add \"--mode=prod\" when starting the development server. 🛠 Built artifact files for:ex.js... ⁎ 123a4b95-678c-9012-3456-d7e8f90g1hi2--home built ✔ ✔ Nerdpack built successfully! ★ Starting as orchestrator... ✔ Server ready! Test it at: https://one.newrelic.com/?nerdpacks=local ↩ Server will reload automatically if you modify any file! ℹ Additionally, you can test the following artifacts at: Launchers: ⁎ launcher https://onenr.io/0JBQrggmDwZ ℹ You can use \"npm start -- --mode=prod\" to run the development server in prod mode. Step 5 of 6 Use the url at the bottom of the output to open your launcher: bash Copy Launchers: ⁎ launcher https://onenr.io/0JBQrggmDwZ ℹ You can use \"npm start -- --mode=prod\" to run the development server in prod mode. Step 6 of 6 Here, you see your Nerdlet with your \"Hello, world!\" message: Publish your application Because you're serving your Nerdpack locally, your colleagues can't see it. When you're ready, publish it to Instant Observability, our unified catalog of integrations, dashboards, alerts, Nerdpacks, and more. Read our documentation to learn about Nerdpack permissions if you have trouble publishing your Nerdpack. Step 1 of 3 From its root directory, publish your Nerdpack: bash Copy $ nr1 nerdpack:publish Found and loaded 2 nr1.json files on MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g1hi2) Nerdpack. Nerdpack: ✔ MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g1hi2) nr1.json Launchers: ✔ launcher launchers/launcher/nr1.json Nerdlets: ✔ home nerdlets/home/nr1.json 🛠 Built artifact files for: ⁎ 123a4b95-678c-9012-3456-d7e8f90g1hi2--home built ✔ ✔ Nerdpack built successfully! Publishing Nerdpack MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g1hi2) ✔ Nerdpack published successfully! ✔ Tagged 123a4b95-678c-9012-3456-d7e8f90g1hi2 version 0.1.0 as STABLE. Step 2 of 3 In New Relic, click Instant Observability: Step 3 of 3 Find and click your new Nerdpack: When your new application opens, notice that it doesn't display any descriptive information. The next section shows you how to add descriptive metadata. Describe your project with catalog details Now that your new application is in Instant Observability, you can add information to help users understand what your application does and how to use it. Step 1 of 4 In your Nerdpack's root directory, execute the following: bash Copy $ nr1 create --type catalog ✔ created: launchers/launcher/catalog ✔ created: nerdlets/home/catalog ✔ catalog created successfully! catalog is available at \"./catalog\" This creates three directories: launchers/launcher/catalog: This holds launcher screenshots nerdlets/home/catalog: This holds Nerdlet screenshots catalog: This holds documentation, screenshots, a description, and more information about your Nerdpack Tip If you had other launchers, Nerdlets, or custom visualizations, they would also get catalog directories from this command. Here's how the results look in your project: my-awesome-nerdpack/ ├───README.md ├───icon.png ├───catalog/ │ ├───README.md │ ├───additionalInfo.md │ ├───config.json │ ├───documentation.md │ └───screenshots/ ├───launchers/ │ └───launcher/ │ ├───icon.png │ ├───catalog/ │ │ └───screenshots/ │ └───nr1.json ├───nerdlets/ │ └───home │ ├───index.js │ ├───nr1.json │ ├───catalog/ │ │ └───screenshots/ │ └───styles.scss ├───node_modules/ ├───nr1.json ├───package-lock.json └───package.json Copy Step 2 of 4 In the root catalog directory of your project, add screenshots or various types of metadata to describe your project. You can also add screenshots in the catalog directories of your launcher or Nerdlet. For details about what you can add, see Update your Nerdpack's catalog metadata. Step 3 of 4 After you add the screenshots and descriptions you want, execute the following to save your metadata to the Instant Observability catalog: bash Copy $ nr1 catalog:submit Step 4 of 4 Return to Instant Observability and refresh the page to see your new screenshots and metadata describing your project. And if you added screenshots to your launcher or Nerdlet, you can see them under What's inside: Subscribe accounts to your application You need to subscribe to your application to use it. To learn about what users on your account have the ability to subscribe, read our permissions documentation. Step 1 of 5 If you're not already there, navigate to your application in Instant Observability: Step 2 of 5 On your application's description page, click Add this app: Step 3 of 5 Select the accounts that you want to subscribe to the application, then update your accounts: Step 4 of 5 Go to the Apps page: Here, you find the apps your accounts are susbscribed to. Step 5 of 5 Click your launcher: Here, you see your application: Summary Now that you've completed the steps in this example, you learned the basic steps to: Create a local application Publish the application to Instant Observability so you can share it with your colleagues Add details to the project in the catalog so users understand how to use it Subscribe accounts to your application so other users can use it",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 113.63045,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Subscribe <em>accounts</em> to <em>your</em> application",
        "info": "Build a &quot;Hello, World!&quot; app <em>and</em> publish it to <em>New</em> <em>Relic</em> One",
        "body": " successfully! Publishing Nerdpack MyAwesomeNerdpack (123a4b95-678c-9012-3456-d7e8f90g<em>1</em>hi2) ✔ Nerdpack published successfully! ✔ Tagged 123a4b95-678c-9012-3456-d7e8f90g<em>1</em>hi2 version 0.<em>1</em>.0 as STABLE. <em>Step</em> 2 of 3 In <em>New</em> <em>Relic</em>, click Instant Observability: <em>Step</em> 3 of 3 Find and click <em>your</em> <em>new</em> Nerdpack: When"
      },
      "id": "6091f9c864441f70d82f36c4"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda": [
    {
      "image": "https://developer.newrelic.com/static/f22f2f9b68bb3a2c69b68a3ee063554e/0086b/otel-data.png",
      "url": "https://developer.newrelic.com/collect-data/opentelemetry/view/",
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "lab",
        "View your data",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-22T01:43:57Z",
      "title": "View your OpenTelemetry data in New Relic",
      "updated_at": "2021-12-22T01:43:57Z",
      "type": "developer",
      "external_id": "1a149f37a72e22fbc350c958a716652817d4dfa1",
      "document_type": "page",
      "popularity": 1,
      "info": "View your OpenTelemetry data in New Relic",
      "body": "lab This procedure is part of a lab that teaches you how to instrument your application with OpenTelemetry. Each procedure in the lab builds upon the last, so make sure you've completed the last procedure, Instrument your application with OpenTelemetry, before starting this one. You've instrumented your weather forecast application with OpenTelemetry and you're sending metric and trace data to New Relic. Here, you move to New Relic to see the kinds of detailed telemetry data that OpenTelemetry was able to collect automatically with just a few lines of SDK code. View your data Step 1 of 8 Log into New Relic. Step 2 of 8 In the entity explorer, click the Weather-Forecast OpenTelemetry service: This brings you to a service view that shows trace data from your application, including: Response time Throughput Error rate Step 3 of 8 In the left-hand navigation, click Distributed tracing: This shows trace data that the OpenTelemetry SDK automatically captured in your service, such as: Trace count Trace duration Trace groups Step 4 of 8 Under Trace groups click the WeatherForecast group: This group shows similar traces. Since your application has only one endpoint, all traces are grouped together. Step 5 of 8 Click one of the traces: Because your weather application is simple, there is only one span in the trace. Step 6 of 8 Click on the span: Here, you see information about the particular span, including not only performance metrics, but also attributes that OpenTelemetry sent. Step 7 of 8 Click Attributes: You configured many of the attributes you see here in your SDK code. Step 8 of 8 While New Relic doesn't yet have a curated experience for .NET OpenTelemetry metrics data, you can see the metrics in the metrics explorer: Summary As the developer of WeatherForecast, you've now instrumented your application with OpenTelemetry to send automatically collected metrics and traces to New Relic. And because you instrumented your app with OpenTelemetry instead of a .NET agent, you are more flexible in how you can use your data. For example, if you want to add additional backend data sources besides New Relic, you can easily change that without having to add another vendor-specific agent. Homework Now that you know how to instrument a .NET application with OpenTelemetry and send that data to New Relic, here are some things you can do next to familiarize yourself even more with New Relic and OpenTelemetry: Check out our repository of OpenTelemetry examples Learn more about OpenTelemetry's .NET SDK Read our documentation on New Relic + OpenTelemetry",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 118.900536,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " together. <em>Step</em> <em>5</em> of 8 Click one of the traces: Because your weather application is simple, there is only one span in the trace. <em>Step</em> 6 of 8 Click on the span: Here, you see information about the particular span, including not only performance metrics, but also attributes that OpenTelemetry sent"
      },
      "id": "61c282dd64441f3aebc53c5f"
    },
    {
      "sections": [
        "Populate your alert configurations with NerdGraph",
        "Important",
        "Set up your quickstart's alerts directory",
        "Look up your alert's condition ID",
        "Query alert conditions in NerdGraph",
        "Query your static alert condition",
        "Tip",
        "Query your baseline alert condition",
        "Summary"
      ],
      "title": "Populate your alert configurations with NerdGraph",
      "type": "developer",
      "tags": [
        "nerdgraph query components",
        "quickstart"
      ],
      "external_id": "8b4b19743ae8b2f1b8b222df1244044b71697220",
      "image": "https://developer.newrelic.com/static/dff07d9a1d9bc95aa1aea42233563152/0086b/static-query-response.png",
      "url": "https://developer.newrelic.com/contribute-to-quickstarts/query-alerts-for-quickstart/",
      "published_at": "2021-12-22T01:39:15Z",
      "updated_at": "2021-12-22T01:39:14Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Use NerdGraph to query your existing alert configurations, and add those configurations to your quickstart.",
      "body": "With a quickstart, you let your users quickly install dashboards, alerts, and other resources. Here, you learn how to use New Relic's GraphQL API, NerdGraph, to query your existing alert conditions and configure them in your quickstart. Important This guide assumes you already have alerts in your New Relic account and a quickstart that you want to add those alerts to. If you don't already have a quickstart, follow our lab to learn how to build one. Set up your quickstart's alerts directory This guide assumes you have a quickstart. However, your quickstart may or may not already have alerts. Either way, to add alerts to your quickstart, you need an alerts directory. If your quickstart already has one, you can skip this section. The _template directory of New Relic One quickstarts contains an alerts template folder. Copy this folder to your quickstart. From here, you use the YAML file that corresponds to the alert condition type you want to add to your quickstart. Once your quickstart is ready to add alerts, you need to look up your alert condition's ID. Look up your alert's condition ID To populate your alert configurations with NerdGraph, you first need to look up its identifier. Step 1 of 5 From your New Relic homepage, go to Alerts & AI. Step 2 of 5 Click Policies in left hand navigation. Step 3 of 5 Choose your policy from the list. Step 4 of 5 Here, you see the list of conditions. Choose the condition that you want to query. Step 5 of 5 On the Next page, you see ID, Account, and Policy associated with the condition. Copy the ID. With this identifier, you can now query your alert conditions and use the response to build out alert resources in your quickstart. Query alert conditions in NerdGraph There are three types of alerts you can have in New Relic: Static Baseline Jump to the appropriate section for the kind of alert you want to add to your quickstart. Query your static alert condition Step 1 of 4 Open the NerdGraph API explorer and select your key from the dropdown menu. Step 2 of 4 Copy the following GraphQL query and paste it in the center pane of the explorer. { actor { account(id: REPLACE_ACCOUNT_ID) { alerts { nrqlCondition(id: REPLACE_CONDITION_ID) { ... on AlertsNrqlStaticCondition { id name type nrql { query } valueFunction terms { operator priority threshold thresholdDuration thresholdOccurrences } violationTimeLimitSeconds } } } } } } Copy Here, you query AlertsNrqlStaticCondition for your condition's ID, name, query and more. These are the required fields you need to create the same alert in your quickstart. Important Make sure you replace your account ID and condition ID in the above query. Step 3 of 4 Execute the query to get a JSON representation of the specified condition. Next, use this response to add a static alert to your quickstart. Tip Notice the checkboxes in the left-hand pane get checked when you paste the query in the explorer. This query returns the fields required to add alert to the quickstart. If you've set custom fields or want to query more information, feel free to either edit the query in the center pane of the explorer or check the corresponding box in the left-hand pane. Step 4 of 4 Populate static-alert.yml from your alerts quickstart folder with the data returned from your query. Given the example response from the last step, our file looks like: --- # Name of the alert name: Static Condition # Description and details details: |+ This alert is triggered whenever the host count is < 2. # Type of alert type: STATIC # NRQL query nrql: query: \"SELECT uniqueCount(host) FROM Transaction\" # Function used to aggregate the NRQL query value(s) for comparison to the terms.threshold (Default: SINGLE_VALUE) valueFunction: SINGLE_VALUE # List of Critical and Warning thresholds for the condition terms: - priority: CRITICAL # Operator used to compare against the threshold. operator: BELOW # Value that triggers a violation threshold: 2 # Time in seconds; 120 - 3600 thresholdDuration: 300 # How many data points must be in violation for the duration thresholdOccurrences: AT_LEAST_ONCE # Duration after which a violation automatically closes # Time in seconds; 300 - 2592000 (Default: 86400 [1 day]) violationTimeLimitSeconds: 259200 Copy Here, you added a static alert to your quickstart. If it's helpful, you can rename this file to whatever you want. Query your baseline alert condition Step 1 of 4 Open the NerdGraph API explorer and select your key from the dropdown menu. Step 2 of 4 Copy the following GraphQL query and paste it in the center pane of the explorer. { actor { account(id: REPLACE_ACCOUNT_ID) { alerts { nrqlCondition(id: REPLACE_CONDITION_ID) { ... on AlertsNrqlBaselineCondition { id name nrql { query } baselineDirection terms { priority threshold thresholdDuration thresholdOccurrences } violationTimeLimitSeconds } } } } } } Copy Here, you query AlertsNrqlBaselineCondition for your condition's name, query, baselineDirection, and other fields required to add the condition to your quickstart. Important Make sure you replace your account ID and condition ID in the above query. Step 3 of 4 Execute the query to get the configuration data of your alert. Next, use this response to add baseline alert to your quickstart. Tip Notice the checkboxes in the left-hand pane get checked when you paste the query in the explorer. This query returns the fields required to add alert to the quickstart. If you've set custom fields or want to query more information, feel free to either edit the query in the center pane of the explorer or check the corresponding box in the left-hand pane. Step 4 of 4 Populate baseline-alert.yml from your alerts quickstart folder with the data returned from your query. Given the example response from the last step, our file looks like: --- # Name of the alert name: Baseline Condition # Description and details details: |+ This alert is triggered whenever the average Transaction duration deviates 2 standard deviations from the normal. # Type of alert type: BASELINE # NRQL query nrql: # Baseline alerts can use an optional FACET query: \"SELECT average(duration) FROM Transaction\" # Direction in which baseline is set (Default: LOWER_ONLY) baselineDirection: UPPER_ONLY # List of Critical and Warning thresholds for the condition terms: - priority: CRITICAL # Value that triggers a violation threshold: 2 # Time in seconds; 120 - 3600, must be a multiple of 60 for Baseline conditions thresholdDuration: 180 # How many data points must be in violation for the duration thresholdOccurrences: ALL # Duration after which a violation automatically closes # Time in seconds; 300 - 2592000 (Default: 86400 [1 day]) violationTimeLimitSeconds: 259200 Copy Here, you added a baseline alert to your quickstart. If it's helpful, you can rename this file to whatever you want. Summary In this guide, you learned how to query your existing alert conditions using NerdGraph and how to use the query's JSON response to populate corresponding alert files in quickstart. Read our documentation to learn more about: Alerts Building quickstarts",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 110.50798,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Populate your alert <em>configurations</em> with NerdGraph",
        "sections": "Populate your alert <em>configurations</em> with NerdGraph",
        "info": "Use NerdGraph to query your existing alert <em>configurations</em>, and add those <em>configurations</em> to your quickstart.",
        "body": ". <em>Step</em> 1 of <em>5</em> From your New Relic homepage, go to Alerts &amp; AI. <em>Step</em> 2 of <em>5</em> Click Policies in left hand navigation. <em>Step</em> 3 of <em>5</em> Choose your policy from the list. <em>Step</em> 4 of <em>5</em> Here, you see the list of conditions. Choose the condition that you want to query. <em>Step</em> <em>5</em> of <em>5</em> On the Next page, you see ID"
      },
      "id": "617b50fa28ccbcad47822e01"
    },
    {
      "sections": [
        "Using Terragrunt to Manage Multiple Environments",
        "Before you begin",
        "Create a configuration",
        "Add to your configuration",
        "Tip",
        "Use your environment as a Terragrunt variable",
        "Move your state to remote storage",
        "Create a new environment",
        "Conclusion"
      ],
      "title": "Using Terragrunt to Manage Multiple Environments",
      "type": "developer",
      "tags": [
        "notification channel",
        "alerts",
        "terraform"
      ],
      "external_id": "4bf455aad61b7703def538f147b8954af49c4e15",
      "image": "",
      "url": "https://developer.newrelic.com/terraform/terragrunt-configuration/",
      "published_at": "2021-12-19T13:54:13Z",
      "updated_at": "2021-12-19T01:46:40Z",
      "document_type": "page",
      "popularity": 1,
      "info": "Learn how to use [Terragrunt](https://www.terraform.io/) to manage configurations in multiple environments",
      "body": "Terraform is a popular infrastructure-as-code software tool built by HashiCorp. You use it to provision all kinds of infrastructure and services, including New Relic dashboards and alerts. Terragrunt is a thin wrapper around Terraform that provides extra tools for: Reducing repetition Working with multiple Terraform modules Managing remote state In this guide, you use Terragrunt to: Generate your Terraform configurations Create files Manage multiple environments Before you begin To use this guide, you should have some basic knowledge of both New Relic and Terraform. If you haven't already: Install the New Relic Infrastructure agent on your host Install the Terraform CLI Install Terragrunt To follow the examples in this guide, you can find example code on GitHub. Create a configuration Terragrunt provides extra tooling for your Terraform configurations. Here, you create a configuration using Terragrunt, Terraform, and New Relic. Step 1 of 14 Initialize a workspace: bash Copy $ mkdir terragrunt-config && cd terragrunt-config Step 2 of 14 In your new folder, create a terragrunt.hcl file: bash Copy $ touch terragrunt.hcl Step 3 of 14 Next, create an environments folder with a subfolder called dev: bash Copy $ mkdir -p environments/dev Step 4 of 14 Then, create a src folder with main.tf and provider.tf files: bash Copy $ mkdir src $ touch src/main.tf $ touch src/provider.tf You configure Terraform resources in main.tf and providers in provider.tf. Step 5 of 14 In src/provider.tf, configure a New Relic provider. terraform { required_version = \"~> 0.14.3\" required_providers { newrelic = { source = \"newrelic/newrelic\" version = \"~> 2.14.0\" } } } Copy Step 6 of 14 In src/main.tf, add a New Relic alert policy named DemoPolicy: resource \"newrelic_alert_policy\" \"DemoPolicy\" { name = \"My Demo Policy\" } Copy Step 7 of 14 In environments/dev, create a file named terragrunt.hcl: bash Copy $ touch environments/dev/terragrunt.hcl Step 8 of 14 In it, add the following include statement: include { path = find_in_parent_folders() } Copy This instructs Terragrunt to use any .hcl configuration files it finds in parent folders. Step 9 of 14 Add a terraform block to give Terragrunt a source reference: include { path = find_in_parent_folders() } terraform { source = \"../../src\" } Copy Step 10 of 14 In src/provider.tf, configure the New Relic provider with an API key, account ID, and region: terraform { required_version = \"~> 0.14.3\" required_providers { newrelic = { source = \"newrelic/newrelic\" version = \"~> 2.14.0\" } } } variable \"newrelic_personal_apikey\" {} variable \"newrelic_account_id\" {} variable \"newrelic_region\" {} provider \"newrelic\" { account_id = var.newrelic_account_id api_key = var.newrelic_personal_apikey region = var.newrelic_region } Copy You use variables to keep your configuration dynamic. Step 11 of 14 In environments/dev, initialize terragrunt: bash Copy $ terragrunt init This sets up a bit of context, including environment variables, then runs terraform init: bash Copy Terraform has created a lock file .terraform.lock.hcl to record the provider selections it made above. Include this file in your version control repository so that Terraform can guarantee to make the same selections by default when you run \"terraform init\" in the future. Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. [terragrunt] [/workspace/terragrunt-config/environments/dev] 2021/02/02 13:30:31 Copying lock file [output] from /workspace/terragrunt-config/environments/dev/.terragrunt-cache/e-PoBgWhdv3v8QGOtDQxS_WeYu4/ 69zjIFUfApJiUt8gFmi-6-dcPe8/.terraform.lock.hcl to /workspace/terragrunt-config/environments/dev Step 12 of 14 In environments/dev/terragrunt.hcl, add an inputs block to provide values for your New Relic account variables: inputs = { newrelic_personal_apikey = \"NRAK-***\" # Your New Relic account ID newrelic_account_id = \"12345\" # Your New Relic account ID newrelic_region = \"US\" # US or EU (defaults to US) } Copy Step 13 of 14 Now, run terragrunt plan: bash Copy An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: # newrelic_alert_policy.DemoPolicy will be created + resource \"newrelic_alert_policy\" \"DemoPolicy\" { + account_id = (known after apply) + id = (known after apply) + incident_preference = \"PER_POLICY\" + name = \"My Demo Policy\" } Plan: 1 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. Terragrunt provides the inputs block's values. Step 14 of 14 Run terragrunt apply: bash Copy $ terragrunt apply Now your Demo Policy is in your New Relic account. Add to your configuration Now that you've created a basic New Relic configuration, add the configurations from our Getting Started with Terraform and Terraform modules guides. Tip If you haven't done these guides yet, you can copy their configurations from the Terragrunt intro Github repo. Step 1 of 2 In src/main.tf, update the email address in the alert channel to your preferred email address: resource \"newrelic_alert_policy\" \"DemoPolicy\" { name = \"My Demo Policy\" } resource \"newrelic_alert_channel\" \"DemoChannel\" { name = \"My Demo Channel\" type = \"email\" config { recipients = \"your@email_address.com\" include_json_attachment = \"1\" } } resource \"newrelic_alert_policy_channel\" \"ChannelSubs\" { policy_id = newrelic_alert_policy.DemoPolicy.id channel_ids = [ newrelic_alert_channel.DemoChannel.id ] } module \"HostConditions\" { source = \"git::https://github.com/jsbnr/demo-terraform.git\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = 88 cpu_warning = 78 diskPercent = 68 } Copy Here, you added a New Relic alert channel, subscribed the demo policy to the alert channel, and added a module hosted on Github. Step 2 of 2 Run terragrunt init and then run terragrunt apply: bash Copy $ terragrunt init $ terragrunt apply After Terraform finishes processing, your alert policy has two conditions and one alert channel. Use your environment as a Terragrunt variable With Terragrunt, you can add the name of the environment you're running to the name of the data you're creating, making your resource more identifiable in New Relic. Step 1 of 9 In the root terragrunt.hcl file, create an input for env_name: inputs = { env_name = \"develop\" } Copy Step 2 of 9 In the src/main.tf, file add a new variable called env_name: variable \"env_name\" {} Copy Step 3 of 9 Add the new env_name variable to the alert policy and alert channel resource blocks: resource \"newrelic_alert_policy\" \"DemoPolicy\" { name = \"${var.env_name}: My Demo Policy\" } resource \"newrelic_alert_channel\" \"DemoChannel\" { name = \"${env_name}: My Demo Channel\" type = \"email\" config { recipients = \"your@email_address.com\" include_json_attachment = \"1\" } } Copy Step 4 of 9 Run terragrunt plan to see the environment variable added to your policy name: bash Copy # newrelic_alert_policy.DemoPolicy will be updated in-place ~ resource \"newrelic_alert_policy\" \"DemoPolicy\" { id = \"1216533\" ~ name = \"My Demo Policy\" -> \"develop: My Demo Policy\" # (2 unchanged attributes hidden) } # newrelic_alert_policy_channel.ChannelSubs must be replaced -/+ resource \"newrelic_alert_policy_channel\" \"ChannelSubs\" { ~ channel_ids = [ - 4737437, ] -> (known after apply) # forces replacement ~ id = \"1216533:4737437\" -> (known after apply) # (1 unchanged attribute hidden) } Here, you hardcoded the environment in terragrunt.hcl. To make this more dynamic, use a terragrunt built-in function to get the environment for you. Step 5 of 9 In the root terragrunt.hcl file, update the input to use path_relative_to_include(), and pass the value as the env_name variable: inputs = { env_name = path_relative_to_include() } Copy Step 6 of 9 Run terragrunt plan: bash Copy # newrelic_alert_policy.DemoPolicy will be updated in-place ~ resource \"newrelic_alert_policy\" \"DemoPolicy\" { id = \"1216533\" ~ name = \"My Demo Policy\" -> \"environments/dev: My Demo Policy\" # (2 unchanged attributes hidden) } # newrelic_alert_policy_channel.ChannelSubs must be replaced -/+ resource \"newrelic_alert_policy_channel\" \"ChannelSubs\" { ~ channel_ids = [ - 4737437, ] -> (known after apply) # forces replacement ~ id = \"1216533:4737437\" -> (known after apply) # (1 unchanged attribute hidden) } Plan: 2 to add, 1 to change, 2 to destroy. Note that the env_name variable has the entire ./environments/dev/ path. Instead, you want to include only the \"dev\" part. Step 7 of 9 Update the terragrunt.hcl to strip \"environements/\" from env_name: locals { env_name = replace(path_relative_to_include(), \"environments/\", \"\") } inputs = { env_name = local.env_name } Copy Here, you added a locals block to create a local variable and used the built-in replace function to remove the unwanted parts of the relative path. Then, you updated the inputs block to use the local variable. Step 8 of 9 Run terragrunt plan: bash Copy # newrelic_alert_policy.DemoPolicy will be updated in-place ~ resource \"newrelic_alert_policy\" \"DemoPolicy\" { id = \"1216533\" ~ name = \"My Demo Policy\" -> \"dev: My Demo Policy\" # (2 unchanged attributes hidden) } # newrelic_alert_policy_channel.ChannelSubs must be replaced -/+ resource \"newrelic_alert_policy_channel\" \"ChannelSubs\" { ~ channel_ids = [ - 4737437, ] -> (known after apply) # forces replacement ~ id = \"1216533:4737437\" -> (known after apply) # (1 unchanged attribute hidden) } Plan: 2 to add, 1 to change, 2 to destroy. Your new policy name is \"dev: My Demo Policy\". Step 9 of 9 Run terragrunt apply to update your configurations: bash Copy $ terragrunt apply Move your state to remote storage At the moment, your state file is local. Now, you update your Terraform configurations to store it in Amazon S3. Tip Since Terragrunt allows you to configure multiple environments, you should store state files in their own S3 buckets so they don't overwrite each other. Step 1 of 4 Create an S3 bucket for you development state file. Step 2 of 4 Create an IAM user with permissions to store files in your bucket. Step 3 of 4 In your root terragrunt.hcl, add a remote_state block that tells Terragrunt where to place your file in S3: remote_state { backend = \"s3\" generate = { path = \"backend.tf\" if_exists = \"overwrite_terragrunt\" } config = { bucket = \"YOUR_S3_BUCKET_NAME\" # Amazon S3 bucket required key = \"envs/${local.env_name}/terraform.tfstate\" region = \"us-east-1\" encrypt = true profile = \"YOUR_PROFILE_NAME\" # Profile name required } } Copy Here, you defined a remote state configuration that specifies a bucket name, region, encryption, and profile. Make sure you replace the placeholder values with real ones. For key, you used the local env_name you created earlier to dynamically set the environment for the state file. Finally, you told Terragrunt to generate a new file called backend.tf in your bucket. Step 4 of 4 Run terragrunt plan: bash Copy $ terragrunt plan In your bucket, you see a folder named envs. Inside it is a folder called devs containing a terraform.tfstate file. Tip Inside envs/dev, there is a hidden folder named terragrunt-cache. In it, is the backend.tf file that Terragrunt generated. Create a new environment Now that you've configured your development environment, create another that reuses most of your work. Step 1 of 8 Under environments, create a folder named nonprod. In it, create a file called terragrunt.hcl: bash Copy $ mkdir nonprod && cd nonprod $ touch terragrunt.hcl Step 2 of 8 In environments/nonprod/terragrunt.hcl, copy the configuration from the environments/dev/terragrunt.hcl: include { path= find_in_parent_folders() } terraform { source = \"../../src\" } inputs = { newrelic_personal_apikey = \"NRAK-***\" # Your New Relic account ID newrelic_account_id = \"12345\" # Your New Relic account ID newrelic_region = \"US\" # US or EU (defaults to US) } Copy Tip If you're using a different account for your nonprod environment, update inputs with a new account ID, API key, and region. Step 3 of 8 Inside nonprod, run terragrunt init and terragrunt apply: bash Copy $ terragrunt init $ terragrunt apply Terraform creates a new set of resources prefixed with \"nonprod:\". Now, you've created two environments, dev and nonprod, but they're the same, other than their name. Step 4 of 8 In src/main.tf, add new variables for the Host Conditions module: variable \"cpu_critical\" {default = 89} variable \"cpu_warningl\" {default = 79} variable \"diskPercentage\" {default = 69} Copy Using variables like these makes your configurations more dynamic. Step 5 of 8 Update HostConditions to use the cpu_critical, cpu_warning, and diskPercentage variables: module \"HostConditions\" { source = \"git::https://github.com/jsbnr/demo-terraform.git\" policyId = newrelic_alert_policy.DemoPolicy.id cpu_critical = var.cpu_critical cpu_warning = var.cpu_warninig diskPercent = var.dskPercentage } Copy Step 6 of 8 Run terragrunt plan: bash Copy $ terragrunt plan The HostConditions values now include the variable defaults. Step 7 of 8 In nonprod/terragrunt.hcl, add values for your variables: inputs = { newrelic_personal_apikey = \"NRAK-***\" # Your New Relic account ID newrelic_account_id = \"12345\" # Your New Relic account ID newrelic_region = \"US\" # US or EU (defaults to US) cpu_critical = 50 cpu_warninig = 40 diskPercentage = 98 } Copy This passes the values into your environment configurations. Step 8 of 8 Run terragrunt apply: bash Copy $ terragrunt apply In your New Relic account, you have a new policy with nonprod-specific configurations. Conclusion Congratulations! You've used Terragrunt to generate New Relic configurations and manage multiple environments. Review the Terragrunt intro example, New Relic Terraform provider documentation, and Terragrunt quick start to learn how you can take your configuration to the next level.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 103.80974,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Create a <em>configuration</em>",
        "info": "Learn how to use [Terragrunt](https:&#x2F;&#x2F;www.terraform.io&#x2F;) to manage <em>configurations</em> in multiple environments",
        "body": " with a subfolder called dev: bash Copy $ mkdir -p environments&#x2F;dev <em>Step</em> 4 of 14 Then, create a src folder with main.tf and provider.tf files: bash Copy $ mkdir src $ touch src&#x2F;main.tf $ touch src&#x2F;provider.tf You configure Terraform resources in main.tf and providers in provider.tf. <em>Step</em> <em>5</em> of 14 In src&#x2F;provider.tf"
      },
      "id": "6091fa9964441fe25f2f36f4"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-aws-lambda-monitoring": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/go-release-notes/go-agent-390/",
      "sections": [
        "Go agent v3.9.0",
        "3.9.0",
        "Changes"
      ],
      "published_at": "2021-12-19T23:04:20Z",
      "title": "Go agent v3.9.0",
      "updated_at": "2021-09-20T19:23:48Z",
      "type": "docs",
      "external_id": "b4a315226fb28d6e060d53538a35278656cd807f",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "3.9.0 Changes When sending Serverless telemetry using the nrlambda integration, support an externally-managed named pipe. The articles below provide additional instructions on support for an externally-managed named pipe in lambdas: Legacy manual instrumentation Enable monitoring for AWS Lambda Layer installation instructions Sample Go application",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1593.4502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "3.9.0 Changes When sending Serverless telemetry using the nrlambda integration, support an externally-managed named pipe. The articles below provide additional instructions on support for an externally-managed named pipe in lambdas: Legacy manual instrumentation <em>Enable</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> Layer installation instructions Sample Go application"
      },
      "id": "603e7b0ee7b9d213522a07e3"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/configure-serverless-monitoring-aws-lambda/",
      "sections": [
        "Step 5: Additional configuration",
        "Set up alerts",
        "Add custom events"
      ],
      "published_at": "2021-12-20T02:53:49Z",
      "title": "Step 5: Additional configuration",
      "updated_at": "2021-08-27T08:19:45Z",
      "type": "docs",
      "external_id": "7ccc0cbc8f96ad38d90cfa4e6c12b53f8ebfcbb4",
      "document_type": "page",
      "popularity": 1,
      "body": "After you enable serverless monitoring for AWS Lambda, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can monitor with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about setting up alerts on Lambda functions, see monitoring for AWS Lambda: Configuring alerts Add custom events Besides the data we provide by default, you can also set up your own events or attributes. For details about these language-specific settings, see Configuring custom attributes and events in AWS Lambda.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1171.626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "After you <em>enable</em> serverless <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, you can add additional configuration to fine-tune your data. Set up alerts Our alerts let you get notifications on anything you can <em>monitor</em> with New Relic, including APM metrics, key transactions, NRQL queries, and more. For details about"
      },
      "id": "603e94df196a676d7ea83ddc"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-12-20T04:58:46Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 704.08734,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot <em>enabling</em> serverless <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot <em>enabling</em> serverless <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to <em>enable</em> serverless <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy": [
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/release-notes/agent-release-notes/go-release-notes/go-agent-390/",
      "sections": [
        "Go agent v3.9.0",
        "3.9.0",
        "Changes"
      ],
      "published_at": "2021-12-19T23:04:20Z",
      "title": "Go agent v3.9.0",
      "updated_at": "2021-09-20T19:23:48Z",
      "type": "docs",
      "external_id": "b4a315226fb28d6e060d53538a35278656cd807f",
      "document_type": "release_notes",
      "popularity": 1,
      "body": "3.9.0 Changes When sending Serverless telemetry using the nrlambda integration, support an externally-managed named pipe. The articles below provide additional instructions on support for an externally-managed named pipe in lambdas: Legacy manual instrumentation Enable monitoring for AWS Lambda Layer installation instructions Sample Go application",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1363.9147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": "3.9.0 Changes When sending Serverless telemetry using the nrlambda integration, support an externally-managed named pipe. The articles below provide additional instructions on support for an externally-managed named pipe in lambdas: <em>Legacy</em> <em>manual</em> <em>instrumentation</em> Enable <em>monitoring</em> for AWS <em>Lambda</em> Layer installation instructions Sample Go application"
      },
      "id": "603e7b0ee7b9d213522a07e3"
    },
    {
      "sections": [
        "Lambda monitoring architecture",
        "The New Relic Lambda monitoring stack",
        "Your function",
        "New Relic agent or SDK",
        "New Relic Lambda Extension",
        "New Relic's backend",
        "Lambda UI in New Relic One",
        "The legacy CloudWatch path"
      ],
      "title": "Lambda monitoring architecture",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Background",
        "Architecture"
      ],
      "external_id": "61c238aabc54923ed6f7d08d9a0cc111193f72a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture/",
      "published_at": "2021-12-20T06:06:23Z",
      "updated_at": "2021-12-05T04:36:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Lambda monitoring stack There are several important parts to Lambda monitoring: Your function The New Relic agent or SDK The New Relic Lambda Extension New Relic's backend The New Relic One Lambda UI Your function Your function is the code you want to understand. You want to know when it's encountering errors, why it's slow, or how often it gets invoked. New Relic agent or SDK This is a library that New Relic provides for the language that your function is written in. Its job is to do the actual monitoring of your code. It measures the duration of your function invocations, notes errors that occur, records details about the source events, and your functions responses. To do this, it needs to wrap around your Lambda invocation handler function. With a bit more work on your part, you can break your invocation into interesting segments, and tie together the interaction of your function with other functions and services, providing a holistic view of your serverless application. New Relic Lambda Extension This sidecar process runs inside the Lambda execution environment, alongside your code. It enhances the telemetry that the agent collects, and sends it to New Relic's back end in batches. It can also send your function's logs to New Relic. The extension is a small application that integrates tightly with the AWS Lambda lifecycle, and works to minimize both the time it takes your telemetry to arrive at New Relic, and the impact that instrumentation has on your function's latency and throughput. See more about our Lambda extension. New Relic's backend The New Relic service receives your telemetry, processes it into AwsLambdaInvocation, AwsLambdaInvocationError, Span, and custom events, and stores all that in our telemetry database: NRDB. Lambda UI in New Relic One Lambda functions aren't quite like traditional services, so the experience of managing them is a little different from the classic APM experience. Inside New Relic One, Lambda functions have a custom UI, which quickly surfaces the most important information about your function, and integrates closely with our logging and distributed tracing features. Backed by NRDB and NRQL, you can also write custom dashboards and alerts for your functions. The legacy CloudWatch path Older integrations send telemetry in a slightly different way. Instead of passing telemetry off to the extension, the agent writes it out to CloudWatch as a log line. By adding a log subscription filter to pipe your function logs into the aws-log-ingestion Lambda function, we can recover that Cloudwatch log line, and forward it on to New Relic, along with some other platform telemetry. In the past, we've seen that this approach has some considerable drawbacks. The AWS CloudWatch service can generate a lot of data. If you're on the free tier, you may hit your data limit pretty quickly. If you're paying for data, you may find this service making up the largest share of the data you're sending to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 126.11343,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Lambda</em> <em>monitoring</em> architecture",
        "sections": "<em>Lambda</em> <em>monitoring</em> architecture",
        "tags": "AWS <em>Lambda</em> <em>monitoring</em>",
        "body": "The New Relic <em>Lambda</em> <em>monitoring</em> stack There are several important parts to <em>Lambda</em> <em>monitoring</em>: Your function The New Relic agent or SDK The New Relic <em>Lambda</em> Extension New Relic&#x27;s backend The New Relic One <em>Lambda</em> UI Your function Your function is the code you want to understand. You want to know when"
      },
      "id": "605ab190196a67fc8238d740"
    },
    {
      "sections": [
        "Compatibility and requirements for the Java agent",
        "Requirements to install the agent",
        "JVM",
        "Tip",
        "Security requirements",
        "Use of other monitoring software",
        "Built-in instrumentation",
        "App/Web servers",
        "Frameworks and libraries",
        "HTTP and messaging",
        "Datastores",
        "Instance-level database information",
        "Hosting services",
        "Asynchronous instrumentation",
        "Other instrumented features",
        "Connect the agent to other New Relic products"
      ],
      "title": "Compatibility and requirements for the Java agent",
      "type": "docs",
      "tags": [
        "Agents",
        "Java agent",
        "Getting started"
      ],
      "external_id": "2e87a574d5fcccc5f5775c0030f57d39d6672097",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apm/agents/java-agent/getting-started/compatibility-requirements-java-agent/",
      "published_at": "2021-12-22T01:42:25Z",
      "updated_at": "2021-12-19T16:46:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's Java agent includes built-in instrumentation of the most popular parts of the Java ecosystem, including app servers, frameworks, databases, and message queuing systems. For frameworks and libraries that are not instrumented out of the box, you can extend the agent with Java custom instrumentation. Want to try out New Relic's Java agent? Create a New Relic account for free! No credit card required. Requirements to install the agent Before you install the Java agent, ensure your system meets these requirements: JVM Tip The Java agent is compatible with any JVM-based language, including: Java, Scala, Kotlin, and Clojure. For instrumentation support for language-specific features, see the Automatically instrumented frameworks and libraries section below. In order to continue to innovate and efficiently provide new capabilities to our customers, we'll occasionally need to drop support for older JVM versions. When that happens, you can continue using a version of the agent that supports your older JVM version, but new features and fixes won't be included in those older agent versions. We recommend upgrading to a currently supported JVM version to take advantage of the latest agent releases. Please see the table of compatible agent versions to determine which JVM versions are compatible. Java version Compatible agent versions Java 5 Agent v1.3.0 to v2.21.7 Java 6 Agent v3.0.0 to v4.3.0 Java 7 Agent v3.0.0 to v6.5.0 and v6.5.2 Java 8 Agent v3.10.0 to current Java 9 Agent v3.43.0 to current Java 10 Agent v4.4.0 to current Java 11 Agent v4.7.0 to current Java 12 Agent v4.12.0 to current Java 13 Agent v5.7.0 to current Java 14 Agent v5.11.0 to current Java 15 Agent v6.1.0 to current Java 16 Agent v7.3.0 to current Java 17 Agent v7.4.0 to current Compatible: IBM JVM versions 8 for Linux Eclipse OpenJ9 versions 8 to 13 for Linux, Windows, and macOS OpenJDK and AdoptOpenJDK JVM versions 8 to 16 for Linux, Windows, and macOS Oracle Hotspot JVM versions 8 to 16 for Linux, Solaris, Windows, and macOS Azul Zing JVM versions 8 and 11 for Linux, Windows, and macOS Azul Zulu JVM versions 8 to 12 for Linux, Windows, and macOS Amazon Corretto JVM versions 8 and 11 for Linux, Windows, and macOS Alibaba Dragonwell JVM versions 8 and 11 for Linux, Windows, and macOS (Java 1.7) Compatible only with Java agent 6.5.x [ ZIP | 15.4 MB] legacy agent: OpenJDK and AdoptOpenJDK JVM versions 7 IBM JVM version 7 Oracle Hotspot JVM version 7 for Linux, Solaris, Windows, macOS (Java 1.6) Compatible only with Java agent 4.3.x [ ZIP | 9.9 MB] legacy agent: Apple Hotspot JVM version 6 for macOS IBM JVM version 6 Oracle Hotspot JVM version 6.0 for Linux, Solaris, Windows, macOS (Java 1.5) Compatible only with Java agent 2.21.x [ ZIP | 2.8 MB] legacy agent: Oracle Hotspot JVM version 5.0 for Linux, Solaris, Windows, macOS (Java SE 5.0) Oracle JRockit up to and including 1.6.0_50 Security requirements As a standard security measure for data collection, your app server must support SHA-2 (256-bit). SHA-1 is not supported. Use of other monitoring software If your application uses other application monitoring software besides our agent, we cannot guarantee that our agent will work correctly and we cannot offer technical support. For more information, see Errors while using other monitoring software. Built-in instrumentation After you install the Java agent, it automatically instruments many popular frameworks and libraries. With automatic instrumentation, the agent collects rich data out of the box, and data will show up in your New Relic dashboards within minutes of installation. Even if your library is not automatically instrumented, you can still collect data with custom instrumentation and the Java agent API. The agent automatically instruments these frameworks and libraries: App/Web servers The agent automatically instruments the following app/web servers. To install the Java agent on supported app/web servers, see Install the Java agent. ColdFusion 10 Glassfish 3.0 to 5.x JBoss 7.0 to latest JBoss EAP 6.0 + Jetty 7.0.0.M3 to 9.4.x Mule ESB 3.4 to 3.8.x Netty 3.3.0.Alpha1 to 5.0.0.Alpha1 Resin 3.1.9 to 4.0.x Spray-can 1.3.1 to latest Tomcat 7.0.0 to 9.0.x TomEE 1.5 to 8.0.x WebLogic 12.1.2.1 to 12.2.x WebSphere 8.5.x to 9.x WebSphere Liberty Profile 8.5 to latest WildFly 8.0.0.Final to latest Frameworks and libraries The agent automatically instruments the following frameworks. To install the Java agent on supported frameworks, see Install the Java agent. Akka 2.2.0-RC1 to latest AmazonS3 client 1.2.13 to latest AmazonSNS and AmazonSNSAsync clients 1.11.12 to latest AmazonSQS and AmazonSQSAsync clients 1.3.22 to latest Cats Effect v2 Scala 2.12: 2.1 to latest Scala 2.13: 2.1 to latest GraphQL 16.0 - 16.2 GraphQL 17.0 to latest S3Client 2.1.0 to latest SnsClient 2.1.0 to latest SqsClient 2.1.0 to latest CXF 2.1.3 to latest Grails 1.3.7 to 2.3.x Hibernate 3.3.0.CR1 to 6.0.0.Alpha2 Hystrix 1.3.15 to latest JAX-RS 1.0 to 2.0 JCache API 1.0.0 to latest Jersey 1.0.1 to 2.x JSF (Java Server Faces) Play 2.3.0 to latest Quartz Job Scheduler 1.8.3 to 2.2.x RESTEasy 2.2-RC-1 to latest Spray 1.3.1 to latest Spring 3.0.0.RELEASE to latest Spring webclient 5.0.0.RELEASE to latest Spring Web Services from 1.5.7 to latest Spring Boot 1.4.x to latest Struts 2 Thrift 0.8.0 to latest Vert.x 3.2.0 to 3.8.3 ZIO Scala 2.13: 1.0.9 to 2.0.0-M2 HTTP and messaging The agent automatically instruments the following HTTP clients and messaging services. For instructions, see Install the Java agent. Akka HTTP 2.4.5 to latest Akka Http Core from 0.4 to latest AsyncHttpClient 2.0.0-RC1 to latest gRPC 1.4.0 to 1.39.0 HTTP4s Blaze client Scala 2.12: 0.21 - 0.23.0-M1 Scala 2.13: 0.21 - 0.23.0-M1 HTTP4s Blaze server Scala 2.12: 0.21 - 0.22.0-M8 Scala 2.13: 0.21 - 0.22.0-M8 HttpAsyncClient 4.1 to latest Apache Httpclient from 3.0 to latest java.net.HttpURLConnection JMS and Spring-JMS 1.1 to latest Kafka Clients 0.10.0.0 to 2.8.1 (for metric and event data) Kafka Clients 0.11.0.0 to latest (for distributed tracing, metric, and event data) OkHttp 3.x to 4.3.x Ning AsyncHttpClient 1.x Play WS 2.6.0 to latest RabbitMQ 1.7.2 to latest (AMQP and JMS) Spray-client 1.3.1 to latest Spring webclient from 5.0.0.release to latest STTP v2 Scala 2.12: 2.2.3 to latest 2.x Scala 2.13: 2.2.3 to latest 2.x, 3.0.0 to latest 3.x Datastores New Relic currently supports MySQL and PostgreSQL to capture explain plans for slow database queries. Amazon v1 DynamoDB 1.11.106 to latest Amazon v2 DynamoDB 2.1.0 to latest Anorm from 2.0 to 2.5 DataStax Cassandra 2.1.2 to 4.0.0 (If you use high security, see the configuration documentation for allow lists.) DB2 9.1 to latest Derby 10.2.1.6 to latest Generic JDBC (any JDBC compliant driver) H2 1.0.57 to latest HSQL 1.7.2.2 to latest INet Oracle Driver (Oranxo) 3.06, 3.14 INet MERLIA 7.0.3, 8.04.03, and 8.06 Jedis Redis driver 1.4.0 to 2.10.x, 3.0.0 to latest jTDS 1.2 to latest MariaDB 1.1.7 or higher Microsoft SQL Server 1.2 to latest MongoDB 2.12.0-rc0 to latest (synchronous clients only) MySQL mysql-connector-java 3.0.8 to latest Oracle ojdbc5, ojdbc6, ojdbc7, ojdbc8, ojdbc10, ojdbc14 Postgres 8.0-312.jdbc3 to latest Slick 3.0.0 to latest Solr 4.0 to latest Spymemcached 2.11 to latest Sybase (jConnect) JDBC 3 driver 6.0 to latest Instance-level database information New Relic collects instance details for a variety of databases and database drivers. The ability to view specific instances and the types of database information in APM depends on your New Relic agent version. New Relic's Java agent versions 3.33.0 or higher support the following: Any compatible JDBC driver Amazon DynamoDB 1.11.106 or higher DataStax Cassandra driver 2.1.2 to 4.0.0 Jedis Redis driver 1.4 to 2.10.x, 3.0.0 to latest Mongo 2.12.0 to latest (synchronous clients only)/li> Spymemcached 2.11.0 to 2.12.x Exception: Instance-level information is not reported for calls to the getBulk() API method. The Java agent reports the database name and database server/identifier attributes on slow query traces and transaction traces for these database drivers. To request instance-level information from additional datastores, get support at support.newrelic.com. Hosting services You can install the Java agent on a variety of hosting services, including ones not listed below. Here are detailed installation guides for particular hosting services: Google App Engine (GAE) flexible environment Heroku Asynchronous instrumentation For supported frameworks, the Java agent usually instruments async work automatically. However, you can use the Java agent API to extend this instrumentation. Other instrumented features EJB Session Beans 3.0 or higher JMX JSP (Java Server Pages) 2.0 to 2.2 Scala 2.9.3 to 2.13.x Connect the agent to other New Relic products The Java agent integrates with other New Relic products to give you end-to-end visibility: Product Integration Browser monitoring The Java agent automatically injects the browser JavaScript agent when you enable auto-instrumentation. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and manual instrumentation, see Browser monitoring and the Java agent. Infrastructure monitoring When you install the Infrastructure and APM agents on the same host, they automatically detect one another. You can then view a list of hosts in the APM UI, and filter your Infrastructure hosts by APM app in the Infrastructure UI. For more information, see APM data in Infrastructure. New Relic One dashboards The Java agent sends default events and attributes to dashboards, or you can run NRQL queries in the query builder. You can also record custom events for advanced analysis. Synthetic monitoring Synthetic transaction traces connect requests from Synthetics monitors to the underlying APM transaction.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 123.69429,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements <em>for</em> the Java agent",
        "sections": "Use of other <em>monitoring</em> software",
        "body": " JavaScript agent when you enable auto-<em>instrumentation</em>. After enabling browser injection, you can view browser data in the APM Summary page and quickly switch between the APM and browser data for a particular app. For configuration options and <em>manual</em> <em>instrumentation</em>, see Browser <em>monitoring</em>"
      },
      "id": "617e61a1196a670ec4f7d6cf"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example": [
    {
      "image": "https://developer.newrelic.com/static/f22f2f9b68bb3a2c69b68a3ee063554e/0086b/otel-data.png",
      "url": "https://developer.newrelic.com/collect-data/opentelemetry/view/",
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "lab",
        "View your data",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-22T01:43:57Z",
      "title": "View your OpenTelemetry data in New Relic",
      "updated_at": "2021-12-22T01:43:57Z",
      "type": "developer",
      "external_id": "1a149f37a72e22fbc350c958a716652817d4dfa1",
      "document_type": "page",
      "popularity": 1,
      "info": "View your OpenTelemetry data in New Relic",
      "body": "lab This procedure is part of a lab that teaches you how to instrument your application with OpenTelemetry. Each procedure in the lab builds upon the last, so make sure you've completed the last procedure, Instrument your application with OpenTelemetry, before starting this one. You've instrumented your weather forecast application with OpenTelemetry and you're sending metric and trace data to New Relic. Here, you move to New Relic to see the kinds of detailed telemetry data that OpenTelemetry was able to collect automatically with just a few lines of SDK code. View your data Step 1 of 8 Log into New Relic. Step 2 of 8 In the entity explorer, click the Weather-Forecast OpenTelemetry service: This brings you to a service view that shows trace data from your application, including: Response time Throughput Error rate Step 3 of 8 In the left-hand navigation, click Distributed tracing: This shows trace data that the OpenTelemetry SDK automatically captured in your service, such as: Trace count Trace duration Trace groups Step 4 of 8 Under Trace groups click the WeatherForecast group: This group shows similar traces. Since your application has only one endpoint, all traces are grouped together. Step 5 of 8 Click one of the traces: Because your weather application is simple, there is only one span in the trace. Step 6 of 8 Click on the span: Here, you see information about the particular span, including not only performance metrics, but also attributes that OpenTelemetry sent. Step 7 of 8 Click Attributes: You configured many of the attributes you see here in your SDK code. Step 8 of 8 While New Relic doesn't yet have a curated experience for .NET OpenTelemetry metrics data, you can see the metrics in the metrics explorer: Summary As the developer of WeatherForecast, you've now instrumented your application with OpenTelemetry to send automatically collected metrics and traces to New Relic. And because you instrumented your app with OpenTelemetry instead of a .NET agent, you are more flexible in how you can use your data. For example, if you want to add additional backend data sources besides New Relic, you can easily change that without having to add another vendor-specific agent. Homework Now that you know how to instrument a .NET application with OpenTelemetry and send that data to New Relic, here are some things you can do next to familiarize yourself even more with New Relic and OpenTelemetry: Check out our repository of OpenTelemetry examples Learn more about OpenTelemetry's .NET SDK Read our documentation on New Relic + OpenTelemetry",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.09329,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " into New Relic. <em>Step</em> 2 of 8 In the entity explorer, click the Weather-Forecast OpenTelemetry service: This brings you to a service view that shows trace data from your application, including: Response time Throughput Error rate <em>Step</em> <em>3</em> of 8 In the left-hand navigation, click Distributed tracing"
      },
      "id": "61c282dd64441f3aebc53c5f"
    },
    {
      "image": "",
      "url": "https://developer.newrelic.com/collect-data/opentelemetry/set-up-env/",
      "sections": [
        "Set up your lab environment",
        "lab",
        "Technical Detail"
      ],
      "published_at": "2021-12-22T01:43:56Z",
      "title": "Set up your lab environment",
      "updated_at": "2021-12-22T01:43:56Z",
      "type": "developer",
      "external_id": "405aba57e04eca245e781b95071ef53df597fad9",
      "document_type": "page",
      "popularity": 1,
      "info": "Spin up your weather forecast application and simulator",
      "body": "lab This procedure is part of a lab that teaches you how to instrument your application with OpenTelemetry. If you haven't already, check out the lab introduction. Before you can walk through the lab proper, you need to set up your development environment. Here, you: Spin up your .NET application Send traffic to your app with a simple load generator Step 1 of 3 Clone the lab repository: bash Copy $ git clone https://github.com/newrelic-experimental/opentelemetry-dotnet-lab-materials Step 2 of 3 Restore dependencies, build, and run the application: bash Copy $ cd opentelemetry-dotnet-lab-materials $ dotnet restore app $ dotnet build app $ dotnet run --project app In the output, you see a url for your app: bash Copy Determining projects to restore... All projects are up-to-date for restore. Microsoft (R) Build Engine version 17.0.0+c9eb9dd64 for .NET Copyright (C) Microsoft Corporation. All rights reserved. Determining projects to restore... All projects are up-to-date for restore. opentelemetry-dotnet-lab-materials -> /workspace/opentelemetry-dotnet-lab-materials/app/bin/Debug/net6.0/opentelemetry-dotnet-lab-materials.dll Build succeeded. 0 Warning(s) 0 Error(s) Time Elapsed 00:00:01.42 Building... info: Microsoft.Hosting.Lifetime[14] Now listening on: https://localhost:7072 info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down. info: Microsoft.Hosting.Lifetime[0] Hosting environment: Development info: Microsoft.Hosting.Lifetime[0] Content root path: /workspace/opentelemetry-dotnet-lab-materials/app/ The application has a single endpoint at /WeatherForcast, which you can visit in your browser or with curl: bash Copy $ curl -k https://localhost:7072/WeatherForecast [{\"date\":\"2021-11-18T16:03:02.655159-05:00\",\"temperatureC\":38,\"temperatureF\":100,\"summary\":\"Chilly\"},{\"date\":\"2021-11-19T16:03:02.655161-05:00\",\"temperatureC\":-3,\"temperatureF\":27,\"summary\":\"Mild\"},{\"date\":\"2021-11-20T16:03:02.655162-05:00\",\"temperatureC\":-8,\"temperatureF\":18,\"summary\":\"Hot\"},{\"date\":\"2021-11-21T16:03:02.655162-05:00\",\"temperatureC\":3,\"temperatureF\":37,\"summary\":\"Cool\"},{\"date\":\"2021-11-22T16:03:02.655162-05:00\",\"temperatureC\":10,\"temperatureF\":49,\"summary\":\"Warm\"}] Technical Detail You use the -k option to instruct curl to not verify the site's SSL certification. This is fine because you're making a request against localhost. Leave this open so you can simulate requests against it. Step 3 of 3 In another terminal window, run the load generator: bash Copy $ cd opentelemetry-dotnet-lab-materials/sim $ pip install requests $ python simulator.py Now that you've got your application and load generator running, it's time to see what OpenTelemetry's all about. lab This procedure is part of a lab that teaches you how to instrument your application with OpenTelemetry. Now that you've set up your environment, instrument your application.",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 138.38007,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "info": "Spin up your weather forecast <em>application</em> <em>and</em> simulator",
        "body": " Send traffic to your app with a simple load generator <em>Step</em> 1 of <em>3</em> Clone the lab repository: bash Copy $ git clone https:&#x2F;&#x2F;github.com&#x2F;newrelic-experimental&#x2F;opentelemetry-dotnet-lab-materials <em>Step</em> 2 of <em>3</em> Restore dependencies, build, and run the application: bash Copy $ cd opentelemetry-dotnet-lab"
      },
      "id": "61c282dc64441fa172c548a2"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/enable-serverless-monitoring-aws-lambda-legacy/",
      "sections": [
        "Legacy manual instrumentation for Lambda monitoring",
        "Go",
        "Zip and upload recommendations",
        "Java",
        "Tip",
        ".NET Core",
        "Async handler function",
        "Inheriting from APIGatewayProxyFunction",
        "Important",
        "Using the SQS Wrapper",
        "Using the SNS Wrapper",
        "Node.js",
        "Python"
      ],
      "published_at": "2021-12-20T02:45:49Z",
      "title": "Legacy manual instrumentation for Lambda monitoring",
      "updated_at": "2021-10-19T00:59:11Z",
      "type": "docs",
      "external_id": "694e22b2ce401a96d200ab2e12a08850532b3e5a",
      "document_type": "page",
      "popularity": 1,
      "body": "On this page, you will learn how to manually instrument your lambda function. It's organized by runtime language. Go To instrument your Go-language Lambda: Download our Go agent package and place it in the same directory as your function. Install the agent: go get -u github.com/newrelic/go-agent/v3/newrelic. Install the nrlambda integration go get -u github.com/newrelic/go-agent/v3/integrations/nrlambda. In your Lambda code, import our components, create an application, and update how you start your Lambda. See our instrumentation examples: Extension repo Go agent repo Optional: Add custom events that will be associated with your Lambda invocation by using the RecordCustomEvent API. For example: func handler(ctx context.Context) { if txn := newrelic.FromContext(ctx); nil != txn { txn.Application().RecordCustomEvent(\"MyEvent\", map[string]interface{}{ \"zip\": \"zap\", }) } fmt.Println(\"hello world!\") } Copy Build and zip your Lambda function and upload it to AWS. Zip and upload recommendations Here are suggestions for zipping and uploading the Lambda: Build the binary for execution on Linux. This produces a binary file called main. You can use: $ GOOS=linux go build -o main Copy Zip the binary into a deployment package using: $ zip deployment.zip main Copy Upload the zip file to AWS using either the AWS Lambda console or the AWS CLI. Name the handler main (to match the name given during the binary build). The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this is the account ID for the root/parent account. Optional: To configure logging, see Go agent logging. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Java Monitoring for AWS Lambda in Java doesn't use our APM Java agent. Instead, it uses these two OpenTracing dependencies: AWS Lambda OpenTracing Java SDK: OpenTracing instrumentation for AWS Lambda RequestHandler and RequestStreamHandler. Our AWS Lambda OpenTracing Tracer: An OpenTracing Tracer implementation designed to monitor AWS Lambda. It generates spans, error events, transaction events, error traces, and provides distributed tracing support. Tip Supported OpenTracing Versions OpenTracing 0.31.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:1.1.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:1.0.0 OpenTracing 0.32.0, 0.33.0: Lambda Tracer: com.newrelic.opentracing:newrelic-java-lambda:2.2.1 Lambda SDK: com.newrelic.opentracing:java-aws-lambda:2.1.0 To instrument your Java Lambda: In your project’s build.gradle file, include our OpenTracing AWS Lambda Tracer and the AWS Lambda OpenTracing SDK dependencies: dependencies { compile(\"com.newrelic.opentracing:java-aws-lambda:2.1.0\") compile(\"com.newrelic.opentracing:newrelic-java-lambda:2.2.1\") compile(\"io.opentracing:opentracing-util:0.33.0\") } Copy Implement the AWS Lambda RequestHandler interface as shown in the Java Lambda example and override the doHandleRequest method. In the doHandleRequest method, call the LambdaTracing.instrument(...) API to create a root span to trace the lambda function's execution. This is also where you will define your business logic for the lambda function. Register a LambdaTracer.INSTANCE as the OpenTracing Global tracer, as shown in the Java Lambda example. Create a ZIP deployment package and upload it to AWS Lambda. Or deploy it via other means. In the AWS Lambda console, set the handler. For the example Java Lambda, the handler would be com.handler.example.MyLambdaHandler::handleRequest. Because handleRequest is assumed, you could also use com.handler.example.MyLambdaHandler. The following AWS console environment variables are required if you want your Lambda function to be included in distributed tracing. This is recommended. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_PRIMARY_APPLICATION_ID. This is also your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this must be the account ID for the root/parent account. Optional: In the Lambda console, enable debug logging by adding this environment variable: NEW_RELIC_DEBUG is true. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, you'll configure CloudWatch to send those logs to New Relic. Please see the AWS Lambda distributed tracing example for a complete project that illustrates common use cases such as: Distributed tracing between Lambda functions Manual span creation (aka custom instrumentation) Tracing external calls Adding custom attributes (aka Tags) to spans .NET Core Our monitoring of .NET Core-based AWS Lambda functions doesn't use our standard .NET Core APM agent. Instead, it uses a NuGet package. To instrument your .NET Core Lambda: In your Lambda Functions project, install the NewRelic.OpenTracing.AmazonLambda.Tracer NuGet package. Note: NewRelic.OpenTracing.AmazonLambda.Tracer depends on version 1.2.0+ of Amazon.Lambda.APIGatewayEvent NuGet package. If the environment already uses a lower version of Amazon.Lambda.APIGatewayEvent, the New Relic package may produce errors such as System.MissingMethodException . Import the NuGet package and OpenTracing utils: using OpenTracing.Util; using NewRelic.OpenTracing.AmazonLambda; Copy Instrument your function, as shown in this example: public class Function { static Function() { // Register The NewRelic Lambda Tracer Instance GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public object FunctionWrapper(ILambdaContext context) { // Instantiate NewRelic TracingWrapper and pass your FunctionHandler as // an argument return new TracingRequestHandler().LambdaWrapper(FunctionHandler, context); } /// <summary> /// A simple function that takes a string and does a ToUpper /// </summary> /// <param name=\"input\"></param> /// <param name=\"context\"></param> /// <returns></returns> public object FunctionHandler(ILambdaContext context) { ... } } Copy Tip The arguments passed to FunctionWrapper must match the signature of FunctionHandler. If your handler function returns a Task, the Lambda wrapper will block on the return task until it completes, so that it can measure the duration and capture exceptions, if any are present. In addition, you may also inherit from the APIGatewayProxyFunction. For an example, see below: Async handler function public async Task<int> FunctionHandlerAsync(ILambdaContext lambdaContext) { return await new TracingRequestHandler().LambdaWrapper( ActualFunctionHandlerAsync, lambdaContext); } public async Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(ILambdaContext lambdaContext) { // Function can make other async operations here ... } Copy Inheriting from APIGatewayProxyFunction public class LambdaFunction : APIGatewayProxyFunction { static LambdaFunction() { // Register The NewRelic Lambda Tracer Instance OpenTracing.Util.GlobalTracer.Register(NewRelic.OpenTracing.AmazonLambda.LambdaTracer.Instance); } public override Task<APIGatewayProxyResponse> FunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { Task<APIGatewayProxyResponse> task = new TracingRequestHandler().LambdaWrapper(ActualFunctionHandlerAsync, request, lambdaContext); return task; } public Task<APIGatewayProxyResponse> ActualFunctionHandlerAsync(APIGatewayProxyRequest request, ILambdaContext lambdaContext) { return base.FunctionHandlerAsync(request, lambdaContext); } } Copy Optional for SQS and SNS: Starting in version 1.0 of our .NET Lambda Tracer, distributed tracing support has been added for SQS and SNS. To enable distributed tracing for SQS or SNS you will need to complete the items in this step as well as setup the environment variables in the step that follows this one. Important Enabling distributed tracing support for SQS and SNS will disable automatic instrumentation for both of SQS and SNS and require the use of these wrappers to instrument them. Set the NEW_RELIC_USE_DT_WRAPPER environment variable to true. To instrument SQS and SNS calls you will need to use the provided wrappers. Using the SQS Wrapper The SQS wrapper supports wrapping the following methods: Amazon.SQS.AmazonSQSClient.SendMessageAsync(...) Amazon.SQS.AmazonSQSClient.SendMessageBatchAsync(...) Examples // SQS Client AmazonSQSClient client = new AmazonSQSClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // SendMessageRequest SendMessageRequest sendRequest = new SendMessageRequest(\"QUEUE_URI_STRING\", \"An SQS Message\"); Task<SendMessageResponse> responseOne = SQSWrapper.WrapRequest(client.SendMessageAsync, sendRequest); // String-based Task<SendMessageResponse> responseTwo = SQSWrapper.WrapRequest(client.SendMessageAsync, \"QUEUE_URI_STRING\", \"Another SQS Message\"); // SendMessageBatchRequest List<SendMessageBatchRequestEntry> batchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id1\", \"First SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id2\", \"Second SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id3\", \"Third SQS Message\")); SendMessageBatchRequest sendBatchRequest = new SendMessageBatchRequest(QUEUE_URI, batchEntries); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, sendBatchRequest); // SendMessageBatchRequestEntry List List<SendMessageBatchRequestEntry> moreBatchEntries = new List<SendMessageBatchRequestEntry>(); batchEntries.Add(new SendMessageBatchRequestEntry(\"id4\", \"Fourth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id5\", \"Fifth SQS Message\")); batchEntries.Add(new SendMessageBatchRequestEntry(\"id6\", \"Sixth SQS Message\")); Task<SendMessageBatchResponse> response = SQSWrapper.WrapRequest(client.SendMessageBatchAsync, moreBatchEntries); Copy Using the SNS Wrapper The SNS wrapper supports wrapping the following methods: Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient.PublishAsync(...) Examples // SNS Client AmazonSimpleNotificationServiceClient client = new Amazon.SimpleNotificationService.AmazonSimpleNotificationServiceClient(\"AWS_SECRET_ACCESS_KEY\", AWS_REGION); // PublishRequest - Phone Number PublishRequest phonePublishRequest = new PublishRequest(); phonePublishRequest.PhoneNumber = +1XXX5555100; phonePublishRequest.Message = \"An SNS Message for phones\"; Task<PublishResponse> phoneResponse = SNSWrapper.WrapRequest(client.PublishAsync, phonePublishRequest); // PublishRequest - ARN PublishRequest publishRequest = new PublishRequest(\"TOPIC_ARN\", \"An SNS Message\"); Task<PublishResponse> publishResponse = SNSWrapper.WrapRequest(client.PublishAsync, publishRequest); // String-based without subject Task<PublishResponse> ResponseOne = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Another SNS Message\"); // String-based with subject Task<PublishResponse> ResponseTwo = SNSWrapper.WrapRequest(client.PublishAsync, \"TOPIC_ARN\", \"Yet Another SNS Message\", \"A Subject\"); Copy The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS Lambda console: NEW_RELIC_ACCOUNT_ID: The account ID the Lambda is reporting to. NEW_RELIC_TRUSTED_ACCOUNT_KEY: This is also the account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Ensure that the wrapper function (FunctionWrapper in above example) is set up as the function handler. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Node.js To instrument your Node.js Lambda: Download our Node.js agent package and place it in the same directory as your function, ensuring the agent is installed as a dependency in the node_modules directory. Use the Node Package Manager: npm install newrelic --save Copy Install our AWS SDK module alongside the Node.js agent: npm install @newrelic/aws-sdk --save Copy In your Lambda code, require the agent module and the AWS SDK at the top of the file, and wrap the handler function. For example: const newrelic = require('newrelic'); require('@newrelic/aws-sdk'); // Other module loads go under the two require statements above module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { // This is your handler function code console.log('Lambda executed'); callback(); }); Copy Optional: You can also add custom events to your Lambda using the recordCustomEvent API. For example: module.exports.handler = newrelic.setLambdaHandler((event, context, callback) => { newrelic.recordCustomEvent(‘MyEventType’, {foo: ‘bar’}); console.log('Lambda executed'); callback(); }); Copy Zip your Lambda function and the Node.js agent folder together. Requirements and recommendations: The New Relic files outside the New Relic agent folder don't need to be included. If your Lambda function file name is, for example, lambda_function.node, we recommend naming your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set these environment variables: NEW_RELIC_NO_CONFIG_FILE. Set to true if not using a configuration file. NEW_RELIC_APP_NAME: Your application name. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To run the agent in serverless mode outside of AWS in a local environment, set the environment variable NEW_RELIC_SERVERLESS_MODE_ENABLED to true. (When executing this in an AWS Lambda environment, the agent will automatically run in serverless mode. Do not use this variable if you're running in AWS.) Optional: To enable logging in serverless mode, set these environment variables: Set NEW_RELIC_LOG_ENABLED to true. Set NEW_RELIC_LOG to stdout for output to CloudWatch, or set to any writeable file location. The log level is set to info by default. See other log levels. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. Our wrapper gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next you'll configure CloudWatch to send those logs to New Relic. Python To instrument your Python Lambda: Download our Python agent package and place it in the same directory as your function. To do this, use pip: pip install -t . newrelic Copy Important If you use Homebrew, you may get this error: DistutilsOptionError: must supply either home or prefix/exec-prefix -- not both. For details, see the Homebrew GitHub post. In your Lambda code, import the Python agent module and decorate the handler function using the New Relic decorator. The New Relic package must be imported first in your code. Here's an example: import newrelic.agent newrelic.agent.initialize() @newrelic.agent.lambda_handler() def handler(event, context): ... Copy Optional: You can also add custom events to your Lambda using the record_custom_event API. Here's an example: @newrelic.agent.lambda_handler() def handler(event, context): newrelic.agent.record_custom_event('CustomEvent', {'foo': 'bar'}) … Copy Zip your lambda_function.py and newrelic/ folder together using these guidelines: The New Relic files outside the newrelic/ folder don't need to be included. If your Lambda function file name is, for example, lambda_function.py, name your zip file lambda_function.zip. Do not use a tarball. Your Lambda and its associated modules must all be in the zip file's root directory. This means that if you zip a folder that contains the files, it won't work. Upload the zipped file to your AWS Lambda account. In the AWS console, set this environment variable: NEW_RELIC_SERVERLESS_MODE_ENABLED. Set to true The following environment variables are not required for Lambda monitoring to function but they are required if you want your Lambda functions to be included in distributed traces. To enable distributed tracing, set these environment variables in the AWS console: NEW_RELIC_DISTRIBUTED_TRACING_ENABLED. Set to true. NEW_RELIC_ACCOUNT_ID. Your account ID. NEW_RELIC_TRUSTED_ACCOUNT_KEY. This is also your account ID. If your account is a child account, this needs to be the account ID for the root/parent account. Optional: To configure logging, use the NEW_RELIC_LOG and NEW_RELIC_LOG_LEVEL environment variables in the AWS Console. Invoke the Lambda at least once. This creates a CloudWatch log group, which must be present for the next step to work. The New Relic decorator gathers data about the Lambda execution, generates a JSON message, and logs it to CloudWatch Logs. Next, configure CloudWatch to send those logs to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.88025,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "sections": "Legacy manual <em>instrumentation</em> for <em>Lambda</em> monitoring",
        "body": "On this page, you will learn how to manually <em>instrument</em> your <em>lambda</em> <em>function</em>. It&#x27;s organized by runtime language. Go To <em>instrument</em> your Go-language <em>Lambda</em>: Download our Go agent package and place it in the same directory as your <em>function</em>. Install the agent: go get -u github.com&#x2F;newrelic&#x2F;go-agent&#x2F;v<em>3</em>"
      },
      "id": "603ebbcb64441f800a4e8850"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-your-own": [
    {
      "sections": [
        "New Relic Flex: Build your own integration",
        "What is Flex?",
        "Requirements",
        "How does Flex work?",
        "Example config",
        "Learn more"
      ],
      "title": "New Relic Flex: Build your own integration",
      "type": "docs",
      "tags": [
        "Instrument everything",
        "Develop your own integrations"
      ],
      "external_id": "97b0a696cf7f831d225ecc76fb79b81599d1fc83",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/flex-integration-tool-build-your-own-integration/",
      "published_at": "2021-12-20T04:10:54Z",
      "updated_at": "2021-10-30T16:11:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic provides integrations and quickstarts for many popular services and frameworks. If you have New Relic and want to report data from a service we don't have an integration for, there are several ways New Relic lets you create your own integration: With New Relic infrastructure monitoring, you can use our lightweight Flex tool (recommended, documented below) or, to build a complete on-host integration, see our Integrations SDK. Telemetry (metrics, traces) monitoring solutions: Use our Telemetry SDKs. Build a custom New Relic One application that uses your own JavaScript UI functionality. What is Flex? New Relic Flex is an application-agnostic, all-in-one tool that allows you to collect metric data from a wide variety of services. It comes bundled with our infrastructure agent. You can instrument any app that exposes metrics over a standard protocol (HTTP, file, shell) in a standard format (for example, JSON or plain text): you create a YAML config file, start the Infrastructure agent, and your data is reported to New Relic. Flex can send event and metric data to New Relic from a wide range of sources. Using a simple YAML config file, you can run HTTP/HTTPS requests, run shell commands, and parse file content. You can also use standard regex expressions to customize and control the data gathered from those inputs. See an example config. After collecting and cleaning up the data, you can then query Flex data in New Relic, create custom charts for it, and use that data in your dashboards. Requirements Flex comes bundled with our infrastructure agent. To use Flex, you need: Infrastructure agent version 1.10.7 or higher (update | check version) running on Linux, Windows, or Kubernetes. How does Flex work? Flex uses our infrastructure agent to execute commands that generate the data you want to report. Here's a brief overview of how Flex works to report data: You define the data you want to report in a YAML configuration file, located in the infrastructure agent package. See an example configuration: Example config The following is an example of a Flex configuration for monitoring the uptime of a Linux server. This configuration is placed in a file named flex-uptime.yml. This would be placed in the infrastructure agent's integration configuration section, located at /etc/newrelic-infra/integrations.d/flex-uptime.yml. integrations: - name: nri-flex config: name: linuxUptimeIntegration apis: - name: Uptime commands: - run: 'cat /proc/uptime' split: horizontal split_by: \\s+ set_header: [uptimeSeconds,idletimeSeconds] Copy Some notes on what this configuration does: run defines the command to execute. The name indicated by name: Uptime is appended with Sample to generate an event called UptimeSample. The name should not start with the ESX or PCF prefix. The split_by: \\s+ splits the fields based on the space character. The command generates attributes attached to the UptimeSample event. The attributes are named uptimeSeconds and idletimeSeconds. The infrastructure agent runs Flex at a frequency based on its own configuration (default: every 30 seconds) and sends the data to New Relic. You can then query your data, create custom charts with it, and add it to dashboards. Learn more The Flex integration comes bundled with the infrastructure agent. Learn more about requirements. To learn more, see our complete documentation on GitHub: README Tutorial",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.1725,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "New Relic Flex: Build <em>your</em> <em>own</em> integration",
        "sections": "New Relic Flex: Build <em>your</em> <em>own</em> integration",
        "tags": "Develop <em>your</em> <em>own</em> integrations",
        "body": "New Relic provides integrations and quickstarts for many popular services and frameworks. If you have New Relic and want to report data from a service we don&#x27;t have an integration for, there are several ways New Relic lets you create <em>your</em> <em>own</em> integration: With New Relic infrastructure monitoring"
      },
      "id": "617d6ec5196a673341f7cebc"
    },
    {
      "image": "https://developer.newrelic.com/static/f22f2f9b68bb3a2c69b68a3ee063554e/0086b/otel-data.png",
      "url": "https://developer.newrelic.com/collect-data/opentelemetry/view/",
      "sections": [
        "View your OpenTelemetry data in New Relic",
        "lab",
        "View your data",
        "Summary",
        "Homework"
      ],
      "published_at": "2021-12-22T01:43:57Z",
      "title": "View your OpenTelemetry data in New Relic",
      "updated_at": "2021-12-22T01:43:57Z",
      "type": "developer",
      "external_id": "1a149f37a72e22fbc350c958a716652817d4dfa1",
      "document_type": "page",
      "popularity": 1,
      "info": "View your OpenTelemetry data in New Relic",
      "body": "lab This procedure is part of a lab that teaches you how to instrument your application with OpenTelemetry. Each procedure in the lab builds upon the last, so make sure you've completed the last procedure, Instrument your application with OpenTelemetry, before starting this one. You've instrumented your weather forecast application with OpenTelemetry and you're sending metric and trace data to New Relic. Here, you move to New Relic to see the kinds of detailed telemetry data that OpenTelemetry was able to collect automatically with just a few lines of SDK code. View your data Step 1 of 8 Log into New Relic. Step 2 of 8 In the entity explorer, click the Weather-Forecast OpenTelemetry service: This brings you to a service view that shows trace data from your application, including: Response time Throughput Error rate Step 3 of 8 In the left-hand navigation, click Distributed tracing: This shows trace data that the OpenTelemetry SDK automatically captured in your service, such as: Trace count Trace duration Trace groups Step 4 of 8 Under Trace groups click the WeatherForecast group: This group shows similar traces. Since your application has only one endpoint, all traces are grouped together. Step 5 of 8 Click one of the traces: Because your weather application is simple, there is only one span in the trace. Step 6 of 8 Click on the span: Here, you see information about the particular span, including not only performance metrics, but also attributes that OpenTelemetry sent. Step 7 of 8 Click Attributes: You configured many of the attributes you see here in your SDK code. Step 8 of 8 While New Relic doesn't yet have a curated experience for .NET OpenTelemetry metrics data, you can see the metrics in the metrics explorer: Summary As the developer of WeatherForecast, you've now instrumented your application with OpenTelemetry to send automatically collected metrics and traces to New Relic. And because you instrumented your app with OpenTelemetry instead of a .NET agent, you are more flexible in how you can use your data. For example, if you want to add additional backend data sources besides New Relic, you can easily change that without having to add another vendor-specific agent. Homework Now that you know how to instrument a .NET application with OpenTelemetry and send that data to New Relic, here are some things you can do next to familiarize yourself even more with New Relic and OpenTelemetry: Check out our repository of OpenTelemetry examples Learn more about OpenTelemetry's .NET SDK Read our documentation on New Relic + OpenTelemetry",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 163.46696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>your</em> OpenTelemetry data in New Relic",
        "sections": "View <em>your</em> OpenTelemetry data in New Relic",
        "info": "View <em>your</em> OpenTelemetry data in New Relic",
        "body": ": This shows trace data that the OpenTelemetry SDK automatically captured in <em>your</em> service, such as: Trace count Trace duration Trace groups <em>Step</em> <em>4</em> of 8 Under Trace groups click the WeatherForecast group: This group shows similar traces. Since <em>your</em> application has only one endpoint, all traces are grouped"
      },
      "id": "61c282dd64441f3aebc53c5f"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/instrument-example/",
      "sections": [
        "Step 3: Instrument a test Lambda function",
        "Example features",
        "Examples",
        "Tip",
        "Distributed tracing"
      ],
      "published_at": "2021-12-20T02:45:49Z",
      "title": "Step 3: Instrument a test Lambda function",
      "updated_at": "2021-09-14T18:20:50Z",
      "type": "docs",
      "external_id": "0c40022f960080d787a0e4288d5fd2ee7d29c44e",
      "document_type": "page",
      "popularity": 1,
      "body": "This is one step of enabling New Relic's AWS Lambda monitoring. New Relic provides working minimal examples as a starting point for instrumenting your own serverless functions, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for your own instrumentation. While there are many ways to manage and deploy Lambda functions, AWS CloudFormation is the mechanism we use for our examples. It requires minimal tooling, has first-party support, and underpins many of the third party deployment options as well. Example features Each of our basic examples is functionally identical, and illustrates the following New Relic features: Sending invocation telemetry to New Relic, via the New Relic Lambda Extension Adding custom attributes to the invocation event Adding custom events to the telemetry In addition, each demonstrates: Using the New Relic Lambda layer with your function Adding permissions to the function to access the AWS Secrets Manager and retrieve the New Relic license key Runtime-specific techinques for wrapping your handler, so that New Relic can capture telemetry Managing function log retention in CloudWatch Optionally, forwarding function logs to New Relic's logging product via the Lambda Extension Examples Our examples are published, alongside the New Relic Lambda Extension, in this GitHub repository. There's one for each Lambda runtime that New Relic can instrument: NodeJS Python Go Java .NET Tip As you test the examples, you may notice that telemetry isn't always sent right away. The AWS Lambda lifecycle places certain constraints on the execution of our agent and Lambda Extension. In addition, valuable platform telemetry is only available after an invocation has completed. The New Relic Extension balances overall performance against the need for timely telemetry delivery by buffering telemetry for a period of time, and delivering it to New Relic in batches, during a subsequent invocation (or during shutdown). In a production function, we find this works very well. When manually testing, it's often necessary to wait seven seconds, and then invoke a function again to give it an opportunity to deliver previously buffered telemetry. While we make an effort to keep the templates in our examples up to date, you can always find the latest New Relic Lambda layer for your region and runtime at our layers site. This site also offers an API, which you're welcome to use in your CI/CD pipeline to keep your own templates up to date. Distributed tracing In addition to our basic examples, we offer an example of how to integrate distributed tracing into a non-trivial serverless application in our distributed tracing example. It illustrates manual trace propagation for SQS and SNS, two of the more popular services that might invoke Lambda functions, with Node, Python and Java functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 149.30766,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Step</em> 3: <em>Instrument</em> a test <em>Lambda</em> <em>function</em>",
        "sections": "<em>Step</em> 3: <em>Instrument</em> a test <em>Lambda</em> <em>function</em>",
        "body": "This is one <em>step</em> of enabling New Relic&#x27;s AWS <em>Lambda</em> monitoring. New Relic provides working minimal examples as a starting point for instrumenting <em>your</em> <em>own</em> serverless <em>functions</em>, so that you can become familiar with the necessary elements, test the account link, and use them as a reference for <em>your</em>"
      },
      "id": "605aa85628ccbcc6d13ae663"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/set-up-cloudwatch-logs": [
    {
      "sections": [
        "Amazon SageMaker MLOps integration",
        "Stream AWS CloudWatch Metrics to New Relic",
        "Important",
        "Manual option",
        "Automated option",
        "Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch",
        "Advanced options",
        "Explore your MLOps entities and dashboards"
      ],
      "title": "Amazon SageMaker MLOps integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "MLOPs",
        "Amazon SageMaker"
      ],
      "external_id": "51bf2cfead556f345a559403dce5efba6b574116",
      "image": "https://docs.newrelic.com/static/cc36912643153bc52f79def15b0fce81/a76f4/aws-sm-flow.png",
      "url": "https://docs.newrelic.com/docs/mlops/integrations/aws-sagemaker-mlops-integration/",
      "published_at": "2021-12-19T14:30:55Z",
      "updated_at": "2021-12-14T05:09:17Z",
      "document_type": "page",
      "popularity": 1,
      "body": "By integrating Amazon SageMaker's integration with New Relic, you'll be able to instrument, analyze, troubleshoot, and optimize your machine-learning performance across your entire system. Rigorously observe your capabilities to react quickly to changes in the model's input or output and the relationship between the two. Take the next steps to monitor your Amazon SagaMaker metrics and objects (that are sent to AWS CloudWatch) and view them as entities and dashboards in New Relic. Stream AWS CloudWatch Metrics to New Relic Start benefiting from New Relic MLOps entities in a single simple step (and just a few minutes!): Important Each metric sent to CloudWatch is automatically sent to New Relic's metric table in NRDB, according to the namespace filter. You can always query them using NRQL: FROM Metric SELECT * WHERE aws.Namespace='/aws/sagemaker/Endpoints' LIMIT MAX SINCE 1 WEEK AGO Copy Manual option Follow our docs to set up CloudWatch Metric Streams. Automated option You may automate the set up with the Terraform code: module \"example_usage\" { source = \"modules/nr-cloudwatch-metric-stream\" name_suffix = \"suffix\" # optional aws_account_id = \"your-aws-account-id\" newrelic_collector_endpoint = \"newrelic-endpoint-url\" newrelic_trusted_account_id = \"12345678\" newrelic_license_key = \"your-newrelic-license-key\" } Copy When calling the module, please write the correct newrelic_collector_endpoint: HTTP endpoint URL - US datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 When you set the metric stream you can choose to stream the metric from all the namespaces, or you can specify namespaces. Important You can view each entity's metrics in a dashboard that's created automatically when the metrics arrive at the New Relic. Monitor your data and model in Amazon SageMaker, and send the metrics to CloudWatch SageMaker automatically monitors your endpoints’ performance, and sends statistic metrics to CloudWatch. For more information, see Endpoint CloudWatch Metrics. To obtain more benefits from the Amazon SageMaker MLOps integration, use the Amazon SageMaker Model Monitor tools. You'll have to define scheduled monitoring jobs to monitor the quality of your machine learning models in production and send metrics to CloudWatch. The Amazon SageMaker Model Monitor provides the following types of monitoring: Monitor Data Quality: Monitor drift in data quality. Example notebook: Amazon SageMaker Model Monitor Namespace: aws/sagemaker/Endpoints/data-metrics Monitor Model Quality: Monitor drift in model quality metrics, such as accuracy. Example notebook: Amazon SageMaker Model Quality Monitor Namespace: aws/sagemaker/Endpoints/model-metrics Monitor Bias Drift for Models in Production: Monitor bias in you model's predictions. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/bias-metrics Monitor Feature Attribution Drift for Models in Production: Monitor drift in feature attribution. Example notebook: Monitoring bias drift and feature attribution drift Amazon SageMaker Clarify Namespace: aws/sagemaker/Endpoints/explainability-metrics Advanced options You can aso publish metric data points to Amazon CloudWatch and define the namespaces and one of the above using the put_metric_data function. If you use your own algorithm for hyperparameter tuning, make sure that it sends at least one metric by writing evaluation data to stderr or stdout. Read more on how to define metrics in automatic model tuning. See also the example notebook Develop, Train, Optimize and Deploy Scikit-Learn Random Forest. Explore your MLOps entities and dashboards We generate aws-entities (under the MLOps entity domain) for the detailed namespaces. For these entities, you can get out-of-the-box dashboards and views. You can also create your own dashboard to view metrics that are not being displayed as part of the entities' views. New Relic entity Namespace Machine learning endpoint /aws/sagemaker/Endpoints, AWS/SageMaker Machine learning model data aws/sagemaker/Endpoints/data-metrics Machine learning model aws/sagemaker/Endpoints/model-metrics, aws/sagemaker/Endpoints/explainability-metrics Go to one.newrelic.com and select the Explorer to view: Your machine-learning entities The dashboard for the metrics of the endpoint from one of the Amazon SageMaker entities The dashboard for the model data entity",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 352.3858,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "Stream <em>AWS</em> <em>CloudWatch</em> Metrics to New Relic",
        "body": " Manual <em>option</em> Follow our docs to <em>set</em> <em>up</em> <em>CloudWatch</em> Metric Streams. Automated <em>option</em> You may automate the <em>set</em> <em>up</em> with the Terraform code: module &quot;example_usage&quot; { source = &quot;modules&#x2F;nr-<em>cloudwatch</em>-metric-stream&quot; name_suffix = &quot;suffix&quot; # <em>optional</em> <em>aws</em>_account_id = &quot;your-<em>aws</em>-account-id"
      },
      "id": "61b332d428ccbc3c8e8c55b8"
    },
    {
      "sections": [
        "Amazon CloudWatch Metric Streams integration",
        "Why does this matter?",
        "Cost considerations",
        "Set up a Metric Stream to send CloudWatch metrics to New Relic",
        "How to map New Relic and AWS accounts and regions",
        "Guided setup using CloudFormation",
        "Manual setup using AWS Console, API, or calls",
        "Tip",
        "Validate your data is received correctly",
        "Metrics naming convention",
        "Query Experience, metric storage and mapping",
        "AWS namespaces' entities in the New Relic Explorer",
        "Important",
        "Set alert conditions",
        "Tags collection",
        "Metadata collection",
        "Curated dashboards",
        "How to import dashboards",
        "Manage your data",
        "Migrating from AWS API polling integrations",
        "Migration steps",
        "Query, dashboard, alert and inventory considerations",
        "Integrations not fully replaced by metric streams",
        "Infrastructure Agent metrics and EC2 metadata decoration"
      ],
      "title": "Amazon CloudWatch Metric Streams integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "AWS integrations list"
      ],
      "external_id": "cdfc973cb6b9ade1fff6625905f9bf93fe062869",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/",
      "published_at": "2021-12-20T10:13:04Z",
      "updated_at": "2021-12-04T17:07:45Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic currently provides independent integrations with AWS to collect performance metrics and metadata for more than 50 AWS services. With the new AWS Metric Streams integration, you only need a single service, AWS CloudWatch, to gather all AWS metrics and custom namespaces and send them to New Relic. Why does this matter? Our current system, which relies on individual integrations, runs on a polling fleet and calls multiple AWS APIs at regular intervals to retrieve the metrics and metadata. Using AWS CloudWatch significantly improves how metrics are gathered, overcoming some of the limitations of using the individual integrations. API mode Stream mode It requires an integration with each AWS service to collect the metrics. All CloudWatch metrics from all AWS services and custom namespaces are available in New Relic at once, without needing a specific integration to be built or updated. There are two exceptions: percentiles and a small number of metrics that are made available to CloudWatch with more than 2 hours delay, and therefore not included in the stream. It adds an additional delay to metrics being available in New Relic for alerting and dashboarding. The fastest polling interval we offer today is 5 minutes. Latency is significantly improved, since metrics are streamed in less than two minutes since they are made available in AWS CouldWatch. It may lead to AWS API throttling for large AWS environments. AWS API throttling is eliminated. Cost considerations Consider the following when evaluating the cost of the AWS CloudWatch metric streams integration with New Relic: AWS CloudWatch metric updates. See Metric Streams. AWS Kinesis Firehose ingest. AWS Kinesis Firehose data transfer. Optionally, custom tags and CloudWatch metrics enrichment with resource metadata is based on the AWS Config service. Set up a Metric Stream to send CloudWatch metrics to New Relic To stream CloudWatch metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a CloudWatch Metric Stream that sends metrics to that Firehose. How to map New Relic and AWS accounts and regions If you manage multiple AWS accounts, then each account needs to be connected to New Relic. If you manage multiple regions within those accounts, then each region needs to be configured with a different Kinesis Data Firehose pointing to New Relic. You will typically map one or many AWS accounts to a single New Relic account. Guided setup using CloudFormation First, you need to link each of your AWS accounts with your New Relic account. To do so: Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. You may automate this step with NerdGraph. Next, set up the metric stream using the CloudFormation template we provide in the last step of our UI. This template is provided as a base to setup the integration on a single region, and can be customized and extended based on your requirements. Manual setup using AWS Console, API, or calls Create a Kinesis Data Firehose Delivery Stream and configure the following destination parameters: Source: Direct PUT or other sources Data transformation: Disabled Record format conversion: Disabled Destination: New Relic Ensure the following settings are defined: New Relic configuration (Destination Settings) HTTP endpoint URL - US Datacenter: https://aws-api.newrelic.com/cloudwatch-metrics/v1 HTTP endpoint URL - EU Datacenter: https://aws-api.eu01.nr-data.net/cloudwatch-metrics/v1 API key: Enter your license key Content encoding: GZIP Retry duration: 60 S3 backup mode: Failed data only S3 bucket: select a bucket or create a new one to store metrics that failed to be sent. New Relic buffer conditions Buffer size: 1 MB Buffer interval: 60 (seconds) Permissions IAM role: Create or update IAM role Create the metric stream. Go to CloudWatch service in your AWS console and select the Streams option under the Metrics menu. Click on Create metric stream. Determine the right configuration based on your use cases: Use inclusion and exclusion filters to select which services should push metrics to New Relic. Select your Kinesis Data Firehose. Define a meaningful name for the stream (for example, newrelic-metric-stream). Change default output format to Open Telemetry 0.7 (JSON is not supported) Confirm the creation of the metric stream. Alternatively, you can find instructions on the AWS documentation in order to create the CloudWatch metric stream using a CloudFormation template, API, or the CLI. Add the new AWS account in the Metric streams mode in the New Relic UI. Go to one.newrelic.com > Infrastructure > AWS, click on Add an AWS account, then on Use metric streams, and follow the steps. Tip The following are the minimal permissions that should be granted on the AWS role configured in New Relic so that CloudWatch metrics can be enriched with additional service metadata and custom tags when applicable: config:BatchGetResourceConfig config:ListDiscoveredResources tag:GetResources Copy The New Relic UI currently recommends the ReadOnlyAccess policy over these individual items so that New Relic has proper permissions to collect service data that's not available in AWS CloudWatch Metric Streams. Validate your data is received correctly To confirm you are receiving data from the Metric Streams, follow the steps below: Go to one.newrelic.com > Infrastructure > AWS, and search for the Stream accounts. You can check the following: Account status dashboard. Useful to confirm that metric data is being received (errors, number of namespaces/metrics ingested, etc.) Explore your data. Use the Data Explorer to find a specific set of metrics, access all dimensions available for a given metric and more. Tip AWS CloudWatch metrics for global services such as AWS S3 or AWS Billing are only availble in the us-east-1 region. Make sure there's an active CloudWatch metric stream configured in that region. Metrics naming convention Metrics received from AWS CloudWatch are stored in New Relic as dimensional metrics following this convention: Metrics are prefixed by the AWS namespace, all lowercase, where / is replaced with . : AWS/EC2 -> aws.ec2 AWS/ApplicationELB -> aws.applicationelb The original AWS metric name with its original case: aws.ec2.CPUUtilization aws.s3.5xxErrors aws.sns.NumberOfMessagesPublished If the resource the metric belongs to has a specific namespace prefix, it is used. If the resource the metric belongs to doesn't have a specific namespace prefix, metrics use the aws. prefix. aws.Region aws.s3.BucketName Current namespaces supported by AWS can be found in the CloudWatch documentation website. Query Experience, metric storage and mapping Metrics coming from AWS CloudWatch are stored as dimensional metrics of type summary and can be queried using NRQL. We have mapped metrics from the current cloud integrations to the new mappings that will come from AWS Metric Streams. You can continue to use the current metric naming, and queries will continue to work and pick data from AWS Metric Streams and the current cloud integrations. Check our documentation on how current cloud integrations metrics map to the new metric naming. All metrics coming from the metric stream will have these attributes: aws.MetricStreamArn collector.name = ‘cloudwatch-metric-streams’. AWS namespaces' entities in the New Relic Explorer We generate New Relic entities for most used AWS namespaces and will continue adding support for more namespaces. When we generate New Relic entities for a namespace you can expect to: Browse those entities in the New Relic Explorer. Access an out-of-the-box entity dashboard for those entities. Get metrics and entities from that namespace decorated with AWS tags. Collecting AWS tags requires that you have given New Relic the tag:GetResources permission which is part of the setup process in the UI. AWS tags show in metrics as tag.AWSTagName; for example, if you have set a Team AWS tag on the resource, it will show as tag.Team. Leverage all the built-in features that are part of the Explorer. Important Lookout view in Entity Explorer is not compatible with entities created from the AWS Metric Streams integration at this time. Set alert conditions You can create NRQL alert conditions on metrics from a metric stream. Make sure your filter limits data to metrics from the CloudWatch metric stream only. To do that, construct your queries like this: SELECT sum(aws.s3.5xxErrors) FROM Metric WHERE collector.name = 'cloudwatch-metric-streams' FACET aws.accountId, aws.s3.BucketName Copy Then, to make sure that alerts processes the data correctly, configure the advanced signal settings. These settings are needed because AWS CloudWatch receives metrics from services with a certain delay (for example, Amazon guarantees that 90% of EC2 metrics are available in CloudWatch within 7 minutes of them being generated). Moreover, streaming metrics from AWS to New Relic adds up to 1 minute additional delay, mostly due to buffering data in the Firehose. To configure the signal settings, under Condition Settings, click on Advanced Signal Settings and enter the following values: Aggregation window. We recommend setting it to 1 minute. If you are having issues with flapping alerts or alerts not triggering, consider increasing it to 2 minutes. Offset evaluation by. Depending on the service, CloudWatch may send metrics with a certain delay. The value is set in windows. With a 1-minute aggregation window, setting the offset to 8 ensures the majority of the metrics are evaluated correctly. You may be able to use a lower offset if the delay introduced by AWS and Firehose is less. Fill data gaps with. Leave this void, or use Last known value if gaps in the data coming from AWS lead to false positives or negatives. See our documentation on how to create NRQL alerts for more details. Tags collection New Relic provides enhanced dimensions from metrics coming from AWS CloudWatch metric streams. Resource and custom tags are automatically pulled from most services and are used to decorate metrics with additional dimensions. Use the data explorer to see which tags are available on each AWS metric. The following query shows an example of tags being collected and queried as dimensions in metrics: SELECT average(`aws.rds.CPUUtilization`) FROM Metric FACET `tags.mycustomtag` SINCE 30 MINUTES AGO TIMESERIES Copy Note that not all metrics have their custom tags as dimensions. Currently, only metrics linked to entities in the New Relic Explorer have their custom tags associated. The AWS CloudWatch metric stream doesn't include tags as part of the stream message, hence, additional processing is required on the New Relic side. Metadata collection Like with custom tags, New Relic also pulls metadata information from relevant AWS services in order to decorate AWS CloudWatch metrics with enriched metadata collected from AWS Services APIs. This metadata is accessible in New Relic as additional dimensions on the metrics provided by AWS CloudWatch. This is an optional capability that's complementary to the CloudWatch Metric Streams integration. The solution relies on AWS Config, which might incur in additional costs in your AWS account. AWS Config provides granular controls to determine which services and resources are recorded. New Relic will only ingest metadata from the available resources in your AWS account. The following services / namespaces are supported: EC2 Lambda RDS ALB/NLB S3 API Gateway (excluding API v1) ELB EBS DynamoDB ECS Curated dashboards A set of dashboards for the most popular AWS Services are available in New Relic Instant Observaiblity. How to import dashboards Follow these steps in order to browse and import dashboards: Click Instant Observability from the top bar in New Relic One. Search for any AWS service name, such as AWS SQS, AWS RDS, AWS ELB, or AWS EC2. Access the AWS service tile. Click Install this quickstarts and select your account. Click Done to confirm that AWS metric stream is already configured. Browse and adapt the dashboard according to your needs. Have an interesting dashboard to share with the community? See contribution guidelines in the Instant Observability Github repository. Manage your data New Relic provides a set of tools to keep track of the data being ingested in your account. Go to Manage your data in the settings menu to see all details. Metrics ingested from AWS Metric Streams integrations are considered in the Metric bucket. If you need a more granular view of the data you can use the bytecountestimate() function on Metric in order to estimate the data being ingested. For example, the following query represents data ingested from all metrics processed via AWS Metric Streams integration in the last 30 days (in bytes): FROM Metric SELECT bytecountestimate() where collector.name='cloudwatch-metric-streams' since 30 day ago Copy We recommend the following actions to control the data being ingested: Make sure metric streams are enabled only on the AWS accounts and regions you want to monitor with New Relic. Use the inclusion and exclusion filters in the CloudWatch Metric Stream in order to select which services / namespaces are being collected. Consider using drop data rules to discard metrics based on custom filters (for example, drop metrics by namespace and tag, tag value, or any other valid NRQL criteria). Important Metrics sent via AWS Metric Streams count against your Metric API limits for the New Relic account where data will be ingested. Migrating from AWS API polling integrations When metrics are sent via Metric Streams to New Relic, if the same metrics are being retrieved using the current poll-based integrations, those metrics will be duplicated. For example, alerts and dashboards that use sum or count will return twice the actual number. This includes alerts and dashboards that use metrics that have a .Sum suffix. We recommend sending the data to a non-production New Relic account where you can safely do tests. If that is not an option, then AWS CloudWatch Metric Stream filters are available to include or exclude certain namespaces that can cause trouble. Alternatively, you can use filtering on queries to distinguish between metrics that come from Metric Streams and those that come through polling. All metrics coming from Metric Streams are tagged with collector.name='cloudwatch-metric-streams'. Migration steps On a typical deployment, migrating from API polling to metric stream involves the following steps (we recommend trying this on a dev / staging environment first): Go through the AWS UI in New Relic (or use NerdGraph APIs) to link your AWS account with New Relic. This is currently needed even if your AWS account is already linked with polling integrations. Make sure you complete the last step in the onboarding, which involves enabling AWS CloudWatch metric stream and the AWS Kinesis Data Firehose to push metrics to New Relic. Complete this step for any additional AWS region you want to monitor, since AWS CloudWatch requires one stream per region. Ensure metrics are received from all connected regions and namespaces. This may take several minutes. Disable all unnecessary polling integrations in the previous AWS provider account. The following integrations still need to be enabled since they aren't fully replaced by metric streams: AWS Billing, AWS CloudTrail, AWS Health, AWS Trusted Advisor. Query, dashboard, alert and inventory considerations AWS Metric Streams integration uses the Metric API to push metrics in the dimensional metric format. Poll-based integrations push metrics based on events (for example, ComputeSample event), and will be migrated to dimensional metrics in the future. To assist in this transition, New Relic provides a mechanism (known as shimming) that transparently lets you write queries in any format. Then these queries are processed as expected based on the source that's available (metrics or events). This mechanism works both ways, from events to metrics, and viceversa. Please consider the following when migrating from poll-based integrations: Dashboards: Custom dashboards that use poll-based AWS integration events will still work as expected. Alerts: Alert conditions that use poll-based AWS events will still work. We recommend adapting those to the dimensional metric format (using NRQL as source). Entities: New Relic Explorer might show duplicated entities for up to 24 hours. Inventory: the Inventory page is not supported with AWS CloudWatch metric streams (inventory telemetry is not included in the stream). Integrations not fully replaced by metric streams The AWS CloudWatch Metric Streams integration only collects CloudWatch metrics, resource metadata and custom tags. The following API polling integrations still need to be enabled to get complete visibility from AWS: AWS Billing AWS CloudTrail AWS Health AWS Trusted Advisor AWS VPC Infrastructure Agent metrics and EC2 metadata decoration As with the EC2 API polling integration, when the infrastructure agent is installed on a host and the EC2 namespace is active via AWS CloudWatch metric stream integration, then all the infrastructure agent events and metrics are decorated with additional metadata. The following attributes will decorate infrastructure samples (some might not be applicable on all environments): awsAvailabilityZone, ec2InstanceId, ec2PublicDnsName, ec2State, ec2EbsOptimized, ec2PublicIpAddress, ec2PrivateIpAddress, ec2VpcId, ec2AmiId, ec2PrivateDnsName, ec2KeyName, ec2SubnetId, ec2InstanceType, ec2Hypervisor, ec2Architecture, ec2RootDeviceType, ec2RootDeviceName, ec2VirtualizationType, ec2PlacementGroupName, ec2PlacementGroupTenancy.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 308.9572,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Amazon <em>CloudWatch</em> Metric Streams integration",
        "sections": "<em>Set</em> <em>up</em> a Metric Stream to send <em>CloudWatch</em> metrics to New Relic",
        "tags": "<em>AWS</em> integrations list",
        "body": " metadata is based on the <em>AWS</em> Config service. <em>Set</em> <em>up</em> a Metric Stream to send <em>CloudWatch</em> metrics to New Relic To stream <em>CloudWatch</em> metrics to New Relic you need to create Kinesis Data Firehose and point it to New Relic and then create a <em>CloudWatch</em> Metric Stream that sends metrics to that Firehose. How to map"
      },
      "id": "617da828196a6740e2f7d130"
    },
    {
      "sections": [
        "AWS Lambda for sending CloudWatch logs",
        "Install and configure the Cloudwatch logs Lambda function",
        "Create a Lambda trigger",
        "Configure retries (optional)",
        "Tip",
        "Resources created by the SAM template",
        "View log data",
        "What's next?"
      ],
      "title": "AWS Lambda for sending CloudWatch logs",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "69c310375d48a667779ffabead6f920eb6a34004",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/aws-lambda-sending-cloudwatch-logs/",
      "published_at": "2021-12-19T17:26:32Z",
      "updated_at": "2021-12-04T21:55:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can send your Amazon CloudWatch logs to New Relic using our AWS Lambda function, newrelic-log-ingestion. This can be easily deployed from the AWS Serverless application repository. Forwarding your CloudWatch logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Install and configure the Cloudwatch logs Lambda function The following setup shows one approach for configuring environment variables. You can also configure them from the Functions page. Complete the following: Make sure you have a New Relic license key. Open the AWS Serverless Application Repository in your browser. Search for newrelic and check Show apps that create custom IAM roles or resource policies to find newrelic-log-ingestion. Open the newrelic-log-ingestion details and click Deploy. In the function's Configure menu, go to Environment Variables and configure log forwarding using the following environment variables: Key Description DEBUG_LOGGING_ENABLED A boolean to determine if you want to output debug messages in the CloudWatch console. Optional. To turn on debug logs, set this to true. Default is false. LICENSE_KEY New Relic license key is used for sending data to New Relic. Required. LOGGING_ENABLED Determines if logs are forwarded to New Relic. Required. To turn on logging, set this to true. NR_LOGGING_ENDPOINT New Relic ingestion endpoint for logs. Required. Two endpoints are available: US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 NR_TAGS Specify tags to be added to all log events. Optional. Each tag is composed of a colon-delimited key and value. Multiple key-value pairs are semicolon-delimited; for example, env:prod;team:myTeam. Acknowledge that the app creates custom IAM roles, and then click Deploy. Once the process completes, create a Lambda trigger to link your Lambda function to CloudWatch logs. Create a Lambda trigger To get your logs streaming to New Relic, attach a trigger to the Lambda: From the left side menu, select Functions. Find and select the previously created newrelic-log-ingestion function. Under Designer, click Add Triggers, and select Cloudwatch Logs from the dropdown. Select the the appropriate Log group for your application. Enter a name for your filter. Optional: Enter a filter pattern. Check the Enable trigger checkbox, then click Add to create the trigger. Configure retries (optional) You can configure the number of retries you want to perform in case the function fails to send the data in case of communication issues. Recommended number is 3 retries, but you can change the retry behavior by changing the below parameters: Tip The more the number of retries there are can make the function run for longer times. This increases the probability of having higher costs for Lambda. However, decreasing the number of retries could increase the probability of data loss. MAX_RETRIES = 3 # Defines the number of retries after lambda failure to deliver data INITIAL_BACKOFF = 1 # Defines the initial wait seconds until next retry is executed BACKOFF_MULTIPLIER = 2 # Time multiplier between the retries As an example, in default above configuration, first retry will happen after 1 second, second retry after 2 seconds and third retry will happen after 4 seconds. Copy Resources created by the SAM template When you create the application from the repository, the following resources are also created: The Lambda function itself A role used to give execution permissions to the Lambda function based in CloudWatch Logs. All other Lambda configurations not listed can be left as the defaults. View log data If everything is configured correctly and your data is being collected, you should see data logs in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 306.7748,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>AWS</em> Lambda for sending <em>CloudWatch</em> <em>logs</em>",
        "sections": "<em>AWS</em> Lambda for sending <em>CloudWatch</em> <em>logs</em>",
        "tags": "<em>Logs</em>",
        "body": "You can send your Amazon <em>CloudWatch</em> logs to New Relic using our <em>AWS</em> Lambda function, newrelic-<em>log</em>-ingestion. This can be easily deployed from the <em>AWS</em> Serverless application repository. Forwarding your <em>CloudWatch</em> logs to New Relic will give you enhanced <em>log</em> management capabilities to <em>collect</em>"
      },
      "id": "603ea6bb28ccbc228deba74c"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/enable-lambda-monitoring/update-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Lambda monitoring architecture",
        "The New Relic Lambda monitoring stack",
        "Your function",
        "New Relic agent or SDK",
        "New Relic Lambda Extension",
        "New Relic's backend",
        "Lambda UI in New Relic One",
        "The legacy CloudWatch path"
      ],
      "title": "Lambda monitoring architecture",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Background",
        "Architecture"
      ],
      "external_id": "61c238aabc54923ed6f7d08d9a0cc111193f72a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture/",
      "published_at": "2021-12-20T06:06:23Z",
      "updated_at": "2021-12-05T04:36:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Lambda monitoring stack There are several important parts to Lambda monitoring: Your function The New Relic agent or SDK The New Relic Lambda Extension New Relic's backend The New Relic One Lambda UI Your function Your function is the code you want to understand. You want to know when it's encountering errors, why it's slow, or how often it gets invoked. New Relic agent or SDK This is a library that New Relic provides for the language that your function is written in. Its job is to do the actual monitoring of your code. It measures the duration of your function invocations, notes errors that occur, records details about the source events, and your functions responses. To do this, it needs to wrap around your Lambda invocation handler function. With a bit more work on your part, you can break your invocation into interesting segments, and tie together the interaction of your function with other functions and services, providing a holistic view of your serverless application. New Relic Lambda Extension This sidecar process runs inside the Lambda execution environment, alongside your code. It enhances the telemetry that the agent collects, and sends it to New Relic's back end in batches. It can also send your function's logs to New Relic. The extension is a small application that integrates tightly with the AWS Lambda lifecycle, and works to minimize both the time it takes your telemetry to arrive at New Relic, and the impact that instrumentation has on your function's latency and throughput. See more about our Lambda extension. New Relic's backend The New Relic service receives your telemetry, processes it into AwsLambdaInvocation, AwsLambdaInvocationError, Span, and custom events, and stores all that in our telemetry database: NRDB. Lambda UI in New Relic One Lambda functions aren't quite like traditional services, so the experience of managing them is a little different from the classic APM experience. Inside New Relic One, Lambda functions have a custom UI, which quickly surfaces the most important information about your function, and integrates closely with our logging and distributed tracing features. Backed by NRDB and NRQL, you can also write custom dashboards and alerts for your functions. The legacy CloudWatch path Older integrations send telemetry in a slightly different way. Instead of passing telemetry off to the extension, the agent writes it out to CloudWatch as a log line. By adding a log subscription filter to pipe your function logs into the aws-log-ingestion Lambda function, we can recover that Cloudwatch log line, and forward it on to New Relic, along with some other platform telemetry. In the past, we've seen that this approach has some considerable drawbacks. The AWS CloudWatch service can generate a lot of data. If you're on the free tier, you may hit your data limit pretty quickly. If you're paying for data, you may find this service making up the largest share of the data you're sending to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 93.39603,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Lambda</em> <em>monitoring</em> architecture",
        "sections": "<em>Lambda</em> <em>monitoring</em> architecture",
        "tags": "AWS <em>Lambda</em> <em>monitoring</em>",
        "body": "The New Relic <em>Lambda</em> <em>monitoring</em> stack There are several important parts to <em>Lambda</em> <em>monitoring</em>: Your function The New Relic agent or SDK The New Relic <em>Lambda</em> Extension New Relic&#x27;s backend The New Relic One <em>Lambda</em> UI Your function Your function is the code you want to understand. You want to know when"
      },
      "id": "605ab190196a67fc8238d740"
    },
    {
      "sections": [
        "Partial or missing logs for RDS, VPC, AWS Lambda",
        "Problem",
        "Solution"
      ],
      "title": "Partial or missing logs for RDS, VPC, AWS Lambda",
      "type": "docs",
      "tags": [
        "Integrations",
        "Amazon integrations",
        "Troubleshooting"
      ],
      "external_id": "7fca60f53fbe11e2ab4d0c0657de8bea0ea3522f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/infrastructure/amazon-integrations/troubleshooting/partial-or-missing-logs-rds-vpc-aws-lambda/",
      "published_at": "2021-12-20T04:09:42Z",
      "updated_at": "2021-10-23T16:44:34Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You are using NewRelic-log-ingestion, the lambda function for pushing logs from AWS to our RDS Enhanced Monitoring, VPC Flow Logs integrations, or early versions (alpha and beta) of monitoring for AWS Lambda. It is not working or it is sending partial data. Solution The NewRelic-log-ingestion lambda versions prior to 2.1 are being deprecated. Update to the latest lambdas published in the AWS Serverless Repository. You can either use the New Relic CLI or update manually. Recommended: The main way to update the log ingestion lambda function is to follow standard procedures to update the function using the New Relic CLI. You can also update the function manually: Avoid false positives in alerting: Follow UI procedures or API procedures to disable all alert conditions associated with monitoring integrations with AWS Lambda, RDS Enhanced Monitoring, and VPC Flow Logs. Remove the outdated lambda version of the lambda: Go to your AWS Lambda Console, and remove newrelic-log-ingestion. Be aware that this stops the RDS Enhanced Monitoring and the VPC Flow Logs integration until the next step is completed. Re-enable the service: Follow the instructions in RDS Enhanced Monitoring or VPC Flow Logs, or follow the step to configure CloudWatch logs to stream to New Relic Lambda. Check that your data is flowing through the new lambda.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 91.78545,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Partial or missing logs for RDS, VPC, AWS <em>Lambda</em>",
        "sections": "Partial or missing logs for RDS, VPC, AWS <em>Lambda</em>",
        "body": " the function using the New Relic CLI. You can also <em>update</em> the function manually: Avoid false positives in alerting: Follow UI procedures or API procedures to disable all alert conditions associated with <em>monitoring</em> integrations with AWS <em>Lambda</em>, RDS Enhanced <em>Monitoring</em>, and VPC Flow Logs. Remove"
      },
      "id": "617dc4c2e7b9d24595c05021"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-12-20T04:58:46Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 79.83347,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling serverless <em>monitoring</em> of AWS <em>Lambda</em>",
        "sections": "Troubleshoot enabling serverless <em>monitoring</em> of AWS <em>Lambda</em>",
        "tags": "AWS <em>Lambda</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable serverless <em>monitoring</em> for AWS <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture": [
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-12-20T06:07:23Z",
      "updated_at": "2021-09-14T18:21:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. To better understand how Lambda monitoring works, read about the New Relic Lambda monitoring stack. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.90742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-12-20T00:04:41Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.33014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-12-20T04:58:46Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 158.15384,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring": [
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-12-20T06:07:23Z",
      "updated_at": "2021-09-14T18:21:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. To better understand how Lambda monitoring works, read about the New Relic Lambda monitoring stack. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.26564,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": " and requirements See Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>. Next steps: Enable and use <em>Lambda</em> <em>monitoring</em> To <em>get</em> <em>started</em> using our <em>Lambda</em> <em>monitoring</em>, see the installation and enablement instructions. To better understand how <em>Lambda</em> <em>monitoring</em> works, read about the New Relic <em>Lambda</em> <em>monitoring</em> stack. You can also set up alerts or add your own custom events or attributes."
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Lambda monitoring architecture",
        "The New Relic Lambda monitoring stack",
        "Your function",
        "New Relic agent or SDK",
        "New Relic Lambda Extension",
        "New Relic's backend",
        "Lambda UI in New Relic One",
        "The legacy CloudWatch path"
      ],
      "title": "Lambda monitoring architecture",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Background",
        "Architecture"
      ],
      "external_id": "61c238aabc54923ed6f7d08d9a0cc111193f72a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture/",
      "published_at": "2021-12-20T06:06:23Z",
      "updated_at": "2021-12-05T04:36:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Lambda monitoring stack There are several important parts to Lambda monitoring: Your function The New Relic agent or SDK The New Relic Lambda Extension New Relic's backend The New Relic One Lambda UI Your function Your function is the code you want to understand. You want to know when it's encountering errors, why it's slow, or how often it gets invoked. New Relic agent or SDK This is a library that New Relic provides for the language that your function is written in. Its job is to do the actual monitoring of your code. It measures the duration of your function invocations, notes errors that occur, records details about the source events, and your functions responses. To do this, it needs to wrap around your Lambda invocation handler function. With a bit more work on your part, you can break your invocation into interesting segments, and tie together the interaction of your function with other functions and services, providing a holistic view of your serverless application. New Relic Lambda Extension This sidecar process runs inside the Lambda execution environment, alongside your code. It enhances the telemetry that the agent collects, and sends it to New Relic's back end in batches. It can also send your function's logs to New Relic. The extension is a small application that integrates tightly with the AWS Lambda lifecycle, and works to minimize both the time it takes your telemetry to arrive at New Relic, and the impact that instrumentation has on your function's latency and throughput. See more about our Lambda extension. New Relic's backend The New Relic service receives your telemetry, processes it into AwsLambdaInvocation, AwsLambdaInvocationError, Span, and custom events, and stores all that in our telemetry database: NRDB. Lambda UI in New Relic One Lambda functions aren't quite like traditional services, so the experience of managing them is a little different from the classic APM experience. Inside New Relic One, Lambda functions have a custom UI, which quickly surfaces the most important information about your function, and integrates closely with our logging and distributed tracing features. Backed by NRDB and NRQL, you can also write custom dashboards and alerts for your functions. The legacy CloudWatch path Older integrations send telemetry in a slightly different way. Instead of passing telemetry off to the extension, the agent writes it out to CloudWatch as a log line. By adding a log subscription filter to pipe your function logs into the aws-log-ingestion Lambda function, we can recover that Cloudwatch log line, and forward it on to New Relic, along with some other platform telemetry. In the past, we've seen that this approach has some considerable drawbacks. The AWS CloudWatch service can generate a lot of data. If you're on the free tier, you may hit your data limit pretty quickly. If you're paying for data, you may find this service making up the largest share of the data you're sending to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.5143,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Lambda</em> <em>monitoring</em> architecture",
        "sections": "<em>Lambda</em> <em>monitoring</em> architecture",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "The New Relic <em>Lambda</em> <em>monitoring</em> stack There are several important parts to <em>Lambda</em> <em>monitoring</em>: Your <em>function</em> The New Relic agent or SDK The New Relic <em>Lambda</em> Extension New Relic&#x27;s backend The New Relic One <em>Lambda</em> UI Your <em>function</em> Your <em>function</em> is the code you want to understand. You want to know when"
      },
      "id": "605ab190196a67fc8238d740"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-12-20T04:58:46Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.94997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring": [
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-12-20T00:04:41Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.39024,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    },
    {
      "sections": [
        "Lambda monitoring architecture",
        "The New Relic Lambda monitoring stack",
        "Your function",
        "New Relic agent or SDK",
        "New Relic Lambda Extension",
        "New Relic's backend",
        "Lambda UI in New Relic One",
        "The legacy CloudWatch path"
      ],
      "title": "Lambda monitoring architecture",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Background",
        "Architecture"
      ],
      "external_id": "61c238aabc54923ed6f7d08d9a0cc111193f72a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture/",
      "published_at": "2021-12-20T06:06:23Z",
      "updated_at": "2021-12-05T04:36:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Lambda monitoring stack There are several important parts to Lambda monitoring: Your function The New Relic agent or SDK The New Relic Lambda Extension New Relic's backend The New Relic One Lambda UI Your function Your function is the code you want to understand. You want to know when it's encountering errors, why it's slow, or how often it gets invoked. New Relic agent or SDK This is a library that New Relic provides for the language that your function is written in. Its job is to do the actual monitoring of your code. It measures the duration of your function invocations, notes errors that occur, records details about the source events, and your functions responses. To do this, it needs to wrap around your Lambda invocation handler function. With a bit more work on your part, you can break your invocation into interesting segments, and tie together the interaction of your function with other functions and services, providing a holistic view of your serverless application. New Relic Lambda Extension This sidecar process runs inside the Lambda execution environment, alongside your code. It enhances the telemetry that the agent collects, and sends it to New Relic's back end in batches. It can also send your function's logs to New Relic. The extension is a small application that integrates tightly with the AWS Lambda lifecycle, and works to minimize both the time it takes your telemetry to arrive at New Relic, and the impact that instrumentation has on your function's latency and throughput. See more about our Lambda extension. New Relic's backend The New Relic service receives your telemetry, processes it into AwsLambdaInvocation, AwsLambdaInvocationError, Span, and custom events, and stores all that in our telemetry database: NRDB. Lambda UI in New Relic One Lambda functions aren't quite like traditional services, so the experience of managing them is a little different from the classic APM experience. Inside New Relic One, Lambda functions have a custom UI, which quickly surfaces the most important information about your function, and integrates closely with our logging and distributed tracing features. Backed by NRDB and NRQL, you can also write custom dashboards and alerts for your functions. The legacy CloudWatch path Older integrations send telemetry in a slightly different way. Instead of passing telemetry off to the extension, the agent writes it out to CloudWatch as a log line. By adding a log subscription filter to pipe your function logs into the aws-log-ingestion Lambda function, we can recover that Cloudwatch log line, and forward it on to New Relic, along with some other platform telemetry. In the past, we've seen that this approach has some considerable drawbacks. The AWS CloudWatch service can generate a lot of data. If you're on the free tier, you may hit your data limit pretty quickly. If you're paying for data, you may find this service making up the largest share of the data you're sending to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.51428,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Lambda</em> <em>monitoring</em> architecture",
        "sections": "<em>Lambda</em> <em>monitoring</em> architecture",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "The New Relic <em>Lambda</em> <em>monitoring</em> stack There are several important parts to <em>Lambda</em> <em>monitoring</em>: Your <em>function</em> The New Relic agent or SDK The New Relic <em>Lambda</em> Extension New Relic&#x27;s backend The New Relic One <em>Lambda</em> UI Your <em>function</em> Your <em>function</em> is the code you want to understand. You want to know when"
      },
      "id": "605ab190196a67fc8238d740"
    },
    {
      "sections": [
        "Troubleshoot enabling serverless monitoring of AWS Lambda",
        "Problem",
        "Solution",
        "Recommended: Attach your CloudWatch logs to the ticket",
        "Important"
      ],
      "title": "Troubleshoot enabling serverless monitoring of AWS Lambda",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Troubleshooting"
      ],
      "external_id": "73f864add78be5efb2429485506dc5a679a9820e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda/",
      "published_at": "2021-12-20T04:58:46Z",
      "updated_at": "2021-03-16T18:38:54Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem You’re attempting to enable serverless monitoring for AWS Lambda and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the AWS integration step wasn't completed. Not seeing data on Troubleshooting category UI pages. If you aren't seeing data on the Distributed tracing, Errors, and Invocations UI tabs, this means the APM agent instrumentation step wasn't completed. Besides these basic enablement problems, there are some additional problems that may cause an issue: CloudWatch error \"HTTP error 401: unauthorized.\" This is due to an incorrect API Key. The --nr-api-keyargument in the Configure AWS enable step takes your user key, which is different from the REST API key. Custom metrics are missing. Lambda monitoring is not compatible with our custom metrics. Use custom attributes to add metadata. Invocations missing. To see invocation breakdown details, distributed tracing must be enabled as part of the Lambda instrumentation step. Distributed tracing is required so that span details can be displayed in the invocation details pane. You've completed the installation, integration, and instrumentation steps correctly, and your function is sending logs to CloudWatch but you're not seeing traces for specific dependencies (or any traces) in the UI. This may result from the order of layer merging (if you're using our Lambda layers) or from the order of import (if you're instrumenting manually): If you're instrumenting with layers: make sure in your function configuration that the New Relic layer is merged before other layers (though if your function uses webpack, the New Relic layer should be merged after the webpack layer). If you're instrumenting a Node function manually, make sure that your function imports newrelic and @newrelic/aws-sdk before it imports any dependencies you expect to monitor. If none of these solutions help you, contact our support team. The following information will help you when you talk to support technicians: Has the Lambda function appeared in the UI before? If so, what is the name of the function? If some data for the Lambda function is appearing in the UI, what specific data is appearing? What APM language agent are you using to instrument the function? Recommended: Attach your CloudWatch logs to the ticket To provide our support team with logging information when opening a ticket: Invoke the function in AWS Lambda. Click on the logs link after your function runs. This will take you to the CloudWatch logs in AWS. On the left-hand sidebar in AWS, under Logs, click on Insights. Select your function and also the newrelic-log-ingestion stream. Apply an appropriate Time Filter, and a log entry limit (the default of 20 may not be enough). Under Actions select Copy query results (ASCII). Paste the copied text into a new text file, then save and upload the text file to the ticket. Important The NR_LAMBDA_MONITORING payload contains all the information the agent attempts to send up, including metrics, events, some AWS account metadata, invocations and errors data. Note that some of that data (for example, our legacy metrics) will not make it to our UI because our ingest pipeline does not consume them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 157.94997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "sections": "Troubleshoot enabling <em>serverless</em> <em>monitoring</em> of <em>AWS</em> <em>Lambda</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Problem You’re attempting to enable <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em> and are having an issue or error. Solution There are two common problems related to not completing all of the enablement procedures: Not seeing data on CloudWatch metrics UI page. This means the <em>AWS</em> integration step wasn&#x27;t"
      },
      "id": "603ea6bb64441f85284e889b"
    }
  ],
  "/docs/serverless-function-monitoring/aws-lambda-monitoring/troubleshooting/troubleshoot-enabling-serverless-monitoring-aws-lambda": [
    {
      "sections": [
        "Lambda monitoring architecture",
        "The New Relic Lambda monitoring stack",
        "Your function",
        "New Relic agent or SDK",
        "New Relic Lambda Extension",
        "New Relic's backend",
        "Lambda UI in New Relic One",
        "The legacy CloudWatch path"
      ],
      "title": "Lambda monitoring architecture",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Background",
        "Architecture"
      ],
      "external_id": "61c238aabc54923ed6f7d08d9a0cc111193f72a3",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/architecture/",
      "published_at": "2021-12-20T06:06:23Z",
      "updated_at": "2021-12-05T04:36:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The New Relic Lambda monitoring stack There are several important parts to Lambda monitoring: Your function The New Relic agent or SDK The New Relic Lambda Extension New Relic's backend The New Relic One Lambda UI Your function Your function is the code you want to understand. You want to know when it's encountering errors, why it's slow, or how often it gets invoked. New Relic agent or SDK This is a library that New Relic provides for the language that your function is written in. Its job is to do the actual monitoring of your code. It measures the duration of your function invocations, notes errors that occur, records details about the source events, and your functions responses. To do this, it needs to wrap around your Lambda invocation handler function. With a bit more work on your part, you can break your invocation into interesting segments, and tie together the interaction of your function with other functions and services, providing a holistic view of your serverless application. New Relic Lambda Extension This sidecar process runs inside the Lambda execution environment, alongside your code. It enhances the telemetry that the agent collects, and sends it to New Relic's back end in batches. It can also send your function's logs to New Relic. The extension is a small application that integrates tightly with the AWS Lambda lifecycle, and works to minimize both the time it takes your telemetry to arrive at New Relic, and the impact that instrumentation has on your function's latency and throughput. See more about our Lambda extension. New Relic's backend The New Relic service receives your telemetry, processes it into AwsLambdaInvocation, AwsLambdaInvocationError, Span, and custom events, and stores all that in our telemetry database: NRDB. Lambda UI in New Relic One Lambda functions aren't quite like traditional services, so the experience of managing them is a little different from the classic APM experience. Inside New Relic One, Lambda functions have a custom UI, which quickly surfaces the most important information about your function, and integrates closely with our logging and distributed tracing features. Backed by NRDB and NRQL, you can also write custom dashboards and alerts for your functions. The legacy CloudWatch path Older integrations send telemetry in a slightly different way. Instead of passing telemetry off to the extension, the agent writes it out to CloudWatch as a log line. By adding a log subscription filter to pipe your function logs into the aws-log-ingestion Lambda function, we can recover that Cloudwatch log line, and forward it on to New Relic, along with some other platform telemetry. In the past, we've seen that this approach has some considerable drawbacks. The AWS CloudWatch service can generate a lot of data. If you're on the free tier, you may hit your data limit pretty quickly. If you're paying for data, you may find this service making up the largest share of the data you're sending to New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.6471,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Lambda</em> <em>monitoring</em> architecture",
        "sections": "<em>Lambda</em> <em>monitoring</em> architecture",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "The New Relic <em>Lambda</em> <em>monitoring</em> stack There are several important parts to <em>Lambda</em> <em>monitoring</em>: Your <em>function</em> The New Relic agent or SDK The New Relic <em>Lambda</em> Extension New Relic&#x27;s backend The New Relic One <em>Lambda</em> UI Your <em>function</em> Your <em>function</em> is the code you want to understand. You want to know when"
      },
      "id": "605ab190196a67fc8238d740"
    },
    {
      "sections": [
        "Monitoring AWS Lambda with Serverless monitoring",
        "Why it matters",
        "Access and requirements",
        "Next steps: Enable and use Lambda monitoring"
      ],
      "title": "Monitoring AWS Lambda with Serverless monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "5d1d86ec786398b3190ed1a6e152373e0547dc57",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/monitoring-aws-lambda-serverless-monitoring/",
      "published_at": "2021-12-20T06:07:23Z",
      "updated_at": "2021-09-14T18:21:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We offer in-depth performance monitoring for your serverless AWS Lambda functions. Read on to learn about the feature, how it works, and its requirements. This Lambda monitoring feature is not the same as the Lambda monitoring integration, which only uses CloudWatch data. Serverless Lambda monitoring is more extensive and uses both CloudWatch data and code-level instrumentation to deliver more in-depth monitoring. Why it matters Do you need to rapidly instrument monitoring and observability to your serverless functions without resorting to code changes? Our Lambda layer provides unified visibility into the most detailed behaviors of your Lambda functions so you can understand what's going on in your serverless applications. Use all this information to troubleshoot your systems and optimize your functions so they can function faster and deliver with confidence on serverless architectures. Spend less time instrumenting, and more time building. Lambda monitoring gives you: Every invocation of your Lambda functions, including performance data like detailed duration, cold starts, exceptions, and tracebacks. AWS Lambda event source information, which provides context and attributes about events that triggered each AWS Lambda invocation, such as API Gateway, ALB SNS, SQS, DynamoDB, and more. Visibility into your entire ecosystem with distributed tracing: see the path of requests that led to your Lambda, and see Lambda spans in your other distributed traces. Logs in context, which provides full invocation and function level logs right along side the metrics, attributes, and trace data. Inventoried tags and metadata. We retrieve information from your AWS entities, giving you the ability to filter and facet down to the team, or specific metadata attributes on the function configuration or invocation itself. Easy ability to query your data with an automatic facet builder, which instantly facets your dashboards and charts by attribute or function to explore custom data, without having to write queries. Lambda data is displayed in its own dedicated UI in New Relic One. Access and requirements See Compatibility and requirements of AWS Lambda monitoring. Next steps: Enable and use Lambda monitoring To get started using our Lambda monitoring, see the installation and enablement instructions. To better understand how Lambda monitoring works, read about the New Relic Lambda monitoring stack. You can also set up alerts or add your own custom events or attributes.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 165.90742,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "sections": "<em>Monitoring</em> <em>AWS</em> <em>Lambda</em> with <em>Serverless</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "We offer in-depth performance <em>monitoring</em> for your <em>serverless</em> <em>AWS</em> <em>Lambda</em> functions. Read on to learn about the feature, how it works, and its requirements. This <em>Lambda</em> <em>monitoring</em> feature is not the same as the <em>Lambda</em> <em>monitoring</em> integration, which only uses CloudWatch data. <em>Serverless</em> <em>Lambda</em>"
      },
      "id": "603eb08b28ccbc8b90eba75c"
    },
    {
      "sections": [
        "Compatibility and requirements of AWS Lambda monitoring",
        "Recommended AWS Lambda language runtimes",
        "About AWS costs"
      ],
      "title": "Compatibility and requirements of AWS Lambda monitoring",
      "type": "docs",
      "tags": [
        "Serverless function monitoring",
        "AWS Lambda monitoring",
        "Get started"
      ],
      "external_id": "067a3685f16418cb4e6df1477a9584edeed006f7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/serverless-function-monitoring/aws-lambda-monitoring/get-started/compatibility-requirements-aws-lambda-monitoring/",
      "published_at": "2021-12-20T00:04:41Z",
      "updated_at": "2021-09-02T16:45:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Before enabling serverless monitoring for AWS Lambda, make sure you meet the requirements and learn about AWS charges resulting from its use. Recommended AWS Lambda language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2, java11 .NET Core: dotnetcore3.1 AWS has older runtimes for these languages as well, but AWS has not chosen to support the latest Lambda APIs with those older runtimes. Integration for older runtimes requires a different strategy, but is possible. Python and NodeJS are by far the most popular languages in the Lambda ecosystem. The New Relic Lambda Layers for Node and Python include the very latest New Relic Agent version, and provide rich instrumentation with minimal configuration, right out of the box. Similarly, Go uses the New Relic Go Agent. We recommend building self-hosting Go lambda functions, because the latest AWS Lambda APIs are not supported in the AWS go1.x runtime. Fortunately, this is well supported by the AWS Lambda SDK for Go. New Relic recommends keeping the agent module up to date. Support is limited for agent versions older than 3.9.0. To minimize performance impact, we've taken a different approach with Java and .NET Core. New Relic provides OpenTelemetry SDKs for these runtimes. This approach requires a bit more code to integrate. For complete Lambda instrumentation, some of our agents included in our Lambda layers depend on a language-specific AWS SDK. If an AWS SDK is not used, Lambda data will appear as external service calls in the UI, with minimal detail. In other words, we rely on the AWS SDK to facilitate instrumentation of your function. For the following services, only the \"target\" (Lambda function name, SNS topic ARN, DynamoDB table name, etc.) is reported: Autoscaling, Athena, Batch, Cloud9, CodeBuild, DynamoDB, Greengrass, IoT, Kinesis (Streams, Firehose, Analytics, Video), Lambda, Lex, Machine Learning, MQ, Redshift, Rekognition, S3, SES, SimpleDB, SNS, SQS, Storage Gateway, and STS. About AWS costs Enabling serverless monitoring for AWS Lambda may result in Amazon Web Services charges. Our newrelic-log-ingestion Lambda function, which reports your Lambda data to us, is considered a Third Party Service: AWS charges resulting from your use of it are your responsibility. If you use the Lambda Extension, you can avoid the CloudWatch Logs ingest charge for the telemetry gathered by New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 164.33014,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "sections": "Compatibility and requirements of <em>AWS</em> <em>Lambda</em> <em>monitoring</em>",
        "tags": "<em>Serverless</em> <em>function</em> <em>monitoring</em>",
        "body": "Before enabling <em>serverless</em> <em>monitoring</em> for <em>AWS</em> <em>Lambda</em>, make sure you meet the requirements and learn about <em>AWS</em> charges resulting from its use. Recommended <em>AWS</em> <em>Lambda</em> language runtimes NodeJS: nodejs12.x, nodejs14.x Python: python3.7, python3.8, python3.9 Go: provided, provided.al2 Java: java8.al2"
      },
      "id": "603e98bd64441ff7454e8885"
    }
  ]
}