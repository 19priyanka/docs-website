{
  "/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.87973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.83812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "iOS application licenses"
      ],
      "title": "iOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "a6df56e363112e7387e6887f04381a36a5457e84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/ios-application-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-09-27T15:25:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation http://alamofire.org/ Ace BSD Copyright © 2010, Ajax.org B.V. ActiveLabel MIT Copyright © 2015 Optonaut Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation Analytics MIT Copyright © 2016 Segment.io, Inc. BBlock MIT Copyright © 2012 David Keegan BigNumber MIT Copyright © 2019 mkrd CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright © 2016-2019 Daniel Cohen Gindi & Philipp Jahoda ECSlidingViewController MIT Copyright © 2013 EdgeCase LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. ObjectMapper MIT Copyright © 2014 Hearst RadarKit New Relic License © 2010-2021 New Relic, Inc. All rights reserved. SSPullToRefresh MIT Copyright © 2012-2014 Sam Soffes, http://soff.es UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. jsTimezoneDetect MIT Copyright © 2012 Jon Nylander, project maintained at bitbucket.org lodash MIT Copyright © JS Foundation and other contributors js.foundation The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.5945,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "iOS application <em>licenses</em>",
        "sections": "iOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> iOS app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "603e9db1196a670e70a83df3"
    }
  ],
  "/docs/licenses/product-or-service-licenses/new-relic-synthetics/new-relic-synthetics-licenses": [
    {
      "sections": [
        "CodeStream licenses"
      ],
      "title": "CodeStream licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "CodeStream"
      ],
      "external_id": "331f3d1cd0897f453f98bc054fda09a9ad2725c1",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/codestream/codestream-licenses/",
      "published_at": "2021-10-24T17:53:35Z",
      "updated_at": "2021-10-23T17:05:38Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. CodeStream license on GitHub CodeStream's third-party software notices on GitHub",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 261.87973,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "CodeStream <em>licenses</em>",
        "sections": "CodeStream <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and we use the following with CodeStream. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. CodeStream license on GitHub CodeStream&#x27;s third-party software notices on GitHub"
      },
      "id": "617440e2196a677ea62f0193"
    },
    {
      "sections": [
        "tvOS application licenses"
      ],
      "title": "tvOS application licenses",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "Mobile app licenses"
      ],
      "external_id": "0b3ac8ec42cef00f5a4d3ddf354e4be38ad0595f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/mobile-app-licenses/tvos-application-licenses/",
      "published_at": "2021-10-24T17:56:58Z",
      "updated_at": "2021-10-24T17:56:58Z",
      "document_type": "page",
      "popularity": 1,
      "body": "We love open-source software, and use the following in the New Relic for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software licenses, and in that case we have listed the license we've chosen to use. Library License Copyright AFNetworking MIT Copyright © 2011-2020 Alamofire Software Foundation (http://alamofire.org/) Alamofire MIT Copyright © 2014-2021 Alamofire Software Foundation (http://alamofire.org/) CDMarkdownKit MIT Copyright © 2016-2017 Christopher de Haan contact@christopherdehaan.me Charts Apache License, Version 2.0 Copyright 2016-2019 Daniel Cohen Gindi & Philipp Jahoda LoginManagerSDK New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. Mantle MIT Copyright © GitHub, Inc. All rights reserved. Copyright © 2012, Bitswift, Inc MetricMetadata New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NRCharts New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. NVActivityIndicatorView MIT Copyright © 2016 Vinh Nguyen NewRelicAgent New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. UICKeyChainStore MIT Copyright © 2011 kishikawa katsumi WidgetLibrary New Relic License Copyright © 2010-2021 New Relic, Inc. All rights reserved. XYPieChart MIT Copyright © 2012 Xiaoyang Feng, XYStudio.cc Yams MIT Copyright © 2016 JP Simard. iOS-fontawesome CC BY 3.0 & MIT Copyright © 2012 Alex Usbergo. All rights reserved. The remainder of the code is covered by the New Relic License agreement.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 251.83812,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "tvOS application <em>licenses</em>",
        "sections": "tvOS application <em>licenses</em>",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "We love open-source software, and use the following in the <em>New</em> <em>Relic</em> for TV app. Thank you, open-source community, for making these fine tools! Some of these are listed under multiple software <em>licenses</em>, and in that case we have listed the license we&#x27;ve chosen to use. Library License Copyright"
      },
      "id": "6072d619196a6795b664a75c"
    },
    {
      "sections": [
        "Preview access for New Relic One"
      ],
      "title": "Preview access for New Relic One",
      "type": "docs",
      "tags": [
        "Licenses",
        "Product or service licenses",
        "New Relic One"
      ],
      "external_id": "5a11f3d0ff23ad22ec459a0115a70ddbb2964d1e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/licenses/product-or-service-licenses/new-relic-one/preview-access-new-relic-one/",
      "published_at": "2021-10-24T17:59:23Z",
      "updated_at": "2021-10-24T17:59:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As a customer with a paid subscription to New Relic products, you are eligible to participate in preview access of the New Relic One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING THE PREVIEW ACCESS PRODUCTS, YOU AGREE THAT YOUR PREVIEW ACCESS USAGE IS PURSUANT TO THESE SEPARATE TERMS AND CONDITIONS IN LIEU OF ANY OTHER TERMS. These terms do not have to be signed in order to be binding. If you do not agree to these terms and conditions, your sole remedy is to not participate in Preview Access. New Relic reserves the right to terminate or restrict Preview Access, in whole or in part, at any time. Notwithstanding the foregoing and any other materials provided by New Relic, select customers are ineligible for the Preview Access.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 238.8581,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Preview access for <em>New</em> <em>Relic</em> One",
        "sections": "Preview access for <em>New</em> <em>Relic</em> One",
        "tags": "<em>Product</em> <em>or</em> <em>service</em> <em>licenses</em>",
        "body": "As a customer with a paid subscription to <em>New</em> <em>Relic</em> products, you are eligible to participate in preview access of the <em>New</em> <em>Relic</em> One platform for the period beginning July 31, 2020 and ending December 31, 2020 (“Preview Access”). BY DOWNLOADING, ACCESSING, INDICATING YOUR AGREEMENT TO, OR USING"
      },
      "id": "603e891464441f2af14e883b"
    }
  ],
  "/docs/logs/forward-logs/aws-firelens-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.7221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95514,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/aws-lambda-sending-cloudwatch-logs": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74567,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.7221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95514,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/aws-lambda-sending-logs-s3": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74548,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.7219,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95502,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/azure-log-forwarding": [
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 360.15942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>logs</em> in context. <em>Log</em> forwarding options Use any of these solutions to forward your <em>logs</em> to <em>New</em> <em>Relic</em>. Recommended: Infrastructure <em>monitoring</em> agent Amazon: AWS <em>Cloud</em>Watch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending <em>logs</em> from S3 Microsoft: <em>Azure</em> ARM template Other <em>log</em>"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 359.3098,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 336.92035,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google <em>Cloud</em> Platform",
        "sections": "Forward <em>logs</em> from GCP <em>Cloud</em> <em>Logging</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google <em>Cloud</em> Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google <em>Cloud</em> Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/enable-log-management-new-relic": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.41272,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> context",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> context",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in context for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/forward-logs/fluent-bit-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/fluentd-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74524,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72168,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95483,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent": [
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72147,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95465,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.41254,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> context",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> context",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in context for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/forward-logs/google-cloud-platform-log-forwarding": [
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 361.82953,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your <em>platform</em> with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 359.3094,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "You can forward your <em>logs</em> to <em>New</em> <em>Relic</em> using our infrastructure <em>monitoring</em> agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your <em>platform</em> performance data. Forwarding your <em>logs</em> to <em>New</em> <em>Relic</em> will give you enhanced <em>log</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.85016,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> context",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> context",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in context for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    }
  ],
  "/docs/logs/forward-logs/heroku-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/kubernetes-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74484,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72125,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/logstash-plugin-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/stream-logs-using-kinesis-data-firehose": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74463,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72104,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95435,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/forward-logs/vector-output-sink-log-forwarding": [
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure <em>monitoring</em> agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 365.72083,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "Forward your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in context of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    },
    {
      "sections": [
        "Forward logs from Google Cloud Platform",
        "Generate a GCP Pub/Sub ingest URL",
        "Create a GCP Pub/Sub Topic",
        "Prepare a GCP Pub/Sub Topic to forward logs to New Relic",
        "Forward logs from GCP Cloud Logging to New Relic",
        "What's next?"
      ],
      "title": "Forward logs from Google Cloud Platform",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic",
        "GCP",
        "Google Cloud Platform"
      ],
      "external_id": "468037bc9c5a2039d0f964af9f947c2bee1a58da",
      "image": "https://docs.newrelic.com/static/3cf698759572f3f93a807069a7d1cc2d/c1b63/gcp-create-sink.png",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/google-cloud-platform-log-forwarding/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-23T13:23:40Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use these steps to configure a Google Cloud Platform Pub/Sub topic to send logs to New Relic. Generate a GCP Pub/Sub ingest URL Navigate to New Relic Logs Click Add more data sources Click Google Cloud Platform, then select the New Relic account you want to forward logs to and click Continue. Optionally, you can configure metadata. Here you can define attribute-value pairs that will be included in every log event sent to the ingest URL you will generate in the next step. Click Generate URL. Copy your newly generated ingest URL and keep it in a safe place, you will need it once you are ready to configure a Pub/Sub topic to send logs to New Relic. Create a GCP Pub/Sub Topic Navigate to the GCP Pub/Sub Console Click Create Topic Enter a meaningful Topic ID, then configure other options as desired and click Create Topic. Prepare a GCP Pub/Sub Topic to forward logs to New Relic Once you have created your Pub/Sub topic, return to the GCP Pub/Sub Console. Click on the Pub/Sub topic you created in the last section. Scroll down and select the Subscriptions tab, then click Create Subscription and select Create subscription. Enter a Subscription ID and select Push under Delivery Type. Paste the ingest URL you generated in the first section in the Endpoint URL field. Configure remaining settings as desired and click Create. Forward logs from GCP Cloud Logging to New Relic Navigate to the GCP Logs Router Console. Click Create Sink. Provide a Sink name and Sink description, then click Next. Select Cloud Pub/Sub topic under Select sink service, and select the topic you created in the previous section under Select a Cloud Pub/Sub topic. Configure remaining filters as desired and click Create sink to complete setup. What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 342.95416,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward <em>logs</em> from Google Cloud Platform",
        "sections": "Prepare a GCP Pub&#x2F;Sub Topic to forward <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "Use these steps to configure a Google Cloud Platform Pub&#x2F;Sub topic to send <em>logs</em> to <em>New</em> <em>Relic</em>. Generate a GCP Pub&#x2F;Sub ingest URL Navigate to <em>New</em> <em>Relic</em> <em>Logs</em> Click Add more data sources Click Google Cloud Platform, then select the <em>New</em> <em>Relic</em> account you want to forward <em>logs</em> to and click Continue"
      },
      "id": "61740cdc28ccbc5833c6a8c2"
    }
  ],
  "/docs/logs/index": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.541626,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Logs</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.38412,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Logs</em>",
        "body": "Problem After enabling <em>log</em> management capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> troubleshooting Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    },
    {
      "sections": [
        "View log messages in real time (live tail)",
        "Problem",
        "Solution"
      ],
      "title": "View log messages in real time (live tail)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "04b7a62fd3ff5ba7772226b0990f22729e6166da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:25Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When you deploy a new host, server, or make other application changes, you want to immediately see how your system responds to these changes. You need to view your log messages as they arrive in real time. Solution To focus on messages as they arrive in real time, enable live tail logging: Go to one.newrelic.com > Logs. Enter a query to focus on the type of log info you need, then click Query logs; for example: Find logs where annotations.restartRequested:\"2020-12-23T18:00:00Z\" Copy Click the Livetail icon to enable or disable it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 83.38407,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>log</em> messages in real time (live tail)",
        "sections": "View <em>log</em> messages in real time (live tail)",
        "tags": "<em>Logs</em>",
        "body": ": Go to one.newrelic.com &gt; <em>Logs</em>. Enter a query to focus on the type of <em>log</em> info you need, then click Query <em>logs</em>; for example: Find <em>logs</em> where annotations.restartRequested:&quot;2020-12-23T18:00:00Z&quot; Copy Click the Livetail icon to enable or disable it."
      },
      "id": "603e9aa428ccbc8f36eba76d"
    }
  ],
  "/docs/logs/log-management/get-started/get-started-log-management": [
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-10-24T17:42:05Z",
      "updated_at": "2021-10-24T17:42:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log pattern functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. For example, accounts still using our original pricing model require an Owner or Admin role. If you see Patterns are turned off in your Logs UI, click Configure patterns and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you have patterns enabled but do not see any pattern data. If you're sure none of these items are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.75607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.26978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 197.89597,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em> capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> troubleshooting Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    }
  ],
  "/docs/logs/log-management/get-started/new-relics-log-management-security-privacy": [
    {
      "sections": [
        "Get started with log management",
        "Find problems faster, reduce context switching",
        "Bring in your logging data",
        "View your logging data in New Relic",
        "What's next"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. New Relic offers a fast, scalable log management platform so you can connect your logs with the rest of your telemetry and infrastructure data in a single place. See how it works with this video (approx. 2 minutes). Our log management solution provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. Find problems faster, reduce context switching Log management provides a way to connect your log data with the rest of your application and infrastructure data. You can get to the root cause of problems quickly, without losing context switching between tools. Log management features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Visualize everything in a single place. Bring in your logging data To forward your log data to New Relic, you can: Use our infrastructure monitoring agent as a lightweight data collector, without having to install additional software. Select from a wide range of log forwarding plugins, including Amazon, Microsoft, Fluentd, Fluent Bit, Kubernetes, Logstash, and more. Use our OpenTelemetry solutions. Send your log data by using the Log API or TCP endpoint. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic You can explore your logging data in the UI or by API: Logs UI at one.newrelic.com Logs UI for EU region data center if applicable: one.eu.newrelic.com You can also query the Log data type. For example, use NRQL to run: SELECT * FROM Log Copy You can also use NerdGraph, our GraphQL-format API, to request the exact data you need. What's next Ready to get started with our log management solutions? If you don't have one already, create a New Relic account. It's free, forever. Forward your logs to New Relic. Recommendation: Use our infrastructure agent as your log forwarder, so you can get logs in context of your platform and services directly in our UI. For apps monitored by a New Relic APM agent, configure logs in context. Explore the logging data across your platform with our Logs UI in New Relic One, where you can add alerts, query your data, and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 260.1862,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "sections": "<em>Get</em> <em>started</em> with <em>log</em> <em>management</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " data you need. What&#x27;s next Ready to <em>get</em> <em>started</em> with our <em>log</em> <em>management</em> solutions? If you don&#x27;t have one already, create a New Relic account. It&#x27;s free, forever. Forward your <em>logs</em> to New Relic. Recommendation: Use our infrastructure agent as your <em>log</em> forwarder, so you can <em>get</em> <em>logs</em> in context of your"
      },
      "id": "603ea62ee7b9d249432a07e2"
    },
    {
      "sections": [
        "Discover value in log data with patterns",
        "Technical overview",
        "Availability",
        "Get started",
        "Explore log patterns",
        "Explore logs with no pattern",
        "Masked attributes and wildcards",
        "Troubleshooting",
        "Put the platform to work with patterns"
      ],
      "title": "Discover value in log data with patterns",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "8f1e27c94327ca4888a945f8e12f9c2310ccd7a6",
      "image": "https://docs.newrelic.com/static/578d7186bb34352855696e5307cc82f2/c1b63/log-patterns-logs-without-a-pattern.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns/",
      "published_at": "2021-10-24T17:42:05Z",
      "updated_at": "2021-10-24T17:42:05Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Log patterns are the fastest way to discover value in log data without searching. Log data is high volume telemetry with a low value per individual record. Searching can quickly lead to logs that provide a root cause explanation, but most data is repetitive and hard to contextualize when browsing. Patterns can make log data discoverable without spending a lot of time reading through low value data. Logs > Patterns: Use patterns as the basis for alerts when the frequency of important data changes, or for configuring drop rules to get rid of unnecessary repetitive data. Technical overview Log pattern functionality applies machine learning to normalize and group log messages that are consistent in format but variable in content. These grouped messages can be sorted, making it easy to find the most frequent or rarest sets of logs in your environment. Use patterns as the basis for alerts when the frequency of important data changes, or to configure drop rules to get rid of unnecessary repetitive data. Log patterns use advanced clustering algorithms to group together similar log messages automatically. With patterns, you can: Orient more quickly through millions of logs. Reduce the time it takes to identify unusual behavior in your log estate. Monitor the frequency of known patterns over time to focus your energy on what matters, and exclude what's irrelevant. Availability The ability to configure this feature is dependent on role-based permissions. For example, accounts still using our original pricing model require an Owner or Admin role. If you see Patterns are turned off in your Logs UI, click Configure patterns and enable it. If you don't see patterns within 30 minutes of enabling the feature, there may be a lack of data with a message attribute for the system to create a pattern from it. Log patterns Limitations and considerations Pricing There is no separate pricing for log patterns. The only cost is for additional data generated and added to your log records. A pattern attribute will be added to all logs that match a pattern. Attributes also may be added when common values are discovered, such as GUIDs, IP addresses, URL, or email addresses. These attributes are automatically extracted from the log message as part of the pattern process. HITRUST accounts The log patterns feature is not FedRAMP compliant. FedRAMP or other HITRUST accounts are not eligible to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing logs and their patterns. These parsing limits can have an impact on the data you get. For more information, see our documentation about parsing limits. Get started To start examining patterns: Go to one.newrelic.com > Logs, and use the account picker dropdown to select the target account where you want to explore patterns. In the left navigation of the Logs UI, click Patterns. The main log UI changes to show patterns that match the query in the query bar. Logs > Log patterns: The line chart shows the top 5 patterns over time. Use the time picker and query bar to adjust the results. Explore log patterns By default the log patterns UI first shows the most frequent occurrence of patterns. To sort to show the rarest patterns first, click the Count column. You can also use the query bar or attributes bar to filter your log patterns. If you want to... Do this... Understand the rate of change in patterns Look at the line chart. The color-coded patterns correspond to the plot column in the table. You can toggle individual plot patterns to narrow your focus. See the individual log messages that match each pattern Click pattern to expand the row and see a table of individual log records. To see additional records, scroll up or down. To explore an individual log in more detail, click it to open the details panel. Group and filter patterns by their attributes Use the query bar and time picker. As you apply different filters and time windows, the log patterns adjust to your new target data. Create an alert from a pattern Add the pattern to the query bar and run the query. Then click Create alert condition in the left nav. Troubleshoot log messages that haven't been clustered into a pattern Use the Logs with no pattern tab in the Log patterns UI. Clicking a specific log message will open the log message details panel you're familiar with from the Logs management page. Explore logs with no pattern The Logs with no pattern tab groups all recent log messages in your account that were not clustered into a known pattern yet. These log messages don't represent any problem or flaw in the system; they have no pattern because they are too new to have been processed by the machine learning system. This makes them valuable to explore when you want to understand what has recently changed in your environment. Logs > Log patterns: New Relic's log patterns feature automatically groups logs without a matching pattern. For example: Are any of these logs tied to a recent problem? This is a quick way to discover unique log data that is appearing for the first time in your environment. Does your log data have a new format? Sometimes the logs don't represent a problem, but a new format of log data that deviates from the data model you expect your applications to follow. Catching these logs early gives you the opportunity to ask developers to correct any deviations in their log output. The more consistent people are in the way log data is generated, the easier it becomes to use logs across a diverse set of teams. Masked attributes and wildcards Parts of the log messages in patterns are classified as variables and are substituted by masked attributes. The masking process supports and improves the clustering phase by allowing the algorithm to ignore changing details and focus on the repetitive structure. Masked attributes include: date_time ip url uuid Masked attributes are highlighted and are easy to identify, as shown in the following example. Here is an example of a log pattern that has masked attributes. Log patterns extract other less trivial variables that don't belong to any masked attribute. These variables are indicated as wildcards *. Here is an example of how wildcards * group variables in the Log patterns UI. Troubleshooting Here are a few reasons why you have patterns enabled but do not see any pattern data. If you're sure none of these items are true, get help from support.newrelic.com. No data has arrived in the timeframe you're observing. Try expanding the time range you're viewing with the time picker. It's been less than 24 hours since patterns were enabled in the account. This means the ML model may not be generated for the account yet. None of the data coming in has a message field. Patterns will only be generated for values in the message field of a log record. If your logs don't contain message, there will be no data. Put the platform to work with patterns Patterns are a value that is enriched onto the existing log message as a new attribute named newrelic.logPattern. Anything you can do with logs generally can be done with log patterns, such as: Build your own dashboards with patterns, to monitor a specific pattern or group of patterns you care about. Create alerts for patterns by adding NRQL alerts. Use baseline alert conditions to detect anomalies in known log patterns.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.75607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Discover value in <em>log</em> data with patterns",
        "sections": "<em>Get</em> <em>started</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " to use patterns. Parsing limits We have a system of safety limits on memory and CPU resources when processing <em>logs</em> and their patterns. These parsing limits can have an impact on the data you <em>get</em>. For more information, see our documentation about parsing limits. <em>Get</em> <em>started</em> To <em>start</em> examining"
      },
      "id": "6072d46128ccbc244451c18b"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 198.26978,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    }
  ],
  "/docs/logs/log-management/log-api/introduction-log-api": [
    {
      "sections": [
        "Get started with log management",
        "Find problems faster, reduce context switching",
        "Bring in your logging data",
        "View your logging data in New Relic",
        "What's next"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. New Relic offers a fast, scalable log management platform so you can connect your logs with the rest of your telemetry and infrastructure data in a single place. See how it works with this video (approx. 2 minutes). Our log management solution provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. Find problems faster, reduce context switching Log management provides a way to connect your log data with the rest of your application and infrastructure data. You can get to the root cause of problems quickly, without losing context switching between tools. Log management features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Visualize everything in a single place. Bring in your logging data To forward your log data to New Relic, you can: Use our infrastructure monitoring agent as a lightweight data collector, without having to install additional software. Select from a wide range of log forwarding plugins, including Amazon, Microsoft, Fluentd, Fluent Bit, Kubernetes, Logstash, and more. Use our OpenTelemetry solutions. Send your log data by using the Log API or TCP endpoint. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic You can explore your logging data in the UI or by API: Logs UI at one.newrelic.com Logs UI for EU region data center if applicable: one.eu.newrelic.com You can also query the Log data type. For example, use NRQL to run: SELECT * FROM Log Copy You can also use NerdGraph, our GraphQL-format API, to request the exact data you need. What's next Ready to get started with our log management solutions? If you don't have one already, create a New Relic account. It's free, forever. Forward your logs to New Relic. Recommendation: Use our infrastructure agent as your log forwarder, so you can get logs in context of your platform and services directly in our UI. For apps monitored by a New Relic APM agent, configure logs in context. Explore the logging data across your platform with our Logs UI in New Relic One, where you can add alerts, query your data, and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.88882,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>log</em> <em>management</em>",
        "sections": "Get started with <em>log</em> <em>management</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " data by using the <em>Log</em> <em>API</em> or TCP endpoint. Once <em>log</em> <em>management</em> is enabled, you can also connect your <em>logs</em> with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our <em>logs</em> in context extensions. View your logging data in New Relic You can explore"
      },
      "id": "603ea62ee7b9d249432a07e2"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.23376,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " on YouTube (approx. 4-1&#x2F;2 minutes). New Relic parses <em>log</em> data according to rules. This document describes how <em>logs</em> parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your <em>log</em> parsing rules by using NerdGraph, our GraphQL <em>API</em>"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 202.33894,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    }
  ],
  "/docs/logs/log-management/log-api/log-event-data": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.7038,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.69696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68768,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/log-api/use-tcp-endpoint-forward-logs-new-relic": [
    {
      "sections": [
        "Introduction to the Log API",
        "HTTP endpoint",
        "HTTP setup",
        "HTTP headers",
        "HTTP query parameters",
        "JSON body",
        "Simplified JSON body message",
        "Detailed JSON body message",
        "Limits and restricted characters",
        "Caution",
        "Important",
        "Rate limit violations",
        "HTTP requests per minute",
        "JSON bytes per minute",
        "Log payload format",
        "JSON message attributes",
        "Common block attributes",
        "Logs block attributes",
        "JSON message attribute parsing",
        "Log JSON examples",
        "Log POST message example",
        "JSON POST request example",
        "What's next?"
      ],
      "title": "Introduction to the Log API",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Log API"
      ],
      "external_id": "198ebbf54f4a13fdf2f5b0f19d8cc8677afd09a2",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/log-api/introduction-log-api/",
      "published_at": "2021-10-24T16:44:08Z",
      "updated_at": "2021-10-19T03:43:55Z",
      "document_type": "page",
      "popularity": 1,
      "body": "If our log forwarding solutions don't meet your needs, you can use our Log API to send log data directly to New Relic via an HTTP endpoint. Want to try out our Log API? Create a New Relic account for free! No credit card required. HTTP endpoint Use the endpoint that's applicable for your New Relic account: United States (US) endpoint: https://log-api.newrelic.com/log/v1 Copy European Union (EU) endpoint: https://log-api.eu.newrelic.com/log/v1 Copy HTTP setup To send log data to your New Relic account via the Log API: Get your New Relic license key. Review the limits and restricted characters for your JSON payload. Generate the JSON message using the required headers and body fields. Ensure that your Api-Key or License-Key is included in your headers or query parameters. Refer to the log JSON examples. Send your JSON message to the appropriate HTTP endpoint for your New Relic account in a POST request. US: https://log-api.newrelic.com/log/v1 EU: https://log-api.eu.newrelic.com/log/v1 Generate some traffic and wait a few minutes, then check your account for data. If no data appears after you enable our log management capabilities, follow our troubleshooting procedures. HTTP headers When creating your HTTP headers, use these guidelines: Header Supported values Content-Type Required application/json json application/gzip gzip Api-Key Required A New Relic license key. You can also send this via query parameter. You can also use an Insights insert key but the license key is preferred. Gzipped JSON formatting is accepted. If sending compressed JSON, please include the Content-Type: application/json and Content-Encoding: gzip headers. HTTP query parameters The license key can also be passed as a query string parameter. This can be useful when sending logs from cloud-based sources that don't allow custom HTTP request headers. Query parameter Value Api-Key Your license key. Use this key whenever you send a header. You can also use an Insights insert key but the license key is preferred. JSON body You can send your JSON message using either a simplified or detailed set of attributes: Simplified JSON body message When using the simplified format to create your JSON message, send a single JSON object with the following: Field Value type Format Required Notes \"timestamp\" Integer Either milliseconds or seconds since epoch No If the field is not specific as millisecond or seconds since epoch, the message will be timestamped using the ingest time \"message\" String any string No This is the main log message field that is searched by default \"logtype\" String any string No Primary field for identifying logs and matching parsing rules other_fields (must not contain white space) String any string No These will become attributes of the log message Note: Log management does not support white space in attribute names Detailed JSON body message When using the detailed format to create your body, it must be a JSON array containing one or more JSON objects, each of which with the following format: Field Value type Format Required Notes \"common\" Object See common. No Any attributes that are common to all log messages \"logs\" Array See logs. Yes Array with the log entries Limits and restricted characters Caution Avoid calling our API from within the code of a customer-facing application. This can cause performance issues or block your application if response time is slow. If you need to do it this way, call our API asynchronously to avoid these performance issues. Restrictions on logs sent to the Log API: Payload total size: 1MB(10^6 bytes) maximum per POST. We highly recommend using compression. The payload must be encoded as UTF-8. Number of attributes per event: 255 maximum Length of attribute name: 255 characters Length of attribute value: 4096 maximum character length Some specific attributes have additional restrictions: accountId: This is a reserved attribute name. If it is included, it will be dropped during ingest. entity.guid, entity.name, and entity.type: These attributes are used internally to identify entities. Any values submitted with these keys in the attributes section of a metric data point may cause undefined behavior such as missing entities in the UI or telemetry not associating with the expected entities. For more information please refer to Entity synthesis. eventType: This is a reserved attribute name. If it is included, it will be dropped during ingest. timestamp: Must be a Unix epoch timestamp. You can define timestamps either in seconds or in milliseconds. Important Payloads with timestamps older than 48 hours may be dropped. Rate limits on logs sent to the Log API: Maximum rate for HTTP requests sent to the Log API: 300,000 requests per minute Maximum rate of uncompressed Log JSON bytes sent to the Log API: 10 GB per minute Rate limit violations Exceeding rate limits affects how the Log API behaves. Follow these instructions if this happens. HTTP requests per minute When the maximum request rate limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, either reduce the number of data points you are sending, or request a rate limit change. Subsequent subscription changes do not impact modified rate limits. If an account change impacts your rate limit, you must notify us to adjust your rate limit. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. JSON bytes per minute When the maximum Log JSON byte limit is exceeded for an account, the New Relic Log API returns a 429 response for the remainder of the minute. This response includes a Retry-After header indicating how long to wait in seconds before resubmitting or sending new data. To resolve this issue, try to reduce the amount of log data you are sending, or spread it out over a larger period of time. To request rate limit changes, contact your New Relic account representative, or visit our Support portal. Log payload format We accept any valid JSON payload. The payload must encoded as UTF-8. Important Log management does not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. JSON message attributes Common block attributes This is a block containing attributes that will be common to all log entries in logs: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message Logs block attributes This is an array containing log entries with the following format: Field Value type Format Required Notes \"timestamp\" Integer Milliseconds or seconds since epoch No Message timestamp default to ingest time \"attributes\" Object JSON No This sub-object contains all other attributes of the message \"message\" String (any string) Yes This is the main log message field that is searched by default \"log\" String (any string) No We will rewrite this string as the field message on ingest \"LOG\" String (any string) No We will rewrite this string as the field message on ingest \"MESSAGE\" String (any string) No We will rewrite this string as the field message on ingest JSON message attribute parsing Our log management capabilities will parse any message attribute as JSON. The resulting JSON attributes in the parsed message will be added to the event. If the message attribute is not JSON, it is left as is. Important New Relic's log management capabilities do not support white space in attribute names. For example, {\"Sample Attribute\": \"Value\"} would cause errors. Here is an example message attribute: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"login-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\" } Copy This will be treated as: { \"timestamp\": 1562767499238, \"message\": \"{\\\"service-name\\\": \\\"my-service\\\", \\\"user\\\": {\\\"id\\\": 123, \\\"name\\\": \\\"alice\\\"}}\", \"service-name\": \"my-service\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy Log JSON examples Attributes can be scalar JSON types like string and number. They can also be compound (or nested) objects. Compound attributes will have their associated attributes stored with flattened names. For example, here is a compound user attribute in a log entry's attributes: \"attributes\": { \"action\": \"login\", \"user\": { \"id\": 123, \"name\": \"alice\" } } Copy This will result in the following attributes being stored with the log event: Attribute Value \"action\" \"login\" \"user.id\" 123 \"user.name\" \"alice\" Log POST message example Log POST message example: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 319 [{ \"common\": { \"attributes\": { \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } }, \"logs\": [{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\" },{ \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged out\", \"attributes\": { \"auditId\": 123 } }] }] Copy This POST message would result in the following log messages being stored in New Relic: Attribute Value \"logtype\" \"accesslogs\" \"service\" \"login-service\" \"hostname\" \"login.example.com\" Here's an example of stored logs block attributes: Attribute Value \"timestamp\" 1550086450124 \"message\" \"User 'xyz' logged out\" \"auditId\" 123 JSON POST request example Here's an example of a JSON POST request: POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: <YOUR_LICENSE_KEY> Accept: */* Content-Length: 133 { \"timestamp\": <TIMESTAMP_IN_UNIX_EPOCH>, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 252.62003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to the <em>Log</em> <em>API</em>",
        "sections": "Introduction to the <em>Log</em> <em>API</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " in a POST request. US: https:&#x2F;&#x2F;<em>log</em>-<em>api</em>.newrelic.com&#x2F;<em>log</em>&#x2F;v1 EU: https:&#x2F;&#x2F;<em>log</em>-<em>api</em>.eu.newrelic.com&#x2F;<em>log</em>&#x2F;v1 Generate some traffic and wait a few minutes, then check your account for data. If no data appears after you enable our <em>log</em> <em>management</em> capabilities, follow our troubleshooting procedures. HTTP headers"
      },
      "id": "603ea832196a6726e7a83da1"
    },
    {
      "sections": [
        "Get started with log management",
        "Find problems faster, reduce context switching",
        "Bring in your logging data",
        "View your logging data in New Relic",
        "What's next"
      ],
      "title": "Get started with log management",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Get started"
      ],
      "external_id": "77761091d3c83970c78e92210970ade2a7441df9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/get-started/get-started-log-management/",
      "published_at": "2021-10-24T16:43:23Z",
      "updated_at": "2021-10-24T16:43:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "As applications move towards the cloud, microservices architecture is becoming more dispersed, making the ability to monitor logs essential. New Relic offers a fast, scalable log management platform so you can connect your logs with the rest of your telemetry and infrastructure data in a single place. See how it works with this video (approx. 2 minutes). Our log management solution provides deeper visibility into application and infrastructure performance data (events and errors) to reduce mean-time-to-resolve (MTTR) and quickly troubleshoot production incidents. Find problems faster, reduce context switching Log management provides a way to connect your log data with the rest of your application and infrastructure data. You can get to the root cause of problems quickly, without losing context switching between tools. Log management features include: Instantly search through your logs. Visualize your log data directly from the Logs UI. Use logging data to create custom charts, dashboards, and alerts. Troubleshoot performance issues without switching between tools. Visualize everything in a single place. Bring in your logging data To forward your log data to New Relic, you can: Use our infrastructure monitoring agent as a lightweight data collector, without having to install additional software. Select from a wide range of log forwarding plugins, including Amazon, Microsoft, Fluentd, Fluent Bit, Kubernetes, Logstash, and more. Use our OpenTelemetry solutions. Send your log data by using the Log API or TCP endpoint. Once log management is enabled, you can also connect your logs with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our logs in context extensions. View your logging data in New Relic You can explore your logging data in the UI or by API: Logs UI at one.newrelic.com Logs UI for EU region data center if applicable: one.eu.newrelic.com You can also query the Log data type. For example, use NRQL to run: SELECT * FROM Log Copy You can also use NerdGraph, our GraphQL-format API, to request the exact data you need. What's next Ready to get started with our log management solutions? If you don't have one already, create a New Relic account. It's free, forever. Forward your logs to New Relic. Recommendation: Use our infrastructure agent as your log forwarder, so you can get logs in context of your platform and services directly in our UI. For apps monitored by a New Relic APM agent, configure logs in context. Explore the logging data across your platform with our Logs UI in New Relic One, where you can add alerts, query your data, and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 222.8887,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Get started with <em>log</em> <em>management</em>",
        "sections": "Get started with <em>log</em> <em>management</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " data by using the <em>Log</em> <em>API</em> or TCP endpoint. Once <em>log</em> <em>management</em> is enabled, you can also connect your <em>logs</em> with your APM agent, Kubernetes clusters, or distributed tracing to get additional contextual logging data with our <em>logs</em> in context extensions. View your logging data in New Relic You can explore"
      },
      "id": "603ea62ee7b9d249432a07e2"
    },
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.23364,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> data",
        "sections": "<em>Logs</em> <em>API</em> example",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " on YouTube (approx. 4-1&#x2F;2 minutes). New Relic parses <em>log</em> data according to rules. This document describes how <em>logs</em> parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your <em>log</em> parsing rules by using NerdGraph, our GraphQL <em>API</em>"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    }
  ],
  "/docs/logs/log-management/troubleshooting/find-issues-cause-or-impact-surrounding-logs": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.98169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em> capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    },
    {
      "sections": [
        "View log messages in real time (live tail)",
        "Problem",
        "Solution"
      ],
      "title": "View log messages in real time (live tail)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "04b7a62fd3ff5ba7772226b0990f22729e6166da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:25Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When you deploy a new host, server, or make other application changes, you want to immediately see how your system responds to these changes. You need to view your log messages as they arrive in real time. Solution To focus on messages as they arrive in real time, enable live tail logging: Go to one.newrelic.com > Logs. Enter a query to focus on the type of log info you need, then click Query logs; for example: Find logs where annotations.restartRequested:\"2020-12-23T18:00:00Z\" Copy Click the Livetail icon to enable or disable it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.89221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>log</em> messages in real time (live tail)",
        "sections": "View <em>log</em> messages in real time (live tail)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": Go to one.newrelic.com &gt; <em>Logs</em>. Enter a query to focus on the type of <em>log</em> info you need, then click Query <em>logs</em>; for example: Find <em>logs</em> where annotations.restartRequested:&quot;2020-12-23T18:00:00Z&quot; Copy Click the Livetail icon to enable or disable it."
      },
      "id": "603e9aa428ccbc8f36eba76d"
    }
  ],
  "/docs/logs/log-management/troubleshooting/json-message-not-parsed": [
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.98169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em> capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    },
    {
      "sections": [
        "View log messages in real time (live tail)",
        "Problem",
        "Solution"
      ],
      "title": "View log messages in real time (live tail)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "04b7a62fd3ff5ba7772226b0990f22729e6166da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:25Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When you deploy a new host, server, or make other application changes, you want to immediately see how your system responds to these changes. You need to view your log messages as they arrive in real time. Solution To focus on messages as they arrive in real time, enable live tail logging: Go to one.newrelic.com > Logs. Enter a query to focus on the type of log info you need, then click Query logs; for example: Find logs where annotations.restartRequested:\"2020-12-23T18:00:00Z\" Copy Click the Livetail icon to enable or disable it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.89221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>log</em> messages in real time (live tail)",
        "sections": "View <em>log</em> messages in real time (live tail)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": Go to one.newrelic.com &gt; <em>Logs</em>. Enter a query to focus on the type of <em>log</em> info you need, then click Query <em>logs</em>; for example: Find <em>logs</em> where annotations.restartRequested:&quot;2020-12-23T18:00:00Z&quot; Copy Click the Livetail icon to enable or disable it."
      },
      "id": "603e9aa428ccbc8f36eba76d"
    },
    {
      "sections": [
        "Log message is truncated",
        "Problem",
        "Solution"
      ],
      "title": "Log message is truncated",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "ad33f133d73934287c81c382038c5e79486460db",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/log-message-truncated/",
      "published_at": "2021-10-24T16:32:37Z",
      "updated_at": "2021-10-24T16:32:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Not all log data in a message or for a specific attribute is being displayed. The log data ends with an ellipses (...) and the remaining data isn't shown. Solution This occurs because the logs datastore in New Relic limits the field length to 4,096 characters. Any data longer than that is truncated during ingestion. If you have values exceeding the character limit, here are some options to try: Troubleshooting tips Comments Parse long messages Parse your log message into shorter key/value pairs. A common example is a single log line from an NGINX access log. That log message can be parsed using built-in parsing via Logstash, Fluentd, or Fluent Bit. For more information, see our documentation about parsing log data. Use JSON output Use JSON as an output format instead of plain text. JSON log messages will automatically be parsed into key/value pairs, which makes it much less likely to hit the character limit. Expand blob data The first 4,094 characters in a log message are stored as a string. The next 128,000 bytes are stored as a blob. To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy For more information, see our documentation about long messages stored as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.88586,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> message is truncated",
        "sections": "<em>Log</em> message is truncated",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem Not all <em>log</em> data in a message or for a specific attribute is being displayed. The <em>log</em> data ends with an ellipses (...) and the remaining data isn&#x27;t shown. Solution This occurs because the <em>logs</em> datastore in New Relic limits the field length to 4,096 characters. Any data longer than"
      },
      "id": "604413de196a67578c960f79"
    }
  ],
  "/docs/logs/log-management/troubleshooting/log-message-truncated": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34549,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.98169,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em> capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    },
    {
      "sections": [
        "View log messages in real time (live tail)",
        "Problem",
        "Solution"
      ],
      "title": "View log messages in real time (live tail)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "04b7a62fd3ff5ba7772226b0990f22729e6166da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:25Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When you deploy a new host, server, or make other application changes, you want to immediately see how your system responds to these changes. You need to view your log messages as they arrive in real time. Solution To focus on messages as they arrive in real time, enable live tail logging: Go to one.newrelic.com > Logs. Enter a query to focus on the type of log info you need, then click Query logs; for example: Find logs where annotations.restartRequested:\"2020-12-23T18:00:00Z\" Copy Click the Livetail icon to enable or disable it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.89221,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>log</em> messages in real time (live tail)",
        "sections": "View <em>log</em> messages in real time (live tail)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": Go to one.newrelic.com &gt; <em>Logs</em>. Enter a query to focus on the type of <em>log</em> info you need, then click Query <em>logs</em>; for example: Find <em>logs</em> where annotations.restartRequested:&quot;2020-12-23T18:00:00Z&quot; Copy Click the Livetail icon to enable or disable it."
      },
      "id": "603e9aa428ccbc8f36eba76d"
    }
  ],
  "/docs/logs/log-management/troubleshooting/no-log-data-appears-ui": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "View log messages in real time (live tail)",
        "Problem",
        "Solution"
      ],
      "title": "View log messages in real time (live tail)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "04b7a62fd3ff5ba7772226b0990f22729e6166da",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:25Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When you deploy a new host, server, or make other application changes, you want to immediately see how your system responds to these changes. You need to view your log messages as they arrive in real time. Solution To focus on messages as they arrive in real time, enable live tail logging: Go to one.newrelic.com > Logs. Enter a query to focus on the type of log info you need, then click Query logs; for example: Find logs where annotations.restartRequested:\"2020-12-23T18:00:00Z\" Copy Click the Livetail icon to enable or disable it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.89209,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "View <em>log</em> messages in real time (live tail)",
        "sections": "View <em>log</em> messages in real time (live tail)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": ": Go to one.newrelic.com &gt; <em>Logs</em>. Enter a query to focus on the type of <em>log</em> info you need, then click Query <em>logs</em>; for example: Find <em>logs</em> where annotations.restartRequested:&quot;2020-12-23T18:00:00Z&quot; Copy Click the Livetail icon to enable or disable it."
      },
      "id": "603e9aa428ccbc8f36eba76d"
    },
    {
      "sections": [
        "Log message is truncated",
        "Problem",
        "Solution"
      ],
      "title": "Log message is truncated",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "ad33f133d73934287c81c382038c5e79486460db",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/log-message-truncated/",
      "published_at": "2021-10-24T16:32:37Z",
      "updated_at": "2021-10-24T16:32:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Not all log data in a message or for a specific attribute is being displayed. The log data ends with an ellipses (...) and the remaining data isn't shown. Solution This occurs because the logs datastore in New Relic limits the field length to 4,096 characters. Any data longer than that is truncated during ingestion. If you have values exceeding the character limit, here are some options to try: Troubleshooting tips Comments Parse long messages Parse your log message into shorter key/value pairs. A common example is a single log line from an NGINX access log. That log message can be parsed using built-in parsing via Logstash, Fluentd, or Fluent Bit. For more information, see our documentation about parsing log data. Use JSON output Use JSON as an output format instead of plain text. JSON log messages will automatically be parsed into key/value pairs, which makes it much less likely to hit the character limit. Expand blob data The first 4,094 characters in a log message are stored as a string. The next 128,000 bytes are stored as a blob. To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy For more information, see our documentation about long messages stored as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.88573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> message is truncated",
        "sections": "<em>Log</em> message is truncated",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem Not all <em>log</em> data in a message or for a specific attribute is being displayed. The <em>log</em> data ends with an ellipses (...) and the remaining data isn&#x27;t shown. Solution This occurs because the <em>logs</em> datastore in New Relic limits the field length to 4,096 characters. Any data longer than"
      },
      "id": "604413de196a67578c960f79"
    }
  ],
  "/docs/logs/log-management/troubleshooting/view-log-messages-real-time-live-tail": [
    {
      "sections": [
        "JSON message is not parsed",
        "Problem",
        "Solution"
      ],
      "title": "JSON message is not parsed",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "71924cf03b8b93718cd1d2c307478455f4d1000c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/json-message-not-parsed/",
      "published_at": "2021-10-24T17:30:14Z",
      "updated_at": "2021-10-24T17:30:13Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem When JSON content is sent in the log's message field, it's not automatically parsed, and it's not stored as attributes (key/value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening: If the content is not valid JSON, it won't be parsed. Instead, it will be stored as a string and truncated if it exceeds the character limit. If the content is valid JSON, it may have been \"stringified\" with escape characters. If that's the case, it will first be evaluated as a string, meaning that it will be truncated to 4,096 characters before being evaluated as JSON. The result of the truncation will be invalid JSON, and the data will be stored as a string. To solve this problem, send messages containing JSON that haven't been converted to a string. This content will be parsed even if the total length exceeds the character limit. If the JSON contains arrays, they'll be flattened and stored as unparsed strings.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 240.34534,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem When JSON content is sent in the <em>log</em>&#x27;s message field, it&#x27;s not automatically parsed, and it&#x27;s not stored as attributes (key&#x2F;value pairs). Instead, the content remains in the message. It also may be truncated if the message exceeds the character limit. Solution Reasons this may be happening"
      },
      "id": "614fd9ffe7b9d23e7a8de34a"
    },
    {
      "sections": [
        "No log data appears in the UI",
        "Problem",
        "Solution"
      ],
      "title": "No log data appears in the UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "f94f57bdbf1bfd9ae492383a009364224cf4a56a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/no-log-data-appears-ui/",
      "published_at": "2021-10-24T16:33:26Z",
      "updated_at": "2021-10-24T16:33:26Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem After enabling log management capabilities in New Relic, no data appears in your Logs UI after about five minutes. Solution If no data appears after you send some log payloads and wait about five minutes, try the following: Logs troubleshooting Comments Access to data See Factors affecting access to features and data. Compatibility Make sure you've installed a compatible log forwarder. Status codes Check the response status code being returned from the New Relic log collection endpoint. For example, you might see: HTTP Error 403: Forbidden. Review your license key. Copy This error means that you're using an invalid security key. New Relic requires a license key to enable log shipping. An HTTP 202 response indicates success. Errors Run a query using the NrIntegrationErrors event to see if any errors are related to logging. For example, look for messages like: Error unmarshalling message payload Copy Query Log Try querying the Log data type in New Relic One: SELECT * FROM Log Copy If no data appears in the query builder, then no data will appear in the Logs UI. For more information, see our documentation about data query options in New Relic.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.98157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "No <em>log</em> data appears in the UI",
        "sections": "No <em>log</em> data appears in the UI",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem After enabling <em>log</em> <em>management</em> capabilities in New Relic, no data appears in your <em>Logs</em> UI after about five minutes. Solution If no data appears after you send some <em>log</em> payloads and wait about five minutes, try the following: <em>Logs</em> <em>troubleshooting</em> Comments Access to data See Factors affecting"
      },
      "id": "6044181d64441f9138378f05"
    },
    {
      "sections": [
        "Log message is truncated",
        "Problem",
        "Solution"
      ],
      "title": "Log message is truncated",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "Troubleshooting"
      ],
      "external_id": "ad33f133d73934287c81c382038c5e79486460db",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/troubleshooting/log-message-truncated/",
      "published_at": "2021-10-24T16:32:37Z",
      "updated_at": "2021-10-24T16:32:37Z",
      "document_type": "troubleshooting_doc",
      "popularity": 1,
      "body": "Problem Not all log data in a message or for a specific attribute is being displayed. The log data ends with an ellipses (...) and the remaining data isn't shown. Solution This occurs because the logs datastore in New Relic limits the field length to 4,096 characters. Any data longer than that is truncated during ingestion. If you have values exceeding the character limit, here are some options to try: Troubleshooting tips Comments Parse long messages Parse your log message into shorter key/value pairs. A common example is a single log line from an NGINX access log. That log message can be parsed using built-in parsing via Logstash, Fluentd, or Fluent Bit. For more information, see our documentation about parsing log data. Use JSON output Use JSON as an output format instead of plain text. JSON log messages will automatically be parsed into key/value pairs, which makes it much less likely to hit the character limit. Expand blob data The first 4,094 characters in a log message are stored as a string. The next 128,000 bytes are stored as a blob. To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy For more information, see our documentation about long messages stored as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 239.88573,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Log</em> message is truncated",
        "sections": "<em>Log</em> message is truncated",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Problem Not all <em>log</em> data in a message or for a specific attribute is being displayed. The <em>log</em> data ends with an ellipses (...) and the remaining data isn&#x27;t shown. Solution This occurs because the <em>logs</em> datastore in New Relic limits the field length to 4,096 characters. Any data longer than"
      },
      "id": "604413de196a67578c960f79"
    }
  ],
  "/docs/logs/log-management/ui-data/built-log-parsing-rulesets": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.70325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.69638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-10-24T17:42:41Z",
      "updated_at": "2021-10-24T17:42:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For lengthy string values that are longer than can be stored in NRDB (4,094 characters), we store the long string in three pieces: Long log sections Description First 4,094 characters The first 4,094 characters are stored in Log event field with the same name. So a long message value would have its first 4,094 characters stored in a message field. Next 128,000 UTF-8 bytes The next 128,000 UTF-8 bytes of the string are stored in a blob field with the name with newrelic.ext. prepended. So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a blob. The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Remaining characters Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by: Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " other attribute. Be sure to enclose the blob&#x27;s attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/data-partitions": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.70325,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.69638,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.6871,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/ui-data/drop-data-drop-filter-rules": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.70306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.6962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/ui-data/find-unusual-logs-log-patterns": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.70306,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.6962,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68692,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/ui-data/long-logs-blobs": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.70288,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/ui-data/parsing": [
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.696,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68674,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-10-24T17:42:41Z",
      "updated_at": "2021-10-24T17:42:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For lengthy string values that are longer than can be stored in NRDB (4,094 characters), we store the long string in three pieces: Long log sections Description First 4,094 characters The first 4,094 characters are stored in Log event field with the same name. So a long message value would have its first 4,094 characters stored in a message field. Next 128,000 UTF-8 bytes The next 128,000 UTF-8 bytes of the string are stored in a blob field with the name with newrelic.ext. prepended. So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a blob. The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Remaining characters Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by: Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " other attribute. Be sure to enclose the blob&#x27;s attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/log-management/ui-data/query-syntax-logs": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.7027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Use Logs UI",
        "Explore your log data",
        "Tip",
        "Save your views",
        "Examples",
        "Create an alert from log data",
        "Add log volume chart to a dashboard",
        "Troubleshoot an error (logs in context)",
        "Troubleshoot latency (logs in context)",
        "Links to logs in New Relic"
      ],
      "title": "Use Logs UI",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "755cbbeff91c2d0e7c7071cfb777baff6e440689",
      "image": "https://docs.newrelic.com/static/dd5a4f42bcdd62ac4686acc2dc7a1b39/c1b63/logs-ui-042721-summary.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/use-logs-ui/",
      "published_at": "2021-10-24T17:43:32Z",
      "updated_at": "2021-10-24T17:43:32Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Use the Logs UI at one.newrelic.com or our EU region data center (if applicable) at one.eu.newrelic.com/ to: Spot interesting or significant patterns in your logs. Examine more context around a particular log line. Explore and manipulate your logging data with filters and parsing rules. Query and share the data with charts, add to dashboards, etc. Organize your account's log data, and optimize query performance with data partitions. Set up alert conditions for problems you want to prevent. To stay up to date with new capabilities and improvements, subscribe to our RSS feed for Logs release notes. Explore your log data Use the left nav in the Logs UI as an easy workflow through all logs, patterns, live-tail logging, and queries. Get more details about specific logs and their attributes from the center nav. To explore your logging data, follow this basic workflow. If you have not customized your New Relic One navigation bar, go to one.newrelic.com, click Browse data and select Logs. Look for patterns: To spot suspicious spikes or drops in log messages, click the patterns icon on the left nav. To look at logs for a specific time period, click that point (or click and drag an area) on the chart, or use the time picker. Narrow your focus: To narrow the focus of your initial search results or quickly find outliers, expand any attributes in the log details to view the ten most common values within the results. For example, if a host listed under the hostname attribute is generating significantly more error messages than the others, select that value to apply it to your search. To make your log messages easier to query and understand, use our built-in parsing rules, or create your own parsing rules for attributes that match a particular value. To manage the amount of log data collected and to store fewer logs, create drop filter rules that avoid collecting data you don't need. Examine log details: Select a log message to view its details as a table of attributes or as JSON. To see which attributes are included in a log message, click the log line. Add or remove attributes as needed to help your query focus on the details you need. To help troubleshoot problems related to a specific value in the log details, click the Show surrounding logs icon for the attribute's details. To control which attributes appear in the results, click any highlighted value in the log's log_summary column. To get more details in extremely long messages, expand the data stored as blobs. Search: By default, the Logs UI shows all your logs, but you can also search with keywords or phrases to find the results you want; for example, process failed. OR From the search field, use the type-ahead dropdowns to select an attribute, operator, and value; for example: service_name equals my service Copy For more information, see the Logs query syntax documentation. Tip To organize data within an account and to optimize query performance, create data partition rules. Get related logs: For example: To immediately see how your system responds to deployments or other app changes, enable live-tail logging. To view all the logs for a specific value, review the attributes list in the selected log's Log details. To help identify an issue's root cause before it occurred or its impact after an event, click the Show surrounding logs icon. Share your findings: Use any of the core New Relic One functions (specific account, time range, data explorer, query builder, etc.) to share the data with charts, add to dashboards, etc. For more information, see the examples in this document. Save your views You can save your logs query, table configuration, time range, and attribute grouping in a saved view, so that you can quickly return to it later. To save a log analytics view after you've configured the view: Click the Saved Views tab in the Logs UI left nav. Click Save current view. Give your saved view the name you want for it to be listed in the Saved Views tab. Select which aspects from the current view you want to save. Select the permission level: Private, Public (Read-only), and Public (Read and write). Public means that any user with access to the account is able to see the saved view. Click Save view. Examples Here are a few examples of how you can use the Logs UI to get detailed information. To use some of these examples, you must be able to see logs in context. Create an alert from log data You can create alert conditions directly in the Logs UI: Go to one.newrelic.com > Logs. Search for results that you want to alert on; for example, service_name:\"your service\" \"fatal error\". From the Manage data section on the left nav, click Create alert condition. Complete the Create an alert condition section that slides out, then review the NRQL query that will power the alert condition. After you save the Logs alert condition, you can view it in the Alerts UI, where you can make additional changes as needed. Add log volume chart to a dashboard You can add log charts to a dashboard directly from the Logs UI. Go to one.newrelic.com > Logs. Search for results you want to plot; for example, service_name:\"checkout service\" \"process failed\". OR Select a saved view. Click Add to dashboard, then fill out the details to add to an existing or new dashboard. You can also create charts with the data explorer or the query builder in New Relic One. Troubleshoot an error (logs in context) To troubleshoot errors this way, you must be able to see [logs in context] /docs/logs/logs-context/configure-logs-context-apm-agents/). Then, to have a better understanding of what was happening on the host at the time an error occurred in your app: Go to APM > (select an app) > Events > Error analytics and select an error trace. From the error trace Details, click See logs. From the Logs UI, browse the related log details. To identify the host generating the error, click Show surrounding logs. Troubleshoot latency (logs in context) To troubleshoot latency this way, you must be able to see logs in context. Then, to have a better understanding of how your systems were operating when performance noticeably slowed: Go to one.newrelic.com > Distributed tracing. Select a particularly slow trace. From the trace Details, click See logs for this trace. Browse related logs in the Logs UI. Links to logs in New Relic Depending on your New Relic subscription, you can access your logs from several places in the New Relic UI. For some of these options, you must be able to see logs in context. To view logs... Do this... Directly from the Logs UI Go to one.newrelic.com > Logs. EU region data center (if available): Go to one.eu.newrelic.com/ > Logs. From distributed tracing Go to one.newrelic.com > Distributed tracing > (select a trace > Logs (if available). From a host in your infrastructure Go to one.newrelic.com > Infrastructure > Hosts > (select a host) > Events explorer > Logs (if available). From Kubernetes Go to one.newrelic.com > Kubernetes cluster explorer > (select a cluster) > (select a pod or container) > See logs (if available). From an entity Go to one.newrelic.com > Explorer > (select an entity) > Logs (if available). From your app in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Events > Logs (if available). From an error trace in APM (logs in context) Go to one.newrelic.com > APM > (select an app) > Error analytics > (select an error trace) > See logs (if available).",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.69583,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Use <em>Logs</em> <em>UI</em>",
        "sections": "Use <em>Logs</em> <em>UI</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Use the <em>Logs</em> <em>UI</em> at one.newrelic.com or our EU region <em>data</em> center (if applicable) at one.eu.newrelic.com&#x2F; to: Spot interesting or significant patterns in your <em>logs</em>. Examine more context around a particular <em>log</em> line. Explore and manipulate your logging <em>data</em> with filters and parsing rules. Query"
      },
      "id": "603ea62e64441ff7ba4e8854"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    }
  ],
  "/docs/logs/log-management/ui-data/use-logs-ui": [
    {
      "sections": [
        "Parsing log data",
        "Example",
        "How log parsing works",
        "Important",
        "Limits",
        "Tip",
        "Built-in parsing rules",
        "List of built-in rules",
        "Add the logtype attribute",
        "New Relic infrastructure agent example",
        "Fluentd example",
        "Fluent Bit example",
        "Logstash example",
        "Logs API example",
        "Create custom parsing rules",
        "Troubleshooting"
      ],
      "title": "Parsing log data",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "52955adb68242c4ca582ba9cb8e22963955a8275",
      "image": "https://docs.newrelic.com/static/dc392bb7142d2fdb253a649daf4ebe6d/c1b63/log-parsing-rule-ui.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/parsing/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-10-24T17:44:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Parsing is the process of splitting unstructured log data into attributes (key/value pairs). You can use these attributes to facet or filter logs in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial on YouTube (approx. 4-1/2 minutes). New Relic parses log data according to rules. This document describes how logs parsing works, how to use built-in rules, and how to create custom rules. You can also create, query, and manage your log parsing rules by using NerdGraph, our GraphQL API, at api.newrelic.com/graphiql. For more information, see our NerdGraph tutorial for parsing. Example A good example is a default NGINX access log containing unstructured text. It is useful for searching but not much else. Here's an example of a typical line: 127.180.71.3 - - [10/May/1997:08:05:32 +0000] \"GET /downloads/product_1 HTTP/1.1\" 304 0 \"-\" \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" Copy In an unparsed format, you would need to do a full text search to answer most questions. After parsing, the log is organized into attributes, like response code and request URL: { \"remote_addr\":\"93.180.71.3\", \"time\":\"1586514731\", \"method\":\"GET\", \"path\":\"/downloads/product_1\", \"version\":\"HTTP/1.1\", \"response\":\"304\", \"bytesSent\": 0, \"user_agent\": \"Debian APT-HTTP/1.3 (0.8.16~exp12ubuntu10.21)\" } Copy Parsing makes it easier to create custom queries that facet on those values. This helps you understand the distribution of response codes per request URL and quickly find problematic pages. How log parsing works Here's an overview of how New Relic implements parsing of logs: Log parsing How it works What All parsing takes place against the message field; no other fields can be parsed. Each parsing rule is created with matching criteria that determines which logs the rule will attempt to parse. To simplify the matching process, we recommend adding a logtype attribute to your logs. However, you are not limited to using logtype; any attribute can be used as matching criteria. When Parsing will only be applied once to each log message. If multiple parsing rules match the log, only the first that succeeds will be applied. Parsing takes place during log ingestion, before data is written to NRDB. Once data has been written to storage, it can no longer be parsed. Parsing occurs in the pipeline before data enrichments take place. Be careful when defining the matching criteria for a parsing rule. If the criteria is based on an attribute that doesn't exist untail after parsing or enrichment take place, that data won't be present in the logs when matching occurs. As a result, no parsing will happen. How Rules can be written in Grok, regex, or a mixture of the two. Grok is a collection of patterns that abstract away complicated regular expressions. If the content of the message field is JSON, it will be parsed automatically. New Relic's log ingestion pipeline can parse data by matching a log event to a rule that describes how the log should be parsed. There are two ways log events can be parsed: Use a built-in rule. Define a custom rule. Rules are a combination of matching logic and parsing logic. Matching is done by defining a query match on an attribute of the logs. Rules are not applied retroactively. Logs collected before a rule is created are not parsed by that rule. The simplest way to organize your logs and how they are parsed is to include the logtype field in your log event. This tells New Relic what built-in rule to apply to the logs. Important Once a parsing rule is active, data parsed by the rule is permanently changed. This cannot be reverted. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. Limits Parsing is computationally expensive, which introduces risk. Parsing is done for custom rules defined in an account and for matching patterns to a log. A large number of patterns or poorly defined custom rules will consume a huge amount of memory and CPU resources while also taking a very long time to complete. In order to prevent problems, we apply two parsing limits: per-message-per-rule and per-account. Limit Description Per-message-per-rule The per-message-per-rule limit prevents the time spent parsing any single message from being greater than 100 ms. If that limit is reached, the system will cease attempting to parse the log message with that rule. The ingestion pipeline will attempt to run any other applicable on that message, and the message will still be passed through the ingestion pipeline and stored in NRDB. The log message will be in its original, unparsed format. Per-account The per-account limit exists to prevent accounts from using more than their fair share of resources. The limit considers the total time spent processing all log messages for an account per-minute. The limit is not a fixed value; it scales up or down proportionally to the volume of data stored daily by the account and the environment size that is subsequently allocated to support that customer. Tip To easily check if your rate limits have been reached, go to your system Limits page in the New Relic UI. Built-in parsing rules Common log formats have well-established parsing rules already created for them. To get the benefit of built-in parsing rules, add the logtype attribute when forwarding logs. Set the value to something listed in the following table, and the rules for that type of log will be applied automatically. List of built-in rules The following logtype attribute values map to a predefined parsing rule. For example, to query the Application Load Balancer: From the New Relic UI, use the format logtype: alb. From NerdGraph, use the format logtype = 'alb'. To learn what fields are parsed for each rule, see our documentation about built-in parsing rules. logtype Example matching query alb AWS Application Load Balancer logtype:alb apache Apache Access logtype:apache cloudfront-web CloudFront Web logtype:cloudfront-web elb Amazon Elastic Load Balancer logtype:elb iis_w3c Microsoft IIS server logs - W3C format logtype:iis_w3c monit Monit logs logtype:monit mysql-error MySQL Error logtype:mysql-error nginx NGINX access logs logtype:nginx nginx-error NGINX error logs logtype:nginx-error route-53 Amazon Route 53 logs logtype:route-53 syslog-rfc5424 Syslog logtype:syslog-rfc5424 Add the logtype attribute When aggregating logs, it's important to provide metadata that makes it easy to organize, search, and parse those logs. One simple way of doing this is to add the attribute logtype to the log messages when they are shipped. Built-in parsing rules are applied by default to certain logtype values. Here are some examples of how to add logtype to logs sent by some of our supported shipping methods. New Relic infrastructure agent example Add logtype as an attribute. You must set the logtype for each named source. Learn more about using the infrastructure agent to add attributes. logs: - name: file-simple file: /path/to/file attributes: logtype: fileRaw - name: nginx-example file: /var/log/nginx.log attributes: logtype: nginx Copy Fluentd example Add a filter block to the .conf file, which uses a record_transformer to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluentd examples. <filter containers> @type record_transformer enable_ruby true <record> #Add logtype to trigger a built-in parsing rule for nginx access logs logtype nginx #Set timestamp from the value contained in the field \"time\" timestamp record[\"time\"] #Add hostname and tag fields to all records hostname \"#{Socket.gethostname}\" tag ${tag} </record> </filter> Copy Fluent Bit example Add a filter block to the .conf file that uses a record_modifier to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Fluent Bit examples. [FILTER] Name record_modifier Match * Record logtype nginx Record hostname ${HOSTNAME} Record service_name Sample-App-Name Copy Logstash example Add a filter block to the Logstash configuration which uses an add_field mutate filter to add a new field. In this example we use a logtype of nginx to trigger the build-in NGINX parsing rule. Check out other Logstash examples. filter { mutate { add_field => { \"logtype\" => \"nginx\" \"service_name\" => \"myservicename\" \"hostname\" => \"%{host}\" } } } Copy Logs API example You can add attributes to the JSON request sent to New Relic. In this example we add a logtype attribute of value nginx to trigger the built-in NGINX parsing rule. Learn more about using the Logs API. POST /log/v1 HTTP/1.1 Host: log-api.newrelic.com Content-Type: application/json X-License-Key: YOUR_LICENSE_KEY Accept: */* Content-Length: 133 { \"timestamp\": TIMESTAMP_IN_UNIX_EPOCH, \"message\": \"User 'xyz' logged in\", \"logtype\": \"accesslogs\", \"service\": \"login-service\", \"hostname\": \"login.example.com\" } Copy Create custom parsing rules Many logs are formatted or structured in a unique way. In order to parse them, custom logic must be built and applied. From the left nav in the Logs UI, select Parsing, then create your own custom parsing rule with an attribute, value, and Grok pattern. To create and manage your own, custom parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing, then click Create parsing rule. Enter the parsing rule's name. Choose an attribute and value to match on. Write your Grok pattern and test the rule. To learn about Grok and custom parsing rules, read our blog post about how to parse logs with Grok patterns. Enable and save the custom parsing rule. To view the list of custom parsing rules: From Manage Data on the left nav of the Logs UI, click Parsing. To view existing parsing rules: Go to one.newrelic.com > Logs. From Manage Data on the left nav of the Logs UI, click Parsing. Troubleshooting If parsing is not working the way you intended, it may be due to: Logic: The parsing rule matching logic does not match the logs you want. Timing: If your parsing matching rule targets a value that doesn't exist yet, it will fail. This can occur if the value is added later in the pipeline as part of the enrichment process. Limits: There is a fixed amount of time available every minute to process logs via parsing, patterns, drop filters, etc. If the maximum amount of time has been spent, parsing will be skipped for additional log event records. To resolve these problems, create or adjust your custom parsing rules.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.7027,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Parsing <em>log</em> <em>data</em>",
        "sections": "Parsing <em>log</em> <em>data</em>",
        "tags": "<em>Log</em> <em>management</em>",
        "body": "Parsing is the process of splitting unstructured <em>log</em> <em>data</em> into attributes (key&#x2F;value pairs). You can use these attributes to facet or filter <em>logs</em> in useful ways. This in turn helps you build better charts and alerts. To get started with parsing, you may want to watch the following video tutorial"
      },
      "id": "603e7eb4196a67b0c4a83dd1"
    },
    {
      "sections": [
        "Built-in log parsing rules",
        "Apache",
        "Application Load Balancer",
        "Cloudfront",
        "Elastic Load Balancer",
        "Microsoft IIS",
        "Monit",
        "MySQL Error",
        "NGINX",
        "NGINX Error",
        "Route 53",
        "Syslog RFC-5424"
      ],
      "title": "Built-in log parsing rules",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "cb5909f2453d475a85d408d75cd3b2a321a8518e",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/built-log-parsing-rulesets/",
      "published_at": "2021-10-24T17:42:42Z",
      "updated_at": "2021-10-24T17:42:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic can parse common log formats according to built-in rules, so that you don't have to create your own parsing rules. Here are the log parsing rules, their Grok patterns, and what fields are parsed. To enable built-in log parsing, see our documentation for adding the logtype attribute. To manage your parsing rules programmatically, use NerdGraph, our GraphQL-format API, at api.newrelic.com/graphiql. For more information, see the NerdGraph tutorial to create, query, and delete your parsing rules. Apache Source: logtype = 'apache' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client. verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent Application Load Balancer Source: logtype = 'alb' Grok: ^%{NOTSPACE:type} %{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:target_ip}:%{NOTSPACE:target_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:target_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:target_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} %{NOTSPACE:target_group_arn} \"%{DATA:trace_id}\" \"%{NOTSPACE:domain_name}\" \"%{NOTSPACE:chosen_cert_arn}\" %{NOTSPACE:matched_rule_priority} %{TIMESTAMP_ISO8601:request_creation_time} \"%{NOTSPACE:actions_executed}\" \"%{NOTSPACE:redirect_url}\" \"%{NOTSPACE:error_reason}\" (?:\"|)%{DATA:target_port_list}(?:\"|) (?:\"|)%{DATA:target_status_code_list}(?:\"|) \"%{NOTSPACE:classification}\" \"%{NOTSPACE:classification_reason}\" Copy Results: Field Definition type The type of request or connection. Possible values are: http: HTTP https: HTTP over SSL/TLS h2: HTTP/2 over SSL/TLS ws: WebSockets wss: WebSockets over SSL/TLS elb The resource ID of the load balancer. If you are parsing access log entries, note that resources IDs can contain forward slashes (/). client The IP address and port of the requesting client target The IP address and port of the target that processed this request. If the client didn't send a full request, the load balancer can't dispatch the request to a target, and this value is set to -. If the target is a Lambda function, this value is set to -. If the request is blocked by AWS WAF, this value is set to -, and the value of elb_status_code is set to 403. request_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the request until the time it sent it to a target. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. target_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer sent the request to a target until the target started to send the response headers. This value is set to -1 if the load balancer can't dispatch the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. This value can also be set to -1 if the registered target does not respond before the idle timeout. response_processing_time The total time elapsed (in seconds, with millisecond precision) from the time the load balancer received the response header from the target until it started to send the response to the client. This includes both the queuing time at the load balancer and the connection acquisition time from the load balancer to the client. This value is set to -1 if the load balancer can't send the request to a target. This can happen if the target closes the connection before the idle timeout or if the client sends a malformed request. elb_status_code The status code of the response from the load balancer target_status_code The status code of the response from the target. This value is recorded only if a connection was established to the target and the target sent a response. Otherwise, it is set to -. received_bytes The size of the request, in bytes, received from the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes received from the client on the connection. sent_bytes The size of the response, in bytes, sent to the client (requester). For HTTP requests, this includes the headers. For WebSockets, this is the total number of bytes sent to the client on the connection. method The HTTP verb of the request uri The URI the request was targeting http_version The HTTP version number of the request user_agent User-Agent string that identifies the client that originated the request, enclosed in double quotes. The string consists of one or more product identifiers, product/version. If the string is longer than 8 KB, it is truncated. ssl_cipher The SSL cipher. This value is set to - if the listener is not an HTTPS listener. ssl_protocol The SSL protocol. This value is set to - if the listener is not an HTTPS listener. target_group_arn The Amazon Resource Name (ARN) of the target group trace_id The contents of the X-Amzn-Trace-Id header, enclosed in double quotes domain_name The SNI domain provided by the client during the TLS handshake, enclosed in double quotes. This value is set to - if the client doesn't support SNI or the domain doesn't match a certificate and the default certificate is presented to the client. chosen_cert_arn The ARN of the certificate presented to the client, enclosed in double quotes. Set to session-reused if the session is reused. Set to - if the listener is not an HTTPS listener. matched_rule_priority The priority value of the rule that matched the request. If a rule matched, this is a value from 1 to 50000. If no rule matched and the default action was taken, this value is set to 0. If an error occurs during rules evaluation, it is set to -1. For any other error, it is set to -. request_creation_time The time when the load balancer received the request from the client, in ISO 8601 format. actions_executed The actions taken when processing the request, enclosed in double quotes. This value is a comma-separated list that can include the values described in actions_taken. If no action was taken, such as for a malformed request, this value is set to -. redirect_url The URL of the redirect target for the location header of the HTTP response, enclosed in double quotes. If no redirect actions were taken, this value is set to -. error_reason The error reason code, enclosed in double quotes. If the request failed, this is one of the error codes described in Error Reason Codes. If the actions taken do not include an authenticate action or the target is not a Lambda function, this value is set to -. Cloudfront Source: logtype = 'cloudfront-web' Grok: ^%{NOTSPACE:date}%{SPACE}%{NOTSPACE:time}%{SPACE}%{NOTSPACE:x_edge_location}%{SPACE}%{NOTSPACE:sc_bytes}%{SPACE}%{NOTSPACE:c_ip}%{SPACE}%{NOTSPACE:cs_method}%{SPACE}%{NOTSPACE:cs_host}%{SPACE}%{NOTSPACE:cs_uri_stem}%{SPACE}%{NOTSPACE:sc_status}%{SPACE}%{NOTSPACE:cs_referer}%{SPACE}%{NOTSPACE:cs_user_agent}%{SPACE}%{NOTSPACE:cs_uri_query}%{SPACE}%{NOTSPACE:cs_Cookie}%{SPACE}%{NOTSPACE:x_edge_result_type}%{SPACE}%{NOTSPACE:x_edge_request_id}%{SPACE}%{NOTSPACE:x_host_header}%{SPACE}%{NOTSPACE:cs_protocol}%{SPACE}%{NOTSPACE:cs_bytes}%{SPACE}%{NOTSPACE:time_taken}%{SPACE}%{NOTSPACE:x_forwarded_for}%{SPACE}%{NOTSPACE:ssl_protocol}%{SPACE}%{NOTSPACE:ssl_cipher}%{SPACE}%{NOTSPACE:x_edge_response_result_type}%{SPACE}%{NOTSPACE:cs_protocol_version}%{SPACE}%{NOTSPACE:fle_status}%{SPACE}%{NOTSPACE:fle_encrypted_fields}%{SPACE}%{NOTSPACE:c_port}%{SPACE}%{NOTSPACE:time_to_first_byte}%{SPACE}%{NOTSPACE:x_edge_detailed_result_type}%{SPACE}%{NOTSPACE:sc_content_type}%{SPACE}%{NOTSPACE:sc_content_len}%{SPACE}%{NOTSPACE:sc_range_start}%{SPACE}%{NOTSPACE:sc_range_end} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request, either in IPv4 or IPv6 format. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. See also X-Forwarded-For. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks in URLs and query strings are not included. sc_status An HTTP status code; for example, 200. Status code 000 indicates the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer The name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request, and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value is a hyphen (-). fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle-encrypted-fields can have a value even if the value of fle-status is an error. If field-level encryption is not configured for the distribution, the value of fle-encrypted-fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x-edge-result-type is not Error, this field contains the same value as x-edge-result-type. When x-edge-result-type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Elastic Load Balancer Source: logtype = 'elb' Grok: ^%{TIMESTAMP_ISO8601:time} %{NOTSPACE:elb} %{NOTSPACE:client_ip}:%{NOTSPACE:client_port} ((%{NOTSPACE:backend_ip}:%{NOTSPACE:backend_port})|-) %{NOTSPACE:request_processing_time} %{NOTSPACE:backend_processing_time} %{NOTSPACE:response_processing_time} %{NOTSPACE:elb_status_code} %{NOTSPACE:backend_status_code} %{NOTSPACE:received_bytes} %{NOTSPACE:sent_bytes} \"%{DATA:request}\" \"%{DATA:user_agent}\" %{NOTSPACE:ssl_cipher} %{NOTSPACE:ssl_protocol} Copy Results: Field Definition x_edge_location The edge location that served the request. Each edge location is identified by a three-letter code and an arbitrarily assigned number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) sc_bytes The total number of bytes that CloudFront served to the viewer in response to the request, including headers; for example, 1045619. For WebSocket connections, this is the total number of bytes sent from the server to the client through the connection. c_ip The IP address of the viewer that made the request. If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip is the IP address of the proxy or load balancer. cs_method The HTTP request method: DELETE, GET, HEAD, OPTIONS, PATCH, POST, or PUT. cs_host The domain name of the CloudFront distribution; for example, d111111abcdef8.cloudfront.net. cs_uri_stem The portion of the URI that identifies the path and object; for example, /images/cat.jpg. Question marks (?) in URLs and query strings are not included in the log. sc_status An HTTP status code (for example, 200). Status code 000 indicates that the viewer closed the connection (for example, closed the browser tab) before CloudFront could respond to a request. If the viewer closes the connection after CloudFront starts to send the response, the log contains the applicable HTTP status code. cs_referer he name of the domain that originated the request. Common referrers include search engines, other websites that link directly to your objects, and your own website. cs_user_agent The value of the User-Agent header in the request. The User-Agent header identifies the source of the request, such as the type of device and browser that submitted the request and which search engine if applicable. cs_uri_query The query string portion of the URI, if any. When a URI doesn't contain a query string, this field's value is a hyphen (-). cs_cookie The cookie header in the request, including name-value pairs and the associated attributes. If you enable cookie logging, CloudFront logs the cookies in all requests, regardless of which cookies you choose to forward to the origin. If a request doesn't include a cookie header, this field's value is a hyphen (-). x_edge_result_type How CloudFront classifies the response after the last byte left the edge location. In some cases, the result type can change between the time that CloudFront is ready to send the response and the time that CloudFront has finished sending the response. x_edge_request_id An encrypted string that uniquely identifies a request. In the response header, this is x-amz-cf-id. x_host_header The value that the viewer included in the Host header for this request. This is the domain name in the request. If you're using the CloudFront domain name in your object URLs, this field contains that domain name. If you're using alternate domain names in your object URLs, such as [http://example.com/logo.png, this field contains the alternate domain name, such as example.com. To use alternate domain names, you must add them to your distribution. cs_protocol The protocol that the viewer specified in the request: http, https, ws, or wss. cs_bytes The number of bytes of data that the viewer included in the request, including headers. For WebSocket connections, this is the total number of bytes sent from the client to the server on the connection. time_taken The number of seconds (to the thousandth of a second; for example, 0.002) between the time that a CloudFront edge server receives a viewer's request and the time that CloudFront writes the last byte of the response to the edge server's output queue as measured on the server. From the perspective of the viewer, the total time to get the full object will be longer than this value due to network latency and TCP buffering. x_forwarded_for If the viewer used an HTTP proxy or a load balancer to send the request, the value of c_ip in field 5 is the IP address of the proxy or load balancer. In that case, this field is the IP address of the viewer that originated the request. This field contains IPv4 and IPv6 addresses as applicable. If the viewer did not use an HTTP proxy or a load balancer, the value of x_forwarded_for is a hyphen (-). ssl_protocol When cs_protocol in field 17 is https, this field contains the SSL/TLS protocol that the client and CloudFront negotiated for transmitting the request and response. Possible values include: SSLv3 TLSv1 TLSv1.1 TLSv1.2 When cs_protocol in field 17 is http, the value for this field is a hyphen (-). ssl_cipher When cs_protocol in field 17 is https, this field contains the SSL/TLS cipher that the client and CloudFront negotiated for encrypting the request and response. Possible values include: ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA AES128-GCM-SHA256 AES256-GCM-SHA384 AES128-SHA256 AES256-SHA AES128-SHA DES-CBC3-SHA RC4-MD5 When cs_protocol is http, the value for this field is a hyphen (-). x_edge_response_result_type How CloudFront classified the response just before returning the response to the viewer. Possible values include: Hit: CloudFront served the object to the viewer from the edge cache. RefreshHit: CloudFront found the object in the edge cache but it had expired, so CloudFront contacted the origin to verify that the cache has the latest version of the object. Miss: The request could not be satisfied by an object in the edge cache, so CloudFront forwarded the request to the origin server and returned the result to the viewer. LimitExceeded: The request was denied because a CloudFront limit was exceeded. CapacityExceeded: CloudFront returned a 503 error because the edge location didn't have enough capacity at the time of the request to serve the object. Error: Typically this means the request resulted in a client error (sc_status is 4xx) or a server error (sc_status is 5xx). If the value of x_edge_result_type is Error and the value of this field is not Error, the client disconnected before finishing the download. Redirect: CloudFront redirects from HTTP to HTTPS. If sc_status is 403 and you configured CloudFront to restrict the geographic distribution of your content, the request might have come from a restricted location. cs_protocol_version The HTTP version that the viewer specified in the request. Possible values include: HTTP/0.9 HTTP/1.0 HTTP/1.1 HTTP/2.0 fle_status When field-level encryption is configured for a distribution, this field contains a code that indicates whether the request body was successfully processed. If field-level encryption is not configured for the distribution, the value of this field is a hyphen (-). When CloudFront successfully processes the request body, encrypts values in the specified fields, and forwards the request to the origin, the value of this field is Processed. The value of x_edge_result_type can still indicate a client-side or server-side error in this case. If the request exceeds a field-level encryption limit, fle-status contains one of the following error codes, and CloudFront returns HTTP status code 400 to the viewer. fle-encrypted-fields The number of fields that CloudFront encrypted and forwarded to the origin. CloudFront streams the processed request to the origin as it encrypts data, so fle_encrypted_fields can have a value even if the value of fle_status is an error. If field-level encryption is not configured for the distribution, the value of fle_encrypted_fields is a hyphen (-). c_port The port number of the request from the viewer. time_to_first_byte The number of seconds between receiving the request and writing the first byte of the response, as measured on the server. x_edge_detailed_result_type When x_edge_result_type is not Error, this field contains the same value as x_edge_result_type. When x_edge_result_type is Error, this field contains the specific type of error. sc_content_type The value of the HTTP Content-Type header of the response. sc_content_len The value of the HTTP Content-Length header of the response. sc_range_start When the response contains the HTTP Content-Range header, this field contains the range start value. sc-range-end When the response contains the HTTP Content-Range header, this field contains the range end value. Microsoft IIS Source: logtype = 'iis_w3c' Grok: %{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:server_ip} %{WORD:method} %{NOTSPACE:uri} %{NOTSPACE:uri_query} %{NOTSPACE:server_port} %{NOTSPACE:username} %{NOTSPACE:client_ip} %{NOTSPACE:user_agent} %{NOTSPACE:referer} %{NOTSPACE:status} %{NOTSPACE:substatus} %{NOTSPACE:win32_status} %{NOTSPACE:time_taken} Copy Monit Source: logtype = 'monit' Grok: \\\\[%{NOTSPACE:tz} %{SYSLOGTIMESTAMP:nr_timestamp}\\\\] %{WORD:state}%{SPACE}: %{GREEDYDATA:message} Copy Results: state: The severity of the log line message: The message MySQL Error Source: logtype = 'mysql-error' Grok: \\\\[%{WORD:log_level}\\\\] Copy Results: log_level: The severity of the log line NGINX Source: logtype = 'nginx' Grok: %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \\[%{HTTPDATE:timestamp}\\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent} Copy Results: clientip: The IP address of the client verb: The HTTP verb ident: The user identity of the client making the request response: The HTTP status code of the response request: The URI and request being made httpversion: The HTTP version of the request rawrequest: The raw HTTP request if data is posted bytes: The number of bytes sent referrer: The HTTP referrer agent: The client's user agent NGINX Error Source: logtype = 'nginx-error' Grok: ^(?<timestamp>%{YEAR:year}[./-]%{MONTHNUM:month}[./-]%{MONTHDAY:day}[- ]%{TIME:time}) \\\\[%{LOGLEVEL:severity}\\\\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP:clientip}|%{HOSTNAME:hostname}))(?:, server: %{IPORHOSTORUNDERSCORE:server})(?:, request: %{QS:request})?(?:, upstream: \\\"%{URI:upstream}\\\")?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer}\\\")?$ Copy Results: severity: The severity of the log line pid: The server process ID errormessage: The error message clientip: The IP address of the calling client server: The server IP address request: The full request upstream: The upstream URI host: The server's hostname referrer: The HTTP referrer Route 53 Source: logtype = 'route-53' Grok: %{NUMBER:log_format_version} %{TIMESTAMP_ISO8601} %{WORD:zone_id} %{IPORHOST:query} %{WORD:query_type} %{WORD:response_code} %{WORD:protocol} %{WORD:edge_location} %{IP:resolver_ip} %{GREEDYDATA:edns_client_subnet} Copy Results: log_format_version: A versioned format for the log. zone_id: The ID of the hosted zone that is associated with all the DNS queries in this log. query: The domain or subdomain that was specified in the request. query_type: Either the DNS record type that was specified in the request, or ANY. response_code: The DNS response code that Route 53 returned in response to the DNS query. protocol: The protocol that was used to submit the query, either TCP or UDP. edge_location: The Route 53 edge location that responded to the query. Each edge location is identified by a three-letter code and an arbitrary number; for example, DFW3. The three-letter code typically corresponds with the International Air Transport Association airport code for an airport near the edge location. (These abbreviations might change in the future.) resolver_ip: The IP address of the DNS resolver that submitted the request to Route 53. edns_client_subnet: A partial IP address for the client that the request originated from, if available from the DNS resolver. Syslog RFC-5424 Source: logtype = 'syslog-rfc5424' Grok: <%{NONNEGINT:pri}>%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:log.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{DATA:structured.data}\\]|-|) +%{GREEDYDATA:message} Copy Results: pri: The priority represents both the message facility and severity. version: Syslog protocol version. log.timestamp: Original timestamp. hostname: The machine that originally sent the Syslog message. app.name: The device or application that originated the message. procid: The process name or process ID associated with a Syslog system. msgid: Identifies the type of message. structured.data: Structured data string value. sd.<var>sd-id</var>.<var>sd-param-name</var>: The structured.data content is also parsed into separate attributes following a predefined naming convention: sd.<var>sd-id</var>.<var>sd-param-name</var>. See the structured data parsing examples, which follow. message: Free-form message that provides information about the event. Structured data parsing examples: The structured data [example one=\"1\" two=\"2\"] would be parsed into two different attributes: sd.example.one: \"1\" sd.example.two: \"2\" Copy If the same structured data block contains duplicate param names, it also appends an index-based suffix on the attribute name. For example, the structured data [example number=\"1\" number=\"2\"] would be parsed as: sd.example.number.0: \"1\" sd.example.number.1: \"2\" Copy For structured data with enterprise numbers assigned, an extra attribute is also parsed. For example, the structured data [example@123 number=\"1\"] would be parsed as: sd.example.enterprise.number: 123 sd.example.number: \"1\" Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68655,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Built-in <em>log</em> parsing rules",
        "sections": "Built-in <em>log</em> parsing rules",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " RFC-5424 Source: logtype = &#x27;syslog-rfc5424&#x27; Grok: &lt;%{NONNEGINT:pri}&gt;%{NONNEGINT:version} +(?:%{TIMESTAMP_ISO8601:<em>log</em>.timestamp}|-) +(?:%{HOSTNAME:hostname}|-) +(?:\\\\-|%{NOTSPACE:app.name}) +(?:\\\\-|%{NOTSPACE:procid}) (?:\\\\-|%{NOTSPACE:msgid}) +(?:\\[%{<em>DATA:structured.data</em>}\\]|-|) +%{GREEDYDATA:message"
      },
      "id": "603e7b9164441f1b2d4e8872"
    },
    {
      "sections": [
        "Find data in long logs (blobs)",
        "How blobs work",
        "Tip",
        "Query your data for blobs",
        "Data retention for long logs"
      ],
      "title": "Find data in long logs (blobs)",
      "type": "docs",
      "tags": [
        "Logs",
        "Log management",
        "UI and data"
      ],
      "external_id": "0f8c586e5227c95813221647e6a9c2e01c7044a5",
      "image": "https://docs.newrelic.com/static/25249afab9ba5695a0764e676d14dfb3/c1b63/log-blob-query.png",
      "url": "https://docs.newrelic.com/docs/logs/log-management/ui-data/long-logs-blobs/",
      "published_at": "2021-10-24T17:42:41Z",
      "updated_at": "2021-10-24T17:42:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Extensive log data can help you troubleshoot issues. But what if an attribute in your log contains thousands of characters? How much of this data can New Relic store? And how can you find useful information in all this data? How blobs work For lengthy string values that are longer than can be stored in NRDB (4,094 characters), we store the long string in three pieces: Long log sections Description First 4,094 characters The first 4,094 characters are stored in Log event field with the same name. So a long message value would have its first 4,094 characters stored in a message field. Next 128,000 UTF-8 bytes The next 128,000 UTF-8 bytes of the string are stored in a blob field with the name with newrelic.ext. prepended. So a long message value would have characters past the first 4,094 characters stored in a newrelic.ext.message field as a blob. The actual number of characters stored depends on the UTF-8 representation of the characters. UTF-8 represents Unicode characters as one to four bytes, so we will store anywhere between 32,000 and 128,000 characters past the first 4,094 characters. Remaining characters Any characters past 4,094 characters plus 128,000 bytes are dropped and not stored. So the long message field would be stored as: message: <first 4,094 characters as a string> newrelic.ext.message: <next 128,000 bytes as a 'blob'> Copy Tip You can search the first 4,094 characters of a string attribute. You can also create alerts for the first 4,094 characters. However, since 'blob' storage is not searchable, text beyond the first 4,094 characters is not searchable or alertable. Query your data for blobs To query for any log data in New Relic, run the following query: SELECT * FROM Log Copy To expand the blob data, run the following query, using message or any other attribute. Be sure to enclose the blob's attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM Log Copy To query extended blob data in your logs, be sure to include backticks in your attribute's blob syntax. This expands the data in the blob so you can see (but not search) it. For example, New Relic returns: { \"message\": <first 4,094 characters> \"newrelic.ext.message\": <the next 128,000 bytes as Base64> \"another-attribute\": <first 4,094 characters> \"newrelic.ext.another-attribute\": <the next 128,000 bytes as Base64> } Copy The Logs UI automatically stitches the original value back together when looking at the Log Detail View. When querying using NRQL directly, you need to manually stitch the information together by: Decoding the Base64 of the newrelic.ext. attribute value Converting the resulting UTF-8 into a string Appending that string to the first 4,094 characters in the \"main\" attribute Data retention for long logs NRDB retains your blob records for a month. If you have existing long log messages stored as LogExtendedRecord, that data will also continue to be available for a month in NRDB. After a month passes, no more new LogExtendedRecord attributes will be created. They will all be stored in NRDB as blobs.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 333.68637,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "sections": "Find <em>data</em> in long <em>logs</em> (blobs)",
        "tags": "<em>Log</em> <em>management</em>",
        "body": " other attribute. Be sure to enclose the blob&#x27;s attribute with backticks. For example: SELECT message, another-attribute, blob(`newrelic.ext.message`), blob(`newrelic.ext.another-attribute) FROM <em>Log</em> Copy To query extended blob <em>data</em> in your <em>logs</em>, be sure to include backticks in your attribute&#x27;s blob"
      },
      "id": "6150569228ccbcf314f21423"
    }
  ],
  "/docs/logs/logs-context/annotate-logs-logs-context-using-apm-agent-apis": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.84845,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET <em>agent</em> connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-24T23:37:57Z",
      "updated_at": "2021-10-19T03:54:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, follow standard procedures in this doc for Ruby on Rails configuration. No additional configuration is required for the lograge gem. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.999,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby <em>agent</em> connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Ruby app To <em>enable</em> <em>logs</em>"
      },
      "id": "612d460128ccbc17bf56a863"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.6128,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Forward your <em>logs</em> using the <em>infrastructure</em> <em>agent</em>",
        "sections": "Sending the <em>infrastructure</em> <em>agent&#x27;s</em> <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring <em>agent</em>: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/logs-context/c-sdk-configure-logs-context": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 436.42273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b9fbeafa564247287e5d6466630d5bdcdb85affb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/java-configure-logs-context-all/",
      "published_at": "2021-10-24T23:39:32Z",
      "updated_at": "2021-10-06T21:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.50034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "7f77d1e4599c8f7b9b2a44bc817f328f11410651",
      "image": "https://docs.newrelic.com/static/49f9b37d2957292090bdbf226eadacea/c1b63/new-relic-logs-in-context-diagram.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-10-24T19:39:40Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.49826,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-apm-agents": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 436.42273,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b9fbeafa564247287e5d6466630d5bdcdb85affb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/java-configure-logs-context-all/",
      "published_at": "2021-10-24T23:39:32Z",
      "updated_at": "2021-10-06T21:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.50034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "87eeada741d7f22204b37e7d6a906b9546ab8d4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-10-24T22:48:15Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.5003,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-go": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 274.41052,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-24T23:37:57Z",
      "updated_at": "2021-10-19T03:54:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, follow standard procedures in this doc for Ruby on Rails configuration. No additional configuration is required for the lograge gem. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.52986,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Ruby app To <em>enable</em> <em>logs</em>"
      },
      "id": "612d460128ccbc17bf56a863"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 209.5997,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-nodejs": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.84814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-24T23:37:57Z",
      "updated_at": "2021-10-19T03:54:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, follow standard procedures in this doc for Ruby on Rails configuration. No additional configuration is required for the lograge gem. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.99886,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Ruby app To <em>enable</em> <em>logs</em>"
      },
      "id": "612d460128ccbc17bf56a863"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.61255,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-php": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.84796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-24T23:37:57Z",
      "updated_at": "2021-10-19T03:54:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, follow standard procedures in this doc for Ruby on Rails configuration. No additional configuration is required for the lograge gem. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.9988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Ruby app To <em>enable</em> <em>logs</em>"
      },
      "id": "612d460128ccbc17bf56a863"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.61243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-python": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.84796,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Ruby: Configure logs in context",
        "Set up your Ruby app",
        "Standard Ruby on Rails configuration",
        "Incompatible gems",
        "Rails advanced configuration",
        "Ruby configuration without Rails",
        "Lograge configuration",
        "Other logging extensions",
        "Troubleshooting",
        "What's next?"
      ],
      "title": "Ruby: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Logs in context for Ruby"
      ],
      "external_id": "d2100c0d6ddffe6b52a1f968f61f777a1e56a13c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-ruby/",
      "published_at": "2021-10-24T23:37:57Z",
      "updated_at": "2021-10-19T03:54:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Ruby agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Ruby app To enable logs in context for APM apps monitored by Ruby: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Ruby agent version, and enable distributed tracing. Use Ruby agent version 6.7.0 or higher for logs in context. For Rails applications, use a supported Rails version. Configure logs in context for Ruby. Standard Ruby on Rails configuration Rails logging is controlled by two components: A logger you can customize by setting config.logger A log formatter you can customize by setting config.log_formatter) In most cases, you should configure logs in context by setting config.log_formatter to the DecoratingFormatter in your Rails application. For more information about Rails configuration, see the rubyonrails.org documentation. In your application's config, require newrelic_rpm, then add the following line: module ________ class Application < Rails::Application ... config.log_formatter = ::NewRelic::Agent::Logging::DecoratingFormatter.new end end Copy This configuration uses the New Relic formatter for log messages, but the remaining configuration is provided by the other Rails settings. Incompatible gems New Relic's decorating logger is known to be incompatible with the following gems: logging semantic logger rails_stdout_logger rails_12factor Rails advanced configuration If setting the log_formatter option doesn't meet your needs, replace the entire Rails logger with an instance of the New Relic logger. Provide the parameters to the logger's constructor, like this: module ________ class Application < Rails::Application ... config.logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( \"log/application.log\", #etc... ) end end Copy Ruby configuration without Rails For non-Rails applications, use the DecoratingLogger in place of the Ruby standard ::Logger, like this: logger = ::NewRelic::Agent::Logging::DecoratingLogger.new( 'log/application.log', #etc... ) ... logger.info(...) Copy The DecoratingLogger is a drop-in replacement for the Ruby standard ::Logger. Their constructors accept the same parameters. Lograge configuration To configure this extension with the lograge gem, follow standard procedures in this doc for Ruby on Rails configuration. No additional configuration is required for the lograge gem. Other logging extensions To use our logging extension with a different logging implementation or with your own custom logger, use the DecoratingFormatter. For example: module ________ class Application < Rails::Application ... config.logger = ::YourCustomLoggerImplementation.new( $stdout, formatter: ::NewRelic::Agent::Logging::DecoratingFormatter.new ) end end Copy To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you have configured your logging in /config/application.rb or in /config/environments/development.rb, run your application locally and check its logging output. You should see some output like this: {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"00fc7d46\",\"timestamp\":1567701375543,\"message\":\"example log message one\",\"log.level\":\"DEBUG\"} {\"entity.name\":\"your_app_name\",\"entity.type\":\"SERVICE\",\"hostname\":\"79bcbf8d\",\"trace.id\":\"79bcbf8d\",\"span.id\":\"6754870b\",\"timestamp\":1567702843604,\"message\":\"example log message two\",\"log.level\":\"DEBUG\"} Copy Troubleshooting If you don't see log data in the UI, follow the troubleshooting procedures. Also, if you see JSON logs in your application's output, but your query does not return logs, check your log forwarder. If the logs from your application are not formatted in JSON with fields like trace.id and span.id, there may be a problem with your log forwarding extension. In this situation: Check that the application is using a supported logging framework. Check that your logging configuration has been applied to all the environments where you want to forward and enrich the log data being sent to New Relic. Check that another logger is not configured later in your application's configuration. Logs in context for Ruby does not support tagged logging. If you are initializing your logger with a log_tags argument, your custom tags may not appear on the final version of your logs. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 218.9988,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Ruby: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Ruby agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Ruby app To <em>enable</em> <em>logs</em>"
      },
      "id": "612d460128ccbc17bf56a863"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.61243,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    }
  ],
  "/docs/logs/logs-context/configure-logs-context-ruby": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 268.84784,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: Configure <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "Forward your logs using the infrastructure agent",
        "Basic process",
        "System requirements",
        "Important",
        "Install the infrastructure agent",
        "Tip",
        "Configure the infrastructure agent",
        "Log forwarding parameters",
        "Name (required)",
        "Log source (required)",
        "file",
        "systemd",
        "syslog",
        "tcp",
        "winlog",
        "Optional configuration",
        "attributes",
        "attributes automatically inserted by the infrastructure agent",
        "pattern",
        "max_line_kb",
        "fluentbit",
        "Sample configuration file",
        "logging.d/sample.yaml",
        "View your log data",
        "Troubleshooting",
        "No log data",
        "No data appears when tailing a file",
        "No data appears when capturing via a Syslog socket",
        "No data appears using infrastructure agent proxy",
        "Sending the infrastructure agent's logs to New Relic",
        "Caution",
        "Fluent Bit does not start with the infra agent",
        "Runtime error on Windows",
        "Uninstall log forwarding",
        "What's next?"
      ],
      "title": "Forward your logs using the infrastructure agent",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "a1deac410f0eedfb819348524a85a73bbb9d9daf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/",
      "published_at": "2021-10-24T23:35:34Z",
      "updated_at": "2021-10-24T23:35:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "You can forward your logs to New Relic using our infrastructure monitoring agent. This makes all of your logging data available in one location and provides deeper visibility into both your application and your platform performance data. Forwarding your logs to New Relic will give you enhanced log management capabilities to collect, process, explore, query, and alert on your log data. Basic process To forward your logs through our infrastructure monitoring agent: If you haven't already, create a New Relic account. It's free, forever. Verify the system requirements needed for configuring logs. Ensure you have installed the infrastructure agent, version 1.11.4 or higher. Create a logging.yml configuration file in the infrastructure agent's logging.d directory. Configure your log sources and other parameters. Generate some traffic and wait a few minutes, then check your account for data. Explore your log data in the Logs UI and benefit from the log attributes automatically inserted by the infrastructure agent. System requirements To use the log forwarder of the infrastructure agent, make sure you meet the following requirements: Infrastructure agent version 1.11.4 or higher OpenSSL library 1.1.0 or higher is required by infra-agent starting from v1.16.4. Important The log forwarding feature is not supported on containerized infrastructure agents. The log forwarding feature is compatible with the following operating systems: Operating system Supported version Amazon Linux Amazon Linux 2 CentOS Version 7 or higher Debian Version 9 (\"Stretch\") or higher Exception: Version 11 is not supported. Red Hat Enterprise Linux (RHEL) Version 7 or higher SUSE Linux Enterprise Server (SLES) Version 12 Ubuntu Versions 16.04.x, 18.04.x and 20.04.x (LTS versions) Windows Windows Server 2012, 2016, and 2019, and their service packs. Windows 10 Install the infrastructure agent Starting with version 1.11.4, the infrastructure agent can forward logs to New Relic. To install and run the agent, use a package manager (Linux) or the MSI installer (Windows). Important The log forwarding feature is not included when the infrastructure agent is implemented using Linux tarball or Windows ZIP installations. To use the following links, make sure you are logged to your New Relic account. Amazon Linux CentOS Debian RHEL SLES Ubuntu Windows Tip We are working to integrate log forwarding in the infrastructure agent for ARM architectures. In the meantime, you can follow the steps in the Explorers Hub post. If you don't have a New Relic account yet, or if you prefer to follow the procedure manually, see our tutorial to install the package manager. Configure the infrastructure agent Configuration files describe which log sources are forwarded. Our infrastructure agent uses .yml files to configure logging. You can add as many config files as you want. To add a new configuration file for the log forwarding feature: Navigate to the log forwarder configuration folder: Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ Create a logging.yml configuration file, and add the parameters you need. The logging.d directory has various .yml.example files you can use as a reference or starting point. The agent automatically processes new configuration files without having to restart the infrastructure monitoring service. The only exception to this is when configuring a custom Fluent Bit configuration. Log forwarding parameters The infrastructure log forwarding .yml config supports the following parameters: Name (required) To start, define a name of the log or logs you want to forward to New Relic. Log source (required) What you use for the log source will depend on where you want to forward your logs from. Available options include: file Path to the log file or files. The agent tracks changes on the log files in a way similar to tail -f shell. Example: logs: - name: example-log file: /var/log/example.log # Path to a single log file - name: example-log-two file: /var/log/example-two.log # Path to another single log file Copy The file parameter can point to a specific log file or multiple files by using wildcards applied to names and extensions; for example, /logs/*.log. You can use wildcards in place of directories in a file path, which can be used to tail files located in different directories. Example: logs: - name: docker-logs file: /var/lib/docker/containers/*/*.log # Path to multiple folders and files Copy Important Use of wildcards may significantly increase the number of file descriptors the Fluent Bit process keeps open, which can interfere with log collection if the host's file descriptor limit is reached. We recommend increasing the file descriptor limit on Linux hosts running Fluent Bit by adding the following to the host's /etc/security/limits.conf file: root soft nofile 65536 root hard nofile 65536 *soft nofile 65536 *hard nofile 65536 Copy If you add these changes, reboot the host to ensure your changes are applied. systemd Use the systemd parameter to forward log messages that are collected by the journald daemon in Linux environments. This input type requires the agent to run in root mode. Example: logs: - name: systemd-example systemd: cupsd Copy syslog Syslog data source. Parameters: uri: Syslog socket. Format varies depending on the protocol: TCP/UDP network sockets: [tcp/udp]://LISTEN_ADDRESS:PORT Unix domain sockets: unix_[tcp/udp]:// + /socket/path parser: Syslog parser. Default is rfc3164. Use rfc5424 if your messages include fractional seconds. Note: rfc3164 currently does not work on SuSE. unix_permissions: default is 0644 for domain sockets; this limits entries to processes running as root. You can use 0666 to listen for non-root processes, at your own risk. When running the agent in privileged mode, ports and sockets must be available or owned by nri-agent, with 0666 file permissions, so that other processes can write logs to the sockets. logs: # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 Copy tcp Logs retrieved over TCP connections. Parameters: uri: TCP/IP socket to listen for incoming data. The URI format is tcp://LISTEN_ADDRESS:PORT format: format of the data. It can be json or none. separator: If format: none is used, you can define a separator string for splitting records (default: \\n). logs: - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json Copy winlog Collect events from Windows log channels. Parameters: channel: name of the channel logs will be collected from. collect-eventids: a list of Windows Event IDs to be collected and forwarded to New Relic. Event ID ranges are supported. exclude-eventids: a list of Windows Event IDs to be excluded from collection. Event ID ranges are supported. All events are collected from the specified channel by default. Configure the collect-eventids and exclude-eventids sections to avoid sending unwanted logs to your New Relic account. Add event IDs or ranges to collect-eventids or exclude-eventids to forward or drop specific events. exclude-eventids takes precedence over collect-eventids if the same event ID is present in both sections. Example: logs: # Winlog log ingestion with eventId filters. - name: windows-security winlog: channel: Security collect-eventids: - 4624 - 4265 - 4700-4800 exclude-eventids: - 4735 # entries for the application, system, powershell, and SCOM channels - name: windows-application winlog: channel: Application - name: windows-system winlog: channel: System - name: windows-pshell winlog: channel: Windows Powershell - name: scom winlog: channel: Operations Manager # Entry for Windows Defender Logs - name: windows-defender winlog: channel: Microsoft-Windows-Windows Defender/Operational # Entry for Windows Clustering Logs - name: windows-clustering winlog: channel: Microsoft-Windows-FailoverClustering/Operational # Entry for IIS logs with logtype attribute for automatic parsing - name: iis-log file: C:\\inetpub\\logs\\LogFiles\\w3svc.log attributes: logtype: iis_w3c Copy Optional configuration The following configuration parameters are not required but are still recommended. attributes List of custom attributes specified as key-value pairs that can be used to send additional data with the logs which you can then query. The attributes configuration parameter can be used with any log source. One common use of the attributes configuration parameter is to specify the logtype attribute. This attribute allows leveraging one of the built-in parsing rules supported by New Relic Logs. Example: logs: - name: example-file-attributes file: /var/log/example.log attributes: logtype: nginx region: example-us-02 team: A-team - name: example-tcp-attributes tcp: uri: tcp://0.0.0.0:2345 format: json attributes: logtype: nginx region: example-us-02 team: B-team Copy attributes automatically inserted by the infrastructure agent The infrastructure agent automatically inserts log attributes for your convenience. Some of them are inserted for any log record, while others depend on the configuration parameters you used while setting up the log forwarder. Attribute name Description entity.guids Always inserted. The infrastructure agent inserts the Entity GUID assigned by New Relic to identify the host where it's running. It is available in the entity.guids field. Note: If the captured logs belong to an application instrumented using APM, the entity.guids field contains both the entity GUID of infrastructure, as well as the GUID of APM, separated by a pipe ( | ) delimiter. fb.input Always inserted. The underlying Fluent Bit input plugin type used to capture the logs. Currently its values are tail, systemd, winlog, syslog, and tcp. filePath Inserted when sing the file input type. Absolute file path of the file being monitored. hostname Always inserted. The hostname of the machine/VM/container executing the infrastructure agent. plugin.type Always inserted. Indicates the utility used to capture the logs. In this case, it is the infrastructure agent itself, so this attribute always has the value nri-agent. pattern Regular expression for filtering records. Only supported for the tail, systemd, syslog, and tcp (only with format none) sources. This field works in a way similar to grep -E in Unix systems. For example, for a given file being captured, you can filter for records containing either WARN or ERROR using: - name: only-records-with-warn-and-error file: /var/log/logFile.log pattern: WARN|ERROR Copy No filtering is applied by default. max_line_kb Maximum size of log entries/lines in KB. If log entries exceed the limit, they are skipped. Default is 128. fluentbit External Fluent Bit configuration and parser files. If defined, they are merged with the existing configuration and parser files generated by the infrastructure agent. The infrastructure agent processes the configuration files located in the logging.d directory and will generate a run-time Fluent Bit configuration file that contains the appropriate [INPUT], [FILTER] and [OUTPUT] sections. Optionally, it will also declare an @INCLUDE in case you provided an external Fluent Bit configuration file via the fluentbit option. The runtime file does not define a [SERVICE] section, leaving all default Fluent Bit configuration values. You can still override Fluent Bit's default settings by defining your own [SERVICE] section in your external Fluent Bit configuration file and include it via the fluentbit option. Parameters: config_file: path to an existing Fluent Bit configuration file. Note that any overlapping source results in duplicate messages in New Relic Logs. parsers_file: path to an existing Fluent Bit parsers file. The following parser names are reserved: rfc3164, rfc3164-local and rfc5424. Sample configuration file Here is an example of a logging.d/ configuration file in YAML format. For more configuration examples, see the infrastructure agent repository. logging.d/sample.yaml # Remember to only use spaces for indentation logs: # Example of 'file' source - name: file-with-attributes file: /var/log/test.log # Path to a single file or pattern attributes: # You can use custom attributes to enrich your data logtype: nginx team: The A Team pattern: Error # Regular expression to filter log entries # Example of 'systemd' source (Linux only) - name: systemd-example systemd: cupsd # Examples of 'syslog' source, one per protocol # TCP network socket - name: syslog-tcp-test syslog: uri: tcp://0.0.0.0:5140 # Use the tcp://LISTEN_ADDRESS:PORT format parser: rfc5424 # Default syslog parser is rfc3164 # UDP network socket - name: syslog-udp-test syslog: uri: udp://0.0.0.0:6140 # Use the udp://LISTEN_ADDRESS:PORT format max_line_kb: 35 # Paths for Unix sockets are defined by combining protocol and path: # unix_udp:// + /path/socket - for example, unix_udp:///tmp/socket # Unix TCP domain socket - name: syslog-unix-tcp-test syslog: uri: unix_tcp:///var/unix-tcp-socket-test unix_permissions: 0666 # Default is 0644. Change at your own risk # Unix UDP domain socket - name: syslog-unix-udp-test syslog: uri: unix_udp:///var/unix-udp-socket-test parser: rfc5424 # Examples of 'tcp' source for formats 'none' and 'json' - name: tcp-simple-test tcp: uri: tcp://0.0.0.0:1234 # Use the tcp://LISTEN_ADDRESS:PORT format format: none # Raw text - this is default for 'tcp' separator: \\t # String for separating raw text entries attributes: # You can add custom attributes to any source of logs tcpFormat: none someOtherAttribute: associatedValue max_line_kb: 32 - name: tcp-json-test tcp: uri: tcp://0.0.0.0:2345 # Use the tcp://LISTEN_ADDRESS:PORT format format: json attributes: tcpFormat: json yetAnotherAttribute: 12345 # Example of Fluent Bit configuration import - name: fluentbit-import fluentbit: config_file: /path/to/fluentbit.config parsers_file: /path/to/fluentbit/parsers.conf Copy View your log data If everything is configured correctly and your data is being collected, you should see logs data in both of these places: New Relic Logs UI New Relic tools for running NRQL queries. For example, you can execute a query like this: SELECT * FROM Log Copy Troubleshooting If you encounter problems with configuring your log forwarder, try these troubleshooting tips. No log data If no data appears after you enable our log management capabilities, follow our standard log troubleshooting procedures. No data appears when tailing a file The log forwarding feature requires the agent to have permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes, make sure that the log files you want to forward (and any intermediary directory in its path) are readable by the user running nri-agent. Example: Check file access under Linux Let's check whether the file /var/log/restrictedLogs/logFile.log can be monitored by the nri-agent user. In Linux, you can do a quick check with the namei command: sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr--r-- root root restrictedLogs logFile.log - No such file or directory Copy This command failed because the file is not visible to the nri-agent user. By inspecting the previous output, we can detect that the restrictedLogs directory is missing the execution flag for others. To fix this, execute: sudo chmod 755 /var/log/restrictedLogs Copy And then check for file access again: # sudo -u nri-agent namei -ml /var/log/restrictedLogs/logFile.log f: /var/log/restrictedLogs/logFile.log drwxr-xr-x root root / drwxr-xr-x root root var drwxrwxr-x root syslog log drwxr-xr-x root root restrictedLogs -rw-r----- vagrant vagrant logFile.log Copy The file is now visible to the nri-agent user. You must ensure that the file is also readable by the nri-agent user. To check this, use: # sudo -u nri-agent head /var/log/restrictedLogs/logFile.log head: cannot open '/var/log/restrictedLogs/logFile.log' for reading: Permission denied Copy In this example, the file is missing the read rights for the others group (users other than vagrant and the vagrant user group). You could fix this by granting read permissions to others, but the application could change these permissions upon restart. To avoid this, a better approach is to add the nri-agent user to the vagrant user group. No data appears when capturing via a Syslog socket The log forwarding feature requires that the agent has permission to read the data sources. When running the infrastructure agent in privileged or non-privileged modes: If you're using Unix domain socket files, make sure that the nri-agent user can access these files (please refer to the previous section) and that they have read and write permissions (666) so that other users than nri-agent can write to them. If you're using IP sockets, ensure that the port that you are using is not a system reserved one (like port 80, for example). If no data appears after you enable log management, follow standard log management troubleshooting procedures. No data appears using infrastructure agent proxy As explained in the infrastructure agent configuration guidelines, the proxy parameter must use either HTTP or HTTPS and be in the form https://user:password@hostname:port. The agent can parse the parameter without the HTTP or HTTPS, but the log forwarder cannot. You will see an error like the following in the agent verbose logs: [ERROR] building HTTP transport: parse \\\"hostname:port\\\": first path segment in URL cannot contain colon Copy To solve this problem, check your newrelic-infra.yml file, and ensure the proxy parameter adheres to this form. If you're using caBundleFile or caBundleDir in order to specify any certificate, we recommend to follow the below rules for each OS: Linux For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates and New Relic sends logs into the logging endpoint. However, you can specify the proxy self-signed certificate (PEM file) using either the caBundleFile or caBundleDir parameters. Windows For HTTP proxies you don't need to setup any certificates. The plugin loads the system certificates. For HTTPS, you can configure it in one of the following ways: Import the proxy certificate to the system pool (Recommended) Import the proxy self-signed certificate (PEM file) by using the MMC tool. Refer to this link, and in Step 2 ensure to import it in your Trusted Root Certification Authorities, instead of in the Intermediate Certification Authorities. Using the caBundleFile and caBundleDir parameters On Windows, we cannot load both the certificates from the system certificate pool and the ones specified with the caBundleFile caBundleDir parameters. So, if you are using caBundleFile or caBundleDir, ensure that the following certificates are placed in the same PEM file (when using caBundleFile) or in the same directory (when using caBundleDir): The Proxy certificate (because it's an HTTPS proxy). The Logging Endpoint certificate (eg. https://log-api.newrelic.com/log/v1). The Infrastructure Agent certificate (eg. https://infra-api.newrelic.com). You can check the certificates by running: # openssl s_client -connect log-api.newrelic.com:443 -servername log-api.newrelic.com Copy Sending the infrastructure agent's logs to New Relic You can configure the infrastructure agent to send its own logs to New Relic. This is useful for troubleshooting issues with log forwarding, the agent, or when contacting support. To forward the infrastructure agent logs to New Relic: Edit your newrelic-infra.yml file. Enable agent logging in troubleshooting mode by adding verbose: 3. On Windows and systems that don't use systemd or where journald is inaccessible, verbose:3 causes the agent to write the logs on the disk. Revert to verbose:0 to prevent this. (Recommended): Enable agent logging in JSON format to log_format: json. Restart the agent to load the new settings. This configuration sets up the agent in troubleshooting mode, but the log forwarder (based on Fluent Bit) will continue in a non-verbose mode. Sometimes you can have issues with the log forwarder itself. For example, there may be problems accessing a specific channel when shipping Windows log events or when accessing a particular log file. In these situations, you can also enable the verbose mode for the log forwarder: Set verbose to a value other than 0. Add the configuration option: trace: [\"log.fw\"]. Caution Check whether you are using the [fluentbit] option. When setting verbose: 3 and trace: [\"log.fw\"], ensure that you don't define any [OUTPUT] section pointing to stdout in an external Fluent Bit configuration file, Fluent Bit does not start with the infra agent Important Fluent Bit's tail plugin does not support network drives. For Linux versions prior to 2016, you may need to update the OpenSSL library to 1.1.0 (or higher). To check if you have this problem: See if infra-agent has started Fluent Bit by running: ps -aux | grep fluent-bi Copy If it isn't running go to /var/db/newrelic-infra/newrelic-integrations/logging and run: ./fluent-bit -i systemd -o stdout Copy If you get the following error, update OpenSSL to 1.1.0 or higher: error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory Copy Runtime error on Windows One of the following error messages may appear when enabling log forwarding on Windows: The code execution cannot proceed because VCRUNTIME140.dll was not found. Copy OR error=\"exit status 3221225781\" process=log-forwarder Copy This is caused by a missing DLL. To solve the issue, install the Microsoft Visual C++ Redistributable as applicable: x64 x86 Uninstall log forwarding To uninstall log forwarding capabilities, go to your logging.d directory, and remove files with the .yml extension that were originally added during the configuration process. Linux: /etc/newrelic-infra/logging.d/ Windows: C:\\Program Files\\New Relic\\newrelic-infra\\logging.d\\ What's next? Explore logging data across your platform with the New Relic One UI. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our logs in context capabilities. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.6123,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> using the <em>infrastructure</em> agent",
        "sections": "Sending the <em>infrastructure</em> agent&#x27;s <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " <em>management</em> capabilities to collect, process, explore, query, and alert on your <em>log</em> data. Basic process To forward your <em>logs</em> through our infrastructure monitoring agent: If you haven&#x27;t already, create a <em>New</em> <em>Relic</em> account. It&#x27;s free, forever. Verify the system requirements needed for configuring <em>logs</em>"
      },
      "id": "603e9df164441f6b6f4e8843"
    },
    {
      "sections": [
        "Forward your logs to New Relic",
        "How it works",
        "Get started with log forwarders",
        "Log forwarding options",
        "TCP endpoint",
        "Log API",
        "What's next?"
      ],
      "title": "Forward your logs to New Relic",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Enable log monitoring in New Relic"
      ],
      "external_id": "b6e203ddc367d5a2b5e002916e49d34f4ba17a87",
      "image": "https://docs.newrelic.com/static/c3d5443b84a1e2b26a4767ce35fa58f3/e5166/new-relic-logs-in-context-diagram.jpg",
      "url": "https://docs.newrelic.com/docs/logs/forward-logs/enable-log-management-new-relic/",
      "published_at": "2021-10-24T23:33:42Z",
      "updated_at": "2021-10-24T23:33:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our log management capabilities help you to collect, process, explore, query, and alert on your log data. To get your logs into New Relic, you can: Use your existing log forwarding solution to collect your logs and extend the metadata that is forwarded to New Relic. Use our infrastructure agent as a lightweight data collector, without having to use additional software. Use our Log API to forward your logs via HTTP. Use syslog protocols to forward your logs via a TCP endpoint. How it works The following diagram shows the lifecycle of a log message for an app, from enrichment with APM agent metadata (contextual logging), to formatting and forwarding the log data to New Relic. This diagram illustrates the flow of log messages through New Relic. Standard log formatters transform log events into meaningful output (such as text files) that can be used by downstream people and processes. The NewRelicFormatter transforms log events into the JSON format expected by New Relic. These files contain log information and extended metadata. When you configure your log forwarder (our infrastructure monitoring agent, Fluentd, Logstash, etc.), you can also extend and enrich your log data. By configuring logs in context, the log enricher links the formatted log data with additional transaction information from your application or host. Now your log files are enriched with enhanced metadata and contextual logging data. Your log forwarder sends the files to our logging endpoint for processing. From there you can use our log management capabilities to view, query, set up alerts, and more in New Relic. Get started with log forwarders To forward your logs to New Relic with enriched metadata: If you don't have one already, create a New Relic account. It's free, forever. Have your New Relic account's license key. Install a compatible log forwarder. Ensure that outbound connectivity on TCP port 443 is allowed to the CIDR range that matches your region. Use the DNS name log-api.newrelic.com or log-api.eu.newrelic.com for configuration. For apps monitored by a New Relic APM agent, configure logs in context. Log forwarding options Use any of these solutions to forward your logs to New Relic. Recommended: Infrastructure monitoring agent Amazon: AWS CloudWatch plugin AWS FireLens plugin AWS Kinesis Firehose AWS Lambda for sending logs from S3 Microsoft: Azure ARM template Other log forwarding plugins: Fluent Bit plugin Fluentd plugin Google Cloud Platform Pub/Sub Heroku log streaming Kubernetes plugin Logstash plugin Vector plugin TCP endpoint In some situations you may not have log forwarders; for example, with CDNs, hardware devices, or managed services. You can use syslog protocols such as rsyslog and syslog-ng, and forward your logs to New Relic via a TCP endpoint. Log API If you prefer to connect to New Relic without installing a plugin, we offer an HTTP input integration. This option sends your monitored log data directly to New Relic via the Log API. What's next? After you enable your log forwarder, make the most of your data in New Relic with our log management capabilities: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data if you are forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards. For example, to query and manage your data partition rules, see our NerdGraph tutorial.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 205.59906,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Forward</em> your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "sections": "<em>Forward</em> your <em>logs</em> to <em>New</em> <em>Relic</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " you <em>enable</em> your <em>log</em> forwarder, make the most of your data in <em>New</em> <em>Relic</em> with our <em>log</em> <em>management</em> capabilities: Explore the logging data across your platform with our <em>Logs</em> UI. See your <em>logs</em> in <em>context</em> of your app&#x27;s performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces"
      },
      "id": "61571e0e28ccbcbc52f21431"
    }
  ],
  "/docs/logs/logs-context/java-configure-logs-context-all": [
    {
      "sections": [
        ".NET: Configure logs in context",
        "Set up your .NET app",
        "Configure log4net extension",
        "log4net workflow diagram",
        "log4net 2.0.8 or higher configuration",
        "Configure NLog extension",
        "Nlog workflow diagram",
        "Nlog 4.5 or higher configuration",
        "Nlog file-based configuration",
        "Configure Serilog 2.5 or higher extension",
        "Serilog workflow diagram",
        "Serilog 2.5 or higher configuration",
        "Serilog file-based configuration",
        "View logs in the UI",
        "What's next?"
      ],
      "title": ".NET: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "69a3fc9dab232e3ebfdeccceace39b1014b70beb",
      "image": "https://docs.newrelic.com/static/a3260353a0e479f8512b94e9eb3adb11/c1b63/LogsInContext-Log4Net.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/net-configure-logs-context-all/",
      "published_at": "2021-10-24T23:38:43Z",
      "updated_at": "2021-10-24T23:38:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the .NET agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your .NET app To enable logs in context for APM apps monitored by .NET: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest .NET agent version, and enable distributed tracing. Use .NET agent version 8.21 or higher and the New Relic .NET agent API version 8.21 or higher for logs in context. Install or update to Microsoft .NET Framework 4.5 or higher or .NET Core 2.0 or higher. Install and configure any of the following logging extensions to enrich your log data, including: log4net NLog Serilog Check your log data in the New Relic UI. Configure log4net extension You can use the Apache log4net version 2.0.8 or higher extension to link your log data with related data across the rest of the New Relic platform. log4net workflow diagram The following diagram illustrates the flow of log messages through Apache log4net, highlighting specific components of the New Relic log4net extension. Many log forwarders are available. This example uses Fluentd. Appender: The NewRelicAppender adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans from which they were created. This appender will pass the enriched log events to downstream appenders for further processing. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. Layout: The NewRelicLayout formats the enriched log events into the JSON format expected by New Relic. The appender, which this layout is assigned to, instructs log4net to output the JSON to a file in the location that the log forwarder expects. Log Forwarder: The log forwarder monitors an output folder and incrementally sends the properly formatted and enriched log information to the New Relic logging endpoint. log4net 2.0.8 or higher configuration Log4net uses appender and layout to store and format log messages. NewRelicAppender enriches log messages with contextual information from the New Relic .NET agent if it is attached to your application. The appender passes enriched log messages to downstream appenders to handle specific use cases for log messages. For more information about logging with log4net, see the Apache log4net Getting started documentation. To configure logs in context with the log4net extension: Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.Log4Net package. In your log4net configuration file, update your logging configuration to use the NewRelicAppender as the first level appender, and reference your existing appenders as its children. Also replace the layout of the appender that writes log messages to an output destination with the NewRelicLayout. The following log4net configuration example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\log4netExample.log.json for consumption by the log forwarder: <log4net> <root> <level value=\"ALL\" /> <appender-ref ref=\"NewRelicAppender\" /> </root> <appender name=\"NewRelicAppender\" type=\"NewRelic.LogEnrichers.Log4Net.NewRelicAppender, NewRelic.LogEnrichers.Log4Net\" > <threshold value=\"ALL\"/> <appender-ref ref=\"FileAppender\" /> </appender> <appender name=\"FileAppender\" type=\"log4net.Appender.FileAppender\"> <file value=\"C:\\logs\\log4netExample.log.json\" /> <param name=\"AppendToFile\" value=\"true\" /> <layout type=\"NewRelic.LogEnrichers.Log4Net.NewRelicLayout, NewRelic.LogEnrichers.Log4Net\"> </layout> </appender> </log4net> Copy After you configure the log4net extension and update your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin for New Relic Logs: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\log4netExample.log.json pos_file C:\\logs\\log4netExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Configure NLog extension You can use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Nlog workflow diagram The New Relic NLog extension provides a NewRelicJsonLayout that formats a log event in the way required by the New Relic logging endpoint. Next, it adds contextual information from the .NET agent when attached to your application. Then, a target can be configured to write logging data to an output folder. The log forwarder can monitor this folder and incrementally send log information to New Relic. The following diagram illustrates the flow of log messages through NLog, highlighting specific components of the New Relic NLog extension. New Relic JSON Layout: The NewRelicJsonLayout adds contextual information from the .NET agent (using the API) to the log events generated by the application, and outputs log messages in the JSON format expected by New Relic. This contextual information, known as linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. Since the NewRelicAppender is ForwardingAppender type, it needs to be the first appender in the chain. It also requires another appender that can write to an actual output destination as its child in order to work. File Target: A FileTarget defines a file on disk where log messages are written. Adding the NewRelicJsonLayout to that target allows the output to be formatted correctly for forwarding to New Relic. Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about logging with NLog, see the nlog-project.org documentation. Nlog 4.5 or higher configuration Use our NLog 4.5 or higher extension to link to your log data with related data across the rest of the New Relic platform. Using the Visual Studio NuGet Package Manager, locate and install the NewRelic.LogEnrichers.NLog package. In your application code, update your logging configuration to add the NewRelicJsonLayout and decide if you want to collect MappedDiagnosticsContext (MDC) or the MappedDiagnosticsLogicalContext (MDLC) data. The following configuration examples result in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the target. archiveAboveSize maxArchiveFiles bufferSize enableArchiveFileCompression autoFlush concurrentWrites Although the NLog AsyncWrapper Target is not required, it may help improve performance by performing formatting and output of log files on a different thread. Don't collect MDC or the MDLC data (default): The following code example enriches log events with New Relic linking metadata, but not with MDC or the MDLC data. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); newRelicFileTarget.Layout = new NewRelicJsonLayout(); newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Collect MDC or the MDLC data: If your application uses the MDC or the MDLC, you can configure the NewRelicJsonLayout to include items in those collections. The following code example adds the additional configuration to enable collecting MDC and MDLC data. As in the previous example, it outputs new log files in a specific JSON format at C:\\logs\\NLogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggingConfiguration(); var newRelicFileTarget = new FileTarget(\"NewRelicFileTarget\"); var newRelicLayout = new NewRelicJsonLayout { IncludeMdc = `true,` IncludeMdlc = `true` }; newRelicFileTarget.Layout = newRelicLayout; newRelicFileTarget.FileName = \"C:\\logs\\NLogExample.json\"; loggerConfig.AddTarget(newRelicFileTarget); loggerConfig.AddRuleForAllLevels(\"NewRelicFileTarget\"); LogManager.Configuration = loggerConfig; var logger = LogManager.GetLogger(\"Example\"); Copy Once you have configured the NLog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\NLogExample.log.json pos_file C:\\logs\\NLogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Nlog file-based configuration You can also configure the New Relic NLog extension with file-based configuration providers. The folowing example code creates a logger based on settings contained in an App.config file. Instantiating Logger using .config file var logger = LogManager.GetLogger(\"NewRelicLog\"); logger.Info(\"Hello, New Relic!\"); Copy Sample App.config file <?xml version=\"1.0\" encoding=\"utf-8\" ?> <configuration> <configSections> <section name=\"nlog\" type=\"NLog.Config.ConfigSectionHandler, NLog\"/> </configSections> <startup> <supportedRuntime version=\"v4.0\" sku=\".NETFramework,Version=v4.5\" /> </startup> <nlog xmlns=\"http://www.nlog-project.org/schemas/NLog.xsd\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <extensions> <add assembly=\"NewRelic.LogEnrichers.NLog\" /> </extensions> <targets> <target name=\"NewRelicLogFile\" xsi:type=\"File\" fileName=\"C:/path/to/NewRelicLog.json\"> <layout xsi:type=\"newrelic-jsonlayout\"> </layout> </target> </targets> <rules> <logger name=\"NewRelicLog\" minlevel=\"Info\" writeTo=\"newRelicLogFile\" /> </rules> </nlog> </configuration> Copy Configure Serilog 2.5 or higher extension You can use our Serilog extension to link to your log data with related data across the rest of the New Relic platform. This requires: Serilog 2.5 or higher Serilog File Sinks v4.0 or higher Serilog workflow diagram Serilog is a structured logging framework that records log messages from your application and creates a LogEvent to store the message data. Using Enrichers, you can add additional information to the log events. Sinks and Formatters allow you to format and output those log events for downstream consumption and viewing. The following diagram illustrates the flow of log messages through Serilog, highlighting specific components of the New Relic Serilog extension. Many log forwarders are available. This example uses Fluentd. New Relic Enricher: The NewRelicEnricher adds contextual information from the .NET agent (using the API) to the log events generated by the application. This contextual information, called linking metadata, is used by New Relic to link log messages to the transactions and spans where they were created. New Relic Formatter: The NewRelicFormatter translates enriched log events into the JSON format expected by New Relic. A sink instructs Serilog to output the JSON to a file in the location that the log forwarder expects. New Relic Log Forwarder: The log forwarder is configured to send the properly formatted and enriched log data from the FileTarget output to the New Relic logging endpoint. For more information about Serilog log events, see the Serilog documentation on GitHub. Serilog 2.5 or higher configuration To configure logs in context with the Serilog extension: Use the Visual Studio NuGet Package Manager to locate and install the NewRelic.LogEnrichers.Serilog package. In your application code, update your logging configuration to add the NewRelicEnricher and NewRelicFormatter. The following code example enriches log events with New Relic linking metadata. In addition to the existing log files, it outputs new log files in a specific JSON format at C:\\logs\\SerilogExample.log.json for consumption by the log forwarder: var loggerConfig = new LoggerConfiguration() loggerConfig .Enrich.WithThreadName() .Enrich.WithThreadId() .Enrich.WithNewRelicLogsInContext() .WriteTo.File( path: @\"C:\\logs\\ExistingLoggingOutput.txt\") .WriteTo.File( formatter: new NewRelicFormatter(), path: @\"C:\\logs\\SerilogExample.log.json\"); var log = loggerConfig.CreateLogger(); Copy This configuration results in new JSON files that are written to disk. Some of these configuration options may be useful for managing the amount of disk space used and/or the performance of the sink. restrictedToMinimumLevel buffered rollingInterval rollOnFileSizeLimit retainedFileCountLimit Although not required, using the Serilog Asynchronous Sink Wrapper may help improve the performance by performing formatting and output of log files on a different thread. Once you have configured the Serilog extension and updated your logging file, you can configure your extension to send data to New Relic. Here is an example configuration using the Fluentd plugin to forward logs to New Relic: <!--NewRelicLoggingExample.conf--> <source> @type tail path C:\\logs\\SerilogExample.log.json pos_file C:\\logs\\SerilogExample.log.json.pos tag logfile.* <parse> @type json </parse> </source> <match **> @type newrelic license_key <YOUR NEW_RELIC_LICENSE_KEY> base_uri https://log-api.newrelic.com/log/v1 </match> Copy Serilog file-based configuration You can also configure the New Relic Serilog extension with file-based configuration providers.The following additional NuGet Packages are required: Microsoft.Extensions.Configuration Serilog.Settings.Configuration The following example code creates a logger based on settings contained in an appSettings.json file. Instantiating logger using appsettings.json var builder = new ConfigurationBuilder() .AddJsonFile(\"appsettings.json\"); var configuration = builder.Build(); var logger = new LoggerConfiguration() .ReadFrom.Configuration(configuration) .CreateLogger(); Copy Sample appsettings.json file { \"Serilog\": { \"Using\": [ \"Serilog.Sinks.Console\", \"Serilog.Sinks.File\", \"NewRelic.LogEnrichers.Serilog\" ], \"MinimumLevel\": \"Debug\", \"Enrich\": [ \"WithNewRelicLogsInContext\" ], \"WriteTo\": [ { \"Name\": \"File\", \"Args\": { \"path\": \"C:\\\\Logs\\\\SerilogExample.log.json\", \"formatter\": \"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" } } ], \"Properties\": { \"Application\": \"NewRelic Logging Serilog Example\" } } } Copy The following example code creates a logger based on settings contained in a web.config file. The Serilog.Settings.AppSettings NuGet Package is required. Instantiating logger using .config file var logger = new LoggerConfiguration() .ReadFrom.AppSettings() .CreateLogger(); Copy Sample web.config file <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <appSettings> <add key=\"serilog:using:NewRelic\" value=\"NewRelic.LogEnrichers.Serilog\" /> <add key=\"serilog:using:File\" value=\"Serilog.Sinks.File\" /> <!--Add other enrichers here--> <add key=\"serilog:enrich:WithNewRelicLogsInContext\" /> <add key=\"serilog:write-to:File.path\" value=\"C:\\logs\\SerilogExample.log.json\" /> <add key=\"serilog:write-to:File.formatter\" value=\"NewRelic.LogEnrichers.Serilog.NewRelicFormatter, NewRelic.LogEnrichers.Serilog\" /> </appSettings> Copy View logs in the UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 436.422,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": ".NET: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the .NET agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your .NET app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efe5764441ff155424352"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "87eeada741d7f22204b37e7d6a906b9546ab8d4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-10-24T22:48:15Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.50018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "7f77d1e4599c8f7b9b2a44bc817f328f11410651",
      "image": "https://docs.newrelic.com/static/49f9b37d2957292090bdbf226eadacea/c1b63/new-relic-logs-in-context-diagram.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-10-24T19:39:40Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.49817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    }
  ],
  "/docs/logs/logs-context/net-configure-logs-context-all": [
    {
      "sections": [
        "Java: Configure logs in context",
        "Set up your Java app",
        "Dropwizard 1.3 or higher",
        "java.util.logging",
        "java.util.logging classpath additions",
        "Log4j 1.x",
        "Log4j 2.x",
        "Logback version 1.2.0 or higher",
        "Spring and Springboot",
        "View logs in UI",
        "What's next?"
      ],
      "title": "Java: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "b9fbeafa564247287e5d6466630d5bdcdb85affb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/java-configure-logs-context-all/",
      "published_at": "2021-10-24T23:39:32Z",
      "updated_at": "2021-10-06T21:51:44Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context for the Java agent connects your logs and APM data in New Relic. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the log lines that you need to identify and resolve a problem. Set up your Java app To enable logs in context for APM apps monitored by Java: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Install or update to the latest Java agent version. Use Java agent version 5.6.0 or higher for logs in context. Enable the JVM argument -javaagent, and enable distributed tracing. Configure logs in context for Java to enrich your log data, using any of the following extensions as applicable. If you use Spring or Spring Boot and aren't sure which extension you need, see our Spring documentation. Dropwizard 1.3 or higher We offer a Dropwizard extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with the DropWizard extension: Make sure you have the Dropwizard 1.3 or higher package installed and working on your application. Use the original Dropwizard appenders and logging factory installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Dropwizard 1.3 extension as applicable: Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:dropwizard:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>dropwizard</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your Dropwizard .yaml configuration file with a newrelic-json layout, replacing the currently used type: console or type: file with either type: newrelic-console or type: newrelic-file as appropriate. For example: logging: appenders: - type: newrelic-console # Add the two lines below if you don't have a layout specified on the appender. # If you have a layout, remove all parameters to the layout and set the type. layout: type: newrelic-json Copy The New Relic Dropwizard extension also supports a log-format layout type that uses the standard Dropwizard logging. For testing purposes, you can change the type of the layout with a one-line change: logging: appenders: - type: newrelic-file # This format will be ignored by the newrelic-json layout, but used by the log-format layout. logFormat: \"%date{ISO8601} %c %-5p: %m trace.id=%mdc{trace.id} span.id=%mdc{span.id}%n\" layout: # type: newrelic-json type: log-format Copy java.util.logging We offer a java.util.logging extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the java.util.logging extension: Make sure you have the java.util.logging package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the java.util.logging extension as applicable. If you can't edit these files, you can instead add the jars directly to the application classpath. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:jul:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>jul</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Check if your logging file's handlers property is set to something other than NewRelicMemoryHandler. Look for a line listing the root logger's handlers, like this: handlers = java.util.logging.FileHandler Copy Update your logging properties file to set the root logger's handler to NewRelicMemoryHandler so it intercepts messages destined for another handler: handlers = com.newrelic.logging.jul.NewRelicMemoryHandler Copy Configure the NewRelicMemoryHandler by setting the target to the handler that was previously assigned to the root logger, so it captures data New Relic needs on the thread the log message is coming from: com.newrelic.logging.jul.NewRelicMemoryHandler.target = java.util.logging.FileHandler Copy Use a NewRelicFormatter for the final handler. Update your logging properties file to set the formatter property like the following example. Make sure the handler where you set the formatter is the target handler from the previous step (java.util.logging.FileHandler in this example). java.util.logging.FileHandler.formatter = com.newrelic.logging.jul. NewRelicFormatter Copy The New Relic log format is JSON with telemetry metadata we use to correlate transactions and logs together. Currently we do not support any customization of that format. Once complete, JSON is logged instead of text. The JSON should be formatted as single objects, one per line, and should contain fields like log.level and thread.name. The trace.id, which is required for logs in context, should only have a value for log messages that occur within a transaction. java.util.logging classpath additions The most direct way to get the logs-in-context extensions is to add these dependencies to Maven's pom.xml or Gradle's build.gradle. This allows the packaging tools to pick up the correct dependencies. If you can't edit these files, you can instead add the jars directly to the application classpath for your logging framework's configuration. Before you modify the classpath: Enable the JVM argument -javaagent on your app's Java agent. Verify which logging framework the application is using. Make sure you are able to change your logging framework's configuration. Add the following three jars to the classpath if they aren't already present. Generally, we recommend taking the latest versions published on Maven Central. Group ID com.newrelic.logging and Artifact ID: Select the artifact named after your application's logging framework in Maven. Group ID com.fasterxml.jackson.core and Artifact ID: Use jackson-core. Group ID com.newrelic.agent.java and Artifact ID: Use newrelic-api. Log4j 1.x We offer a Log4j 1.x extension extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 1.x extension, you must configure the Log4j extension in code or via XML. Properties files are not supported because AsyncAppender instances can only be automatically configured via XML. Make sure you have the Log4j 1.x package installed and working on the application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 1.x extension as applicable. Gradle: Add the following to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j1:2.0\") } Copy Maven: Add the following to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j1</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <appender> element with a NewRelicLayout, adding <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/>: <appender name=\" TypicalFile \" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <layout class=\" com.newrelic.logging.log4j1.NewRelicLayout \"/> <!-- only this line needs to be added --> </appender> Copy Use NewRelicAsyncAppender to wrap any appenders that will target New Relic's log forwarder. For example: <appender name=\" NewRelicFile \" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\" TypicalFile \" /> </appender> Copy Use the async appender on the root logger. For example: <root> <appender-ref ref=\" NewRelicFile \" /> </root> Copy Example configuration file for the Log4j 1.x extension: <?xml version=\"1.0\" encoding=\"UTF-8\" ?> <!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"> <log4j:configuration debug=\"false\"> <appender name=\"TypicalFile\" class=\"org.apache.log4j.FileAppender\"> <param name=\"file\" value=\"logs/log4j1-app.log\"/> <param name=\"append\" value=\"false\"/> <!-- layout has been replaced --> <layout class=\"com.newrelic.logging.log4j1.NewRelicLayout\"/> </appender> <!-- this appender was added --> <appender name=\"NewRelicFile\" class=\"com.newrelic.logging.log4j1.NewRelicAsyncAppender\"> <appender-ref ref=\"TypicalFile\" /> </appender> <appender name=\"TypicalConsole\" class=\"org.apache.log4j.ConsoleAppender\"> <layout class=\"org.apache.log4j.PatternLayout\"> <param name=\"ConversionPattern\" value=\"%-5p %c{1} - %m%n\"/> </layout> </appender> <root> ​ <!-- the new appender was used here -->​​ <appender-ref ref=\"NewRelicFile\" /> <appender-ref ref=\"TypicalConsole\" /> </root> </log4j:configuration> Copy Log4j 2.x We offer a Log4j 2.x extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with with the Log4j 2.x extension: Make sure you have the Log4j 2.x or Logs4j 2 binding package installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Log4j 2.x extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:log4j2:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>log4j2</artifactId> <version>2.0</version> </dependency> </dependencies> Copy In your logging configuration XML file, update your <configuration> element by adding the highlighted section: <Configuration xmlns=\"http://logging.apache.org/log4j/2.0/config\" packages=\"com.newrelic.logging.log4j2\" > Copy If you're using a properties file, add packages=com.newrelic.logging.log4j2. Add <NewRelicLayout/> to use a NewRelicLayout element within one of the appenders. For example: <File name=\"MyFile\" fileName=\"logs/app-log-file.log\"> <NewRelicLayout/> </File> Copy If you're using a properties file, only change the layout.type: appender.console.type = Console appender.console.name = STDOUT appender.console.layout.type = NewRelicLayout Copy If you only modified an existing appender, skip this step. If you added a new appender, add <AppenderRef/> within <Root> to use this appender. Use the ref attribute to refer to appender name you created in the previous step. For example: <Root level=\"info\"> <AppenderRef ref=\"MyFile\"/> </Root> Copy If you're using a properties file and added a new appender, add: rootLogger.level = info rootLogger.appenderRef.stdout.ref = STDOUT ​​​​​ Copy Logback version 1.2.0 or higher We offer a Logback extension for logs in context with the Java agent. To get started, review the code and an example application on GitHub. To configure logs in context for your Java app with Logback: Make sure you have Logback version 1.2.0 or higher and the New Relic Java agent version 5.6.0 or higher installed and working on your application. Make sure you have the New Relic Java agent version 5.6.0 or higher installed on your application, and that you have enabled the JVM argument -javaagent. Update your project's dependencies to include the Logback extension as applicable: Gradle: Add the highlighted section to your build.gradle file: dependencies { compile(\"com.newrelic.logging:logback:2.0\") } Copy Maven: Add the highlighted section to your pom.xml file: <dependencies> <dependency> <groupId>com.newrelic.logging</groupId> <artifactId>logback</artifactId> <version>2.0</version> </dependency> </dependencies> Copy Update your logging configuration xml to replace any existing <encoder> element. If you're logging to the console (stdout/stderr), look for ConsoleAppender and replace: <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy If you're logging to a file, look for FileAppender and replace <encoder>: <appender name=\"LOG_FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>logs/app-log-file.log</file> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> Copy Update your logging configuration xml with the NewRelicAsyncAppender. To ensure that NewRelicAsyncAppender wraps any appenders that will target New Relic's log forwarder, add the following section. Change \"LOG_FILE\" to the name of the appender you updated in the previous step. <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"LOG_FILE\" /> </appender> Copy Make sure NewRelicAsyncAppender is the first appender used in your logger. Replace your root logger’s appenders with the ASYNC appender created in the previous step. Then list any other appenders after the NewRelicAsyncAppender in the <root> list. <root> <appender-ref ref=\"ASYNC\" /> </root> Copy Here are examples of an updated logging .xml file for the Logback extension. You can also see a working example in GitHub. Single console appender example Example configuration file after adding in the logging extension information: <configuration> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <!-- changed the encoder --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- added the ASYNC appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"STDOUT\" /> </appender> <root level=\"debug\"> <!-- changed the root logger --> <appender-ref ref=\"ASYNC\" /> </root> </configuration> Copy Two console appenders example This example sends New Relic logging to a file, but still sends standard logging to the console: <configuration> <appender name=\"FILE\" class=\"ch.qos.logback.core.FileAppender\"> <file>myApp.log</file> <!-- encoder changed --> <encoder class=\"com.newrelic.logging.logback.NewRelicEncoder\"/> </appender> <!-- this appender does normal console logging --> <appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"> <encoder> <pattern>%msg%n</pattern> </encoder> </appender> <!-- The required New Relic ASYNC appender wraps the FILE appender --> <appender name=\"ASYNC\" class=\"com.newrelic.logging.logback.NewRelicAsyncAppender\"> <appender-ref ref=\"FILE\" /> </appender> <root level=\"debug\"> <!-- ASYNC is one of the main appenders --> <appender-ref ref=\"ASYNC\" /> <!-- Send every message to normal console logging, as well. --> <appender-ref ref=\"STDOUT\" /> </root> </configuration> Copy Spring and Springboot We offer extensions for current versions of Spring and Spring Boot. If you already know the logging library, you can skip directly to that documentation: java.util.logging log4j 1 log4j 2 logback The extensions support default configurations only on Spring Boot 2.0 and higher. With Spring Boot: Here are tips to determine which logging library you have: If you have spring-boot-starter-log4j2 in your dependencies, you're using log4j 2.x. Refer to the Spring Boot log4j 2.x documentation for basic configuration, and the New Relic log4j 2 extension for customizing your configuration. If you're using Spring Boot but not the starter-log4j2, you're using logback by default. Refer to Spring Boot logback documentation for basic configuration, and the New Relic logback extension for customizing your configuration. With Spring (but not Spring Boot): Spring 5 or higher: Spring implements a bridge to other logging libraries that will automatically find them. However, those individual libraries must be configured and explicitly included in your project dependencies. To identify your logging dependency, consult your Gradle, Maven, or other build tool's dependency tree. Then follow the procedures to configure logs in context for your Java app with that extension. Spring 4 or lower: Spring version 4 and lower uses Apache Commons Logging for its bridge. Refer to the Spring documentation for information on configuring its bridge. View logs in UI To verify that you have configured the log appender correctly, run your application, then check your logs data in New Relic One using the query operator has:span.id has:trace.id. If everything is configured correctly and your data is being forwarded to New Relic with the enriched metadata, your logs should now be emitted as JSON and contain trace.id and span.id fields. If you don't see log data in the UI, follow the troubleshooting procedures. What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.50018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "Java: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> for the Java agent connects your <em>logs</em> and APM data in <em>New</em> <em>Relic</em>. Bringing all of this data together in a single tool helps you quickly get to the root cause of an issue and find the <em>log</em> lines that you need to identify and resolve a problem. Set up your Java app To <em>enable</em> <em>logs</em>"
      },
      "id": "612efca3e7b9d2f718b6f223"
    },
    {
      "sections": [
        "C SDK: Configure logs in context"
      ],
      "title": "C SDK: Configure logs in context",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "87eeada741d7f22204b37e7d6a906b9546ab8d4a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/c-sdk-configure-logs-context/",
      "published_at": "2021-10-24T22:48:15Z",
      "updated_at": "2021-10-06T21:51:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Logs in context is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the Log API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream services. To enable distributed tracing for apps monitored by the C SDK, install or update to the latest C SDK version. Distributed tracing requires C SDK version 1.1.0 or higher.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.50015,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "sections": "C SDK: <em>Configure</em> <em>logs</em> <em>in</em> <em>context</em>",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": "<em>Logs</em> in <em>context</em> is not available for apps monitored by the C SDK. Instead, you can build your own logging extension library by using the <em>Log</em> API. Make sure your app has distributed tracing enabled, so you can quickly understand what happens to requests as they travel through upstream and downstream"
      },
      "id": "6127279b28ccbcf0c6f2618d"
    },
    {
      "sections": [
        "Configure logs in context with APM agents",
        "See the root cause of issues across your platform",
        "Basic process to enable logs in context",
        "API and other options",
        "What's next?"
      ],
      "title": "Configure logs in context with APM agents",
      "type": "docs",
      "tags": [
        "Logs",
        "Enable log management in New Relic",
        "Configure logs in context"
      ],
      "external_id": "7f77d1e4599c8f7b9b2a44bc817f328f11410651",
      "image": "https://docs.newrelic.com/static/49f9b37d2957292090bdbf226eadacea/c1b63/new-relic-logs-in-context-diagram.png",
      "url": "https://docs.newrelic.com/docs/logs/logs-context/configure-logs-context-apm-agents/",
      "published_at": "2021-10-24T19:39:40Z",
      "updated_at": "2021-10-06T21:50:42Z",
      "document_type": "page",
      "popularity": 1,
      "body": "When you need to correlate log data with other telemetry data, enable logs in context in New Relic. Logs in context adds metadata that links your logs with related APM data, like errors or distributed traces, or your platform performance data from infrastructure monitoring in New Relic One. See the root cause of issues across your platform By bringing all of your application and infrastructure data together in a single solution, you can get to the root cause of issues faster. Logs in context help you quickly see meaningful patterns and trends. The following diagram shows the lifecycle of a log message, from enrichment with agent metadata (contextual logging), to formatting and forwarding the log data to New Relic: This diagram illustrates the flow of log messages through New Relic. Don't spend extra time trying to narrow down all your logs from different parts of your platform. Instead, enable logs in context to see the exact log lines you need to identify and resolve a problem. Basic process to enable logs in context The process to enable logs in context is basically the same, regardless of which APM agent you use to monitor your application: Make sure you have already set up logging in New Relic. This includes configuring a supported log forwarder that collects your application logs and extends the metadata that is forwarded to New Relic. Update to a supported APM agent version for your app, and enable distributed tracing. Configure logs in context for your APM agent or for your infrastructure monitoring agent. View your logs within the context of your apps or infrastructure in New Relic One. The main differences in this procedure are which log appenders you can use to extend and enrich your log data, and how to configure the log appender you select for your APM agent. For detailed information, see the logs-in-context procedures for: C SDK Go Java .NET Node.js PHP Python Ruby Infrastructure monitoring agent API and other options If our logging solutions don't meet your needs, you can use other options to send your log data to New Relic: Logging extensions via agent API calls HTTP endpoint via our Log API Syslog protocols via TCP endpoint (useful for CDNs, hardware devices, or managed services) What's next? After you set up APM logs in context, make the most of your logging data: Explore the logging data across your platform with our Logs UI. See your logs in context of your app's performance in the APM UI. Troubleshoot errors with distributed tracing, stack traces, application logs, and more. Get deeper visibility into both your application and your platform performance data by forwarding your logs with our infrastructure monitoring agent. Review your infrastructure logs in the UI. Set up alerts. Query your data and create dashboards.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 293.49814,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "sections": "<em>Configure</em> <em>logs</em> <em>in</em> <em>context</em> with APM agents",
        "tags": "<em>Enable</em> <em>log</em> <em>management</em> <em>in</em> <em>New</em> <em>Relic</em>",
        "body": " logging in <em>New</em> <em>Relic</em>. This includes configuring a supported <em>log</em> forwarder that collects your application <em>logs</em> and extends the metadata that is forwarded to <em>New</em> <em>Relic</em>. Update to a supported APM agent version for your app, and <em>enable</em> distributed tracing. <em>Configure</em> <em>logs</em> in <em>context</em> for your APM agent"
      },
      "id": "603ea62e196a6749f8a83dc9"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui": [
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-10-24T17:45:04Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.36832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>Android</em> <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: <em>Android</em> 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.12166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-10-24T22:15:24Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.5619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app": [
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 217.36832,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Android</em> <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> <em>Android</em> <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    },
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.12166,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-10-24T22:15:24Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 159.5619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> authentication for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for authentication. <em>Android</em> <em>app</em> users will also see a notification message. Important The authentication email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps": [
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-10-24T16:00:05Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.15034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-10-24T17:45:43Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.15018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-10-24T22:15:24Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.7752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-10-24T17:45:03Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.87576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "User settings and authentication",
        "User authentication",
        "User settings",
        "Sign in with additional username",
        "Switch between accounts",
        "Remove or re-add a user name"
      ],
      "title": "User settings and authentication",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "0b40ac4c2e769279d25d0ebb2ea77cebda8d8ea7",
      "image": "https://docs.newrelic.com/static/88ff328efc4a127601923bc728fea229/8c557/device-ipad-switch-user.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication/",
      "published_at": "2021-10-24T16:00:05Z",
      "updated_at": "2021-05-16T06:27:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This explains how to authenticate your New Relic mobile app account, and how to add users to or remove them from your mobile device. User authentication Depending on your New Relic account, additional installation or authentication steps may be required when you install the New Relic mobile app. New Relic account Additional requirements New users If you do not already have a New Relic account: From your desktop web browser, create a New Relic account. Install your application with the appropriate New Relic agent. As part of new account setup, you will receive an email with a password reset link. The password reset link expires after 20 minutes for mobile apps. Existing New Relic users No additional requirements; your applications, hosts, installed plugins, and key transactions automatically appear after you sign in. Users with New Relic partner accounts Depending on the partner, you may need to complete a different authentication process. Azure Store users: Due to the deep integration between Azure Storefront and New Relic, Azure Storefront users cannot access their accounts on the New Relic Android or iOS apps. Users with SAML-SSO enabled accounts When you sign in to the New Relic mobile app, your session automatically redirects to your web browser. From there you can sign in to your New Relic SAML-SSO account. If you see any errors when using SAML-SSO accounts on your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. User settings After you sign in, all New Relic accounts and applications associated with the user appear automatically. Sign in with additional username Follow the procedure for your mobile device. Mobile device To sign in to the app with an additional user name: Android To switch users: Log out from the Android device: Main menu > (selected username) > Logout > Confirm. Log in with a new account. iPhone From the app menu, select your account name, then select the Users menu. From the Users menu, select the plus icon. Sign in with the additional username. iPad To access the Users menu: Select the user icon or slide right. From the Users menu, select the plus icon. Sign in with the additional username. Switch between accounts To switch between accounts associated with your username: From the Users menu, select the user name. Select the account name. Remove or re-add a user name To remove a specific username from this device: From the Users menu, select Logout. To remove a user from this device, select the user's red minus icon. Select the user's Log out icon. To add a user again, sign in with that username again. Select the user icon or slide right to show the New Relic iPad app's Users menu.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.15034,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "User settings <em>and</em> <em>authentication</em>",
        "sections": "User settings <em>and</em> <em>authentication</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This explains how to authenticate your <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> account, and how to add users to or remove them from your <em>mobile</em> device. User <em>authentication</em> Depending on your <em>New</em> <em>Relic</em> account, additional installation or <em>authentication</em> steps may be required when you install the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>"
      },
      "id": "604415a728ccbc8fb52c6068"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-10-24T22:15:24Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.7752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/user-settings-authentication": [
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-10-24T17:45:03Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 212.87576,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "<em>Alerting</em> with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " channel to the <em>alert</em> policy. View <em>alert</em> incident details The notification automatically appears on your device&#x27;s lock screen. To start the <em>New</em> <em>Relic</em> <em>app</em>: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the <em>New</em> <em>Relic</em> <em>app</em>&#x27;s <em>Alerts</em> menu, select"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Troubleshoot SSO accounts using mobile devices",
        "No user name or password",
        "Errors after signing in",
        "Reauthentication problems"
      ],
      "title": "Troubleshoot SSO accounts using mobile devices",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "9ebb373182ce5fea83ba5a6baa03b2c7bccf0174",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/troubleshoot-sso-accounts-using-mobile-devices/",
      "published_at": "2021-10-24T17:45:43Z",
      "updated_at": "2021-05-16T06:23:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Typically when you sign in to the New Relic mobile app, your session redirects automatically to your web browser. From there you can sign in to your New Relic account. Here are troubleshooting tips if you have problems using the New Relic mobile app with your SAML-SSO enabled account. No user name or password You may not have a user name or password for New Relic because some SAML providers will overwrite your password, or because your administrator has not sent you this information. In these situations: From the mobile app's Log in, select the I don't have a password link. Use your mobile device to open your email account. From your email account, retrieve the New Relic authentication email within 20 minutes. Select the Authenticate button or the link below it in the email. Errors after signing in If you see any errors after successfully signing in to your SSO provider with your mobile device, verify that you are able to sign in to one.newrelic.com with a desktop web browser. If no, contact your administrator. If yes, get support at support.newrelic.com. Reauthentication problems If you are using reauthentication on a SAML-SSO account, you must log in to your default account. (All other accounts will be grayed out.) If you attempt to switch to a grayed-out account, an error message will appear, explaining this is currently not supported.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 207.15018,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "sections": "Troubleshoot SSO accounts using <em>mobile</em> devices",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "Typically when you sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, your session redirects automatically to your web browser. From there you can sign in to your <em>New</em> <em>Relic</em> account. Here are troubleshooting tips if you have problems using the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em> with your SAML-SSO enabled account. No user name"
      },
      "id": "604415e0196a67fc3f960f42"
    },
    {
      "sections": [
        "Mobile app authentication for New Relic partners",
        "Important",
        "Confirm your email address",
        "Troubleshoot email problems"
      ],
      "title": "Mobile app authentication for New Relic partners",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "de6bdd35891dbbfea0ae914251a9d5c4487594a9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-apps/mobile-app-features/authentication-partner-saml-sso-accounts/",
      "published_at": "2021-10-24T22:15:24Z",
      "updated_at": "2021-03-13T03:57:54Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important This resource is for New Relic partners. For authentication of users in regular New Relic accounts, see Authentication. Partner account users typically use SAML-SSO to sign in through your New Relic partner site. You may not have separate passwords or authentication information for your New Relic account. If you use an email address associated with a New Relic partner account when you first sign in to the New Relic mobile app, New Relic will send you a confirmation email for authentication. Android app users will also see a notification message. Important The authentication email expires 20 minutes after it is sent. Confirm your email address To authenticate using a SAML-SSO account provided through a New Relic partner: From the New Relic mobile app, type your email address associated with the partner account. Select I don't have a password. Retrieve the authentication email from your mobile device within 20 minutes. Select the Authenticate button (Android users) or email link (Android or iOS users) in the email to log in to New Relic. You will be redirected to the New Relic mobile app and logged in to your partner account. Troubleshoot email problems Here are some troubleshooting tips: If you cannot find the authentication message from New Relic in your mobile device's email in-box, check your Spam folder. If you miss the 20-minute deadline, sign in to the New Relic mobile app again, then select the link to resend the authentication email.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 203.7752,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "sections": "<em>Mobile</em> <em>app</em> <em>authentication</em> for <em>New</em> <em>Relic</em> partners",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": " <em>New</em> <em>Relic</em> account. If you use an email address associated with a <em>New</em> <em>Relic</em> partner account when you first sign in to the <em>New</em> <em>Relic</em> <em>mobile</em> <em>app</em>, <em>New</em> <em>Relic</em> will send you a confirmation email for <em>authentication</em>. Android <em>app</em> users will also see a notification message. Important The <em>authentication</em> email"
      },
      "id": "604418de28ccbc28932c6071"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 269.95755,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Introduction</em> to <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s <em>i</em>Phone and <em>i</em>Pad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> <em>iOS</em> <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s <em>iOS</em> <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-10-24T17:45:03Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.18228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app": [
    {
      "sections": [
        "Install the New Relic iOS mobile app",
        "Compatibility and requirements",
        "Installation"
      ],
      "title": "Install the New Relic iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "a33650792e7ba24040db9a65d8d7fbb25c341d18",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/install-new-relic-ios-mobile-app/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-03-13T04:04:34Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the New Relic iPhone and iPad apps, and links to more detailed information. Compatibility and requirements The New Relic iOS app allows you to view your New Relic applications, Infrastructure data, plugins you have installed from Plugin Central, key transactions, Synthetics monitors, and alerts from an Apple iPhone or iPad. Product requirements include: iOS 7 or higher iPhone users: iPhone 4S or higher iPad users: iPad 2 or higher You can also use an iPod touch, although resolution may be different. Installation You can install the New Relic app from the App Store or learn more from the New Relic website. Follow standard procedures to install any iOS app, and then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or authentication steps may be required. For more information, see User settings and authentication.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 230.39142,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "sections": "<em>Install</em> the <em>New</em> <em>Relic</em> <em>iOS</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "This section provides information about compatibility and requirements, basic instructions on how to install and configure the <em>New</em> <em>Relic</em> <em>i</em>Phone and <em>i</em>Pad <em>apps</em>, and links to more detailed information. Compatibility and requirements The <em>New</em> <em>Relic</em> <em>iOS</em> <em>app</em> allows you to view your <em>New</em> <em>Relic</em> applications"
      },
      "id": "60441616196a67b070960f2b"
    },
    {
      "sections": [
        "Alerting with New Relic mobile apps",
        "Requirements",
        "Turn notifications on or off",
        "View alert incident details",
        "Troubleshoot alert settings",
        "Check notification settings for your mobile device.",
        "Delete the Android or iOS device from your New Relic account.",
        "Uninstall the New Relic mobile app.",
        "Reinstall the New Relic mobile app."
      ],
      "title": "Alerting with New Relic mobile apps",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Authentication and alerts"
      ],
      "external_id": "d55850dc642cc8ade20310e1d4654db61af1e809",
      "image": "https://docs.newrelic.com/static/f942198cbd9a41b7355ef7f01fa6cc66/e5166/alerts-incident-detail-nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/authentication-alerts/alerting-new-relic-mobile-apps/",
      "published_at": "2021-10-24T17:45:03Z",
      "updated_at": "2021-07-09T12:24:33Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Account administrators can set up configuration to receive push notifications on Android and iOS devices from New Relic Alerts. You can receive alerts from any policy by attaching a user channel to the policy. Requirements This feature is available only to users on the original user model, not to users on the New Relic One user model. As a workaround, you can use the email notification channel. Turn notifications on or off When you log in to your New Relic account from an Android or iOS app, your device is automatically associated with your user channel. Be sure to add the associated user channel to the alert policy. View alert incident details The notification automatically appears on your device's lock screen. To start the New Relic app: Android devices: Tap the notification from the notification drawer. OR iOS devices: Swipe the screen. From the New Relic app's Alerts menu, select any alert to view error details for the associated application. Optional: Select Acknowledge. Optional: To view additional details, select Overview, Violations, or Event log. The main menu's Alerts list shows alerts in the following order, sorted by time: Active incidents Resolved incidents from today Resolved incidents and events from the past week, organized by day Troubleshoot alert settings If alerts are not working on your mobile device: Verify that you meet the requirements. Verify that alerts are enabled. Check your mobile device's notification settings, to ensure New Relic is permitted to send alerts. If the notification settings for your mobile device are correct, but you still do not receive notifications, delete the device from your account, then uninstall and reinstall the New Relic application. Check notification settings for your mobile device. Follow the procedure for your mobile device. Device To check notification settings: Android From your Android device's Settings, select Sound and notification. Check the settings for sound volume. Optional: Enable Also vibrate for calls. Check the settings for Interruptions. Check the settings for Notification. Check the settings for App notifications: Select the New Relic app, then check the settings for Block and Priority. iOS Ensure Do Not Disturb is off: From the iOS Settings app, select Do Not Disturb, and check that the Manual switch is off. Ensure the New Relic app is allowed to send notifications: From the iOS Settings app, select Notifications, and locate the New Relic app from the app list. Ensure that the Allow Notifications switch is on. Ensure that the alert style is set to Banners or Alerts. Optional: To enable audio alerts, set Sounds to on. Delete the Android or iOS device from your New Relic account. To delete the mobile device from your New Relic account, use the public graphql api api.newrelic.com/graphiql in a web browser: Query current devices by selecting actor -> mobilePushNotification -> devices and selecting appVersion, deviceId, and deviceName. Run this query to get the list of devices. Mutate to remove a device by selecting mutation -> mobilePushNotificationRemoveDevice, and passing in the deviceId from the list above. Or you can remove the device from the in-app Settings option from the menu -> Settings Look under Push notification devices, and remove from there. On iOS, slide from right to left to Delete a device, on Android, tap Delete Continue with the steps to reinstall the New Relic app from your device. Uninstall the New Relic mobile app. Follow the procedure to uninstall the New Relic app from your device, then reinstall it. Device To uninstall the New Relic app: Android From your Android device's Settings, select Apps, then select the New Relic app. Select Uninstall. Continue with the steps to reinstall the New Relic app. iOS From your iOS home screen, tap and hold the New Relic icon until it shakes. To delete the app, select the X icon. Continue with the steps to reinstall the New Relic app. Reinstall the New Relic mobile app. To reinstall the New Relic mobile app: From your Android device, select Google Play Store. OR From your iOS device's home screen, select App Store. Search for New Relic. Download the app. When the download finishes, sign in to your New Relic mobile app with your New Relic account.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 219.18228,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "sections": "Alerting with <em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": ": Android From your Android device&#x27;s Settings, select <em>Apps</em>, then select the <em>New</em> <em>Relic</em> <em>app</em>. Select Uninstall. Continue with the steps to reinstall the <em>New</em> <em>Relic</em> <em>app</em>. <em>iOS</em> From your <em>iOS</em> home screen, tap and hold the <em>New</em> <em>Relic</em> icon until it shakes. To delete the <em>app</em>, select the X icon. Continue"
      },
      "id": "603e9efd64441f19a14e88ab"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 162.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    }
  ],
  "/docs/mobile-apps/new-relic-mobile-apps/tvos-app/introduction-apple-tv-app": [
    {
      "sections": [
        "Introduction to iOS mobile app",
        "Features",
        "Time range",
        "Synthetic monitoring",
        "Alerts",
        "Mobile monitoring",
        "Data privacy"
      ],
      "title": "Introduction to iOS mobile app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "iOS app"
      ],
      "external_id": "371077582a50dfd2a1e7c57cfbbf9eeaf8013e1c",
      "image": "https://docs.newrelic.com/static/630c7a9a486540073ab96a2c9926e303/442cb/device-ios-synthetics-view-monitor.png",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/ios-app/introduction-ios-mobile-app/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-09-14T07:29:47Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's iPhone and iPad app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. The New Relic iOS apps show near real-time information about your apps, hosts, and more. Features New Relic's iOS app includes these New Relic products and features: New Relic's iOS app for iPhone and iPad includes these New Relic products and features: APM (iPhone and iPad). Includes real-time and historical data. Select the icon to see transaction details. Select Overview Charts to view summary charts of your top five transactions. Browser monitoring (iPhone and iPad). Provide overview dashboard, including average page load time, browser Apdex, average throughput, and more. Infrastructure monitoring (iPhone only). Alerts (iPhone and iPad). Get alert and deployment notifications. Synthetic monitoring (iPhone only). Mobile monitoring (iPhone and iPad). Includes crash reports, network errors, API calls, and active user count. New Relic's iOS app does not have all the features of the New Relic web application. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the clock icon in the top right of the page. This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth across the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). For iPads: to specify an end time other than now, slide the toggle from Ending Now to Custom Date. Synthetic monitoring You can use the iOS app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you connect the iOS app to your New Relic account, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For iOS alerts, notifications appear on your lock screen and can be viewed by swiping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile monitoring If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your iPhone or iPad. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.12164,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "sections": "Introduction to iOS <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s iPhone and iPad <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. The <em>New</em> <em>Relic</em> iOS <em>apps</em> show near real-time information about your <em>apps</em>, hosts, and more. Features <em>New</em> <em>Relic</em>&#x27;s iOS <em>app</em> includes"
      },
      "id": "6044161628ccbc96b62c6092"
    },
    {
      "sections": [
        "Android app UI",
        "Pages",
        "Time range",
        "New Relic Synthetics",
        "Alerts",
        "Mobile apps",
        "For more help"
      ],
      "title": "Android app UI",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "8918a5a2454491a91421c55e26501a0e3f64cd3a",
      "image": "https://docs.newrelic.com/static/fc97ade0bbdbdef58b89495a0d91b734/edd00/deployment-markers_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/android-app-ui/",
      "published_at": "2021-10-24T17:44:09Z",
      "updated_at": "2021-09-14T07:28:15Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The UI for the New Relic Android app provides functionality similar to the standard user interface, with customized details for mobile users. Pages To view details of your New Relic apps, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The New Relic Android app includes: APM metrics, both real-time and historical data, including health maps. And, select the transaction icon for detailed transaction metrics, or an Overview Charts to view summary charts of your top five transactions. New Relic Infrastructure utilization. New Relic Plugins, including a list of their components or instances, and their charts and current values from the plugin's Summary. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Select the filter icon to filter by labels and categories. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. Note: New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Time range When viewing an application or host, you can change the visible time frame by using the time picker icon in the top right of the page (the 7D in the screenshot). This feature is similar to the standard New Relic time picker. Features include: Scrub the New Relic charts to move back and forth in the timeline. Select the time picker to choose a time range that ends now (from 30 minutes to 90 days ago). New Relic Synthetics You can use the Android app to view your New Relic Synthetics data, including charts of your monitor's availability, load times, and load sizes. Select the caret icon to view more detailed charts. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen and can be viewed by tapping the alert. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile apps If you have a mobile application and have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. For more help Additional documentation resources include: New Relic Android app (compatibility, requirements, installation) Android authentication (procedures to add or remove users, and for the users to authenticate with their Android device)",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.12105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Android <em>app</em> UI",
        "sections": "<em>Mobile</em> <em>apps</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The UI for the <em>New</em> <em>Relic</em> Android <em>app</em> provides functionality similar to the standard user interface, with customized details for <em>mobile</em> users. Pages To view details of your <em>New</em> <em>Relic</em> <em>apps</em>, hosts, Synthetics monitors, Alerts, plugins, and key transactions, select a product from the main menu. The <em>New</em>"
      },
      "id": "6044181d28ccbc9a522c60a5"
    },
    {
      "sections": [
        "Introduction to New Relic Android app",
        "Requirements",
        "Install New Relic's mobile app",
        "View New Relic data",
        "New Relic product details",
        "Synthetics data",
        "Alerts",
        "Mobile app monitoring",
        "Details on setting time range",
        "Data privacy"
      ],
      "title": "Introduction to New Relic Android app",
      "type": "docs",
      "tags": [
        "Mobile apps",
        "New Relic mobile apps",
        "Android app"
      ],
      "external_id": "ff8415c00363a49eaa062f4b0b13c795b4717ea5",
      "image": "https://docs.newrelic.com/static/ea914fce17844b32fdabefd60efc457e/e5166/navigation_nexus.jpg",
      "url": "https://docs.newrelic.com/docs/mobile-apps/new-relic-mobile-apps/android-app/introduction-new-relic-android-app/",
      "published_at": "2021-10-24T17:45:04Z",
      "updated_at": "2021-09-14T07:28:16Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The user interface for New Relic's Android app provides functionality similar to New Relic's standard user interface, with customized details for mobile users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install New Relic's mobile app You can install the New Relic Android app from the Google Play Store or learn more from the New Relic website. Follow standard procedures to install any Android app, then sign in with your New Relic user name (account email) and password if applicable. Depending on your New Relic account, additional installation or user authentication steps may be required. View New Relic data To view details of your apps monitored by New Relic, select a product from the app's main menu. See below for details on how to use specific features of the app: New Relic product details The New Relic Android app includes data about these features: APM metrics, both real-time and historical data, including health maps. Select the transaction icon to see detailed transaction metrics, or an Overview chart to view summary charts of your top five transactions. Select the icon to filter by labels and categories. Browser monitoring metrics, including average page load time, Apdex, average throughput, and more. Infrastructure monitoring. Mobile monitoring, including crash reports, network errors, API calls, and active user count. Event notifications, including mobile alerts wherever you are, plus deployment notifications and notes. New Relic's Android app does not have the full feature set of the New Relic web interface. For more detailed analysis, sign in to your New Relic account with a web browser. Synthetics data You can use the Android app to view your synthetic monitoring data, including charts of your monitor's availability, load times, and load sizes. To view more detailed charts, select the caret icon. You can mute or disable your monitor, and view details of any recent errors. For scripted monitors, you can view and search the script log. Alerts When you log in to your New Relic account from the Android app, your device is automatically associated with your user channel. Then, you can add your user channel to your target policy to receive alerts. For Android alerts, notifications appear on your lock screen. To view them, tap the alert event. You can select any alert to view error details or acknowledge the alert. New Relic also sends a push notification when a colleague acknowledges an open event. Then, New Relic sends a final, closing notification when all Critical events end. Mobile app monitoring If you have installed mobile monitoring, you can monitor its performance directly from your Android device. Mobile monitoring includes network errors, API calls, and number of active users. You can also view detailed individual crash reports for a deeper understanding of a particular crash incident. Details on setting time range When viewing an application or host, you can change the visible time frame with the time picker. To move back and forth across the timeline, scrub the New Relic charts. To change the duration of the visible time slice, select the clock icon. To specify an end time other than now, slide the toggle from Ending Now to Custom Date. To save your changes and refresh the chart data, select the clock icon again. Data privacy New Relic's mobile apps only record information needed to help authenticate and troubleshoot: User's email address associated with your New Relic account, including first and last name (for authentication purposes only) IP address Device ID For more information, see our Mobile data privacy and security documentation.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 160.12105,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>New</em> <em>Relic</em> Android <em>app</em>",
        "sections": "Install <em>New</em> <em>Relic&#x27;s</em> <em>mobile</em> <em>app</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>apps</em>",
        "body": "The user interface for <em>New</em> <em>Relic</em>&#x27;s Android <em>app</em> provides functionality similar to <em>New</em> <em>Relic</em>&#x27;s standard user interface, with customized details for <em>mobile</em> users. Requirements Requirements include: Android 4.0 (Ice Cream Sandwich) or higher Screen size of 7 inches or less Install <em>New</em> <em>Relic</em>&#x27;s <em>mobile</em>"
      },
      "id": "604415e0196a67ff23960f46"
    }
  ],
  "/docs/mobile-crash-rest-api-v1": [
    {
      "sections": [
        "Working with the New Relic REST API (v1) (deprecated)",
        "Important"
      ],
      "title": "Working with the New Relic REST API (v1) (deprecated)",
      "type": "docs",
      "tags": [
        "APIs",
        "REST API v1 deprecated",
        "New Relic REST API v1"
      ],
      "external_id": "9cb0f38eb95a8757624ddb63298ff9a32e1176e7",
      "image": "",
      "url": "https://docs.newrelic.com/docs/apis/rest-api-v1-deprecated/new-relic-rest-api-v1/working-new-relic-rest-api-v1-deprecated/",
      "published_at": "2021-10-24T19:10:48Z",
      "updated_at": "2021-03-13T02:32:09Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Currently New Relic supports two versions of the REST API. Version 1 is deprecated and has been replaced with the newer v2. No termination date has been announced. However, no further development or modifications are being made to v1. Important Start new projects by referring to Getting started with API v2 and the New Relic REST API v2 examples. Also, begin migrating your v1 scripts to their v2 equivalent. To use the REST API v1 in any way, your API key is required. Then, from the command line, you can use: curl -gH \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy OR wget -qO- --header \"x-api-key:REPLACE_WITH_YOUR_API_KEY\" 'ENDPOINT_URL' Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 353.91092,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "sections": "Working with the New Relic <em>REST</em> <em>API</em> (<em>v1</em>) (deprecated)",
        "tags": "<em>REST</em> <em>API</em> <em>v1</em> deprecated",
        "body": "Currently New Relic supports two versions of the <em>REST</em> <em>API</em>. Version <em>1</em> is deprecated and has been replaced with the newer <em>v</em>2. No termination date has been announced. However, no further development or modifications are being made to <em>v1</em>. Important Start new projects by referring to Getting started"
      },
      "id": "6043ff97e7b9d20358579a0d"
    },
    {
      "sections": [
        "FedRAMP-compliant endpoints",
        "Customer FedRAMP obligations",
        "Overview of data sources",
        "Agents",
        "APM agents",
        "Mobile monitoring agents",
        "Infrastructure monitoring",
        "Important",
        "Infrastructure agent versions below 1.15.0",
        "Browser agent",
        "Data-ingest APIs",
        "OTLP API",
        "Metric API",
        "Telemetry integrations",
        "Telemetry SDKs",
        "Event API",
        "Log API",
        "Log forwarders",
        "Trace API"
      ],
      "title": "FedRAMP-compliant endpoints",
      "type": "docs",
      "tags": [
        "Security",
        "Security and Privacy",
        "Compliance"
      ],
      "external_id": "ffce8ad6f802717392aca80e0965c9f3fe77ffdf",
      "image": "",
      "url": "https://docs.newrelic.com/docs/security/security-privacy/compliance/fedramp-compliant-endpoints/",
      "published_at": "2021-10-25T15:28:49Z",
      "updated_at": "2021-10-25T15:28:49Z",
      "document_type": "page",
      "popularity": 1,
      "body": "This document provides information on FedRAMP-compliant endpoints in New Relic. For more information about our security accreditation for the Federal Risk and Authorization Management Program (FedRAMP), see our data encryption documentation. For further information on New Relic networks, domains, and ports see our networking documentation. Customer FedRAMP obligations New Relic customers must meet all of the following requirements for New Relic’s FedRAMP environment: New Relic-approved customers: New Relic’s FedRAMP-Moderate authorized environment is only available to New Relic-approved customers. For more information, contact your New Relic account representative. Order form: Customer’s order form with New Relic must include customer’s eligibility for FedRAMP. Subscription level: Customer must have a current and valid subscription to our Enterprise edition or a New Relic-approved subscription. Authorized New Relic endpoints: Customer must send its data only to New Relic’s FedRAMP-designated endpoints. Authorized services and features: Customer must use only FedRAMP audited and authorized New Relic services and features (see below). Overview of data sources There are multiple ways to get data into New Relic. This doc has two sections: Agent settings: for our APM agents, infrastructure agent, browser agent, and mobile agent. Data-ingest APIs: for our Metric API, Event API, Trace API, and Log API, and the integrations that use those APIs. Agents New Relic has several agents for reporting data, like our APM agents, infrastructure agents, mobile agents, and browser agent. Setting these agents to send FedRAMP-compliant data involves setting a configuration setting to use the relevant FedRAMP endpoint. APM agents To ensure FedRAMP compliance, all APM agent configurations must report to gov-collector.newrelic.com rather than the default. Depending on the agent, you can either use code-based configuration or an environment variable. Here are details on enabling this: Language Code or environment variable C SDK In code: strcpy(_newrelic_app_config_t->redirect_collector, \"gov-collector.newrelic.com\"); Copy Environment variable: none Go In code: app, err = newrelic.NewApplication( newrelic.ConfigAppName(\"App Name\"), newrelic.ConfigLicense(os.Getenv(\"NEW_RELIC_LICENSE_KEY\")), func(cfg *newrelic.Config) { cfg.Host = \"gov-collector.newrelic.com\" }, ) Copy Environment variable: NEW_RELIC_HOST Java In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Or set a system property of: newrelic.config.host Copy Environment variable: NEW_RELIC_HOST .NET In your XML config next to the license key: <service licenseKey=\"YOUR_LICENSE_KEY\" host=\"gov-collector.newrelic.com\"/> Copy Environment variable: NEW_RELIC_HOST Node.js In newrelic.js: host: 'gov-collector.newrelic.com' Copy Environment variable: NEW_RELIC_HOST PHP In newrelic.ini: newrelic.daemon.collector_host = gov-collector.newrelic.com Copy Environment variable: none Python In newrelic.ini: [newrelic] host = gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Ruby In newrelic.yml: common: &default_settings host: gov-collector.newrelic.com Copy Environment variable: NEW_RELIC_HOST Elixir (open source agent) In config.exs: config :new_relic_agent, host: \"gov-collector.newrelic.com\" Copy Environment variable: NEW_RELIC_HOST For more on configuring APM agents, see APM configuration. Mobile monitoring agents To ensure FedRAMP compliance when using our mobile monitoring agents, all agent configurations must report to gov-mobile-collector.newrelic.com rather than the default. You must use code-based configuration. Environment variables are not available. Framework-specific configurations: Agent Code or environment variable Android In code: NewRelic.withApplicationToken({APP_TOKEN}) .usingCollectorAddress(\"gov-mobile-collector.newrelic.com\") .usingCrashCollectorAddress(\"gov-mobile-crash.newrelic.com\") .start(this.getApplication()); Copy Environment variable: none iOS In code: [NewRelic startWithApplicationToken:@\"{APP_TOKEN}\" andCollectorAddress:@\"gov-mobile-collector.newrelic.com\" andCrashCollectorAddress:@\"gov-mobile-crash.newrelic.com\"]; Copy Environment variable: none Infrastructure monitoring If you have infrastructure agent version 1.15.0 or higher, simply enable the FedRAMP configuration option. This enables FedRAMP compliancy for data reported by the infrastructure agent, and for any on-host integrations that work with the infrastructure agent to report data. Important The AWS CloudWatch Metric Streams integration is not currently FedRAMP compliant. If you have an older agent version, use the following values to edit your YAML configuration: Infrastructure agent versions below 1.15.0 If you have an infrastructure agent version below 1.15.0, you must change three of the endpoints used for reporting. To set these endpoints, you can change your YAML configuration or use environment variables. YAML config field Endpoint URL collector_url https://gov-infra-api.newrelic.com Copy identity_url https://gov-identity-api.newrelic.com Copy command_channel_url https://gov-infrastructure-command-api.newrelic.com Copy To edit environment variables, use these values: Environment variable Endpoint URL NRIA_COLLECTOR_URL https://gov-infra-api.newrelic.com Copy NRIA_IDENTITY_URL https://gov-identity-api.newrelic.com Copy NRIA_COMMAND_CHANNEL_URL https://gov-infrastructure-command-api.newrelic.com Copy Browser agent To configure the browser agent to use a FedRAMP-compliant endpoint, you must use the copy-paste method method (other browser agent install methods are not supported) and edit the browser code’s script element tag so that the domain is gov-bam.nr-data.net for both beacon and errorBeacon, like this: window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"gov-bam.nr-data.net\",\"errorBeacon\":\"gov-bam.nr-data.net\"... Copy Note: You only need to modify the beacon and errorBeacon properties in the NREUM.info object. These values will override the default values found in the NR loader script. Data-ingest APIs Below are details about the FedRAMP endpoint for our ingest APIs: Metric API, the Event API, the Log API, and the Trace API. OTLP API To ensure FedRAMP compliance when using the OTLP API, instead of sending to the US OTLP API endpoint of https://otlp.nr-data.net:4317, send data to https://gov-otlp.nr-data.net:4317. Metric API To ensure FedRAMP compliance when using the Metric API, instead of sending metric data to the default Metric API endpoint of https://metric-api.newrelic.com/metric/v1, it must be sent to https://gov-metric-api.newrelic.com/metric/v1. The Metric API can be used directly but it's mainly used by various New Relic tools. Below are instructions showing where to edit the configuration for setting the FedRAMP endpoint. Telemetry integrations Here are instructions for our open source telemetry integrations that report metric data: Dropwizard: use the overrideUri configuration. Kamon: use the metric-ingest-url configuration. See Override endpoints. Micrometer: override the public String uri() method on your NewRelicRegistryConfig to return the new endpoint. See an example. Prometheus: Prometheus OpenMetrics: if you are using our nri-prometheus helm chart, you can change the endpoint in your values.yml file, like in this example. If you're using the nri-bundle chart, you need to nest this value under the nri-prometheus key to propagate it to the sub-chart. Remote write integration: not available. Telemetry SDKs Here are instructions for our Telemetry SDKs that report metric data: Go: use the MetricsURLOverride configuration. Java: in the MetricBatchSender section, configure the endpoint. See an example. .NET: use the MetricUrlOverride configuration. Node.js: edit the METRIC_HOST = 'metric-api.newrelic.com' configuration. Python: edit the HOST = \"metric-api.newrelic.com\" configuration. Event API To ensure FedRAMP compliance for the Event API, all traffic reporting to insights-collector.newrelic.com must instead report to gov-insights-collector.newrelic.com. The Event API endpoint is configurable for the following Telemetry SDKs. The Telemetry SDKs are used by our open-source telemetry integrations. Language Solution Java Telemetry SDK In code: SenderConfiguration configuration = SenderConfiguration .builder( \"gov-insights-collector.newrelic.com\", EventBatchSender.EVENTS_PATH) .build(); EventBatchSender eventBatchSender = EventBatchSender.create(configuration); Copy Python Telemetry SDK In code: event_client = EventClient(host=\"gov-insights-collector.newrelic.com\") Copy For more information, see our Telemetry API documentation in GitHub. Log API To ensure FedRAMP compliance for data sent via the Log API, the solution for almost all our logging tools is to replace the https://log-api.newrelic.com/log/v1 endpoint with https://gov-log-api.newrelic.com/log/v1. Here are details for various tools: Log forwarders Here are details on changing the endpoint for our log forwarders: AWS Firelens: Add the endpoint property to the options field of the logConfiguration, similar to to the EU account endpoint change shown in these Firelens endpoint configuration instructions. Fluentbit: Use our Fluentbit endpoint configuration. Fluentd: Use our Fluentd endpoint instructions. Infrastructure agent: See FedRAMP for infrastructure. Kubernetes: Our Kubernetes integration logs are based on fluentbit’s output plugin. Use these endpoint instructions. Logstash: Use our Logstash endpoint configuration. Syslog: For configuring syslog clients, see TCP endpoint configuration. S3: Not available. Vector: Not available. To use the Log API directly, you'd edit the Log API endpoint configuration. Trace API To ensure FedRAMP compliance for data sent via the Trace API (including telemetry integrations that use this API), replace the https://trace-api.newrelic.com/trace/v1 endpoint with https://gov-trace-api.newrelic.com/trace/v1. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and mobile agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. To enable FedRAMP compliance for Infinite Tracing, you would create a new FedRAMP compliant trace observer from the New Relic Edge app.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 334.31152,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "<em>Mobile</em> monitoring agents",
        "body": " with https:&#x2F;&#x2F;gov-trace-<em>api</em>.newrelic.com&#x2F;trace&#x2F;<em>v1</em>. Notes about FedRAMP compliance for other trace data: Trace data is reported by some of our agents, like our APM agents, browser agent, and <em>mobile</em> agent. To enable FedRAMP compliance for that data, you would enable FedRAMP for the applicable agent. To enable FedRAMP compliance for Infinite Tracing, you would create a new FedRAMP compliant trace observer from the New Relic Edge app."
      },
      "id": "603e945164441f64384e8872"
    },
    {
      "sections": [
        "StatsD monitoring integration",
        "Requirements",
        "Install",
        "Install for Kubernetes",
        "Kubernetes manifest examples",
        "Configure",
        "Tip",
        "Example of custom configuration",
        "Docker: overwrite default configuration",
        "Kubernetes: overwrite default configuration",
        "Metric format",
        "Metric types",
        "Counter",
        "Gauge",
        "Timer",
        "Add tags (attributes)",
        "Add default tags that apply to all metrics",
        "Add metric-level tags",
        "Create alerts",
        "Alert example",
        "Find and use data",
        "Check the source code"
      ],
      "title": "StatsD monitoring integration",
      "type": "docs",
      "tags": [
        "Integrations",
        "On-host integrations",
        "On-host integrations list"
      ],
      "external_id": "48ab117ae50533224877d767224d85edd939db42",
      "image": "https://docs.newrelic.com/static/9c86375ad0ec12433df78b2116819aab/c1b63/statsd-nrql-alert-condition-example.png",
      "url": "https://docs.newrelic.com/docs/infrastructure/host-integrations/host-integrations-list/statsd-monitoring-integration-version-2/",
      "published_at": "2021-10-24T21:10:05Z",
      "updated_at": "2021-10-24T00:56:02Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Our StatsD integration lets you easily get StatsD-format data into New Relic. You can also add any arbitrary tags (key-value pairs) to your data. Once your metrics are in New Relic, you can query your data and create custom charts and dashboards. Want to try out our StatsD integration? Create a New Relic account for free! No credit card required. Requirements This integration uses our Metric API and our Event API to ingest data. To use these APIs, you'll need a license key. The integration adheres to the Metric API requirements and data limits. The default rate limit is 100,000 data points per minute (DPM). If you think you're missing metrics or sending more than 100K DPM, see Request data changes. To see if your account is hitting the rate limit, run the following NRQL query of the NrIntegrationError event: SELECT count(*) FROM NrIntegrationError WHERE newRelicFeature ='Metrics' FACET category, message LIMIT 100 since 1 day ago Copy Install This section will explain how to do a standard install. If you want to run StatsD in Kubernetes, see Kubernetes install. To install the StatsD integration, run the following command and include your New Relic account ID and New Relic license key. This generates a TOML configuration file used by gostatsd. docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy If your account is in the EU data center region, add this to the above command: -e NR_EU_REGION=true \\ Copy After installing, you can: Do optional additional configuration Define your metrics Add custom tags to your data Create alerts Install for Kubernetes Here are examples of Kubernetes manifests for deployment and service objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: apiVersion: apps/v1 kind: Deployment metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: selector: matchLabels: app: newrelic-statsd replicas: 2 revisionHistoryLimit: 2 template: metadata: labels: app: newrelic-statsd spec: containers: - name: newrelic-statsd image: newrelic/nri-statsd:2.0.0 env: - name: NR_ACCOUNT_ID value: \"NEW_RELIC_ACCOUNT_ID\" - name: NR_API_KEY value: \"NEW_RELIC_LICENSE_KEY\" Copy service.yml: apiVersion: v1 kind: Service metadata: name: newrelic-statsd namespace: tooling labels: app: newrelic-statsd spec: type: ClusterIP ports: - name: newrelic-statsd port: 80 targetPort: 8125 protocol: UDP selector: app: newrelic-statsd Copy For configuration details, see Kubernetes configuration. Configure In the install procedure, you run nri-statsd with environment variables, and this generates a TOML configuration file. Additionally, you can set these configuration options: Configuration options Description expiry-interval string If a metric is not updated for this amount of time, we stop reporting that metric. Default is 5m. If you want to send the metrics only if the value was updated between the flush intervals, configure this to 1ms. To never expire metrics, set it to 0. percent-threshold list of integers Specifies the percentiles used for metrics aggregation. Default: 90. metrics-addr string Indicates address on which to listen for metrics. Default: :8125. Tip To ensure FedRAMP compliance when using the StatsD integration you must define the following endpoints in the custom configuration: address = 'https://gov-insights-collector.newrelic.com/v1/accounts/ $NR_ACCOUNT_ID/events' Copy address-metrics = 'https://gov-infra-api.newrelic.com/metric/v1' Copy Here are some examples of customizing configuration by overwriting the default configuration: Example of custom configuration # Specify after how long do we expire metrics, default:5m expiry-interval = '1ms' # percent-threshold specify a list of percentiles for metrics aggregation, default:90 percent-threshold = [90, 99] backends='newrelic' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://insights-collector.newrelic.com/v1/accounts/$NR_ACCOUNT_ID/events' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy Disable timer sub-metrics: By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. If you want to disable those metrics you can do it by adding a disabled-sub-metrics configuration section and set true for the ones you want disabled. Here's an example: # disabled-sub-metrics configuration section allows disabling timer sub-metrics [disabled-sub-metrics] # Regular metrics count=false count-per-second=false mean=false median=false lower=false upper=false stddev=false sum=false sum-squares=false # Percentile metrics count-pct=false mean-pct=false sum-pct=false sum-squares-pct=false lower-pct=false upper-pct=false Copy Docker: overwrite default configuration To overwrite the default nri-statsd configuration while running in a container, you can mount a configuration file inside the container. You can adopt the following template as needed for your situation. Example: backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address-metrics = 'https://metric-api.newrelic.com/metric/v1' api-key = 'NEW_RELIC_LICENSE_KEY' Copy To run the container with the file mounted in the appropriate path: docker run \\ ... -v ${PWD}/nri-statsd.toml:/etc/opt/newrelic/nri-statsd.toml \\ ... newrelic/nri-statsd:2.0.0 Copy Kubernetes: overwrite default configuration The best approach to configure nri-statsd running in Kubernetes is to use a configMap and mount the configMap into the container. (This is a similar process to mounting the configuration file in Docker.) Example: apiVersion: v1 kind: ConfigMap metadata: name: nri-statsd-config namespace: default data: nri-statsd.toml: | backends='newrelic' flush-interval='10s' [newrelic] # flush types supported: metrics, insights, infra flush-type = 'metrics' transport = 'default' address = 'https://metric-api.newrelic.com/metric/v1' api-key = '$NEW_RELIC_LICENSE_KEY' Copy To use the configMap, declare a volume on your deployment spec template and then declare a volumeMount on your container spec. Example: apiVersion: apps/v1 kind: Deployment spec: template: spec: containers: .... volumeMounts: - mountPath: /etc/opt/newrelic/ name: nri-statsd-config volumes: - name: nri-statsd-config configMap: name: nri-statsd-config Copy Metric format The integration receives metrics using the StatsD protocol. Optionally, the sample rate can be configured and tags can be added. Here's the metric data format we use: <metric name>:<value>|<type>|@<sample rate>|#<tags> Copy Here are explanations of these fields: Field name Description < metric name> string Required. Name of the metric. < value> string Required. The metric type: c = counter g = gauge ms = timer @ < sample rate> float Optional for simple counters or timer counters. When many metrics must be sent, you can use sampling to reduce network traffic. The downside is a reduction in the resolution of the data. An example of how this would work for sample rates below 1: If you set this to 0.1, the counter would send a measurement one out of every 10 times. # < tags> string Optional. Tags attached to your metrics are converted into attributes (key-value pairs). For more on tagging options, see Tags. Metric types Here are the types of metrics and how to format them: Counter A counter measures the number of occurrences of an event. Examples include cache hits per reporting interval and the number of threads created per reporting interval. A counter can be incremented or decremented during the same flush interval by adding a sign to the value. In the following example, the counter value will be 2: counter:4|c counter:-2|c Copy At each flush, the current count is sent and reset to 0. If the count is not updated, at the next flush it will send the value 0. You can opt to disable this behavior by setting expiry-interval to 1ms. Here’s an example of a counter that is being sampled 1 out of 10 times: counter:4|c@0.1 Copy Gauge A gauge represents a value that can increase or decrease with time. Examples of gauges include temperature, CPU usage, and memory. Here's an example: temperature:40|g Copy If the gauge is not updated, at the next flush it will send the previous value. You can opt to disable this behavior by setting expiry-interval to 1ms. Timer The timer metric type measures timing data. By default, nri_statsd calculates the following for timer metrics: standard deviation, mean, median, sum, lower, and upper bounds for the flush interval. These are sent as sub-metrics in the following format: <metric_base_name>.std_dev <metric_base_name>.median <metric_base_name>.summary <metric_base_name>.sum_squares <metric_base_name>.mean <metric_base_name>.per_second Copy The configured percentiles will generate the following metrics. The percentile threshold value will be attached as a tag. <metric_base_name>.sum_squares.percentiles <metric_base_name>.sum.percentiles <metric_base_name>.count.percentiles <metric_base_name>.upper.percentiles <metric_base_name>.mean.percentiles Copy The percentile threshold can be tweaked with the percent-threshold config option. These can be controlled through the disabled-sub-metrics configuration section. Add tags (attributes) You can add tags to your data, which we save as attributes (key-value pairs). There are two options for adding tags: Add default tags that apply to all metrics: These apply to all metrics. They are fixed and don't change over time. Add metric-level tags: These apply to specific metrics and allow the value to be changed between two submits. Add default tags that apply to all metrics Add tags to metrics and events by defining an environment variable in the startup command. Here's an example that would create two tags: -e TAGS=\"environment:production region:us\" Copy Here's that environment variable used in the startup command: docker run \\ -d --restart unless-stopped \\ --name newrelic-statsd \\ -h $(hostname) \\ -e NR_ACCOUNT_ID=YOUR_ACCOUNT_ID \\ -e NR_API_KEY=NEW_RELIC_LICENSE_KEY \\ -e TAGS=\"environment:production region:us\" \\ -p 8125:8125/udp \\ newrelic/nri-statsd:2.0.0 Copy Add metric-level tags When defining the metric format, you can add tags using this format: <bucket name>:<value>|<type>|#<tags> Copy In this example, <tags> is a comma-separated list of tags. Tags format is: simple or key:value. Here's an example NRQL query that includes a custom tag: SELECT count(*) FROM Metric WHERE environment = 'production' Copy Create alerts You can alert on StatsD data using NRQL alert conditions. Alert example This procedure walks you through sending some sample data and then creating an alert condition using that data. First, send this data to New Relic’s StatsD container: echo \"prod.test.num:32|g\" | nc -v -w 1 -u localhost 8125 Copy Next, create a NRQL alert condition using this query: SELECT latest(prod.test.num) FROM Metric WHERE metricName = 'prod.test.num' Copy Here's an image showing creating this NRQL alert condition. Notice that the sample data sent in is represented by the blue dot on the upper right of the chart. Now we can create the alert condition with these settings: When you create the NRQL alert condition, be sure to set the Condition name. If a metric with a value above 50 is sent, then an incident is created and notified. The incident is closed automatically after 24 hours. To test that the alert is working, run this command: echo \"prod.test.num:60|g\" | nc -v -w 1 -u localhost 8125 Copy Find and use data To query your data, you'd use any New Relic query option. For example, you might run a NRQL query like: SELECT count(*) FROM Metric WHERE metricName = 'myMetric' and environment = 'production' Copy For more on how to query the Metric data type, see Query metric data. Check the source code This integration is open source software. That means you can browse its source code and send improvements, or create your own fork and build it.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 250.36346,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "body": " objects: Kubernetes manifest examples Below are examples of Kubernetes manifests to deploy StatsD in a Kubernetes environment and create a StatsD service named newrelic-statsd. You need to insert your account ID and your license key. deployment.yml: <em>api</em>Version: apps&#x2F;<em>v1</em> kind: Deployment metadata: name"
      },
      "id": "6174af22e7b9d253c613b73d"
    }
  ],
  "/docs/mobile-monitoring/index": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 493.65533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". As part of the installation process, <em>mobile</em> <em>monitoring</em> automatically generates an application token. This is a 40-character hexadecimal string for authenticating each <em>mobile</em> app that you <em>monitor</em>. Follow the Android installation and configuration procedures for your environment as applicable. If you have"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 470.83398,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests UI page that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/understand-data/event-data/events-reported-mobile-monitoring/",
      "sections": [
        "Events reported by mobile monitoring"
      ],
      "published_at": "2021-10-24T20:19:28Z",
      "title": "Events reported by mobile monitoring",
      "updated_at": "2021-10-23T17:24:35Z",
      "type": "docs",
      "external_id": "6173c71cf5e35866f9af6c04f16811ed0ce8a0c0",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description Mobile A Mobile event is created when a crash occurs, when an interaction ends or has run for 1 second, or if a session completes after the app is closed, backgrounded, or has run for 10 minutes. Mobile events were once the only event type and were generated for every event, but now there are several specialized event types. MobileBreadcrumb There are no attributes listed for this event because it's a custom event; attributes will include the session attributes and any custom attributes added. MobileCrash The MobileCrash event is created when an app crashes. MobileCrash includes attributes such as crash line number, class, and crash message. MobileHandledException MobileHandledException is sent when an exception is caught and is used for non-fatal exceptions reported to New Relic using the recordHandledException API call for Android or iOS. The exceptions will be visible in queries of this event and on the Handled exceptions UI page, including stack traces. MobileRequest A MobileRequest event is created when an HTTP request successfully completes, resulting in a response code below 400. New Relic MobileRequest data is enabled by default for: Android version 5.15.2 or higher iOS version 6.0.0 or higher For earlier versions, starting with Android version 5.14.0 or iOS version 5.14.0, you must enable the feature. Upgrade to the latest Android or iOS version, or enable the NetworkRequests feature flag by using the Android or iOS configuration settings. MobileRequestError A MobileRequestError is used for HTTP errors or network failures. HTTP errors are HTTP requests that have a status code greater than 400. A network failure is an HTTP request that results in no response. The event is sent when the HTTP request completes. MobileSession A MobileSession event is sent when an app is closed, backgrounded, or when 10 minutes of active use has elapsed. This is the source of the general session data used by the other mobile monitoring events. MobileSession captures attributes such as device type, device OS, and geographical information. Custom events There is no attribute list for this event type because it is a custom event; attributes will include the session attributes and any custom attributes that you add. Related documentation: Report custom events Extend data retention See example NRQL queries",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 413.93185,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Events reported by <em>mobile</em> <em>monitoring</em>",
        "sections": "Events reported by <em>mobile</em> <em>monitoring</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> in New Relic reports event data that is displayed in some UI displays and is also available for querying and charting. Select an event name in the following table to see its attributes. Event Description <em>Mobile</em> A <em>Mobile</em> event is created when a crash occurs, when an interaction"
      },
      "id": "609f8faf196a675bef22b1ad"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/crash-analysis-group-filter-your-crashes": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/find-build-uuids-unsymbolicated-crashes": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31993,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-occurrences": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31982,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.32607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/investigate-mobile-app-crash-report": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Mobile crash event trail",
        "Tip",
        "View events before mobile app crashes",
        "Use the event trail",
        "Difference between event trail and interaction trail"
      ],
      "title": "Mobile crash event trail",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "58795d499c8db6d8cc95bd6d2c645e970ea10d83",
      "image": "https://docs.newrelic.com/static/3731efca2d88ed92cc150d5f6c06830a/0d6fe/New-Relic-Mobile-crash-event-trail.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail/",
      "published_at": "2021-10-24T16:28:20Z",
      "updated_at": "2021-07-22T01:05:00Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The mobile monitoring crash event trail shows you the events leading up to a crash of a mobile app, based on your subscription level's data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the crash event trail is and how to use it. Tip Access to this feature depends on your subscription level. View events before mobile app crashes When a mobile app crashes and you don't know why, you can study what happened right before the crash. The crash event trail shows you these events so that you can follow the \"breadcrumbs\" leading up to the crash and diagnose the cause of the failure. one.newrelic.com > Mobile > (select a mobile app) > Crash analysis > (selected crash type) > Event trail: The crash event trail shows the activity leading up to a mobile app crash. The crash event trail shows all mobile event types leading up to a crash. You can use the iOS SDK or Android SDK to create custom MobileBreadcrumb events that track whatever app activity you think would help you diagnose a crash. You can also use MobileHandledException events in the crash event trail to aid in debugging. Use the iOS and Android recordHandledException APIs for iOS or Android to annotate where exceptions are handled in your application. These events will automatically appear in the crash event trail. For more about annotating crash event trails with custom data, see Add custom data to mobile monitoring. Use the event trail To use the crash event trail: Go to one.newrelic.com > Mobile > (select a mobile app) > Crash analysis. On the lower right side of the Crash analysis page, select a crash type. On the Crash details page, beside the stack trace, select Event trail. Study the events leading up to a crash type for clues to the reasons for the crash. To expand details about an event's attributes, select it. To view the event trail results in New Relic, select Open session in Insights. To scroll through occurrences of the same crash type, use the event trail's left and right arrows. To make the most out of our crash analysis tools, use: The Android SDK API or iOS SDK API to create custom MobileBreadcrumb or MobileHandledException events Enable MobileRequest events Crash analysis page Interaction trail Difference between event trail and interaction trail The crash event trail is different from the interaction trail. The crash event trail shows all mobile event types leading up to a crash, whereas the interaction trail only shows interaction event types (Mobile events with the category interaction). The interaction trail has additional features, including stack traces and links to the associated interaction charts.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>crash</em> event trail",
        "sections": "View events before <em>mobile</em> app <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The <em>mobile</em> <em>monitoring</em> <em>crash</em> event trail shows you the events leading up to a <em>crash</em> of a <em>mobile</em> app, based on your subscription level&#x27;s data retention policy. These can be events New Relic monitors by default, or custom events. This document explains what the <em>crash</em> event trail is and how to use"
      },
      "id": "604503b1e7b9d201e75799bb"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/crashes/mobile-crash-event-trail": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 233.31972,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " that lead to <em>crashes</em>. To view more information about <em>crashes</em>, create NRQL queries to review Insights charts related to <em>crash</em> data. Android SDK API Use the Android SDK API for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Introduction to mobile handled exceptions",
        "Features",
        "Requirements",
        "Tip",
        "Handled exceptions API and event type"
      ],
      "title": "Introduction to mobile handled exceptions",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "cfdf733d55bb89d157df675fa162b737bdad52c7",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/introduction-mobile-handled-exceptions/",
      "published_at": "2021-10-24T17:32:24Z",
      "updated_at": "2021-07-22T00:02:14Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Exceptions can contribute to invalid application states, resulting not only in application crashes but also in negative user reviews. This may lead to users deleting your app, which in turn may affect your organization's profitability. With the Handled exceptions UI, mobile development managers and their developer teams can identify significant factors affecting poor mobile app experience, and use filterable data to find a resolution more quickly. Features Handling exceptions as they occur can help improve your mobile app users' experience, but it's not enough to catch exceptions. You also need to know how to prevent them. For example: How many different types of handled exceptions are occurring? A high occurrence rate may necessitate changes to the back-end systems. Why does the user's app usage result in a try/catch? What is the context for the exceptions? When can a test environment's responses to handled exceptions indicate additional, more serious problems? What would have caused a crash if the exception had not been caught in production? What else (in the code or back-end API) is still affecting the users' experience? By using handled exceptions, you can identify and resolve these kinds of issues more quickly. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Handled exception features Comments Slice and dice your exception data. You can view exception data via API as well as the UI: Use the recordHandledException() method within a try{...} catch(){...} block to help understand how often your application is throwing exceptions, and under what conditions. Use groups and filters to analyze trends leading to the exception. For example, you can group by OS Build, then filter a specific appVersion. Understand a particular user's experience. Examine the percentage charts to see overall trends with users and sessions at a glance. Then, use custom attributes to focus on exceptions related to paid accounts than free accounts. Pinpoint when most exceptions occur. For example, group on Last Interaction to get an overall view of problems. To drill down further, use filters, such as: To examine exceptions caused by network problems, filter by carrier and then select wifi. To examine exceptions caused by app releases, filter by appVersion. Align issues with common characteristics. For example: Use groups and filters to determine whether handled exception trends appear in networks (ASN, carrier, location, etc.) or in devices (device model, manufacturer, operating system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a crash. With mobile monitoring you get a more complete picture of events before and after crashes occur, so you can analyze and resolve problems from multiple angles: Use the handled exception's Occurrences page for expected exceptions. Use the Crash analysis UI and event trail for unanticipated exceptions. Requirements Tip Access to this feature depends on your subscription level and mobile data retention. Additional requirements include: Android: Android agent version 5.15.0 or higher iOS: iOS agent version 5.15.0 or higher Handled exceptions API and event type Mobile monitoring automatically includes default attributes that you can use to explore your handled exceptions data in the query builder and get specific details: Use the recordHandledExceptions() method for the Android or iOS SDK API. Query the MobileHandledException event type. For more information, see the NRQL examples for mobile monitoring. You can also create your own custom attributes and events. Then, select attributes in the Handled exceptions page, and query or share them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.34157,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>mobile</em> handled exceptions",
        "sections": "Introduction to <em>mobile</em> handled exceptions",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " system build, version, etc.). Explore recurring patterns in stack traces with the top five exception locations table. Query data and share your findings. Explore the event trail before and after a <em>crash</em>. With <em>mobile</em> <em>monitoring</em> you get a more complete picture of events before and after <em>crashes</em> occur, so"
      },
      "id": "603e7e8228ccbc05f9eba770"
    },
    {
      "sections": [
        "Handled exceptions: Analyze trends, prevent crashes",
        "Handled exceptions workflow",
        "Exception percentage charts",
        "Exception percentage charts example",
        "Groups and filters",
        "Groups and filters example",
        "Top five exception locations",
        "Top five exception locations example",
        "Query builder links",
        "Exception locations table",
        "Exception locations table example"
      ],
      "title": "Handled exceptions: Analyze trends, prevent crashes",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Crashes"
      ],
      "external_id": "d325744648613b771d7dd39de3f1448fe8a54ab9",
      "image": "https://docs.newrelic.com/static/5891a9437b94b543d81ee04a70ebe876/8c557/mobile-handled-exceptions-ui.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/crashes/handled-exceptions-analyze-trends-prevent-crashes/",
      "published_at": "2021-10-24T16:17:00Z",
      "updated_at": "2021-07-21T21:33:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Handled exceptions help you identify significant factors contributing to poor mobile application experience, and use filterable data to find a resolution more quickly. You can also use the handled exceptions API to customize the data you send, and use NRQL to query and share the data. Handled exceptions workflow To get the most out of the Handled exceptions UI, use this basic workflow: Go to one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions. Use any of New Relic's standard page functions to drill down into detailed information; for example, zoom into any area of a chart. Look for obvious or general trends in the Users affected and Sessions affected percentage charts. Adjust the types of exceptions shown by using groups and filters. Optional: Query or share the chart data. Look for similar patterns where exceptions appear in stack traces with the Top 5 exception locations table. To view stack trace thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: As you explore the wealth of data in the charts and table, use groups and filters to discover patterns that help you determine the root cause of mobile app exceptions. Exception percentage charts Start with the Users affected and Sessions affected percentage charts to see at a glance whether there are any unexpected spikes, dips, or patterns with exceptions in general. (If the Users affected chart is empty, there were no user sessions during the selected time period.) For example: Are there any spikes near a recent version release? Is there a time period when the percentage of users has been affected significantly by the exception? Are there uneventful periods? To examine data in greater detail: Below any chart, select Expand chart. Exception percentage charts example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: The percentage charts help you quickly see any unexpected spikes, dips, or patterns with exceptions in general. Groups and filters Use the groups and filters to examine attributes for crashes, devices, locations, or other custom attributes in more detail. You can select a group, then filter to specific data. For example: Group the list by exception location (default), cause, app build or version, devices, connections, or other custom attributes. This lets you discover patterns in your exceptions to determine the root cause. Use the time picker to adjust the currently selected time period. Filter by a specific Version or by one or more attribute Filter, such as appVersion, exceptionLocationMethod, lastInteraction, or any of the longer list of standard and custom attributes. The currently selected filters appear at the top of the UI page. You can close them, add other filters, or select other groups and filters. Groups and filters example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: Group the data by attributes that matter to the most to you, then select one or more filters to help pinpoint specific causes behind the exceptions. Top five exception locations Use the Top 5 exception locations table to find or sort patterns in the type of exception you selected from the groups and filters. This includes: Recurring locations in the stack trace Mobile app version Number of occurrences Number of users affected during the selected time period For example, you can group by Exception Message, filter to timeout message, then select individual timeout locations from the table to review the stack trace thread and details about each occurrence. To filter or group by other attributes, use the table's search window, or select any of the available filters. For example, filter by type of occurrence, device, a specific location, or any custom attributes. To look for other historical patterns, change the selected time period. Top five exception locations example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: This example shows the Expand chart button and links to the query builder, where you can query, create dashboards, and share the handled exceptions data. Query builder links Handled exceptions charts use default attributes for mobile events (including MobileHandledException), along with any custom attributes you have added to this event type. When you mouse over the charts, direct links appear below them. These links to the query builder allow you to analyze your mobile app data even deeper. View query link: View the NRQL query used to calculate the chart data. View in query builder link: View the chart, and share it with others. Exception locations table The Exception locations table supplements the charts. It lists where the top five handled exceptions appear in their stack trace thread, and links them to relevant details. Each row helps you find answers to questions such as: How many of this exception occurred within the selected time period? Does a specific app version have a higher (or lower) number of users affected? Which exception has the fewest number of occurrences? You can change the sort order or filter options to focus on just the types of exceptions that matter the most to you and your teams. To view additional thread details for each occurrence of the exception, select a record from the Top 5 exceptions location table. Exception locations table example one.newrelic.com > Mobile > (select an app) > Exceptions > Handled exceptions: To continue to the handled exception's Occurrences page, select any row on the table.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 167.32607,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "sections": "Handled exceptions: Analyze trends, prevent <em>crashes</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " exceptions workflow To get the most out of the Handled exceptions <em>UI</em>, use this basic workflow: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; Exceptions &gt; Handled exceptions. Use any of New Relic&#x27;s standard page functions to drill down into detailed information; for example, zoom into any area"
      },
      "id": "604505ae28ccbc783e2c6085"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/alerts-page-mobile-apps": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.76431,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/devices-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/interactions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index": [
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-10-24T20:57:09Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70612,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-monitoring-email-notifications": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "Version trends: Compare user adoption metrics and performance",
        "Requirements",
        "View version trend data in UI",
        "View version trend details",
        "Performance across releases",
        "Critical user adoption metrics",
        "Key technical indicators",
        "Interpret version trend data (examples)",
        "Query version trend data"
      ],
      "title": "Version trends: Compare user adoption metrics and performance",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile App pages"
      ],
      "external_id": "6fd958a0aa5eec172bddf32f30411f0caab44504",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-08-02T12:36:43Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your mobile app. This helps mobile app development managers and their teams to compare up to five production versions from a single page and to analyze the impact of improvements, fixes, and degradations for each. You can view version trend data in the mobile monitoring UI. You can also enable email notifications. Requirements If you see this message in the Version trends UI: \"No adoption data is available for this version because it is running an older agent,\" this indicates the mobile app wasn't using the New Relic mobile agent version that collects install/upgrade count data. To collect version trend information for your mobile app, make sure your agent version is: New Relic mobile agent for Android version 5.3.3 or higher New Relic mobile agent for iOS version 5.3.4 or higher View version trend data in UI To view the Version trends report: Go to one.newrelic.com > Mobile > (select an app) > App > Version trends. Select the Launch time period to compare versions by day (default), week, or month, or view all available data. Review the version trend details to analyze performance, user adoption, and key technical indicators. For additional suggestions about how to interpret the data, review the examples. Optional: To configure email settings, see Email reports. View version trend details Each version includes several metrics to analyze performance, user adoption, and key technical indicators. Performance across releases An important feature is comparison of app performance across releases, based on data collected when each version was at its peak of popularity. You can select four different views of data for when each version was in production, including: Launch day (default) Launch week Launch month All available data for the version This quickly helps you see whether the adoption and performance characteristics of an app's version are better or worse than others. Summary mobile app information for each release includes: Versions: Versions of your app release, sorted by date of highest popularity Sessions: Count of mobile app sessions showing usage of each release Critical user adoption metrics You can compare different versions to see how successfully they have been adopted by users. Total users: Count of unique users (devices) active Upgrades: Count of unique users (devices) active that were upgrades from a previous app version New installs: Count of unique users (devices) active who performed a new install of this app Upgrades and new installs combine to reveal adoption in the form of total unique installs. Key technical indicators Key technical performance indicators include stability, network health, other app or server problems, and memory usage: To track stability, the UI shows the Crash rate as the percentage of all app sessions that crashed. To understand whether networking problems are originating from the app, network, or server, the UI shows the percentage of server responses that returned an HTTP error code (HTTP errors) and the percentage of network calls that failed to receive a response (Network failure). To identify other problems from the app or server, the UI shows the average number of network requests made per app session (Requests per session) and the average server Response time as seen from the app’s perspective. To compare improvements or problems with Memory usage, the first four versions include metrics indicating better (green) or worse (red) performance than the previous version's. Interpret version trend data (examples) Here are some examples of how to interpret some of the data that appears. Example Comments Improvements A new release with faster response time than previous releases may indicate that development efforts were successful. Problems A new release with a spike in crashes, as compared to the previous releases, may indicate that a change introduced in the library or framework is not handling the new scenario or code path properly. User adoption A new release with low numbers of upgrades or new installs may indicate slow adoption of the newest version. This in turn may help justify a new or changed focus in marketing the new release. Release maintenance An older release with continued higher numbers of total users also may indicate slow adoption of the newest version. This in turn may result in unanticipated costs for continued support, or delays in deprecating the old version and its back-end APIs. Query version trend data When querying with NRQL, we provide two attributes to help analyze version trend information: To track when a session includes a new install or a new upgrade, use install. This attribute records true for new installations. To track the last version of the mobile app when an upgrade is detected, use upgradeFrom. To use these attributes, make sure your version of our Android agent or iOS agent supports them.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 189.7643,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "sections": "View version trend data in <em>UI</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> provides a Version trends report with metrics to compare usage, adoption, and performance across the most recent versions of your <em>mobile</em> <em>app</em>. This helps <em>mobile</em> <em>app</em> development managers and their teams to compare up to five production versions from a single <em>page</em> and to analyze"
      },
      "id": "6044165a196a677c89960f30"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-10-24T20:57:09Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.7061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/version-trends-compare-user-adoption-metrics-performance": [
    {
      "sections": [
        "Mobile apps index",
        "View your list of mobile apps",
        "Standard menu functions"
      ],
      "title": "Mobile apps index",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "38ff00ca55b0ca25a0ad534b57e02b01f4040c97",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-index/",
      "published_at": "2021-10-24T16:22:21Z",
      "updated_at": "2021-08-27T07:51:35Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring UI includes a mobile app index that shows a list of your monitored apps and important summary information about them. View your list of mobile apps To see the mobile apps index, go to [one.newrelic.com > Explorer > Mobile applications. Use the Explorer to access all your entities, that is, anything we can identify that reports data, from applications and hosts to custom groupings of any elements. Alternatively, go to one.newrelic.com > Mobile. The index of available mobile apps includes a colored health status indicating: Green = Normal Yellow = Warning Red = Critical Gray = Not reporting data Standard menu functions To view details for a specific app, select it from the index. Here are some other functions available from the index: If you want to... Do this... View the app's status Mouse over the mobile app's colored health status indicator. If the health status indicator is gray and no data is being reported, you likely need to finish installing mobile monitoring. Monitor another app Select Add more. See the app's metadata To see the app's metadata, including its app ID, entity GUID, and more, click the icon next to the application name. For more about UI functions, see Basic UI functions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 196.91562,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> index",
        "sections": "<em>Mobile</em> <em>apps</em> index",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " status indicator is gray and no data is being reported, you likely need to finish installing <em>mobile</em> <em>monitoring</em>. <em>Monitor</em> another <em>app</em> Select Add more. See the <em>app</em>&#x27;s metadata To see the <em>app</em>&#x27;s metadata, including its <em>app</em> ID, entity GUID, and more, click the icon next to the application name. For more about <em>UI</em> functions, see Basic <em>UI</em> functions."
      },
      "id": "604537fc64441f7903378f35"
    },
    {
      "sections": [
        "OS versions page",
        "Viewing the OS versions page",
        "Viewing drill-down details"
      ],
      "title": "OS versions page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "370b6f1584d001a17f414066097692b9189e1a50",
      "image": "https://docs.newrelic.com/static/8d84abf966c2f4b75ca298b362995c0e/c1b63/os-version-pic_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/os-versions-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-07-09T11:46:41Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The OS versions page for mobile monitoring provides performance details about the top operating system versions hosting your mobile application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill down into details by a major or minor OS version (for example, iOS 8, iOS 7.1.1, Android 4.2.2). Viewing the OS versions page one.newrelic.com > Mobile > (select an app) > App > OS versions: Use this page to view, sort, or drill down into detailed information about the top five types of operation system versions using your mobile app. To view performance details about the operating system versions for your mobile app users: Go to one.newrelic.com > Mobile > (select an app) > App > OS versions. To select the mobile app versions or time period, use the Versions menu and time picker below the UI menu bar. Optional: Select the Sort by and Hide < 1% throughput options. To expand or collapse the list of operating systems to include versions, select the operating system's name (for example, iOS 7). Viewing drill-down details To drill down into detailed information, use any of our standard user interface functions and page functions to drill down into detailed information. In addition: To view details for the minor and point releases of a major OS version (including interaction time, HTTP request times, network failures, active devices, and slowest traces or all subversions), select a major OS version from the list. To view details for a specific OS version, select its name from the expanded OS list. To view trace details a slow transaction (if available), select its link. For more information, see Interactions page. To return to the main OS versions page, select the Close (X) button.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.70619,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "OS versions <em>page</em>",
        "sections": "OS versions <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The OS versions <em>page</em> for <em>mobile</em> <em>monitoring</em> provides performance details about the top operating system versions hosting your <em>mobile</em> application, such as iOS and Android. Charts compare the OS versions by: HTTP request time Network failures Requests per minute Active devices From here you can drill"
      },
      "id": "603eaee9e7b9d260112a0809"
    },
    {
      "sections": [
        "Mobile apps Overview page",
        "Key app metrics",
        "View the Overview page",
        "View drill-down details"
      ],
      "title": "Mobile apps Overview page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Mobile app pages"
      ],
      "external_id": "cd97681b7f6391d971176efba71c85e0fdc76680",
      "image": "https://docs.newrelic.com/static/815e271adddca68b8f3e3810b09f8045/c1b63/new-mobile-apps-overview.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/mobile-app-pages/mobile-apps-overview-page/",
      "published_at": "2021-10-24T20:57:09Z",
      "updated_at": "2021-07-09T11:45:50Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Overview page provides an operational snapshot of your mobile app. All charts, tables, and statistics show data for the currently selected time window and application version. Key app metrics The Overview page captures five key app metrics: Metric Description Application crash rate Plots the number of crashed sessions over time as a percentage of all sessions, broken out by app version. The average crashed session percent, total number of crashes, and count of unique users affected by those crashes during the time window is shown in the upper right. App launches Charts the number of app session launches monitored over the time window. New Relic defines a mobile session as beginning when an app appears on screen and ending when the app is sent to the background. HTTP errors / network failures Charts the number of network requests that result in a http status code error (400 or higher) as a percentage of all completed requests, and the number of failed network calls (for example, a connection failure) as a percentage of completed requests. HTTP response time Charts the average response time of all completed http requests from each of the top five hosts your app communicates with. Top five is calculated based on count of completed requests to each host. Frequent interactions Presents key performance metrics for each of the five most commonly executed Interactions in your app. View the Overview page To view the Overview page for your mobile apps: Go to one.newrelic.com > Mobile > (select an app). To view other pages for your mobile app, select the links from the Overview page or from the Mobile menus. one.newrelic.com > Mobile > (select an app): The Overview page provides charts and tables that you can drill down into, to gain insights about your mobile application's performance. View drill-down details Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. The Overview page includes several additional options. If you want to... Do this Limit information to a specific version of your app Select your choice from the Versions menu below the New Relic menu bar (if applicable). View the Overview page for another mobile app Use the dropdown menu from the currently selected mobile app's title OR: Go to one.newrelic.com > Mobile > Select and App. View additional details about interactions Select the Frequent interactions table's title OR select a named Interaction in the table to drill into that interaction directly. View additional details about mobile app crashes Select the Crash rate chart's title to go to the Crash list page. View additional details about mobile versions Select the App launches chart's title to go to the Versions page. View additional details about HTTP response time Select a point anywhere in the HTTP response time chart to go to the HTTP requests page. View additional details about HTTP errors or network failures Select the HTTP errors/network failure chart's title, OR click anywhere in the table to go to the Errors page.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 185.7061,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "sections": "<em>Mobile</em> <em>apps</em> Overview <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " &gt; <em>Mobile</em> &gt; (select an <em>app</em>). To view other <em>pages</em> for your <em>mobile</em> <em>app</em>, select the links from the Overview <em>page</em> or from the <em>Mobile</em> menus. one.newrelic.com &gt; <em>Mobile</em> &gt; (select an <em>app</em>): The Overview <em>page</em> provides charts and tables that you can drill down into, to gain insights about your <em>mobile</em> application"
      },
      "id": "60450e1728ccbc840c2c60d8"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/analyze-network-requests-using-mobilerequest-event-data": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.64464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/carriers-page": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.64464,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/connection-types-page": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.6446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.6446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-10-24T18:00:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.64458,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page": [
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-10-24T18:00:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.64456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    },
    {
      "sections": [
        "HTTP errors: Network failure analysis",
        "Find and use the HTTP errors page",
        "Group, sort, and filter errors and failures",
        "HTTP error profiles",
        "View more details about a specific error",
        "View and share error data with query builder",
        "View legacy HTTP errors UI page",
        "View the Errors page",
        "Error trace details",
        "View error data in query builder",
        "Unknown errors or URL errors"
      ],
      "title": "HTTP errors: Network failure analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "04631e122b061663c6fd261b605202654aadcf96",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-errors-network-failure-analysis/",
      "published_at": "2021-10-24T18:00:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring's HTTP errors page helps you to better understand HTTP errors and network failures associated with your mobile app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors page to... Manager See a list of errors and failures so you can coordinate mobile app teams with backend teams and share the data they need to fix issues. QA engineer Make sure that a new version of your app does not cause a spike in errors compared to a previous version. DevOps engineer See a list of domains and URLs associated with HTTP errors and network failures, so you can focus on the ones that are causing errors and filter out status codes that are too noisy for your alerts. Mobile developer Find out if there are frontend or backend problems affecting your mobile app (even without an error alert going off) so that you can address them in a new version. Support engineer View the errors and session attributes (geography, connection type, device, app version) associated with an error so that you can help customers with their issues. Find and use the HTTP errors page There are two ways to get to the HTTP errors page: Go to one.newrelic.com > Mobile > (select an app) > Network > Network errors. From a mobile app's Overview page in mobile monitoring, select the HTTP errors/network failures chart title link. From the HTTP errors page, investigate HTTP request and network failures: Use any standard page functions to look for trends in Errors and failures charts. Target specific types of errors and failures by grouping, sorting, and filtering the data. Find anomalies in your request errors with HTTP error profiles. Select an error or failure to view details for it. You can also define NRQL alerts that are focused on error types for your critical services or query your app data. Group, sort, and filter errors and failures If you want to do this... Do this... Change how the page groups and sorts errors and network failures Make selections from the Group by and Sort by dropdowns. By default, the Network errors page is grouped by request domain and sorted by errors and failures. Filter for specific errors and network failures Select an error or failure from the Errors and failures list and/or select multiple filters from the Filter dropdown. See which filters you applied or remove filters The filters you select display next to the filter dropdown. To clear filters, select the X next to the filter you want to clear. Change the time window Select a new time period from the Time picker dropdown. View information for one specific app version Select the version that you want to see charts and lists for in the Versions dropdown. HTTP error profiles Error profiles provide visual details about significant differences in the frequency of different values for HTTP error events. For each attribute, the error profile includes: A pie chart showing how the error's attribute is distributed for values that deviate the most A table comparing the error attribute's distribution to that of other errors This helps you take more of the guesswork out of resolving your mobile application's HTTP errors. You can more easily determine if you safely ignore the error, or if you should attempt to resolve the error with a new deployment, code change, customer communication or other actions. View more details about a specific error To view details about an error or failure, select the Request URL link to be directed to the Error summary page. From the Error summary page, you can view the version information, request attributes, and Response body, as well as get a breakdown of error types for the request URL. View and share error data with query builder To explore the data behind any of the charts or lists on the HTTP errors/requests page: Select for any chart. Select View query and then View in Insights. This will open the query builder. From the query builder, you can add the error data to a dashboard and share it via a permalink. To dig deeper into the error data, query your data for the following events and attributes: MobileRequestError events and attributes MobileRequest events and attributes View legacy HTTP errors UI page Accounts that do not have an Enterprise-level subscription see a different HTTP Errors UI page: The Errors page includes details about HTTP errors (403, 404, 422, 500, 502, etc.) and network failures for your hosts; for example: Secure connection failed Timed out Cannot find host Not connected to Internet Cannot connect to host View the Errors page To view HTTP errors or network failures for your mobile app: Go to one.newrelic.com > Mobile > (select an app) > Network > Errors. To change the view to errors or failures, select the Sort by option. To hide low-usage hosts, select the Hide < 1% throughput option. To limit information to a specific version of your app, or to change the time period, select your choice from the Versions menu or the time picker below the menu bar. To view details for a specific host, HTTP status error, or network failure, select its name. Use any of our standard user interface functions to drill down into detailed information. Error trace details Mobile monitoring will capture the response details from HTTP requests that return a 400 or 500 level status code. In addition, error messages generated from Android apps will include a stack trace. To view details about an error trace on the Errors page, select its request URL link. From here you can: View the response body. Share the error details with others by email. File a ticket about it through a ticketing system integrated with New Relic. Delete or hide the error. The errors chart also appears on the selected mobile app's Overview page. If the chart shows errors, you can select its HTTP errors/network failures title or select anywhere on the Overview page's chart to go directly to this Errors page. View error data in query builder To dig deeper into your request data, use the query builder to query and chart the MobileRequest events and attributes. Unknown errors or URL errors The mobile agents maintain a list of exception types. In some cases, custom exceptions thrown by applications fall outside of this list. When this happens, Unknown may appear in the mobile Errors page. If you find Unknown in your list of errors and need assistance in researching which exception types are being missed, get support at support.newrelic.com.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP errors: <em>Network</em> failure analysis",
        "sections": "View legacy HTTP errors <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em>&#x27;s HTTP errors <em>page</em> helps you to better understand HTTP errors and <em>network</em> failures associated with your <em>mobile</em> app, to connect errors to services that are causing issues, and to share actionable data with your team: Team member View the data on the HTTP errors <em>page</em> to... Manager"
      },
      "id": "603e8eb428ccbcd174eba791"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/mobile-http-error-profiles-find-error-causes": [
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 223.64456,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those <em>network</em> calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    },
    {
      "sections": [
        "Map page for mobile apps (deprecated)",
        "Important",
        "View a map of your mobile app services"
      ],
      "title": "Map page for mobile apps (deprecated)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "a082467948ce481c9ecb544d26a802e8d5f3894b",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/map-page-mobile-apps-deprecated/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-09-14T20:45:23Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Important The mobile Maps UI is deprecated since December 22, 2020. Service maps are available in New Relic One's left navigation for each mobile entity, and they are a better way to visualize and customize representations of your architecture. For more information, see our Explorers Hub post. Maps help you find performance problems for a mobile app or its services. This gives you a clear picture of your app's relationships to other services and the influence of each service on the others. If one service fails, you can see at a glance which other services are affected. View a map of your mobile app services To view your mobile app and its related services as an architectural map, go to one.newrelic.com > Mobile > (select a mobile app) > Monitor > Service map. For more information, see the service maps documentation. If you need to use the deprecated mobile Map page, follow these steps: Go to one.newrelic.com > Mobile > (select an app) > Network > Map. To view HTTP request details for a service, select its name. To view details for an app monitored by APM that is related to the service, select the service's name below the associated hostname. To view throughput details as a chart, select the icon or the cpm bar below the service's name. To view detailed metrics for a service, mouse over the throughput chart. The Map page for mobile monitoring gives an architectural view of your mobile app and the services it uses,",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 194.57806,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "sections": "Map <em>page</em> for <em>mobile</em> apps (deprecated)",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " <em>mobile</em> app services To view your <em>mobile</em> app and its related services as an architectural map, go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select a <em>mobile</em> app) &gt; <em>Monitor</em> &gt; Service map. For more information, see the service maps documentation. If you need to use the deprecated <em>mobile</em> Map <em>page</em>, follow these steps"
      },
      "id": "6044141828ccbc0f862c60ae"
    },
    {
      "sections": [
        "Geography page for mobile apps",
        "Tip",
        "Viewing the Geography page",
        "Viewing drill-down details"
      ],
      "title": "Geography page for mobile apps",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "ec64765f7b48034c3c6e666cd8f553b28be7ca06",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/geography-page-mobile-apps/",
      "published_at": "2021-10-24T16:02:14Z",
      "updated_at": "2021-07-09T12:27:22Z",
      "document_type": "page",
      "popularity": 1,
      "body": "The Geography page shows your mobile users' experience as a world view, including: Color-coded response times Network requests (calls per minute) Data transfer size Active devices Network failure rates You can also drill down to detailed information about each country. Tip The Geography feature is not the same as the Map feature. The Map page shows an architectural view of the relationship between a mobile app and its related services. Viewing the Geography page To view or sort the mobile response time by country: Go to one.newrelic.com > Mobile > (select an app) > Network > Geography. To change the information that appears (including response time, requests per minute, total transfer size, active devices, or network failure rate), select your choice from the Sort by menu. To adjust the amount of information that appears, select Hide < 1% throughput. To view summary information about a location, mouse over any area in color on the map, or mouse over the country's name on the list. Use any of our standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details To view detailed information about a specific location (including average response time, calls per minute, active devices, and network failure by type), select its location on the Geography page's map, or select its name on the list.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 174.6918,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Geography <em>page</em> for <em>mobile</em> apps",
        "sections": "Geography <em>page</em> for <em>mobile</em> apps",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "The Geography <em>page</em> shows your <em>mobile</em> users&#x27; experience as a world view, including: Color-coded response times <em>Network</em> requests (calls per minute) Data transfer size Active devices <em>Network</em> failure rates You can also drill down to detailed information about each country. Tip The Geography feature"
      },
      "id": "6044165a196a67660d960f44"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/usage-pages/monthly-uniques-report": [
    {
      "sections": [
        "Versions analysis",
        "Versions analysis details",
        "Viewing drill-down details",
        "How version numbers are obtained",
        "Android",
        "iOS"
      ],
      "title": "Versions analysis",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Usage pages"
      ],
      "external_id": "3906aba3231864c2adb43694636f085ae5332d0e",
      "image": "https://docs.newrelic.com/static/f359bb98f6fbf2a5c90dd604778a5dcd/c1b63/screen-versions_0.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/usage-pages/versions-analysis/",
      "published_at": "2021-10-24T18:01:48Z",
      "updated_at": "2021-07-09T12:29:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring includes a comparative analysis of adoption and performance between versions of your application, including top versions by: Interaction time Active sessions Error rate The Versions page also includes a table comparing each version by date created, average memory, average CPU, average sessions per minute, and average requests per minute (RPM) per active app. You can also drill down into additional details about a specific version. Versions analysis details one.newrelic.com > Mobile > (select an app) > Usage > Versions: The Versions analysis includes color-coded charts of mobile app usage, plus a table that summarizes mobile app versions and their averages for memory, CPU, active users, and network RPM (requests per minute). The Versions page provides a list of all versions of your app that have been detected, plus overview information on all versions active in the last seven days. To view the comparative analysis: Go to one.newrelic.com > Mobile > (select an app) > Usage > Versions. To select the time period, use the time picker below the New Relic menu bar. Optional: Select the Sort by options. To view details only for a specific version, select its name. The Versions page provides a list of all versions of your app that have been active in the selected time window. Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. Viewing drill-down details one.newrelic.com > Mobile > (select an app) > Usage > Versions > (selected version): Here is an example of details for a selected version. The details page provides further insight into how the selected version compares to a reference version (a recent or popular version), and the average of other versions of your app. Time series show the comparison across error rate, response time, active sessions, and memory usage. To exit the details page, select the Close (X) button. How version numbers are obtained The way that mobile monitoring obtains the version number varies by platform: Android The Android agent obtains the version information from the android:versionName property in the manifest. iOS The iOS agent uses both CFBundleShortVersionString and CFBundleVersion properties to obtain the app version. The agent accesses those properties through iOS APIs. It does not obtain them by reading the info.plist file.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.9599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": " the comparison across error rate, response time, active sessions, and memory <em>usage</em>. To exit the details <em>page</em>, select the Close (X) button. How version numbers are obtained The way that <em>mobile</em> <em>monitoring</em> obtains the version number varies by platform: Android The Android agent obtains the version information"
      },
      "id": "603eaeeae7b9d262be2a080c"
    },
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.33493,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". As part of the installation process, <em>mobile</em> <em>monitoring</em> automatically generates an application token. This is a 40-character hexadecimal string for authenticating each <em>mobile</em> app that you <em>monitor</em>. Follow the Android installation and configuration procedures for your environment as applicable. If you have"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.91357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    }
  ],
  "/docs/mobile-monitoring/mobile-monitoring-ui/usage-pages/versions-analysis": [
    {
      "sections": [
        "Monthly uniques report",
        "Monthly uniques report details",
        "Device tracking"
      ],
      "title": "Monthly uniques report",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Usage pages"
      ],
      "external_id": "8865375eef0e6bab4c0b40fa9edde33da93a752c",
      "image": "https://docs.newrelic.com/static/14ffff087d1c8f0d7c26b59739057f07/c1b63/screen-mobile-monthly-uniques.png",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/usage-pages/monthly-uniques-report/",
      "published_at": "2021-10-24T18:00:58Z",
      "updated_at": "2021-07-09T12:29:03Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring includes a monthly report with a bar chart tracking the number of devices running your app for each month over the last year. To view the report: Go to one.newrelic.com > Mobile > (select an app) > Usage > Monthly uniques. Monthly uniques report details To see the total number of unique devices for any month, mouse over the month's bar in the chart. The current month's device count is a month-to-date value and does not indicate the full month's usage. one.newrelic.com > Mobile > (select an app) > Usage > Monthly uniques: This report provides a bar chart tracking the number of devices running your app for each month over the last year. Use any of New Relic's standard user interface functions and page functions to drill down into detailed information. Unique users are used to calculate your monthly usage, which is used to calculate your subscription level. Device tracking Mobile monitoring does not use hardware identifiers for unique install tracking. On iOS we use the IdentifierForVendor property. (Versions 5.3.4 and lower used the SecureUDID library.) On Android we generate a unique GUID when the application is installed.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 183.9599,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> includes a monthly report with a bar chart tracking the number of devices running your app for each month over the last year. To view the report: Go to one.newrelic.com &gt; <em>Mobile</em> &gt; (select an app) &gt; <em>Usage</em> &gt; Monthly uniques. Monthly uniques report details To see the total number"
      },
      "id": "6044141964441f5cb1378f32"
    },
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 161.33487,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": ". As part of the installation process, <em>mobile</em> <em>monitoring</em> automatically generates an application token. This is a 40-character hexadecimal string for authenticating each <em>mobile</em> app that you <em>monitor</em>. Follow the Android installation and configuration procedures for your environment as applicable. If you have"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "HTTP requests page",
        "Find and use HTTP requests page",
        "Understand HTTP request data",
        "Response time chart",
        "HTTP errors and network failures chart",
        "Total requests",
        "Group, sort, and filter HTTP requests",
        "View and share HTTP request data",
        "View legacy HTTP requests UI page",
        "View legacy HTTP requests UI",
        "View legacy drill-down details",
        "View legacy request data"
      ],
      "title": "HTTP requests page",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "Mobile monitoring UI",
        "Network pages"
      ],
      "external_id": "56c27e3a1cad7439b752d38b4d00a60ab98f0e10",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/mobile-monitoring-ui/network-pages/http-requests-page/",
      "published_at": "2021-10-24T16:30:00Z",
      "updated_at": "2021-10-07T20:06:36Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring has an HTTP requests UI page that helps you better understand HTTP requests associated with your mobile app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests page. Non-Enterprise accounts will see the legacy HTTP requests page. Find and use HTTP requests page To view mobile monitoring's HTTP requests page: Go to one.newrelic.com > Mobile > (select an app) > Network > HTTP requests. Use our standard page functions to look for trends in the HTTP analysis charts. Target specific request and response attributes by grouping, sorting, and filtering the data. Understand HTTP request data Here are some places to find the most important HTTP request information: Response time chart The response time chart shows how your app's network calls are performing across percentiles. Use it to compare the average response time to the 1st, 50th, and 99th percentile. Percentiles let you filter out outliers that may be making your average response time higher than expected. HTTP errors and network failures chart This chart shows the unsuccessful network calls your app is experiencing. Select the chart title to go to the HTTP errors page for more detail on the errors and failures. Total requests Sort by Total requests to identify which network requests are being used most frequently. The reason this can be helpful is because your slowest network calls may be only infrequently used, while more frequently used requests might be more worthy of optimization even if they are not the slowest. For a description of the non-Enterprise HTTP requests UI page, see Legacy HTTP requests. Group, sort, and filter HTTP requests If you want to... Do this... Group and sort HTTP requests in different ways Make selections from the Group by and Sort by dropdowns. By default, the HTTP requests page is grouped by request domain and sorted by average response time. Filter for specific HTTP requests Select an HTTP request from the Errors and failures list and/or select multiple filters from the Filter dropdown. See or remove applied filters The filters you select are displayed next to the filter dropdown. To clear filters, select the X icon on the filter you want to clear. Change the time window Select a new time period from the time picker dropdown. View information for a specific app version Using the Versions dropdown, select the version for which you want to see charts and lists. View and share HTTP request data To view any HTTP requests chart in Insights: Select for any chart. Select View query > View in Insights. Optional: Add the data to a dashboard, or share it by using a permalink. To delve deeper into your request data, query MobileRequest events and attributes. View legacy HTTP requests UI page Accounts that do not have an Enterprise-level subscription see a different HTTP requests UI page: View legacy HTTP requests UI To view your top five domains or drill down into details about specific HTTP requests: Go to one.newrelic.com > (select an app) > Network > HTTP requests. Optional: Select the Sort by and Hide < 1% throughput options. To view or hide all requests made by your app, select Expand all or Collapse all. To view details for a specific host or HTTP request (including request time, average throughput, and data transfer), select its name. View legacy drill-down details Use any of New Relic's standard page functions to drill down into detailed information. In addition, from the HTTP requests page, you can drill down into detailed information about specific requests, including: Top five HTTP request times Average throughput Average data transfer To view legacy details: one.newrelic.com > Mobile > (select an app) > Network > HTTP requests > (select a request): > Switch to legacy requests. If you want to... Do this View information to a specific version of your app Select Versions from the side bar (if applicable). Change the time period Use the time picker below the New Relic menu bar. View legacy request data You can dig deeper into your request data by querying and charting the MobileRequest event.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 153.91356,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "HTTP requests <em>page</em>",
        "sections": "View legacy HTTP requests <em>UI</em> <em>page</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em> <em>UI</em>",
        "body": "<em>Mobile</em> <em>monitoring</em> has an HTTP requests <em>UI</em> <em>page</em> that helps you better understand HTTP requests associated with your <em>mobile</em> app and how those network calls are affecting performance. This document describes the Enterprise-level HTTP requests <em>page</em>. Non-Enterprise accounts will see the legacy HTTP"
      },
      "id": "60450de028ccbc42662c6083"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/get-started/introduction-mobile-monitoring": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.37442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Report custom data"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "016a25d46dedc5da1455b29d8557ce68a4345756",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-10-24T19:36:34Z",
      "updated_at": "2021-10-23T17:32:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. To browse our solutions, see New Relic integrations. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.62817,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "There are many ways to <em>get</em> data into your <em>New</em> <em>Relic</em> account. Any <em>New</em> <em>Relic</em> user can use any of our data ingest methods to report data to our platform. <em>New</em> <em>Relic</em>-built agents and integrations When you enable <em>New</em> <em>Relic</em> solutions like APM, browser <em>monitoring</em>, <em>mobile</em> <em>monitoring</em>, infrastructure"
      },
      "id": "6174474328ccbcdff4c6b77e"
    },
    {
      "sections": [
        "CocoaPods installation",
        "Install your iOS application",
        "Configure using Objective-C",
        "Important",
        "Configure using Swift",
        "Change the logging level (optional)"
      ],
      "title": "CocoaPods installation",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Installation"
      ],
      "external_id": "9a062745f628f66e34f865a47d58713f12e59ac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/installation/cocoapods-installation/",
      "published_at": "2021-10-24T16:53:24Z",
      "updated_at": "2021-10-01T20:15:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These procedures apply to iOS apps using Cocoapods. For other types, see iOS installation and configuration. Install your iOS application As part of the installation process, New Relic automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app you monitor in New Relic. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the Mobile Apps list, select Add a new app. From the Get Started page, select iOS as the platform for mobile monitoring. Type a name for your mobile app, then select Continue. If your installation does not automatically include the prefix header, follow the steps to add the prefix header to your project. Continue with the steps to configure New Relic for mobile monitoring. Configure using Objective-C These procedures to configure your iOS app with CocoaPods and Objective-C also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy In your APP_NAME-Prefix.pch project file (generally found in the Supporting Files folder), include the New Relic header inside the #ifdef __OBJC__ #endif block: #import <NewRelic/NewRelic.h> Copy In your AppDelegate.m file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: [NewRelic startWithApplicationToken:@\"APP_TOKEN\"]; Copy Important The agent must be on the first line of didFinishLaunchingWithOptions and run on the main thread to ensure proper instrumentation. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Configure using Swift These procedures to configure your iOS app with CocoaPods and Swift also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy Create a bridging header: Select File > New > File > Objective-C File. Name the file Placeholder.m, then select Next. Select Create, and confirm Xcode's prompt to generate the bridging header. In your APP_NAME-Bridging-Header.h, add the New Relic header: #import \"NewRelic/NewRelic.h\" Copy In your AppDelegate.swift file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: NewRelic.start(withApplicationToken:\"APP_TOKEN\") Copy Important To ensure proper instrumentation, you must call the agent on the first line of didFinishLaunchingWithOptions(), and run the agent on the main thread. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Change the logging level (optional) Six log levels are available for mobile apps monitoring: none error warning info verbose ALL To increase your logging level in the app, add this method call before calling NewRelic.start(withApplicationToken): [NRLogger setLogLevels:NRLogLevelALL]; Copy For Swift apps: NRLogger.setLogLevels(NRLogLevelALL.rawValue) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.59851,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " <em>mobile</em> app you <em>monitor</em> in <em>New</em> <em>Relic</em>. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the <em>Mobile</em> Apps list, select Add a <em>new</em> app. From the <em>Get</em> <em>Started</em> page, select iOS as the platform for <em>mobile</em> <em>monitoring</em>. Type a name for your <em>mobile</em> app, then select Continue"
      },
      "id": "603ea15d64441fef3d4e8867"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/get-started/mobile-monitoring-alert-information": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.37433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Report custom data"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "016a25d46dedc5da1455b29d8557ce68a4345756",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-10-24T19:36:34Z",
      "updated_at": "2021-10-23T17:32:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. To browse our solutions, see New Relic integrations. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.62811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "There are many ways to <em>get</em> data into your <em>New</em> <em>Relic</em> account. Any <em>New</em> <em>Relic</em> user can use any of our data ingest methods to report data to our platform. <em>New</em> <em>Relic</em>-built agents and integrations When you enable <em>New</em> <em>Relic</em> solutions like APM, browser <em>monitoring</em>, <em>mobile</em> <em>monitoring</em>, infrastructure"
      },
      "id": "6174474328ccbcdff4c6b77e"
    },
    {
      "sections": [
        "CocoaPods installation",
        "Install your iOS application",
        "Configure using Objective-C",
        "Important",
        "Configure using Swift",
        "Change the logging level (optional)"
      ],
      "title": "CocoaPods installation",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Installation"
      ],
      "external_id": "9a062745f628f66e34f865a47d58713f12e59ac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/installation/cocoapods-installation/",
      "published_at": "2021-10-24T16:53:24Z",
      "updated_at": "2021-10-01T20:15:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These procedures apply to iOS apps using Cocoapods. For other types, see iOS installation and configuration. Install your iOS application As part of the installation process, New Relic automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app you monitor in New Relic. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the Mobile Apps list, select Add a new app. From the Get Started page, select iOS as the platform for mobile monitoring. Type a name for your mobile app, then select Continue. If your installation does not automatically include the prefix header, follow the steps to add the prefix header to your project. Continue with the steps to configure New Relic for mobile monitoring. Configure using Objective-C These procedures to configure your iOS app with CocoaPods and Objective-C also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy In your APP_NAME-Prefix.pch project file (generally found in the Supporting Files folder), include the New Relic header inside the #ifdef __OBJC__ #endif block: #import <NewRelic/NewRelic.h> Copy In your AppDelegate.m file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: [NewRelic startWithApplicationToken:@\"APP_TOKEN\"]; Copy Important The agent must be on the first line of didFinishLaunchingWithOptions and run on the main thread to ensure proper instrumentation. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Configure using Swift These procedures to configure your iOS app with CocoaPods and Swift also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy Create a bridging header: Select File > New > File > Objective-C File. Name the file Placeholder.m, then select Next. Select Create, and confirm Xcode's prompt to generate the bridging header. In your APP_NAME-Bridging-Header.h, add the New Relic header: #import \"NewRelic/NewRelic.h\" Copy In your AppDelegate.swift file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: NewRelic.start(withApplicationToken:\"APP_TOKEN\") Copy Important To ensure proper instrumentation, you must call the agent on the first line of didFinishLaunchingWithOptions(), and run the agent on the main thread. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Change the logging level (optional) Six log levels are available for mobile apps monitoring: none error warning info verbose ALL To increase your logging level in the app, add this method call before calling NewRelic.start(withApplicationToken): [NRLogger setLogLevels:NRLogLevelALL]; Copy For Swift apps: NRLogger.setLogLevels(NRLogLevelALL.rawValue) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.5985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " <em>mobile</em> app you <em>monitor</em> in <em>New</em> <em>Relic</em>. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the <em>Mobile</em> Apps list, select Add a <em>new</em> app. From the <em>Get</em> <em>Started</em> page, select iOS as the platform for <em>mobile</em> <em>monitoring</em>. Type a name for your <em>mobile</em> app, then select Continue"
      },
      "id": "603ea15d64441fef3d4e8867"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/get-started/security-mobile-apps": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 195.37433,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Get data into New Relic",
        "New Relic-built agents and integrations",
        "Report custom data"
      ],
      "title": "Get data into New Relic",
      "type": "docs",
      "tags": [
        "Ingest and manage data",
        "Get started"
      ],
      "external_id": "016a25d46dedc5da1455b29d8557ce68a4345756",
      "image": "",
      "url": "https://docs.newrelic.com/docs/data-apis/get-started/introduction-new-relic-data-ingest-apis-sdks/",
      "published_at": "2021-10-24T19:36:34Z",
      "updated_at": "2021-10-23T17:32:51Z",
      "document_type": "page",
      "popularity": 1,
      "body": "There are many ways to get data into your New Relic account. Any New Relic user can use any of our data ingest methods to report data to our platform. New Relic-built agents and integrations When you enable New Relic solutions like APM, browser monitoring, mobile monitoring, infrastructure monitoring, or any of our wide array of integrations, by default you'll receive data from your monitored applications, hosts, services, or other entities. Some options for getting started: Log into one.newrelic.com and click Add more data to get some guidance on setting up New Relic solutions. To browse our solutions, see New Relic integrations. Report custom data If you need to report data that our agents and integrations don't provide, we have tools that will allow you to bring in any type of data you need. To learn more, see Intro to custom data.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 132.62811,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "sections": "<em>Get</em> data into <em>New</em> <em>Relic</em>",
        "tags": "<em>Get</em> <em>started</em>",
        "body": "There are many ways to <em>get</em> data into your <em>New</em> <em>Relic</em> account. Any <em>New</em> <em>Relic</em> user can use any of our data ingest methods to report data to our platform. <em>New</em> <em>Relic</em>-built agents and integrations When you enable <em>New</em> <em>Relic</em> solutions like APM, browser <em>monitoring</em>, <em>mobile</em> <em>monitoring</em>, infrastructure"
      },
      "id": "6174474328ccbcdff4c6b77e"
    },
    {
      "sections": [
        "CocoaPods installation",
        "Install your iOS application",
        "Configure using Objective-C",
        "Important",
        "Configure using Swift",
        "Change the logging level (optional)"
      ],
      "title": "CocoaPods installation",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile iOS",
        "Installation"
      ],
      "external_id": "9a062745f628f66e34f865a47d58713f12e59ac9",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-ios/installation/cocoapods-installation/",
      "published_at": "2021-10-24T16:53:24Z",
      "updated_at": "2021-10-01T20:15:52Z",
      "document_type": "page",
      "popularity": 1,
      "body": "These procedures apply to iOS apps using Cocoapods. For other types, see iOS installation and configuration. Install your iOS application As part of the installation process, New Relic automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app you monitor in New Relic. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the Mobile Apps list, select Add a new app. From the Get Started page, select iOS as the platform for mobile monitoring. Type a name for your mobile app, then select Continue. If your installation does not automatically include the prefix header, follow the steps to add the prefix header to your project. Continue with the steps to configure New Relic for mobile monitoring. Configure using Objective-C These procedures to configure your iOS app with CocoaPods and Objective-C also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy In your APP_NAME-Prefix.pch project file (generally found in the Supporting Files folder), include the New Relic header inside the #ifdef __OBJC__ #endif block: #import <NewRelic/NewRelic.h> Copy In your AppDelegate.m file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: [NewRelic startWithApplicationToken:@\"APP_TOKEN\"]; Copy Important The agent must be on the first line of didFinishLaunchingWithOptions and run on the main thread to ensure proper instrumentation. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Configure using Swift These procedures to configure your iOS app with CocoaPods and Swift also appear on the Get Started page in New Relic. In the Podfile for your project, add the following line: pod 'NewRelicAgent' Copy Close your project in Xcode, and update it by running this command from the Terminal in your project directory: pod install Copy Open your project in Xcode by running this command from the Terminal in your project directory: open App.xcworkspace Copy Create a bridging header: Select File > New > File > Objective-C File. Name the file Placeholder.m, then select Next. Select Create, and confirm Xcode's prompt to generate the bridging header. In your APP_NAME-Bridging-Header.h, add the New Relic header: #import \"NewRelic/NewRelic.h\" Copy In your AppDelegate.swift file, add this call as the first line of application:didFinishLaunchingWithOptions, replacing APP_TOKEN with your application token: NewRelic.start(withApplicationToken:\"APP_TOKEN\") Copy Important To ensure proper instrumentation, you must call the agent on the first line of didFinishLaunchingWithOptions(), and run the agent on the main thread. Starting the call later, on a background thread, or asynchronously can cause unexpected or unstable behavior. Add a build script to your target's Build Phases. Ensure the new build script is the very last build script. Then paste the following, replacing APP_TOKEN with your application token: SCRIPT=`/usr/bin/find \"${SRCROOT}\" -name newrelic_postbuild.sh | head -n 1` /bin/sh \"${SCRIPT}\" \"APP_TOKEN\" Copy Clean and build your app, then run it in the simulator or other device. Change the logging level (optional) Six log levels are available for mobile apps monitoring: none error warning info verbose ALL To increase your logging level in the app, add this method call before calling NewRelic.start(withApplicationToken): [NRLogger setLogLevels:NRLogLevelALL]; Copy For Swift apps: NRLogger.setLogLevels(NRLogLevelALL.rawValue) Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 128.5985,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " <em>mobile</em> app you <em>monitor</em> in <em>New</em> <em>Relic</em>. To install and configure your iOS application: Go to one.newrelic.com. If applicable: From the <em>Mobile</em> Apps list, select Add a <em>new</em> app. From the <em>Get</em> <em>Started</em> page, select iOS as the platform for <em>mobile</em> <em>monitoring</em>. Type a name for your <em>mobile</em> app, then select Continue"
      },
      "id": "603ea15d64441fef3d4e8867"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/maintenance/add-custom-data-new-relic-mobile": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.25652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Customize mobile app settings",
        "Important",
        "Change name of monitored app",
        "Caution",
        "Agent configuration"
      ],
      "title": "Customize mobile app settings",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "8719a1897be60f1d77831f1df82c464884cafadc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/customizing-your-mobile-app-settings/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-03-16T09:42:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic mobile monitoring UI, under Settings, there are options for changing your New Relic-monitored mobile app, editing alert conditions, and editing other settings. To get to mobile monitoring settings: Go to one.newrelic.com, click Mobile, and select a monitored app. Look at the UI pages under the Settings heading. Important Access to this feature depends on user permissions. Available settings include: If you want to... Select this Change your mobile app's name Application Change the Caution and Critical alert conditions for HTTP status code error rates, network failure error rates, or response time Alert conditions Turn on or turn off alert notifications for your mobile app Alert conditions Install our mobile monitoring Installation Upgrade our Mobile SDK in your mobile app Upgrade View your mobile app's authentication token Application or Installation Change another mobile app's settings Select your choice from the dropdown next to the currently selected mobile app's name Change name of monitored app You can change your app's name in the UI anytime, and our mobile monitoring will continue to collect, aggregate, and report data to your app based on the underlying application token used when configuring your mobile app. This means you don't need to change any code in your application. Caution Data reported from your mobile app is tied to a named app based on the application token. All apps with a single application token will report into the same app in our mobile monitoring UI, regardless of the app's name when installed on a mobile device. To rename your mobile app: Go to one.newrelic.com, click Mobile, and select a monitored app. Select Application. Type a new name and select Save settings. Agent configuration You can also configure the agent via API calls: Add custom data to mobile monitoring Android configuration and feature flags iOS configuration and feature flags",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.66563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Customize <em>mobile</em> app settings",
        "sections": "Customize <em>mobile</em> app settings",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "In the <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em> UI, under Settings, there are options for changing your <em>New</em> <em>Relic</em>-monitored <em>mobile</em> app, editing alert conditions, and editing other settings. To get to <em>mobile</em> <em>monitoring</em> settings: Go to one.newrelic.com, click <em>Mobile</em>, and select a monitored app. Look at the UI"
      },
      "id": "603ebe82196a67b7eca83d94"
    },
    {
      "sections": [
        "Application token for New Relic mobile monitoring",
        "Tip"
      ],
      "title": "Application token for New Relic mobile monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "4321d8be4040736dd9ca00e165cf6e0df8d2db5c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/viewing-your-application-token/",
      "published_at": "2021-10-24T16:23:00Z",
      "updated_at": "2021-03-16T09:42:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring automatically assigns a unique, 40-character hexadecimal string to each mobile app you monitor, for both the US and EU datacenter. This application token is similar to a New Relic license key and is required to authenticate your app's data. To view your application token: Go to one.newrelic.com, click Mobile, and select a monitored app. Select Application or Installation. Tip Data reported from your mobile app is tied to a named app based on the application token. All apps with a single application token will report to the same place in our mobile monitoring UI, regardless of the app's name when installed on a mobile device. We recommend using a different application token for each platform to separate iOS and Android versions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.23808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Application token for <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em>",
        "sections": "Application token for <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>mobile</em> <em>monitoring</em> automatically assigns a unique, 40-character hexadecimal string to each <em>mobile</em> app you <em>monitor</em>, for both the US and EU datacenter. This application token is similar to a <em>New</em> <em>Relic</em> license key and is required to authenticate your app&#x27;s data. To view your application"
      },
      "id": "603ebe1964441fd8864e88aa"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/maintenance/customizing-your-mobile-app-settings": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.25652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Application token for New Relic mobile monitoring",
        "Tip"
      ],
      "title": "Application token for New Relic mobile monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "4321d8be4040736dd9ca00e165cf6e0df8d2db5c",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/viewing-your-application-token/",
      "published_at": "2021-10-24T16:23:00Z",
      "updated_at": "2021-03-16T09:42:20Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic's mobile monitoring automatically assigns a unique, 40-character hexadecimal string to each mobile app you monitor, for both the US and EU datacenter. This application token is similar to a New Relic license key and is required to authenticate your app's data. To view your application token: Go to one.newrelic.com, click Mobile, and select a monitored app. Select Application or Installation. Tip Data reported from your mobile app is tied to a named app based on the application token. All apps with a single application token will report to the same place in our mobile monitoring UI, regardless of the app's name when installed on a mobile device. We recommend using a different application token for each platform to separate iOS and Android versions.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.23808,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Application token for <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em>",
        "sections": "Application token for <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>New</em> <em>Relic</em>&#x27;s <em>mobile</em> <em>monitoring</em> automatically assigns a unique, 40-character hexadecimal string to each <em>mobile</em> app you <em>monitor</em>, for both the US and EU datacenter. This application token is similar to a <em>New</em> <em>Relic</em> license key and is required to authenticate your app&#x27;s data. To view your application"
      },
      "id": "603ebe1964441fd8864e88aa"
    },
    {
      "sections": [
        "Add custom data to mobile monitoring",
        "Choose a custom data type",
        "Add session-level custom attributes",
        "Record breadcrumbs",
        "Create custom interactions",
        "Record custom events"
      ],
      "title": "Add custom data to mobile monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "81d73d6610c6cc08cc21a5dbbb1ee1e507f6db16",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/add-custom-data-new-relic-mobile/",
      "published_at": "2021-10-24T16:22:22Z",
      "updated_at": "2021-03-11T11:17:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic mobile monitoring includes a number of ways to customize and extend the data your mobile app reports. We refer to this type of implementation as \"custom instrumentation.\" This document explains how to get additional data into New Relic, and how to view that new data in the UI. Choose a custom data type You can use these options to create your own data types for custom instrumentation for your mobile apps. Using these four options, you can get a wide range of data based on your needs for your apps. Custom data options Description Session-level custom attributes In creating your own attributes, consisting of a key-value pair, you can add custom data for use in tracking session data. Custom breadcrumbs Useful for troubleshooting crash causes, custom breadcrumb events track the user's code-level path through the app by seeing which breadcrumb API calls were reached and reporting app status details from those moments. Custom interactions Custom interactions give you tracing power so you can debug method timings and improve network call efficiency. A common use of interactions is to understand the underlying activity associated with loading a particular app screen. Custom events You can instrument custom events to collect data about user activity as a user navigates through your app. That user activity will in turn trigger other data collection: a collection of breadcrumbs, auto-instrumented HTTP requests and errors, auto-instrumented interactions, and custom interactions. Add session-level custom attributes Custom attributes annotate (or \"tag\") your mobile monitoring data. A custom attribute consists of a key-value pair. For example, you might create the key userEmail with values such as alice@bigcorp.test and bob@example.com. The agent automatically attaches custom attributes to default mobile monitoring data, and to any breadcrumbs or custom events you create. You can use custom attributes to capture usage data that's relevant to your business. Common examples include account names or IDs, user emails, and subscription levels. You can then filter and facet in the Crash analysis page and via NRQL query. Setting custom attributes will add the key-value pair information at the session level. All default mobile monitoring events inherit these session-level custom attributes. As a best practice, use custom attributes to track a single value for a key that can be true across a session (for example, a user's subscription level, or whether SAML was used to log in). To track the change of a value over the course of a session, like a change in connection type, you would instead record a breadcrumb and its own custom attributes. To track a series of discrete user actions that occur across the course of a session, use custom events. To add custom attributes, see: Android: Use setAttribute() and incrementAttribute(). iOS: Use setAttribute() and incrementAttribute(). Record breadcrumbs Breadcrumbs track the state of your app as it runs, then report a snapshot of that state if your app crashes. This allows you to debug your mobile app crashes more easily. Custom interactions only inherit custom attributes created at the session level. Breadcrumbs will inherit those same session-level custom attributes, but optionally you can also report additional custom attributes specific to each recordBreadcrumb() API call. You can use breadcrumbs in several ways: You could record a breadcrumb event when your app receives an HTTP response, and also record the values in that response as custom attributes (for example, the response might tell the app what screen to display next or recording unique timestamps for each change in the course of a session). If the app crashes or throws errors, you will be able to see invalid data from the HTTP response. You could track the success of each step of your user login process, with perhaps a status attribute recording a success or failure key for each step. This would let you debug which step is causing issues. Once you have released a version of your app that creates MobileBreadcrumb custom events, you can see them in the crash event trail whenever they appear in the app's code path as part of a crashed session. You can also query them using NRQL and query either all breadcrumbs or just breadcrumbs from crashed sessions. This lets you see the frequency of app paths that include that particular breadcrumb. To add custom breadcrumbs, see: Android: Use recordBreadcrumb(). iOS: Use recordBreadcrumb(). Create custom interactions Our mobile monitoring agent begins instrumenting an interaction when it detects a screen load or partial screen load (such as fragments for Android or view controllers for iOS). New Relic automatically traces slow interactions, providing a complete, in-depth picture of a single slow interaction, including the methods that were called, what network requests were made, and the CPU and memory usage once that interaction started. Our mobile monitoring automatically selects data-rich traces. The specific criteria the agent looks for are interactions whose instrumented methods account for at least 30% of the overall interaction time. In addition to the auto-instrumentation, you can start a custom interaction to force the agent to start recording a trace beginning at that point in your app code and continuing across the subsequent methods and network calls. Custom interaction traces provide deep information. However, they increase the overhead of the agent compared to other custom data collection methods because of the large amount of data collected for the entire duration of an interaction. When associated with a crash, custom interactions show up in the crash event trail. You can also query them with NRQL for flexible analysis. Interactions are powerful for tracing but are less flexible in other ways than other custom data types: While custom breadcrumbs and custom events let you optimize your custom attributes to specific events, interactions can only inherit session-level attributes. You can also manually end a custom interaction. However, ensure that the interaction includes enough method activity to be recorded. If the agent does not detect any traced activity for 0.5 seconds, the agent stops the interaction tracing because it is assumed no interesting data remains. In addition, the agent can only trace one interaction at a time, so if a new interaction is triggered the current trace will automatically be stopped in preference for the new trace. To add custom interaction traces, see: Android: Use startInteraction() and endInteraction(). iOS: Create and complete interactions. You can also configure interaction tracing globally: Android: Disable entirely with withInteractionTracing(), or disable only auto-instrumented traces with withDefaultInteractions(). iOS: Disable entirely with NRFeatureFlag_InteractionTracing(), or disable only auto-instrumented traces with NRFeatureFlag_DefaultInteractions(). Record custom events Custom events are a powerful tool for reporting arbitrary user activity to New Relic. When associated with a crash, custom events show up in the crash event trail. You can also query them with NRQL for flexible analysis. Unlike custom interactions, custom events allow you to add custom attributes to a particular event within the user session. For example, you could record a custom event each time a user taps a button or accesses a certain feature, and then use NRQL to track how often that feature was used. Beyond a simple count, you can FACET on default mobile app attributes such as location, device, or carrier to analyze usage. Adding session-level custom attributes would let you further examine usage based on the criteria important to you, such as user subscription level or other user characteristics. Adding additional attributes for that custom event would allow you to track user behavior more closely: What data did they enter or what option did they select, for example. To add custom events, see: Android: Use recordCustomEvent(). iOS: Use recordCustomEvent().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom data to <em>mobile</em> <em>monitoring</em>",
        "sections": "Add custom data to <em>mobile</em> <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em> includes a number of ways to customize and extend the data your <em>mobile</em> app reports. We refer to this type of implementation as &quot;custom instrumentation.&quot; This document explains how to get additional data into <em>New</em> <em>Relic</em>, and how to view that <em>new</em> data in the UI. Choose"
      },
      "id": "60450e5028ccbc3cfd2c60d2"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile/maintenance/viewing-your-application-token": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 144.25652,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to Android <em>monitoring</em>",
        "sections": "Introduction to Android <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": " on information in <em>New</em> <em>Relic</em> Insights. To access: In <em>mobile</em> <em>monitoring</em>: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "Customize mobile app settings",
        "Important",
        "Change name of monitored app",
        "Caution",
        "Agent configuration"
      ],
      "title": "Customize mobile app settings",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "8719a1897be60f1d77831f1df82c464884cafadc",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/customizing-your-mobile-app-settings/",
      "published_at": "2021-10-24T16:40:55Z",
      "updated_at": "2021-03-16T09:42:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "In the New Relic mobile monitoring UI, under Settings, there are options for changing your New Relic-monitored mobile app, editing alert conditions, and editing other settings. To get to mobile monitoring settings: Go to one.newrelic.com, click Mobile, and select a monitored app. Look at the UI pages under the Settings heading. Important Access to this feature depends on user permissions. Available settings include: If you want to... Select this Change your mobile app's name Application Change the Caution and Critical alert conditions for HTTP status code error rates, network failure error rates, or response time Alert conditions Turn on or turn off alert notifications for your mobile app Alert conditions Install our mobile monitoring Installation Upgrade our Mobile SDK in your mobile app Upgrade View your mobile app's authentication token Application or Installation Change another mobile app's settings Select your choice from the dropdown next to the currently selected mobile app's name Change name of monitored app You can change your app's name in the UI anytime, and our mobile monitoring will continue to collect, aggregate, and report data to your app based on the underlying application token used when configuring your mobile app. This means you don't need to change any code in your application. Caution Data reported from your mobile app is tied to a named app based on the application token. All apps with a single application token will report into the same app in our mobile monitoring UI, regardless of the app's name when installed on a mobile device. To rename your mobile app: Go to one.newrelic.com, click Mobile, and select a monitored app. Select Application. Type a new name and select Save settings. Agent configuration You can also configure the agent via API calls: Add custom data to mobile monitoring Android configuration and feature flags iOS configuration and feature flags",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 136.66563,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Customize <em>mobile</em> app settings",
        "sections": "Customize <em>mobile</em> app settings",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "In the <em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em> UI, under Settings, there are options for changing your <em>New</em> <em>Relic</em>-monitored <em>mobile</em> app, editing alert conditions, and editing other settings. To get to <em>mobile</em> <em>monitoring</em> settings: Go to one.newrelic.com, click <em>Mobile</em>, and select a monitored app. Look at the UI"
      },
      "id": "603ebe82196a67b7eca83d94"
    },
    {
      "sections": [
        "Add custom data to mobile monitoring",
        "Choose a custom data type",
        "Add session-level custom attributes",
        "Record breadcrumbs",
        "Create custom interactions",
        "Record custom events"
      ],
      "title": "Add custom data to mobile monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile",
        "Maintenance"
      ],
      "external_id": "81d73d6610c6cc08cc21a5dbbb1ee1e507f6db16",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile/maintenance/add-custom-data-new-relic-mobile/",
      "published_at": "2021-10-24T16:22:22Z",
      "updated_at": "2021-03-11T11:17:19Z",
      "document_type": "page",
      "popularity": 1,
      "body": "New Relic mobile monitoring includes a number of ways to customize and extend the data your mobile app reports. We refer to this type of implementation as \"custom instrumentation.\" This document explains how to get additional data into New Relic, and how to view that new data in the UI. Choose a custom data type You can use these options to create your own data types for custom instrumentation for your mobile apps. Using these four options, you can get a wide range of data based on your needs for your apps. Custom data options Description Session-level custom attributes In creating your own attributes, consisting of a key-value pair, you can add custom data for use in tracking session data. Custom breadcrumbs Useful for troubleshooting crash causes, custom breadcrumb events track the user's code-level path through the app by seeing which breadcrumb API calls were reached and reporting app status details from those moments. Custom interactions Custom interactions give you tracing power so you can debug method timings and improve network call efficiency. A common use of interactions is to understand the underlying activity associated with loading a particular app screen. Custom events You can instrument custom events to collect data about user activity as a user navigates through your app. That user activity will in turn trigger other data collection: a collection of breadcrumbs, auto-instrumented HTTP requests and errors, auto-instrumented interactions, and custom interactions. Add session-level custom attributes Custom attributes annotate (or \"tag\") your mobile monitoring data. A custom attribute consists of a key-value pair. For example, you might create the key userEmail with values such as alice@bigcorp.test and bob@example.com. The agent automatically attaches custom attributes to default mobile monitoring data, and to any breadcrumbs or custom events you create. You can use custom attributes to capture usage data that's relevant to your business. Common examples include account names or IDs, user emails, and subscription levels. You can then filter and facet in the Crash analysis page and via NRQL query. Setting custom attributes will add the key-value pair information at the session level. All default mobile monitoring events inherit these session-level custom attributes. As a best practice, use custom attributes to track a single value for a key that can be true across a session (for example, a user's subscription level, or whether SAML was used to log in). To track the change of a value over the course of a session, like a change in connection type, you would instead record a breadcrumb and its own custom attributes. To track a series of discrete user actions that occur across the course of a session, use custom events. To add custom attributes, see: Android: Use setAttribute() and incrementAttribute(). iOS: Use setAttribute() and incrementAttribute(). Record breadcrumbs Breadcrumbs track the state of your app as it runs, then report a snapshot of that state if your app crashes. This allows you to debug your mobile app crashes more easily. Custom interactions only inherit custom attributes created at the session level. Breadcrumbs will inherit those same session-level custom attributes, but optionally you can also report additional custom attributes specific to each recordBreadcrumb() API call. You can use breadcrumbs in several ways: You could record a breadcrumb event when your app receives an HTTP response, and also record the values in that response as custom attributes (for example, the response might tell the app what screen to display next or recording unique timestamps for each change in the course of a session). If the app crashes or throws errors, you will be able to see invalid data from the HTTP response. You could track the success of each step of your user login process, with perhaps a status attribute recording a success or failure key for each step. This would let you debug which step is causing issues. Once you have released a version of your app that creates MobileBreadcrumb custom events, you can see them in the crash event trail whenever they appear in the app's code path as part of a crashed session. You can also query them using NRQL and query either all breadcrumbs or just breadcrumbs from crashed sessions. This lets you see the frequency of app paths that include that particular breadcrumb. To add custom breadcrumbs, see: Android: Use recordBreadcrumb(). iOS: Use recordBreadcrumb(). Create custom interactions Our mobile monitoring agent begins instrumenting an interaction when it detects a screen load or partial screen load (such as fragments for Android or view controllers for iOS). New Relic automatically traces slow interactions, providing a complete, in-depth picture of a single slow interaction, including the methods that were called, what network requests were made, and the CPU and memory usage once that interaction started. Our mobile monitoring automatically selects data-rich traces. The specific criteria the agent looks for are interactions whose instrumented methods account for at least 30% of the overall interaction time. In addition to the auto-instrumentation, you can start a custom interaction to force the agent to start recording a trace beginning at that point in your app code and continuing across the subsequent methods and network calls. Custom interaction traces provide deep information. However, they increase the overhead of the agent compared to other custom data collection methods because of the large amount of data collected for the entire duration of an interaction. When associated with a crash, custom interactions show up in the crash event trail. You can also query them with NRQL for flexible analysis. Interactions are powerful for tracing but are less flexible in other ways than other custom data types: While custom breadcrumbs and custom events let you optimize your custom attributes to specific events, interactions can only inherit session-level attributes. You can also manually end a custom interaction. However, ensure that the interaction includes enough method activity to be recorded. If the agent does not detect any traced activity for 0.5 seconds, the agent stops the interaction tracing because it is assumed no interesting data remains. In addition, the agent can only trace one interaction at a time, so if a new interaction is triggered the current trace will automatically be stopped in preference for the new trace. To add custom interaction traces, see: Android: Use startInteraction() and endInteraction(). iOS: Create and complete interactions. You can also configure interaction tracing globally: Android: Disable entirely with withInteractionTracing(), or disable only auto-instrumented traces with withDefaultInteractions(). iOS: Disable entirely with NRFeatureFlag_InteractionTracing(), or disable only auto-instrumented traces with NRFeatureFlag_DefaultInteractions(). Record custom events Custom events are a powerful tool for reporting arbitrary user activity to New Relic. When associated with a crash, custom events show up in the crash event trail. You can also query them with NRQL for flexible analysis. Unlike custom interactions, custom events allow you to add custom attributes to a particular event within the user session. For example, you could record a custom event each time a user taps a button or accesses a certain feature, and then use NRQL to track how often that feature was used. Beyond a simple count, you can FACET on default mobile app attributes such as location, device, or carrier to analyze usage. Adding session-level custom attributes would let you further examine usage based on the criteria important to you, such as user subscription level or other user characteristics. Adding additional attributes for that custom event would allow you to track user behavior more closely: What data did they enter or what option did they select, for example. To add custom events, see: Android: Use recordCustomEvent(). iOS: Use recordCustomEvent().",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 133.11357,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Add custom data to <em>mobile</em> <em>monitoring</em>",
        "sections": "Add custom data to <em>mobile</em> <em>monitoring</em>",
        "tags": "<em>Mobile</em> <em>monitoring</em>",
        "body": "<em>New</em> <em>Relic</em> <em>mobile</em> <em>monitoring</em> includes a number of ways to customize and extend the data your <em>mobile</em> app reports. We refer to this type of implementation as &quot;custom instrumentation.&quot; This document explains how to get additional data into <em>New</em> <em>Relic</em>, and how to view that <em>new</em> data in the UI. Choose"
      },
      "id": "60450e5028ccbc3cfd2c60d2"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/crashnow-android-sdk-api": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/currentsessionid-android-sdk-api": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8283,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74535,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74446,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/end-interaction": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/increment-attribute": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8282,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74533,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/index": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 1310.5994,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> monitoring",
        "sections": "Introduction to <em>Android</em> monitoring",
        "tags": "New Relic Mobile <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "noticeNetworkFailure (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples",
        "Record network failure"
      ],
      "title": "noticeNetworkFailure (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "eee872a3e0e4d6f512b27b29f3dd956aaad80d1a",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/notice-network-failure/",
      "published_at": "2021-10-24T16:36:33Z",
      "updated_at": "2021-07-09T15:31:33Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.noticeNetworkFailure(string $url, string $httpMethod, long $startTime, long $endTime, exception $exception OR enum $networkFailure) Copy Records network failures. Requirements Compatible with all agent versions. Description The New Relic Android SDK API provides several methods to track network requests. If a network request fails, you can record details about the failure with noticeNetworkFailure. In most cases, place this call inside exception handlers, such as catch blocks. For general info on using the New Relic Android SDK API, see the usage guide. Parameters Parameter Description NewRelic.noticeNetworkFailure(string $url, string $httpMethod, long $startTime, long $endTime, exception $exception OR $networkFailure) Copy $url string Required. The URL of the request. $httpMethod string Required. The HTTP method used, such as GET or POST. $startTime long Required. The start time of the request in milliseconds since the epoch. $endTime long Required. The end time of the request in milliseconds since the epoch. $exception string Either this or $failure parameter is required. This is the exception that occurred. New Relic can automatically translate many common exceptions into network failure types. $failure enum Either this or $exception parameter is required. The type of network failure that occurred. If an exception cannot be resolved to a network failure automatically, this method can be used to categorize the failure accurately. The values are defined by the NetworkFailure enum. Valid values include Unknown, BadURL, TimedOut, CannotConnectToHost, DNSLookupFailed, BadServerResponse, and SecureConnectionFailed. Examples Record network failure Here’s an example of an error listener that uses an error as part of the noticed network failure to New Relic: new Response.ErrorListener() { @Override public void onErrorResponse(Error error) { NewRelic.noticeNetworkFailure(badUrl, \"GET\", System.nanoTime(), System.nanoTime(), NetworkFailure.exceptionToNetworkFailure(error)); } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 789.6942,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "noticeNetworkFailure (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "noticeNetworkFailure (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>Android</em> <em>SDK</em> <em>API</em>",
        "body": "Syntax NewRelic.noticeNetworkFailure(string $url, string $httpMethod, long $startTime, long $endTime, exception $exception OR enum $networkFailure) Copy Records network failures. Requirements Compatible with all agent versions. Description The New Relic <em>Android</em> <em>SDK</em> <em>API</em> provides several methods"
      },
      "id": "6044e87d28ccbcb27a2c60d5"
    },
    {
      "sections": [
        "noticeHttpTransaction (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Parameters",
        "Examples",
        "Record HTTP transaction"
      ],
      "title": "noticeHttpTransaction (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "3232e4a19b883d229a9611a2a5cc7b4a002c9f84",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/notice-http-transaction/",
      "published_at": "2021-10-24T16:10:44Z",
      "updated_at": "2021-07-09T15:31:23Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.noticeHttpTransaction(string $url, string $httpMethod, int $statusCode, long $startTime, long $endTime, long $bytesSent, long $bytesReceived [, string $responseBody]) Copy Tracks networks requests. Requirements Compatible with all agent versions. Description The New Relic Android SDK API provides several methods to track network requests and network failures. You can use noticeHttpTransaction to record HTTP transactions, with an option to also send a response body. If a network request fails, you can record details about the failure with noticeNetworkFailure(). For general info on using the New Relic Android SDK API, see the usage guide. Parameters Parameter Description $url string Required. The URL of the request. $httpMethod string Required. The HTTP method used, such as GET or POST. $statusCode int Required. The statusCode of the HTTP response, such as 200 for OK. $startTime int Required. The start time of the request in milliseconds since the epoch. $endTime int Required. The end time of the request in milliseconds since the epoch. $bytesSent int Required. The number of bytes sent in the request. $bytesReceived int Required. The number of bytes received in the response. $responseBody string Optional. The response body of the HTTP response. The response body will be truncated and included in an HTTP Error metric if the HTTP transaction is an error. Examples Record HTTP transaction An example of tracking an HTTP transaction: public class CustomHttpMetricsLogger implements Interceptor { @Override public Response intercept(Chain chain) throws IOException { Request request = chain.request(); //collect request start time long t1 = System.nanoTime(); //get the size of the request body long requestSize = null == request.body() ? 0 : request.body().contentLength(); //proceed with the request Response response = chain.proceed(request); //capture the time when response returns long t2 = System.nanoTime(); long responseSize = null == response.body() ? 0 : response.body().contentLength(); //tell New Relic to notice this request NewRelic.noticeHttpTransaction(request.urlString(), request.method(), response.code(), t1, t2, requestSize, responseSize); //return response for processing return response; } } Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 756.0517,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "noticeHttpTransaction (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "noticeHttpTransaction (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>Android</em> <em>SDK</em> <em>API</em>",
        "body": " info on using the New Relic <em>Android</em> <em>SDK</em> <em>API</em>, see the usage guide. Parameters Parameter Description $url string Required. The URL of the request. $httpMethod string Required. The HTTP method used, such as GET or POST. $statusCode int Required. The statusCode of the HTTP response, such as 200 for OK"
      },
      "id": "6044e8b6e7b9d26e235799e9"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/notice-http-transaction": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82803,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74532,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74445,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/notice-network-failure": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/recordbreadcrumb": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82788,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/recordcustomevent-android-sdk-api": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/recordhandledexception-android-sdk-api": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/recordmetric-android-sdk-api": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82776,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7453,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74442,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/remove-all-attributes": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/remove-attribute": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.8276,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74529,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.7444,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ],
  "/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-attribute": [
    {
      "sections": [
        "Introduction to Android monitoring",
        "Install the Android agent",
        "Extend your instrumentation",
        "See your errors in CodeStream"
      ],
      "title": "Introduction to Android monitoring",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Get started"
      ],
      "external_id": "ae1aceb4e03cd9acadc71fa9fedf674a3f8cc3cb",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/get-started/introduction-new-relic-mobile-android/",
      "published_at": "2021-10-26T01:45:08Z",
      "updated_at": "2021-10-23T01:47:25Z",
      "document_type": "page",
      "popularity": 1,
      "body": "Mobile monitoring for Android monitors your mobile app, giving you a comprehensive view of your app's performance. It works for Android apps written using Java or Kotlin. Install the Android agent Before you install the Android agent, make sure your app follows the compatibility requirements. As part of the installation process, mobile monitoring automatically generates an application token. This is a 40-character hexadecimal string for authenticating each mobile app that you monitor. Follow the Android installation and configuration procedures for your environment as applicable. If you have problems with your Android installation, or if you do not see data in the mobile monitoring UI for your Android app, follow the troubleshooting procedures. Extend your instrumentation After you install the agent, extend the agent's instrumentation by using the mobile monitoring UI and following up on information in New Relic Insights. To access: In mobile monitoring: In NRQL and dashboards: Custom data Create and record custom events, interaction traces, and attributes to add details to your existing data and traces. Then, view the custom events that you created in NRQL or dashboards. Network requests Enable the MobileRequest event feature so you can perform a full network analysis. To further investigate network request error rates and response times, query MobileRequest and MobileRequestError events. Crash analysis Review detailed information using groups and filters to analyze trends that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. Android SDK API Use the Android SDK API for mobile monitoring to instrument parts of your code that are not instrumented by default. Then, view those custom events and attributes in New Relic Insights. Handled exceptions Report exceptions so you can identify factors creating a poor mobile app experience. To further improve performance, review MobileHandledException event records in New Relic Insights. Breadcrumbs Boost the level of detail in crash event trails by adding breadcrumbs. Then, query MobileBreadcrumbs events to see all breadcrumbs or just breadcrumbs related to crashes. See your errors in CodeStream You can also see your Android application's directly in your IDE using CodeStream and errors inbox. To do this, install CodeStream, connect CodeStream and New Relic and create Git tags that match your appVersion.",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 318.82745,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "Introduction to <em>Android</em> <em>monitoring</em>",
        "sections": "Introduction to <em>Android</em> <em>monitoring</em>",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": " that lead to crashes. To view more information about crashes, create NRQL queries to review Insights charts related to crash data. <em>Android</em> <em>SDK</em> <em>API</em> Use the <em>Android</em> <em>SDK</em> <em>API</em> for <em>mobile</em> <em>monitoring</em> to instrument parts of your code that are not instrumented by default. Then, view those custom events"
      },
      "id": "6043a48f196a6784e6960f6d"
    },
    {
      "sections": [
        "setMaxEventPoolSize (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set maximum size of event pool to 1000"
      ],
      "title": "setMaxEventPoolSize (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "16019f6e7ab593733c87c9dc1831ff9ffa11dbb8",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-pool-size/",
      "published_at": "2021-10-24T17:46:32Z",
      "updated_at": "2021-09-27T15:51:59Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, mobile monitoring collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method controls the maximum size of the event pool stored in the memory until the next harvest cycle. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. This method lets you override the maximum size of that event pool. When the pool size limit is reached, the New Relic Android agent will begin sampling events, discarding some old and some new events, until the pool of events are transmitted with the next harvest cycle. The default value for the event harvest cycle is 600 seconds. See also setMaxEventBufferTime(), which lets you change the length of the event harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxSize int Required. Maximum size of event pool. Return values Returns true if it succeeds, or false if it doesn't. Examples Set maximum size of event pool to 1000 boolean poolSizeSet = NewRelic.setMaxEventPoolSize(1000); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74527,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventPoolSize (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventPoolSize(int $maxSize) Copy Sets the maximum size of the event pool. Requirements Agent version 5.0.0 or higher. Description By default, <em>mobile</em> <em>monitoring</em> collects a maximum of 1,000 events per event harvest cycle, which is 600 seconds long by default. This method"
      },
      "id": "603ea0ea28ccbce4f4eba760"
    },
    {
      "sections": [
        "setMaxEventBufferTime (Android SDK API)",
        "Syntax",
        "Requirements",
        "Description",
        "Important",
        "Parameters",
        "Return values",
        "Examples",
        "Set max event buffer time to 300 seconds"
      ],
      "title": "setMaxEventBufferTime (Android SDK API)",
      "type": "docs",
      "tags": [
        "Mobile monitoring",
        "New Relic Mobile Android",
        "Android SDK API"
      ],
      "external_id": "bef23b1df5e20829e7d8fa83463cdba530aefd4f",
      "image": "",
      "url": "https://docs.newrelic.com/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/set-max-event-buffer-time/",
      "published_at": "2021-10-24T16:11:37Z",
      "updated_at": "2021-09-27T15:50:50Z",
      "document_type": "api_doc",
      "popularity": 1,
      "body": "Syntax NewRelic.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the New Relic Android agent will store events in memory before including the buffered event to be sent to New Relic in the next harvest cycle. Default is 600 seconds (10 minutes). Minimum value cannot be less than 60 seconds. Maximum value should not be greater than 600 seconds. In other words, when the oldest event timestamp exceeds this custom configured time, the agent transmits the buffered content at the harvest cycle between each connection from a New Relic agent to the collector. See also setMaxEventPoolSize(), which sets the maximum number of events that are stored by the agent during a harvest cycle. Important Be aware that reporting a large number of events, or reporting events too frequently, may impact app performance. For context on how to use this API, see Send custom attributes and events to Insights. Parameters Parameter Description $maxBufferTimeInSec int Required. The maximum time (in seconds) that the agent should store events in memory. The default value harvest cycle length is 600 seconds. Return values Returns true if it succeeds, or false if it doesn't. Examples Set max event buffer time to 300 seconds boolean fiveMinuteLimitSet = NewRelic.setMaxEventBufferTime(300); Copy",
      "info": "",
      "_index": "520d1d5d14cc8a32e600034b",
      "_type": "520d1d5d14cc8a32e600034c",
      "_score": 184.74438,
      "_version": null,
      "_explanation": null,
      "sort": null,
      "highlight": {
        "title": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "sections": "setMaxEventBufferTime (<em>Android</em> <em>SDK</em> <em>API</em>)",
        "tags": "<em>New</em> <em>Relic</em> <em>Mobile</em> <em>Android</em>",
        "body": "Syntax <em>NewRelic</em>.setMaxEventBufferTime(int $maxBufferTimeInSec) Copy Sets the event harvest cycle length. Requirements Agent version 5.0.0 or higher. Description This method sets the maximum time in seconds that the <em>New</em> <em>Relic</em> <em>Android</em> agent will store events in memory before including the buffered"
      },
      "id": "603ea0af64441ff7fe4e8853"
    }
  ]
}