---
title: 'Synthetics job manager maintenance and monitoring'
tags:
  - Synthetics
  - Synthetic monitoring
  - Private locations
metaDescription: Keep track of your synthetics job manager health and status.
redirects:
---

import imgIntegrationK8S402X from 'images/img-integration-k8.png'

import dockerLogoCrop from 'images/docker-logo-crop.png'

After [installing your synthetics job manager](/docs/synthetics/synthetic-monitoring/private-locations/install-job-manager), you can keep track of its maintenance and monitoring in several ways:

* Check if the synthetics job manager is healthy and working with the [synthetics job manager status endpoint](#sjm-status).
* See if a private location is under-provisioned and [needs more synthetics job managers](#more-jobmanagers).
* Review your [Docker logs](#) or [Kubernetes logs](#).

<Callout variant="tip">
  You can also get notified of monitor failures with [New Relic's alerts](/docs/synthetics/new-relic-synthetics/using-monitors/alerting-synthetics).
</Callout>

## Check CPM status using HTTP [#sjm-status]

Connecting to a running CPM using HTTP is the easiest way to check if it's healthy and working. The container exposes two ports: `8080` and `8180`. You can check the CPM with the following endpoints:

* `:8080/status/check`: provides details about internal health checks that the minion performs. `HTTP 200` means the status is healthy.

## Check if your private location requires more synthetics job managers [#more-jobmanagers]

If your private location has multiple monitor checks queued up and you experience delays, you may need more synthetics job managers available to execute the monitor checks. In Kubernetes, this could be addressed with more ping runtime replicas and higher parallelism settings for API and browser runtimes.

To learn how to verify this, see [Does my private location need more synthetics job managers?](/docs/synthetics/new-relic-synthetics/private-locations/monitor-private-locations#more-minions)

## Review logs [#monitor-docker-logs]

You can monitor your minion's health by looking at synthetics job manager container logs.

<CollapserGroup>
  <Collapser
    id="review-docker-logs"
    title={<><img src={dockerLogoCrop} title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }}/>Review Docker logs</>}
  >
    This is an example of a synthetics job manager log indicating that the synthetics job manager is working properly in a Docker container system environment:
    ****** REPLACE ME *******
    ```
    $docker logs [<var>YOUR_CONTAINER_NAME</var>]
      2018-10-10 11:33:29,856 - Minion ID: <var>a21f6d7f-4f65-4dec-92fb-88cb975d2a19</var>
      2018-10-10 11:33:29,869 - Publishing resources for Private Minion API: /status/check, /build-info, /status
      2018-10-10 11:33:40,527 - Minion is configured, checking if it is healthy...
      2018-10-10 11:33:43,471 - Launching in PRIVATE Location: <var>123456-example_private_loc-480</var>
      2018-10-10 11:33:43,723 - Configured 2 heavy worker threads, and 50 light worker threads
      2018-10-10 11:33:43,796 -
      2018-10-10 11:33:43,796 - **************************************************************************
      2018-10-10 11:33:43,796 - * <var>Synthetics Minion is ready and servicing location</var> '<var>example_private_location</var>'
      2018-10-10 11:33:43,796 - **************************************************************************
      ... logging continues ...
    ```
  </Collapser>

  <Collapser
    id="review-kubernetes-logs"
    title={<><img src={imgIntegrationK8S402X} title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }}/>Review Kubernetes logs</>}
  >
    This is an example of a synthetics job manager log indicating that the synthetics job manager is working properly in a Kubernetes container orchestration system environment:

    First, get the name of the synthetics job manager pod you want to review logs for:

    ```
    kubectl get pods -n <var>YOUR_NAMESPACE</var>
    ```

    Then, interact with that synthetics job manager pod:

    ```
    $ kubectl logs -n <var>YOUR_NAMESPACE</var> <var>YOUR_JOB_MANAGER_NAME</var>
    2020-05-11 22:57:24,084 - Minion will use 2 heavy workers
    2020-05-11 22:57:24,149 - Minion will use 50 lightweight workers
    2020-05-11 22:57:27,973 - Minion Container System: KUBERNETES
    2020-05-11 22:57:30,158 - Minion deployment mode: PRIVATE_MINION_POD_KUBERNETES
    2020-05-11 22:57:30,178 - No volume mounted at '/var/lib/newrelic/synthetics' in ':rw' mode: Private Minion's ID will change with each boot
    2020-05-11 22:57:30,284 - Minion ID: <var>a21f6d7f-4f65-4dec-92fb-88cb975d2a19</var>
    2020-05-11 22:57:30,654 - Publishing resources for Private Minion API: /status/check, /build-info, /status
    2020-05-11 22:57:31,595 - Minion is configured, checking if it is healthy...
    2020-05-11 22:57:35,457 - Launching in PRIVATE Location: <var>123456-example_private_loc-480</var>
    2020-05-11 22:57:36,060 - Executor for async-worker-* threads configured with a max pool size of 16
    2020-05-11 22:57:36,072 - Configured 2 heavy worker threads, and 50 lightweight worker threads
    2020-05-11 22:57:36,087 -
    2020-05-11 22:57:36,087 - **************************************************************************
    2020-05-11 22:57:36,087 - * Synthetics Minion 3.0.1 is ready and servicing location '<var>example_private_location</var>'
    2020-05-11 22:57:36,087 - **************************************************************************
    2020-05-11 22:57:36,087 -
    ... logging continues ...
    ```
  </Collapser>
</CollapserGroup>

## Enable debug logs [#monitor-docker-debug-logs]

If you experience issues with your synthetics job manager, you can enable debug logs to help troubleshoot issues.

The default level of logging is set to only inform the user of key information and actionable errors. If this is insufficient, you can enable a more verbose logging by using the `LOG_LEVEL` environment variable.

<CollapserGroup>
  <Collapser
    id="docker-debug-logs"
    title={<><img src={dockerLogoCrop} title="Docker icon" alt="Docker icon" style={{ height: '35px', width: '40px' }}/>Enable Docker debug logs</>}
  >
    <Callout variant="tip">
      Adding `-f` to the `Docker logs` makes the command follow logs.
    </Callout>

    ```
    docker run ... -e LOG_LEVEL=DEBUG ...
      docker logs -f <var>YOUR_CONTAINER_NAME</var>
      ... verbose logging continues ...
    ```
  </Collapser>

  <Collapser
    id="kubernetes-debug-logs"
    title={<><img src={imgIntegrationK8S402X} title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }}/>Enable Kubernetes debug logs</>}
  >
    <Callout variant="tip">
      Adding `-f` to the `Kubernetes logs` makes the command follow logs.
    </Callout>

    To enable DEBUG logs add the `--set synthetics.logLevel=DEBUG` option when running your `helm install`:

    ```
    helm install <var>YOUR_JOB_MANAGER_NAME</var> <var>YOUR_REPO_NAME</var>/synthetics-job-manager -n <var>YOUR_NAMESPACE</var> --set synthetics.privateLocationKey=<var>YOUR_PRIVATE_LOCATION_KEY</var> --set synthetics.logLevel=DEBUG
    ```

    Get the name of the synthetics job manager pod you want to review logs for:

    ```
    kubectl get pods -n <var>YOUR_NAMESPACE</var>
    ```

    Then, interact with that synthetics job manager pod:

    ```
    kubectl logs -f -n <var>YOUR_NAMESPACE</var> <var>YOUR_JOB_MANAGER_POD_NAME</var>

    ... verbose logging continues ...
    ```
  </Collapser>
</CollapserGroup>

## Retrieve Kubernetes debugging information [#retrieve-kubernetes-debugging]

If you experience issues with your synthetics job manager in a Kubernetes container orchestration system environment, you can retrieve information about the synthetics job manager pod and the node it is running on to help troubleshoot.

To retrieve information for the synthetics job manager pod:

```
kubectl describe pod -n <var>YOUR_NAMESPACE</var> <var>YOUR_JOB_MANAGER_POD_NAME</var>
```

To retrieve information for the node the synthetics job manager pod is running on, identify the node, and then:

```
kubectl describe node <var>NODE_ASSOCIATED_WITH_YOUR_JOB_MANAGER_POD_NAME</var>
```

## Monitor synthetics job managers with New Relic Infrastructure [#monitor-via-infrastructure]

[New Relic's infrastructure monitoring](/docs/infrastructure) supports [advanced Docker monitoring](/docs/infrastructure/new-relic-infrastructure/data-instrumentation/docker-instrumentation-infrastructure) and [advanced Kubernetes monitoring](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration). 

If you are using the infrastructure agent to monitor these runner containers, configure at least one monitor to run each minute. The infrastructure agent will have more opportunity to notice and collect the above labels from the `docker inspect` of the container before it is deleted.
