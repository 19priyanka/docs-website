---
title: Quality foundation implementation guide 
tags:
  - Observability maturity
  - Customer experience
  - Digital customer experience
  - Implementation guide
  - Quality Foundation
metaDescription: Quality Foundation's goal is to help New Relic users understand your customers' digital experience in a meaningful way.
redirects:
  - /docs/new-relic-solutions/observability-maturity/qf-implementation-guide/
---

## Overview [#overview]

Digital customer experience is your end user’s experience across all your digital touch points. There are four core factors that impact a user’s experience:

- Availability (Is it reachable?)
- Performance (Does it perform well enough to be usable?)
- Content quality (Does it have what users need and can they find it?)
- Product and content relevance (Does it have what users care about?)

![Digital customer experience](./images/cx-what-you-can-measure-nr.png "Digital Customer Experienc-DCX-What you can measure with New Relic")

Digital customer experience includes web, mobile, and IoT. The first version of this guide is focused on measuring the end user web experience.

Quality Foundation is about creating a standard practice to help you understand your digital customer experience in a meaningful way.

## Desired Outcome [#desired-outcome]
This implementation guide will help you:

* Look at customer experience in relation to:
    * Global functions, such as search and login
    * Lines of business
    * Regions
* Report back to business stakeholders on what they care about
* Prioritize what you work on
* Create a repeatable practice

## Key Performance Indicators

Quality Foundation measures the following KPIs:

<CollapserGroup>
  <Collapser
    id="js-errors-kpi"
    title="JavaScript error rate KPI"
  >
    This KPI measures the number of JavaScript errors per page view.

    **Goal:**

    * Remove irrelevant JavaScript errors being tracked either by tuning ingest or using filtering.
    * Reduce JavaScript errors that impact customer performance.

  </Collapser>

  <Collapser
    id="http-errors-kpi"
    title="HTTP error rate KPI"
  >
    HTTP errors (or HTTP `4xx` and `5xx` responses) happen when calls to the backend are not successful.

    **Goal:**

    Measure and reduce the HTTP error rate to ensure your customers are able to do what they came to your site to do.

  </Collapser>
  
  <Collapser
    id="ttfb-kpi"
    title="Time to first byte KPI"
  >
    This KPI measures the time from navigation start (a user clicking a link) to the browser receiving the first byte of the response from the server.

    **Goal:**

    Reduce the time to first byte by improving CDN, network, and service performance.

  </Collapser>
  
  <Collapser
    id="core-web-lcp-kpi"
    title="Core web vitals: Largest contentful paint (LCP) KPI"
  >
    [Core Web Vitals](https://web.dev/vitals/) are part of Google’s [Page Experience Metrics](https://developers.google.com/search/blog/2021/04/more-details-page-experience). They measure the experience from when a page begins rendering. Largest Contentful Paint (LCP) measures the time it takes to load the largest image after a user has navigated to a new page.

    **Goal:**

    * Reduce LCP to 2.5 seconds or better for the 75% percentile for all pages or at least the most critical pages.
    * Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages.

  </Collapser>
  
  <Collapser
    id="core-web-kpi"
    title="Core web vitals: First input delay (FID) KPI"
  >
    This KPI measures the experience from when a page begins rendering.

    **Goal:**

    Reduce FID to 100 milliseconds or better for the 75% percentile for all pages or at least the most critical pages.

  </Collapser>

  <Collapser
    id="layout-shift-kpi"
    title="Cumulative layout shift (CLS) KPI"
  >
    This KPI measures how much the page layout shifts during render.

    **Goal:**

    Maintain a score of 0.1 or less for the 75% percentile for all pages or at least the most critical pages.

  </Collapser>

</CollapserGroup>

## Prerequisites

### Required knowledge

* Familiarity with [synthetic monitoring](/docs/synthetics/synthetic-monitoring/getting-started/get-started-synthetic-monitoring/)
* Familiarity with [browser monitoring](/docs/browser/browser-monitoring/getting-started/)
* Familiarity with [basic Browser UI views](/docs/browser/browser-monitoring/getting-started/introduction-browser-monitoring/)
* Familiarity with [SPA data in Browser UI](/docs/browser/single-page-app-monitoring/use-spa-data/view-spa-data-browser-ui/)

## Required Installation and Configuration

* [Browser Pro installed in all pages](/docs/browser/browser-monitoring/installation/)
* [SPA enabled for single page applications](/docs/new-relic-solutions/best-practices-guides/full-stack-observability/browser-monitoring-best-practices-guide/#how-to-do-it)
*  Synthetics monitors configured:
    
    - [Ping monitors configured for anonymous users ](/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/)
    - [Scripted synthetics check configured for login flow](/docs/synthetics/synthetic-monitoring/using-monitors/store-secure-credentials-scripted-browsers-api-tests/)
    - Monitors should be configured to [test from all regions applicable to your users](/docs/synthetics/synthetic-monitoring/using-monitors/add-edit-monitors/#setting-location)
    - Monitors should be configured for each domain and each login flow
* Data retention for browser events is at least 2x an average sprint.

