---
title: 'ktranslate' container health monitoring
tags:
  - Integrations
  - Network Performance Monitoring
  - Troubleshooting
metaDescription: Monitoring and troubleshooting the health of your ktranslate container.
---

## Problem [#problem]

While running the **ktranslate** Docker container for New Relic NPM, you want to monitor the health of the container to proactively detect potential issues.

## Solutions [#solutions]

The **ktranslate** container image has settings available during runtime (`-tee_logs=true` and `-metrics=jchf`) which allow it to send health metrics into New Relic directly. These are enabled by default when installing NPM via the New Relic One guided installation method and is always a recommended setting when installing manually.

### Logs from ktranslate [#logs] 

<Callout variant="tip">
  If you want to check the logs locally from the Docker host, run `docker logs $CONTAINER_NAME`.
  
  Ex: `docker logs ktranslate-snmp`
</Callout>

The `-tee_logs=true` option sends logs to New Relic One when polling devices. To see them, do the following:
  1. Go to [one.newrelic.com](https://one.newrelic.com/) > **Logs**.
  2. In **Find logs where** enter `collector.name:"ktranslate"` and click **Query logs**.

#### Optional log parsing rule

It can be beneficial to add a [parsing rule](/docs/logs/log-management/ui-data/parsing) to New Relic One logs in order to break the logs from **ktranslate** into fields that are easily searchable. This is especially helpful when you are running more than one container as it allows you to then search by the value of `--service_name` from the Docker container.

Using the [New Relic One logs UI](/docs/logs/log-management/ui-data/parsing), you would want to use the following patterns: 

```
Rule Name: ktranslate-health logs
Query Attribute: "plugin.type"
Query Value: "ktranslate-health"
Parsing logic: %{NOTSPACE:time} ktranslate/%{NOTSPACE:container_service} \[%{NOTSPACE:severity}\] %{GREEDYDATA:message}
```

Alternatively, you can use [New Relic's Nerdgraph API to manage your parsing rules](/docs/apis/nerdgraph/examples/nerdgraph-log-parsing-rules-tutorial/). A sample of the `logConfigurationsCreateParsingRule` is below, you will need to replace `$ACCOUNT_ID` with the ID of your target account.

```graphql
mutation {
  logConfigurationsCreateParsingRule(
    accountId: $ACCOUNT_ID, 
    rule: {
      description: "ktranslate-health logs", 
      enabled: true, 
      grok: "%{NOTSPACE:time} ktranslate/%{NOTSPACE:container_service} \\[%{NOTSPACE:severity}\\] %{GREEDYDATA:message}", 
      lucene: "\"plugin.type\":\"ktranslate-health\"", 
      nrql: "SELECT * FROM Log WHERE `plugin.type` = 'ktranslate-health'"
    }
  ) 
  {
    errors {
      message
      type
    }
    rule {
      accountId
      id
      enabled
      description
      grok
      lucene
      nrql
    }
  }
}
```

The result of this parsing rule is splitting a raw message from this:

```json
{
  "collector.name": "ktranslate",
  "instrumentation.provider": "kentik",
  "message": "2021-12-08T14:59:56.007 ktranslate/snmp [Info] nrmFormat New Metadata for cisco-7513",
  "newrelic.source": "api.logs",
  "plugin.type": "ktranslate-health",
  "timestamp": 1638975596000
}
```

To this, creating the searchable fields of `container_service`, `severity`, and `time`; as well as trimming the `message` field to more actionable data:

```json
{
  "collector.name": "ktranslate",
  "container_service": "snmp",
  "instrumentation.provider": "kentik",
  "message": "nrmFormat New Metadata for cisco-7513",
  "newrelic.source": "api.logs",
  "plugin.type": "ktranslate-health",
  "severity": "Info",
  "time": "2021-12-08T15:29:56.026",
  "timestamp": 1638977396000
}
```

#### Common log searches

Below are some common searches that can be used during troubleshooting to gather data for support:

<CollapserGroup>
  <Collapser
    id="container-version"
    title="What version of ktranslate am I running?"
  >

Logs UI:
```
collector.name:"ktranslate" message:"*KTranslate Running -- Version*"
```

NRQL:
```sql
FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%KTranslate Running -- Version%'
```

Expected Results:
```
KTranslate Running -- Version kt-2021-12-06-1546870234; Build Mon Dec  6 22:22:56 UTC 2021
```

  </Collapser>
  <Collapser
    id="docker-arguments"
    title="What arguments were passed to Docker at runtime?"
  >

Logs UI:
```
collector.name:"ktranslate" message:"*KTranslate CLI:*"
```

NRQL:
```sql
FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%KTranslate CLI:%'
```

Expected Results:
```
KTranslate CLI: [ktranslate -listen off -mapping /etc/ktranslate/config.json -geo /etc/ktranslate/GeoLite2-Country.mmdb -udrs /etc/ktranslate/udr.csv -api_devices /etc/ktranslate/devices.json -asn /etc/ktranslate/GeoLite2-ASN.mmdb -log_level info -snmp /snmp-base.yaml -nr_account_id=2583772 -log_level=info -metrics=jchf -tee_logs=true -service_name=snmp nr1.snmp]
```

  </Collapser>
  <Collapser
    id="container-errors"
    title="What errors am I experiencing?"
  >

**Without a parsing rule applied to your logs**

Logs UI:
```
collector.name:"ktranslate" message:-*\[Info\]*
```

NRQL:
```sql
FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` NOT LIKE '%[Info]%'
```

**With a parsing rule applied to your logs**

Logs UI:
```
collector.name:"ktranslate" severity:-"Info"
```

NRQL:
```sql
FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `severity` != 'Info'
```

Expected Results:
```
KTranslate>cisco-7513 There was an SNMP polling error with the CustomDeviceMetrics walking OID .1.3.6.1.2.1.4.31.1.1.21 after 0 retries: request timeout (after 0 retries).
```

  </Collapser>
  <Collapser
    id="match_attributes"
    title="Is my 'match_attributes' filter working on my device?"
  >

Logs UI:
```
collector.name:"ktranslate" message:"*Match Attribute*"
```

NRQL:
```sql
FROM Log SELECT * WHERE `collector.name` = 'ktranslate' AND `message` LIKE '%Match Attribute%'
```

Expected Results:
```
KTranslate>cisco-7513 Added 1 Match Attribute(s)
```

*Note: It is expected that all devices have at least 1 Match Attribute inherited from the default `monitor_admin_shut: true` configuration. You should expect a value of `2` to be shown for a device that you have added a single match attribute to.*

<Callout variant="tip">
  You can further filter these results by adding the device name to your query: `collector.name:"ktranslate" message:"*$DEVICE_NAME*Match Attribute*"
</Callout>

  </Collapser>
</CollapserGroup>

### Metrics from ktranslate [#metrics]

The `-metrics` option captures the following performance metrics when polling devices:

<table>
  <thead>
    <tr>
      <th style={{ width: "400px" }}>
        Metric
      </th>
      <th>
        Description
      </th>
    </tr>
  </thead>
    <tbody>
    <tr>
      <td>
        `baseserver_healthcheck_execution_total`
      </td>
      <td>
        Rate of internal health checks. Shows mostly that things are not deadlocked.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_metrics_nr`
      </td>
      <td>
        Rate of metrics sent to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_logs_nr`
      </td>
      <td>
        Rate of logs sent to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `delivery_wins_nr`
      </td>
      <td>
        Rate of 200 HTTP codes received from sending metrics and events to New Relic One.
      </td>
    </tr>
    <tr>
      <td>
        `device_metrics`
      </td>
      <td>
        Rate of SNMP polling of device level metrics.
      </td>
    </tr>
    <tr>
      <td>
        `inputq`
      </td>
      <td>
        Messages per second (msg/sec) received over the last 60 seconds from SNMP or network flow devices.
      </td>
    </tr>
    <tr>
      <td>
        `interface_metrics`
      </td>
      <td>
        Rate of SNMP polling of interface level metrics.
      </td>
    </tr>
    <tr>
      <td>
        `jchfq`
      </td>
      <td>
        Gauge rate with number of available pre-allocated buffers. It should be 8,000 aproximately.
      </td>
    </tr>
    </tbody>
</table>

To see these metrics in New Relic One:
1. Go to [one.newrelic.com](https://one.newrelic.com/) and click **Query your data**.
2. Enter the following NRQL query:
  ```SQL
  FROM Metric
  SELECT
  latest(kentik.ktranslate.chf.kkc.baseserver_healthcheck_execution_total) AS 'baseserver_healthcheck_execution_total',
  latest(kentik.ktranslate.chf.kkc.delivery_metrics_nr) AS 'delivery_metrics_nr',
  latest(kentik.ktranslate.chf.kkc.delivery_logs_nr) AS 'delivery_logs_nr',
  latest(kentik.ktranslate.chf.kkc.delivery_wins_nr) AS 'delivery_wins_nr',
  latest(kentik.ktranslate.chf.kkc.device_metrics) AS 'device_metrics',
  latest(kentik.ktranslate.chf.kkc.inputq) AS 'inputq',
  latest(kentik.ktranslate.chf.kkc.interface_metrics) AS 'interface_metrics',
  latest(kentik.ktranslate.chf.kkc.jchfq) AS 'jchfq'
  WHERE provider = 'kentik-agent'
  AND instrumentation.name = 'heartbeat'
  LIMIT MAX
  ```
