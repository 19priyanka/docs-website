
<p>The easiest way to install the Kubernetes integration is to use our automated installer to generate a manifest. It bundles not just the integration DaemonSets, but also other New Relic Kubernetes configurations, like <a href="https://docs.newrelic.com/docs/integrations/kubernetes-integration/kubernetes-events/install-kubernetes-events-integration">Kubernetes events</a>, <a href="https://docs.newrelic.com/docs/integrations/prometheus-integrations/get-started/new-relic-prometheus-openmetrics-integration-kubernetes">Prometheus OpenMetrics</a>, and <a href="https://docs.newrelic.com/docs/logs">New Relic log monitoring</a>.</p>
<p>You can use the automated installer for servers, VMs, and unprivileged environments. The installer can also help you with managed services or platforms after you review a few <a href="#cloud-platforms">preliminary notes</a>. We also have separate instructions if you need a <a href="#customized-manifest">custom manifest</a> or prefer to do a <a href="#unprivileged">manual unprivileged installation</a>.</p>
<div data-component="ButtonLink" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJyb2xlIiwidmFsdWUiOiJidXR0b24ifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidG8iLCJ2YWx1ZSI6Imh0dHBzOi8vb25lLm5ld3JlbGljLmNvbS9sYXVuY2hlci9ucjEtY29yZS5zZXR0aW5ncz9wYW5lPWV5SnVaWEprYkdWMFNXUWlPaUpyT0hNdFkyeDFjM1JsY2kxbGVIQnNiM0psY2kxdVpYSmtiR1YwTG1zNGN5MXpaWFIxY0NKOSJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJwcmltYXJ5In1d">
  <p>Start the installer</p>
</div>
<div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJ0aXAifV0=">
  <p>If your New Relic account <a href="/docs/using-new-relic/welcome-new-relic/get-started/our-eu-us-region-data-centers">is in the EU region</a>, access the installer from <a href="http://one.eu.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">one.eu.newrelic.com</a>.</p>
</div>
<h2>Installs for managed services and platforms [#cloud-platforms]</h2>
<p>Before starting our <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a>, check out these notes for your managed services or platforms:</p>
<div data-component="CollapserGroup" data-prop="W10=">
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJjbGFzc05hbWUiLCJ2YWx1ZSI6ImZyZXEtbGluayJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5zdGFsbC1hbWF6b24tZWtzIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOnsidHlwZSI6Im1keFZhbHVlRXhwcmVzc2lvbiIsInZhbHVlIjoiPD4gPExpbmsgdG89XCIjaW5zdGFsbC1hbWF6b24tZWtzXCI+IEFtYXpvbiBFS1M8L0xpbms+PC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6NDcsImNvbHVtbiI6MTEsIm9mZnNldCI6Mjc0NX0sImVuZCI6eyJsaW5lIjo0NywiY29sdW1uIjo2OCwib2Zmc2V0IjoyODAyfX19fV0=">
    <div data-prop-text="title">[object Object]</div>
    <p>The Kubernetes integration monitors worker nodes. In Amazon EKS, master nodes are managed by Amazon and abstracted from the Kubernetes platforms.</p>
    <p>Before starting our <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a> to deploy the Kubernetes integration in Amazon EKS, make sure you are using the version of <a href="https://docs.aws.amazon.com/eks/latest/userguide/configure-kubectl.html"><code>kubectl</code> provided by AWS</a>.</p>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJjbGFzc05hbWUiLCJ2YWx1ZSI6ImZyZXEtbGluayJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5zdGFsbC1nb29nbGUta3ViZXJuZXRlcy1lbmdpbmUifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6eyJ0eXBlIjoibWR4VmFsdWVFeHByZXNzaW9uIiwidmFsdWUiOiI8PiA8TGluayB0bz1cIiNpbnN0YWxsLWdvb2dsZS1rdWJlcm5ldGVzLWVuZ2luZVwiPiBHb29nbGUgS3ViZXJuZXRlcyBFbmdpbmUgKEdLRSk8L0xpbms+PC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6NTcsImNvbHVtbiI6MTEsIm9mZnNldCI6MzQzNX0sImVuZCI6eyJsaW5lIjo1NywiY29sdW1uIjoxMDIsIm9mZnNldCI6MzUyNn19fX1d">
    <div data-prop-text="title">[object Object]</div>
    <p>The Kubernetes integration monitors worker nodes. In GKE, master nodes are managed by Google and abstracted from the Kubernetes platforms.</p>
    <p>Before starting our <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a> to deploy the Kubernetes integration on GKE, ensure you have sufficient permissions:</p>
    <ol>
      <li>
        <p>Go to <a href="https://console.cloud.google.com/iam-admin/iam">https://console.cloud.google.com/iam-admin/iam</a> and find your username. Click <strong>edit</strong>.</p>
      </li>
      <li>
        <p>Ensure you have permissions to create <code>Roles</code> and <code>ClusterRoles</code>: If you are not sure, add the <strong>Kubernetes Engine Cluster Admin</strong> role. If you cannot edit your user role, ask the owner of the GCP project to give you the necessary permissions.</p>
      </li>
      <li>
        <p>Ensure you have a <code>RoleBinding</code> that grants you the same permissions to create <code>Roles</code> and <code>ClusterRoles</code>:</p>
        <pre><code>kubectl create clusterrolebinding YOUR_USERNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUR_GCP_EMAIL
</code></pre>
        <div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJ0aXAifV0=">
          <p>Creating a RoleBinding is necessary because of a known RBAC issue in Kubernetes and Kubernetes Engine versions 1.6 or higher. For more information, see <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control#defining_permissions_in_a_role">Google Cloud's documentation on defining permissions in a role</a>.</p>
        </div>
      </li>
    </ol>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJjbGFzc05hbWUiLCJ2YWx1ZSI6ImZyZXEtbGluayJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5zdGFsbC1vcGVuc2hpZnQtY29udGFpbmVyLXBsYXRmb3JtIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJPcGVuU2hpZnQgY29udGFpbmVyIHBsYXRmb3JtIn1d">
    <div data-prop-text="title">OpenShift container platform</div>
    <p>To deploy the Kubernetes integration with <a href="https://learn.openshift.com/?extIdCarryOver=true&#x26;sc_cid=701f2000001OH7iAAG">OpenShift</a>:</p>
    <ol>
      <li>
        <p>Add the <code>&#x3C;release_name>-newrelic-infrastructure</code> service account to your privileged <a href="https://docs.openshift.com/enterprise/3.0/admin_guide/manage_scc.html">Security Context Constraints</a>:</p>
        <pre><code>oc adm policy add-scc-to-user privileged \
system:serviceaccount:&#x3C;namespace>:&#x3C;release_name>-newrelic-infrastructure
</code></pre>
        <div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
          <p>The default <code>&#x3C;release_name></code> provided by the installer is <code>nri-bundle</code>.</p>
        </div>
      </li>
      <li>
        <p>Complete the steps in our <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a>.</p>
      </li>
      <li>
        <p>If you're using signed certificates, make sure they are properly configured by using the following variables to set the <code>.pem</code> file:</p>
        <pre><code>- name: NRIA_CA_BUNDLE_DIR 
  value: YOUR_CA_BUNDLE_DIR 
- name: NRIA_CA_BUNDLE_FILE  
  value: YOUR_CA_BUNDLE_NAME
</code></pre>
      </li>
      <li>
        <p>Save your changes.</p>
      </li>
    </ol>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJjbGFzc05hbWUiLCJ2YWx1ZSI6ImZyZXEtbGluayJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5zdGFsbC1henVyZS1ha3MifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6IkF6dXJlIEt1YmVybmV0ZXMgU2VydmljZSAoQUtTKSJ9XQ==">
    <div data-prop-text="title">Azure Kubernetes Service (AKS)</div>
    <p>The Kubernetes integration monitors worker nodes. In Azure Kubernetes Service, master nodes are managed by Azure and abstracted from the Kubernetes platforms.</p>
    <p>To deploy in Azure Kubernetes Service (AKS), complete the steps in our <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a>.</p>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJjbGFzc05hbWUiLCJ2YWx1ZSI6ImZyZXEtbGluayJ9LHsidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5zdGFsbC1wa3MifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6IlBpdm90YWwgQ29udGFpbmVyIFNlcnZpY2UgKFBLUyAvIFZNd2FyZSBUYW56dSkifV0=">
    <div data-prop-text="title">Pivotal Container Service (PKS / VMware Tanzu)</div>
    <p>To deploy in PKS, we recommend that you use the <a href="https://one.newrelic.com/launcher/nr1-core.settings?pane=eyJuZXJkbGV0SWQiOiJrOHMtY2x1c3Rlci1leHBsb3Jlci1uZXJkbGV0Lms4cy1zZXR1cCJ9">automated installer</a>, or you can follow the manual instructions provided in <a href="https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/install-kubernetes-integration-using-helm">Install the Kubernetes integration using Helm</a>.</p>
  </div>
</div>
<h2>Custom manifest [#customized-manifest]</h2>
<p>If the Kubernetes automated installer doesn't provide the settings you need, you can download our manifest template and install the integration manually.</p>
<p>To activate the Kubernetes integration, you must deploy the <code>newrelic-infra</code> agent onto a Kubernetes cluster as a <code>DaemonSet</code>:</p>
<ol>
  <li>
    <p><a href="https://github.com/kubernetes/kube-state-metrics#kubernetes-deployment">Install kube-state-metrics</a> and get it running on the cluster. For example:</p>
    <pre><code>curl -L -o kube-state-metrics-1.9.5.zip https://github.com/kubernetes/kube-state-metrics/archive/v1.9.5.zip &#x26;&#x26; unzip kube-state-metrics-1.9.5.zip &#x26;&#x26; kubectl apply -f kube-state-metrics-1.9.5/examples/standard
</code></pre>
  </li>
  <li>
    <p>Download the manifest file:</p>
    <pre><code>curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml
</code></pre>
  </li>
  <li>
    <p>In the manifest, add your <a href="https://docs.newrelic.com/docs/accounts-partnerships/accounts/account-setup/license-key">New Relic license key</a> and a cluster name to identify your Kubernetes cluster. <strong>Both values are required.</strong></p>
    <div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
      <p><strong>Recommendation:</strong> Do not change the <code>NRIA_PASSTHROUGH_ENVIRONMENT</code> or <code>NRIA_DISPLAY_NAME</code> value in your manifest.</p>
    </div>
    <div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
      <p><code>YOUR_CLUSTER_NAME</code> is your cluster’s id in New Relic’s entity explorer. It doesn’t need to match the name of the cluster running in your environment.</p>
    </div>
    <pre><code>env:
  - name: NRIA_LICENSE_KEY
    value: YOUR_LICENSE_KEY
  - name: CLUSTER_NAME
    value: YOUR_CLUSTER_NAME
</code></pre>
  </li>
  <li>
    <p>Review the <a href="#configure-the-integration">Configure</a> section of this docs in case you need to adapt the manifest to fit your environment.</p>
  </li>
  <li>
    <p>Confirm that <code>kube-state-metrics</code> is installed.</p>
    <pre><code>kubectl get pods --all-namespaces | grep kube-state-metrics
</code></pre>
  </li>
  <li>
    <p>Create the <code>DaemonSet</code>:</p>
    <pre><code>kubectl create -f newrelic-infrastructure-k8s-latest.yaml
</code></pre>
  </li>
  <li>
    <p>Confirm that the <code>DaemonSet</code> has been created successfully by looking for <code>newrelic-infra</code> in the results generated by this command:</p>
    <pre><code>kubectl get daemonsets
</code></pre>
  </li>
</ol>
<p>To confirm that the integration is working: wait a few minutes, then look for data in the <a href="/docs/integrations/kubernetes-integration/cluster-explorer/kubernetes-cluster-explorer">New Relic Kubernetes cluster explorer</a>.</p>
<p>If you don't see data, review the <a href="#install">configuration procedures</a> again, then follow the <a href="/docs/integrations/host-integrations/troubleshooting/kubernetes-integration-troubleshooting-not-seeing-data">troubleshooting procedures</a>.</p>
<div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
  <p>In the future, the number of labels collected on Kubernetes objects will be limited per object type (containers, pods, nodes, etc.) . If objects have labels above the limit, you will be able to configure important labels that should always be sent to New Relic. When the limitation is in place, this documentation will be updated.</p>
</div>
<h3>Make sure New Relic pods can be scheduled</h3>
<p>Some of the New Relic pods are set up as <code>DaemonSet</code> in the manifest file so that they can run on every host. These include <code>newrelic-infrastructure</code> and <code>newrelic-logging</code>. In rare circumstances, it is possible for other pods to be scheduled first and starve the New Relic pods of resources. Since each of these pods have to run on a specific host, they will stay in pending status until that host has enough resources, even if there are other hosts available. This could end up occurring for long periods of time and result in reporting gaps.</p>
<p>To prevent this scenario you can configure the Kubernetes scheduler to give New Relic pods a higher priority. Using the default scheduler:</p>
<ol>
  <li>
    <p>Ensure <code>kube-scheduler</code> flag <code>disablePreemption</code> is not set to <code>true</code> (by default it is <code>false</code>).</p>
  </li>
  <li>
    <p>Create a <a href="https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass">PriorityClass</a> for the New Relic <code>DaemonSet</code> pods.</p>
    <ol>
      <li>Set the appropriate priority value, which should generally be higher than your other pods.</li>
      <li><code>preemptionPolicy</code> is set to <code>PreemptLowerPriority</code> by default. This allows New Relic pods assigned this priority class to remove lower-priority pods that are taking up resources.</li>
    </ol>
  </li>
  <li>
    <p>Edit the manifest file to add <code>priorityClassName</code> to any <code>DaemonSet</code> specs. In the example below, the highlighted line sets the priority class for <code>newrelic-infrastructure</code>:</p>
    <pre><code>apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: default
  labels:
    app: newrelic-infrastructure
    chart: newrelic-infrastructure-1.0.0
    release: nri-bundle
    mode: privileged
  name: nri-bundle-newrelic-infrastructure
spec:
  priorityClassName: your-priority-class
  ...
</code></pre>
  </li>
  <li>
    <p>If you have already deployed the New Relic pods, re-deploy them and confirm they have been created:</p>
    <pre><code>kubectl delete -f newrelic-infrastructure-k8s-latest.yaml
kubectl create -f newrelic-infrastructure-k8s-latest.yaml
kubectl get daemonsets
</code></pre>
  </li>
</ol>
<h2>Unprivileged installs of the Kubernetes integration [#unprivileged]</h2>
<p>For platforms that have stringent security requirements, we provide an unprivileged version of the Kubernetes integration. Changes from the standard Kubernetes integration are:</p>
<ul>
  <li>Runs the infrastructure agent and the Kubernetes integration as a standard user instead of root</li>
  <li>No access to the underlying host filesystem</li>
  <li>No access to <code>/var/run/docker.sock</code></li>
  <li>Container's root filesystem mounted as read-only</li>
  <li><code>allowPrivilegeEscalation</code> is set to <code>false</code></li>
  <li><code>hostnetwork</code> is set to <code>false</code></li>
</ul>
<p>The tradeoff is that the solution will <strong>only</strong> collect metrics from Kubernetes, but it will not collect any metric from the underlying hosts directly. Kubernetes provides some <a href="/docs/integrations/kubernetes-integration/understand-use-data/understand-use-data#metrics">data (metrics and metadata) about its nodes (hosts)</a>.</p>
<div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJ0aXAifV0=">
  <p>Optional: To collect the underlying host metrics, the non-containerized <a href="/docs/infrastructure/new-relic-infrastructure/installation/install-infrastructure-linux">infrastructure agent can be deployed</a> on the underlying host. The infrastructure agent already supports running as non-root. The combination of the Kubernetes integration in its unprivileged version and the agent running on the host will report all the <a href="/docs/infrastructure/new-relic-infrastructure/data-instrumentation/default-infrastructure-attributes-events">metrics that our standard solution for monitoring Kubernetes receives</a>.</p>
</div>
<div data-component="CollapserGroup" data-prop="W10=">
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoidW5wcml2aWxlZ2VkLXN0ZXBzIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJTdGVwcyB0byBjb21wbGV0ZSBhbiB1bnByaXZpbGVnZWQgaW5zdGFsbCJ9XQ==">
    <div data-prop-text="title">Steps to complete an unprivileged install</div>
    <ol>
      <li>
        <p>Install <code>kube-state-metrics</code> and get it running on the cluster. For example:</p>
        <pre><code>curl -L -o kube-state-metrics-1.9.5.zip https://github.com/kubernetes/kube-state-metrics/archive/v1.9.5.zip &#x26;&#x26; unzip kube-state-metrics-1.9.5.zip &#x26;&#x26; kubectl apply -f kube-state-metrics-1.9.5/examples/standard
</code></pre>
      </li>
      <li>
        <p>Download the integration manifest:</p>
        <pre><code>curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-unprivileged-latest.yaml
</code></pre>
      </li>
      <li>
        <p>In the manifest, add your <a href="/docs/accounts-partnerships/accounts/account-setup/license-key">New Relic license key</a> and a cluster name to identify your Kubernetes cluster. <strong>Both values are required.</strong></p>
        <div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
          <p><code>YOUR_CLUSTER_NAME</code> is your cluster’s id in New Relic’s entity explorer. It doesn’t need to match the name of the cluster running in your environment.</p>
        </div>
        <pre><code>env:
  - name: NRIA_LICENSE_KEY
    value: YOUR_LICENSE_KEY
  - name: CLUSTER_NAME
    value: YOUR_CLUSTER_NAME
</code></pre>
      </li>
      <li>
        <p>Confirm that <code>kube-state-metrics</code> is installed.</p>
        <pre><code>kubectl get pods --all-namespaces | grep kube-state-metrics
</code></pre>
      </li>
      <li>
        <p>Create the <code>DaemonSet</code>:</p>
        <pre><code>kubectl create -f newrelic-infrastructure-k8s-unprivileged-latest.yaml
</code></pre>
      </li>
      <li>
        <p>Confirm that the <code>DaemonSet</code> has been created successfully by looking for newrelic-infra in the results generated by this command:</p>
        <pre><code>kubectl get daemonsets
</code></pre>
      </li>
      <li>
        <p>To confirm that the integration has been configured correctly, wait a few minutes, then run this <a href="/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql">NRQL query</a> to see if data has been reported:</p>
        <pre><code>SELECT * FROM K8sPodSample since 5 minutes ago
</code></pre>
      </li>
    </ol>
  </div>
</div>
<h2>Configure the integration</h2>
<p>The Kubernetes integration comes with a default configuration that should work in most environments. To change the configuration, modify the manifest file:</p>
<div data-component="CollapserGroup" data-prop="W10=">
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5jbHVkZS1tYXRjaGluZy1tZXRyaWNzIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJTZWxlY3Qgd2hpY2ggcHJvY2Vzc2VzIHNob3VsZCBzZW5kIHRoZWlyIGRhdGEgdG8gTmV3IFJlbGljIn1d">
    <div data-prop-text="title">Select which processes should send their data to New Relic</div>
    <p>By default, data about the processes running on your pods is not sent to New Relic. You can enable it by setting <a href="https://docs.newrelic.com/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings#enable-process-metrics"><code>enable_process_metrics</code></a> to <code>true</code>.</p>
    <p>To choose what metric data you want to send to New Relic, configure the <a href="/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings#include-matching-metrics"><code>include_matching_metrics</code></a> environment variable in your manifest.</p>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiY3VzdG9tLWs4cy1hcGktdXJsIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJTcGVjaWZ5IHRoZSBLdWJlcm5ldGVzIEFQSSBob3N0IGFuZCBwb3J0In1d">
    <div data-prop-text="title">Specify the Kubernetes API host and port</div>
    <p>This is necessary when you are using SSL and not using the default FQDN. The Kubernetes API FQDN needs to match the FQDN of the SSL certificate.</p>
    <p>You do not need to specify both variables. For example, if you only specify the <code>HOST</code>, the default <code>PORT</code> will be used.</p>
    <pre><code>- name: "KUBERNETES_SERVICE_HOST" 
  value: "KUBERNETES_API_HOST"
- name: "KUBERNETES_SERVICE_PORT" 
  value: "KUBERNETES_API_TCP_PORT"

</code></pre>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiazhzLXZlcnNpb24tMS42LTEuNy42In0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJLdWJlcm5ldGVzIHZlcnNpb25zIDEuNiB0byAxLjcuNTogRWRpdCBtYW5pZmVzdCBmaWxlIn1d">
    <div data-prop-text="title">Kubernetes versions 1.6 to 1.7.5: Edit manifest file</div>
    <p>For Kubernetes versions 1.6 to 1.7.5, uncomment these two lines in the manifest file:</p>
    <pre><code>- name: "CADVISOR_PORT" # Enable direct connection to cAdvisor by specifying the port.  Needed for Kubernetes versions prior to 1.7.6.
  value: "4194"

</code></pre>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiaW5jbHVkZS1tYXRjaGluZy1wcm9jZXNzZXMifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6IlVzZSBlbnZpcm9ubWVudCB2YXJpYWJsZXMifV0=">
    <div data-prop-text="title">Use environment variables</div>
    <p>Use <a href="https://docs.newrelic.com/docs/infrastructure/new-relic-infrastructure/configuration/configure-infrastructure-agent#Environment_Variables">environment variables</a> that can be passed to the Kubernetes integration if you use a proxy to configure its URL.</p>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoiZGlzYWJsZS1rdWJlLXN0YXRlLW1ldHJpY3MifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6eyJ0eXBlIjoibWR4VmFsdWVFeHByZXNzaW9uIiwidmFsdWUiOiI8PkRpc2FibGUgPElubGluZUNvZGU+a3ViZS1zdGF0ZS1tZXRyaWNzPC9JbmxpbmVDb2RlPiBwYXJzaW5nPC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6MzM2LCJjb2x1bW4iOjExLCJvZmZzZXQiOjE4NDAyfSwiZW5kIjp7ImxpbmUiOjMzNiwiY29sdW1uIjo3Nywib2Zmc2V0IjoxODQ2OH19fX1d">
    <div data-prop-text="title">[object Object]</div>
    <p>You can disable <code>kube-state-metrics</code> parsing for the <code>DaemonSet</code> by using the following configuration:</p>
    <pre><code>- name: "DISABLE_KUBE_STATE_METRICS"
   value: "true"

</code></pre>&#x3C;Callout variant="caution">
    Disabling `kube-state-metrics` also disables data collection for the following:
    * `ReplicaSets`
    * `DaemonSets`
    * `StatefulSets`
    * `Namespaces`
    * `Deployments`
    * `Services`
    * `Endpoints`
    * `Pods` (that are **pending**)
    Additionally, disabling this affects the Kubernetes Cluster Explorer in the following ways:
    * No pending pods are shown.
    * No filters based on services.
    &#x3C;/Callout>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoia3ViZS1zdGF0ZS1tZXRyaWNzLXVybC1jaGFuZ2UifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6eyJ0eXBlIjoibWR4VmFsdWVFeHByZXNzaW9uIiwidmFsdWUiOiI8PlNwZWNpZnkgdGhlIDxJbmxpbmVDb2RlPmt1YmUtc3RhdGUtbWV0cmljczwvSW5saW5lQ29kZT4gVVJMPC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6MzY2LCJjb2x1bW4iOjExLCJvZmZzZXQiOjE5MjMxfSwiZW5kIjp7ImxpbmUiOjM2NiwiY29sdW1uIjo3Nywib2Zmc2V0IjoxOTI5N319fX1d">
    <div data-prop-text="title">[object Object]</div>
    <p>If several instances of <code>kube-state-metrics</code> are present in the cluster, uncomment and configure the following lines to specify which one to use:</p>
    <pre><code>- name: "KUBE_STATE_METRICS_URL"
   value: "http://KUBE_STATE_METRICS_IP_OR_FQDN:PORT"

</code></pre>&#x3C;Callout variant="important">
    Even though a `KUBE_STATE_METRICS_URL` is defined, the KSM service should contain one of the following labels for the auto-discovery process:
    * `k8s-app=kube-state-metrics`
    OR
    * `app=kube-state-metrics`
    &#x3C;/Callout>
    &#x3C;Callout variant="important">
    This configuration option overrides `KUBE_STATE_METRICS_POD_LABEL`. If you have both defined, `KUBE_STATE_METRICS_POD_LABEL` has no effect.
    &#x3C;/Callout>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoia3ViZS1zdGF0ZS1tZXRyaWNzLXBvZC1sYWJlbC1kaXNjb3ZlcnkifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6eyJ0eXBlIjoibWR4VmFsdWVFeHByZXNzaW9uIiwidmFsdWUiOiI8PkRpc2NvdmVyIDxJbmxpbmVDb2RlPmt1YmUtc3RhdGUtbWV0cmljczwvSW5saW5lQ29kZT4gcG9kcyB1c2luZyBhIGxhYmVsPC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6MzkxLCJjb2x1bW4iOjExLCJvZmZzZXQiOjIwMTI4fSwiZW5kIjp7ImxpbmUiOjM5MSwiY29sdW1uIjo4OSwib2Zmc2V0IjoyMDIwNn19fX1d">
    <div data-prop-text="title">[object Object]</div>
    <p>If several instances of <code>kube-state-metrics</code> are present in the cluster, another option to easily target one of these instances with the Kubernetes integration is to use label-based discovery.</p>
    <pre><code>- name: "KUBE_STATE_METRICS_POD_LABEL"
   value: "LABEL_NAME"

</code></pre>&#x3C;Callout variant="important">
    When a `KUBE_STATE_METRICS_POD_LABEL` is defined, the label should have a value equal to `true`. For example, if the label name is `my-ksm`, ensure that `my-ksm=true`.
    &#x3C;/Callout>
    &#x3C;Callout variant="important">
    This configuration option is incompatible with `KUBE_STATE_METRICS_URL`. If you have both defined, `KUBE_STATE_METRICS_URL` is used.
    &#x3C;/Callout>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoia3ViZS1zdGF0ZS1tZXRyaWNzLWJlaGluZC1yYmFjIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOnsidHlwZSI6Im1keFZhbHVlRXhwcmVzc2lvbiIsInZhbHVlIjoiPD5RdWVyeSA8SW5saW5lQ29kZT5rdWJlLXN0YXRlLW1ldHJpY3M8L0lubGluZUNvZGU+IGJlaGluZCBSQkFDPC8+IiwicG9zaXRpb24iOnsic3RhcnQiOnsibGluZSI6NDExLCJjb2x1bW4iOjExLCJvZmZzZXQiOjIwOTg3fSwiZW5kIjp7ImxpbmUiOjQxMSwiY29sdW1uIjo3OSwib2Zmc2V0IjoyMTA1NX19fX1d">
    <div data-prop-text="title">[object Object]</div>
    <p>If your instance of <code>kube-state-metrics</code> is behind <a href="https://github.com/brancz/kube-rbac-proxy">kube-rbac-proxy</a>, the integration can be configured in a compatible way using the combination of the label-based discovery and two other environment variables:</p>
    <pre><code>- name: "KUBE_STATE_METRICS_SCHEME"
   value: "https"
 - name: "KUBE_STATE_METRICS_PORT"
   value: "KSM_RBAC_PROXY_PORT"

</code></pre>To confirm which port should be used as the value of `KUBE_STATE_METRICS_PORT`, we recommend running a describe command on the `kube-state-metrics` pod and look for the port exposed by the container named `kube-rbac-proxy-main`.
    &#x3C;Callout variant="important">
    These two configuration options only work when using the `KUBE_STATE_METRICS_POD_LABEL` configuration described above.
    &#x3C;/Callout>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoia3ViZS1zdGF0ZS1tZXRyaWNzLXRpbWVvdXQtY2hhbmdlIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOnsidHlwZSI6Im1keFZhbHVlRXhwcmVzc2lvbiIsInZhbHVlIjoiPD48SW5saW5lQ29kZT5rdWJlLXN0YXRlLW1ldHJpY3M8L0lubGluZUNvZGU+IHRpbWVvdXQ6IEluY3JlYXNlIHRoZSBjbGllbnQgdGltZW91dDwvPiIsInBvc2l0aW9uIjp7InN0YXJ0Ijp7ImxpbmUiOjQzMSwiY29sdW1uIjoxMSwib2Zmc2V0IjoyMTk2NH0sImVuZCI6eyJsaW5lIjo0MzEsImNvbHVtbiI6OTgsIm9mZnNldCI6MjIwNTF9fX19XQ==">
    <div data-prop-text="title">[object Object]</div>
    <p>To increase the client timeout of <code>kube-state-metrics</code>, add a new environment variable, <code>TIMEOUT</code>, to the manifest file:</p>
    <pre><code>env:
  - name: TIMEOUT
    value: 5000 # The default client timeout when calling kube-state-metrics, in milliseconds

</code></pre>Then, add this new environment variable to the [`NRIA_PASSTHROUGH_ENVIRONMENT`](/docs/infrastructure/install-configure-manage-infrastructure/configuration/infrastructure-configuration-settings)
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoibm9uLWRlZmF1bHQtbmFtZXNwYWNlIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJOb24tZGVmYXVsdCBuYW1lc3BhY2UgZGVwbG95bWVudHM6IEVkaXQgY29uZmlnIGZpbGUifV0=">
    <div data-prop-text="title">Non-default namespace deployments: Edit config file</div>
    <p>If you want to deploy in a different namespace from <code>default</code>, change all values of <code>namespace</code> in the manifest.</p>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoidHRsLWZvci1hcGktcmVzcG9uc2VzIn0seyJ0eXBlIjoibWR4QXR0cmlidXRlIiwibmFtZSI6InRpdGxlIiwidmFsdWUiOiJTZXQgdGhlIFRUTCBmb3IgdGhlIEt1YmVybmV0ZXMgQVBJIHJlc3BvbnNlcyBjYWNoZSJ9XQ==">
    <div data-prop-text="title">Set the TTL for the Kubernetes API responses cache</div>
    <p>By default, the integration will cache any retrieved information from the Kubernetes API for 5 minutes.</p>
    <p>Use the <code>API_SERVER_CACHE_TTL</code> environment variable to set a custom cache duration for responses from the API server. Valid time unit values are: <code>ns</code>, <code>us</code>, <code>ms</code>, <code>s</code>, <code>m</code>, and <code>h</code>. To disable caching, set to <code>0s</code>.</p>
    <pre><code>env: 
  - name: API_SERVER_CACHE_TTL 
    value: "1m"

</code></pre>
  </div>
  <div data-component="Collapser" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJpZCIsInZhbHVlIjoia3ViZS1zdGF0ZS1tZXRyaWNzLWNvbnRyb2wtcGxhbmUifSx7InR5cGUiOiJtZHhBdHRyaWJ1dGUiLCJuYW1lIjoidGl0bGUiLCJ2YWx1ZSI6IlNwZWNpZnkgYmFzZSBVUkxzIGZvciBjb250cm9sIHBsYW5lIGNvbXBvbmVudCBlbmRwb2ludHMifV0=">
    <div data-prop-text="title">Specify base URLs for control plane component endpoints</div>
    <p>Use the following environment variables if any of the Kubernetes control plane components export metrics on base URLs that are different <a href="https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#discover-nodes-components">from the defaults</a>. This is necessary for environments such as <a href="http://learn.openshift.com/?extIdCarryOver=true&#x26;sc_cid=701f2000001OH7iAAG">OpenShift</a> when a control plane component metrics endpoint is using SSL or an alternate port.</p>
    <p>Values of these environment variables must be base URLs of the form <code>[scheme]://[host]:[port]</code>. URLs should not include a path component. For example:</p>
    <pre><code>- name: "SCHEDULER_ENDPOINT_URL"
  value: "https://localhost:10259"
- name: "ETCD_ENDPOINT_URL"
  value: "https://localhost:9979"
- name: "CONTROLLER_MANAGER_ENDPOINT_URL"
  value: "https://localhost:10257"
- name: "API_SERVER_ENDPOINT_URL"
  value: "https://localhost:6443"

</code></pre>The `/metrics` path segment is added automatically. In addition, if the `https` scheme is used, authentication to the control plane component pod(s) is accomplished via service accounts.
    &#x3C;Callout variant="caution">
    If a FQDN (fully qualified domain name) is used in a multi-master cluster, inconsistent results may be returned. Therefore, it is recommended to use `localhost` only.
    &#x3C;/Callout>
    &#x3C;Callout variant="important">
    Even though a custom base URL is defined for a given control plane component, the control plane component pod(s) must contain one of [the labels supported by the auto-discovery process](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#discover-nodes-components).
    &#x3C;/Callout>
    &#x3C;Callout variant="important">
    Even though a custom `ETCD_ENDPOINT_URL` can be defined, ETCD will always require `https` and [mTLS authentication to be configured](https://docs.newrelic.com/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring#mtls-how-to).
    &#x3C;/Callout>
  </div>
</div>
<p>Here are some additional configurations to consider:</p>
<ul>
  <li><a href="/docs/integrations/kubernetes-integration/installation/configure-control-plane-monitoring">Do more configuration for control plane monitoring</a></li>
  <li><a href="/docs/integrations/kubernetes-integration/link-your-applications/link-your-applications-kubernetes">Link New Relic APM to the Kubernetes integration</a></li>
  <li><a href="/docs/integrations/kubernetes-integration/installation/kubernetes-installation-configuration#monitor-services">Monitor services that run on Kubernetes</a></li>
</ul>
<h2>Update to the latest version [#update]</h2>
<div data-component="Callout" data-prop="W3sidHlwZSI6Im1keEF0dHJpYnV0ZSIsIm5hbWUiOiJ2YXJpYW50IiwidmFsdWUiOiJpbXBvcnRhbnQifV0=">
  <p>To improve our unified experience, starting from Wednesday, August 12, 2020, Kubernetes integrations that use v1.7 or older will be deprecated. If you are using v1.7 or older, you will need to update your integration in order to continue viewing Kubernetes performance data. For more information, see the <a href="/docs/release-notes/platform-release-notes/kubernetes-integration-release-notes/deprecation-notice-kubernetes-v17-or-lower">Kubernetes v1.7 or older deprecation notice</a>.</p>
</div>
<p>If you are already running the Kubernetes integration and want to update the <code>newrelic-infra</code> agent to the <a href="#logs-versions">latest agent version</a>:</p>
<ol>
  <li>
    <p>Run this <a href="/docs/insights/nrql-new-relic-query-language/using-nrql/introduction-nrql">NRQL query</a> to check which version you are currently running (this will return the image name by cluster):</p>
    <pre><code>SELECT latest(containerImage)  FROM K8sContainerSample 
WHERE containerImage LIKE '%newrelic/infrastructure%' FACET clusterName SINCE 1 day ago
</code></pre>
    <p>If you've set a name other than <code>newrelic/infrastructure</code> for the integration's container image, the above query won't yield results: to make it work, edit the name in the query.</p>
  </li>
  <li>
    <p>Download the integration manifest file:</p>
    <pre><code>curl -O https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/newrelic-infrastructure-k8s-latest.yaml
</code></pre>
  </li>
  <li>
    <p>Copy the changes you made to the manifest. At a minimum, include <code>CLUSTER_NAME</code> and <code>NRIA_LICENSE_KEY</code>, and paste your changes in the manifest you downloaded.</p>
  </li>
  <li>
    <p>Install the latest <code>DaemonSet</code> with the following command (Kubernetes will automatically do a rollout upgrade for the integration's pods):</p>
    <pre><code>kubectl apply -f newrelic-infrastructure-k8s-latest.yaml
</code></pre>
  </li>
</ol>
<h2>Uninstall the Kubernetes integration [#uninstall]</h2>
<p>To uninstall the Kubernetes integration:</p>
<ol>
  <li>
    <p>Verify that <code>newrelic-infrastructure-k8s-latest.yaml</code> corresponds to the filename of the manifest as you have saved it.</p>
    <p><strong>Example:</strong> If you are using the unprivileged version of the integration, the default filename will be <code>newrelic-infrastructure-k8s-unprivileged-latest.yaml</code>.</p>
  </li>
  <li>
    <p>After you verify the filename, use the following command:</p>
    <pre><code>kubectl delete -f newrelic-infrastructure-k8s-latest.yaml
</code></pre>
  </li>
</ol>
<p>You only need to execute this command once, regardless of the number of nodes in your cluster.</p>
